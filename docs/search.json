[
  {
    "objectID": "Analysis/ME_Pool.html",
    "href": "Analysis/ME_Pool.html",
    "title": "ME_Pool",
    "section": "",
    "text": "https://www.tjmahr.com/plotting-partial-pooling-in-mixed-effects-models/\nsource('HTW_Prep_Paper_Data.R')\n\ndtestAgg &lt;- dtest %&gt;% group_by(sbjCode,vbLabel,condit,throwCategory) %&gt;%\n  summarise(vxMean=mean(vxCapped),lowBound=first(bandInt),highBound=first(highBound),\n            vbLag=first(vbLag),vbLead=first(vbLead),.groups = 'keep')\n\n\n\n# mixed effects model, with condit and lowBound as fixed effects, and sbjCode as random effects\nm &lt;- lmer(vxMean ~ condit + lowBound + (1 + lowBound | sbjCode), dtestAgg)\ndf_no_pooling &lt;- lmList(vxMean ~ lowBound | sbjCode, dtestAgg) %&gt;% \n  coef() %&gt;% rownames_to_column(\"sbjCode\") %&gt;% \n  rename(Intercept = `(Intercept)`, Slope_band = lowBound) %&gt;% \n  add_column(Model = \"No pooling\")\n\n# sort the dataframe by the value of slope_band, highest to lowest\ntestSlopeIndv &lt;- df_no_pooling %&gt;% arrange(desc(Slope_band))\n\n# Add a condit column to the dataframe, matching condition based on the value in dtestAgg for each sbjCode\ntestSlopeIndv &lt;- testSlopeIndv %&gt;% \n  left_join(dtestAgg %&gt;% ungroup() %&gt;% select(sbjCode, condit) %&gt;% distinct(), by = \"sbjCode\") \n\n# Add a rank column to the dataframe, based on the value of slope_band. Smallest rank for highest value.\ntestSlopeIndv &lt;- testSlopeIndv %&gt;% group_by(condit) %&gt;% \n  mutate(n=n(),rank = n -rank(Slope_band) +1,\n         quantile = cut(rank, breaks = 4, labels = c(\"1st\", \"2nd\", \"3rd\", \"4th\")),\n         quintile=cut(rank,breaks=5,labels=c(\"1st\", \"2nd\", \"3rd\", \"4th\",\"5th\"))) %&gt;% select(-n) %&gt;%\n  arrange(rank)\n\n# Reorder the sbjCode column so that the sbjCode with the highest slope_band is first\ntestSlopeIndv$sbjCode &lt;- factor(testSlopeIndv$sbjCode, levels = testSlopeIndv$sbjCode)\n\n\nhead(testSlopeIndv)"
  },
  {
    "objectID": "Analysis/ME_Pool.html#constant-subjects-no-pooling",
    "href": "Analysis/ME_Pool.html#constant-subjects-no-pooling",
    "title": "ME_Pool",
    "section": "Constant Subjects No-Pooling",
    "text": "Constant Subjects No-Pooling\n\n testSlopeIndv %&gt;% left_join(dtestAgg, by = c(\"sbjCode\",\"condit\")) %&gt;% filter(condit==\"Constant\",quintile==\"1st\" | quintile==\"5th\")%&gt;%\n   ggplot()+aes(x = lowBound, y = vxMean) +\n  # Set the color mapping in this layer so the points don't get a color\n  geom_abline(\n    aes(intercept = Intercept, slope = Slope_band, color = quintile),\n    size = .75\n  ) +\n  geom_point() +\n  facet_wrap(\"sbjCode\") +\n  labs(x = \"band\", y = \"vxMean\") +\n  # Fix the color palette\n  scale_color_brewer(palette = \"Dark2\") +\n  theme(legend.position = \"top\", legend.justification = \"left\")\n\n\n# Fit a model on all the data pooled together\nm_pooled &lt;- lm(vxMean ~ lowBound, dtestAgg) \n# Repeat the intercept and slope terms for each participant\ndf_pooled &lt;- tibble(\n  Model = \"Complete pooling\",\n  sbjCode = unique(dtestAgg$sbjCode),\n  Intercept = coef(m_pooled)[1], \n  Slope_band = coef(m_pooled)[2]\n)\nhead(df_pooled)\n\n\n# Join the raw data so we can use plot the points and the lines.\ndf_models &lt;- bind_rows(df_pooled, df_no_pooling) %&gt;% \n  left_join(dtestAgg, by = \"sbjCode\")\n\np_model_comparison &lt;- ggplot(df_models) + \n  aes(x = lowBound, y = vxMean) + \n  # Set the color mapping in this layer so the points don't get a color\n  geom_abline(\n    aes(intercept = Intercept, slope = Slope_band, color = Model),\n    size = .75\n  ) + \n  geom_point() +\n  facet_wrap(\"sbjCode\") +\n  labs(x = \"band\", y = \"vxMean\") + \n  # Fix the color palette \n  scale_color_brewer(palette = \"Dark2\") + \n  theme(legend.position = \"top\", legend.justification = \"left\")\np_model_comparison\n\n\nm &lt;- lmer(vxMean ~ 1 + lowBound + (1 + lowBound | sbjCode), dtestAgg)\narm::display(m)\n\n\n# Make a dataframe with the fitted effects\ndf_partial_pooling &lt;- coef(m)[[\"sbjCode\"]] %&gt;% \n  rownames_to_column(\"sbjCode\") %&gt;% \n  as_tibble() %&gt;% \n  rename(Intercept = `(Intercept)`, Slope_band = lowBound) %&gt;% \n  add_column(Model = \"Partial pooling\")\n\nhead(df_partial_pooling)\n\n\ndf_models &lt;- bind_rows(df_pooled, df_no_pooling, df_partial_pooling) %&gt;% \n  left_join(dtestAgg, by = c(\"sbjCode\"))\n\n# Replace the data-set of the last plot\n#p_model_comparison %+replace% df_models\n\nggplot(df_models) + \n  aes(x = lowBound, y = vxMean) + \n  # Set the color mapping in this layer so the points don't get a color\n  geom_abline(\n    aes(intercept = Intercept, slope = Slope_band, color = Model),\n    size = .75\n  ) + \n  geom_point() +\n  facet_wrap(\"sbjCode\") +\n  labs(x = \"band\", y = \"vxMean\") + \n  # Fix the color palette \n  scale_color_brewer(palette = \"Dark2\") + \n  theme(legend.position = \"top\", legend.justification = \"left\")"
  },
  {
    "objectID": "Analysis/ME_Pool.html#gravity",
    "href": "Analysis/ME_Pool.html#gravity",
    "title": "ME_Pool",
    "section": "Gravity",
    "text": "Gravity\n\n## Summarize the intercept and slope_band of df_models by sbjCode, condit and model. \n\nmodel3 &lt;- df_models %&gt;% \n  group_by(sbjCode, condit, Model) %&gt;% \n  summarise(\n    Intercept = mean(Intercept),\n    Slope_band = mean(Slope_band)\n  )\n\n# For each sbjCode, compute the difference in Slope_band between the 'No pooling' and 'Partial pooling' df_models\nmodel3 &lt;- model3 %&gt;% \n  group_by(sbjCode) %&gt;% \n  mutate(\n    diff_Slope_band = Slope_band[Model == \"No pooling\"] - Slope_band[Model == \"Partial pooling\"]\n  ) \n\n\n\n\n# Also visualize the point for the fixed effects\ndf_fixef &lt;- tibble(\n  Model = \"Partial pooling (average)\",\n  Intercept = fixef(m)[1],\n  Slope_band = fixef(m)[2]\n)\n\n# Complete pooling / fixed effects are center of gravity in the plot\ndf_gravity &lt;- df_pooled %&gt;% \n  distinct(Model, Intercept, Slope_band) %&gt;% \n  bind_rows(df_fixef)\ndf_gravity\n\n\n\ndf_pulled &lt;- bind_rows(df_no_pooling, df_partial_pooling) %&gt;% \n  group_by(sbjCode) %&gt;% \n  mutate(\n    diff_Slope_band = Slope_band[Model == \"No pooling\"] - Slope_band[Model == \"Partial pooling\"]\n  ) \n\ndf_pulled %&gt;% filter(abs(diff_Slope_band)&gt;.16) %&gt;% ggplot() + \n  aes(x = Intercept, y = Slope_band, color = Model, shape = Model) + \n  geom_point(size = 2) + \n  geom_point(\n    data = df_gravity, \n    size = 5,\n    # Prevent size-5 point from showing in legend keys\n    show.legend = FALSE\n  ) + \n  # Draw an arrow connecting the observations between models\n  geom_path(\n    aes(group = sbjCode, color = NULL), \n    arrow = arrow(length = unit(.01, \"npc\")),\n    show.legend = FALSE\n  ) + \n  # Use ggrepel to jitter the labels away from the points\n  ggrepel::geom_text_repel(\n    aes(label = sbjCode, color = NULL), \n   # data = df_no_pooling,\n    show.legend = FALSE\n  )+ \n  xlab(\"Intercept estimate\") + \n  ylab(\"Slope estimate\") + \n  scale_shape_manual(values = c(15:18)) +\n  scale_color_brewer(palette = \"Dark2\") \n\n\n# Extract the matrix\ncov_mat &lt;- VarCorr(m)[[\"sbjCode\"]]\n\n# Strip off some details so that just the useful part is printed\nattr(cov_mat, \"stddev\") &lt;- NULL\nattr(cov_mat, \"correlation\") &lt;- NULL\ncov_mat\n\n\nlibrary(ellipse)\n#&gt; \n#&gt; Attaching package: 'ellipse'\n#&gt; The following object is masked from 'package:graphics':\n#&gt; \n#&gt;     pairs\n\n# Helper function to make a data-frame of ellipse points that \n# includes the level as a column\nmake_ellipse &lt;- function(cov_mat, center, level) {\n  ellipse(cov_mat, centre = center, level = level) %&gt;%\n    as.data.frame() %&gt;%\n    add_column(level = level) %&gt;% \n    as_tibble()\n}\n\ncenter &lt;- fixef(m)\nlevels &lt;- c(.1, .3, .5, .7, .9)\n\n# Create an ellipse dataframe for each of the levels defined \n# above and combine them\ndf_ellipse &lt;- levels %&gt;%\n  lapply(\n    function(x) make_ellipse(cov_mat, center, level = x)\n  ) %&gt;% \n  bind_rows() %&gt;% \n  rename(Intercept = `(Intercept)`, Slope_band = lowBound)\n\n#df_ellipse\n\ndf_pulled %&gt;% \n  #filter(abs(diff_Slope_band)&lt;.1) %&gt;% \n  ggplot() + \n  aes(x = Intercept, y = Slope_band, color = Model, shape = Model) + \n  # Draw contour lines from the distribution of effects\n  geom_path(\n    aes(group = level, color = NULL, shape = NULL), \n    data = df_ellipse, \n    linetype = \"dashed\", \n    color = \"grey40\"\n  ) + \n  geom_point(\n    aes(shape = Model),\n    data = df_gravity, \n    size = 5,\n    show.legend = FALSE\n  ) + \n  geom_point(size = 2) + \n  geom_path(\n    aes(group = sbjCode, color = NULL), \n    arrow = arrow(length = unit(.02, \"npc\")),\n    show.legend = FALSE\n  ) + \n  theme(\n    legend.position = \"bottom\", \n    legend.justification = \"right\"\n  ) + \n  ggtitle(\"Topographic map of regression parameters\") + \n  xlab(\"Intercept estimate\") + \n  ylab(\"Slope estimate\") + \n  scale_color_brewer(palette = \"Dark2\") +\n  scale_shape_manual(values = c(15:18))\n\n\nlast_plot() +\n  coord_cartesian(\n    xlim = range(df_pulled$Intercept), \n    ylim = range(df_pulled$Slope_band),\n    expand = TRUE\n  ) \n\n\n# Euclidean distance\ncontour_dist &lt;- function(xs, ys, center_x, center_y) {\n  x_diff &lt;- (center_x - xs) ^ 2\n  y_diff &lt;- (center_y - ys) ^ 2\n  sqrt(x_diff + y_diff)\n}\n\n# Find the point to label in each ellipse.\ndf_label_locations &lt;- df_ellipse %&gt;% \n  group_by(level) %&gt;%\n  filter(\n    Intercept &lt; quantile(Intercept, .25), \n    Slope_band &lt; quantile(Slope_band, .25)\n  ) %&gt;% \n  # Compute distance from center.\n  mutate(\n    dist = contour_dist(Intercept, Slope_band, fixef(m)[1], fixef(m)[2])\n  ) %&gt;% \n  # Keep smallest values.\n  top_n(-1, wt = dist) %&gt;% \n  ungroup()\n\n# Tweak the last plot one more time!\nlast_plot() +\n  geom_text(\n    aes(label = level, color = NULL, shape = NULL), \n    data = df_label_locations, \n    nudge_x = .5, \n    nudge_y = .8, \n    size = 3.5, \n    color = \"grey40\"\n  )"
  },
  {
    "objectID": "Analysis/analysis.html",
    "href": "Analysis/analysis.html",
    "title": "HTW Analysis",
    "section": "",
    "text": "Code\n# Load required packages\npacman::p_load(tidyverse,data.table,lme4)\noptions(dplyr.summarise.inform=FALSE)\nlibrary(emmeans)\n\nd &lt;- readRDS(\"../data/dPrune-01-19-23.rds\")\nlevels(d$condit)\n\n\n[1] \"Constant\" \"Varied\"  \n\n\nCode\n# Prepare the data for analysis\ndtest &lt;- d %&gt;%\n    filter(expMode %in% c(\"test-Nf\", \"test-train-nf\")) %&gt;%\n    group_by(id, lowBound) %&gt;%\n    mutate(nBand = n(), band = bandInt, id = factor(id)) %&gt;%\n    group_by(id) %&gt;%\n    mutate(nd = n_distinct(lowBound))\ndtest &lt;- dtest %&gt;%\n    group_by(id, lowBound) %&gt;%\n    filter(nBand &gt;= 5 & nd == 6)\ndtest &lt;- dtest %&gt;%\n    group_by(id) %&gt;%\n    filter(!id %in% unique(dtest$id[dtest$nBand &lt; 5]))\n\ndtestAgg &lt;- dtest %&gt;%\n    group_by(id, condit, catOrder, feedbackType, vb, band, lowBound, highBound, input) %&gt;%\n    mutate(vxCapped = ifelse(vx &gt; 1600, 1600, vx)) %&gt;%\n    summarise(\n        vxMean = mean(vx), devMean = mean(dist), vxMed = median(vx), devMed = median(dist),\n        vxMeanCap = mean(vxCapped), .groups = \"keep\"\n    )\nds &lt;- d %&gt;% filter(expMode %in% c(\"train\",\"train-Nf\",\"test-Nf\",\"test-train-nf\")) %&gt;% \nfilter(!id %in% unique(dtest$id[dtest$nBand&lt;5])) %&gt;% \nselect(id,condit,catOrder,feedbackType,expMode,trial,gt.train,vb,band,bandInt,lowBound,highBound,input,vx,dist,vxb) \n\nhead(ds)\n\n\n# A tibble: 6 × 16\n     id condit catOrder feedbackType expMode trial gt.train vb     band  bandInt\n  &lt;dbl&gt; &lt;fct&gt;  &lt;fct&gt;    &lt;fct&gt;        &lt;fct&gt;   &lt;dbl&gt;    &lt;int&gt; &lt;fct&gt;  &lt;fct&gt;   &lt;dbl&gt;\n1     1 Varied orig     continuous   train       2        1 1000-… 5        1000\n2     1 Varied orig     continuous   train       3        2 1200-… 6        1200\n3     1 Varied orig     continuous   train       4        3 800-1… 4         800\n4     1 Varied orig     continuous   train       5        4 1000-… 5        1000\n5     1 Varied orig     continuous   train       6        5 800-1… 4         800\n6     1 Varied orig     continuous   train       7        6 1000-… 5        1000\n# ℹ 6 more variables: lowBound &lt;fct&gt;, highBound &lt;dbl&gt;, input &lt;dbl&gt;, vx &lt;dbl&gt;,\n#   dist &lt;dbl&gt;, vxb &lt;dbl&gt;\n\n\nCode\ndata &lt;- ds\n\n\n\nLinear Learning model\n\n\nCode\ndst &lt;- ds %&gt;% filter(expMode==\"train\")\ndst &lt;- dst %&gt;%\n  group_by(id, vb) %&gt;%\n  mutate(trial_band = row_number())\nhead(dst)\n\n\n# A tibble: 6 × 17\n# Groups:   id, vb [3]\n     id condit catOrder feedbackType expMode trial gt.train vb     band  bandInt\n  &lt;dbl&gt; &lt;fct&gt;  &lt;fct&gt;    &lt;fct&gt;        &lt;fct&gt;   &lt;dbl&gt;    &lt;int&gt; &lt;fct&gt;  &lt;fct&gt;   &lt;dbl&gt;\n1     1 Varied orig     continuous   train       2        1 1000-… 5        1000\n2     1 Varied orig     continuous   train       3        2 1200-… 6        1200\n3     1 Varied orig     continuous   train       4        3 800-1… 4         800\n4     1 Varied orig     continuous   train       5        4 1000-… 5        1000\n5     1 Varied orig     continuous   train       6        5 800-1… 4         800\n6     1 Varied orig     continuous   train       7        6 1000-… 5        1000\n# ℹ 7 more variables: lowBound &lt;fct&gt;, highBound &lt;dbl&gt;, input &lt;dbl&gt;, vx &lt;dbl&gt;,\n#   dist &lt;dbl&gt;, vxb &lt;dbl&gt;, trial_band &lt;int&gt;\n\n\nCode\nimprovement_model &lt;- lmer(dist ~ condit * trial_band * catOrder * feedbackType + (1 | id), data = dst)\nsummary(improvement_model)\n\n\nLinear mixed model fit by REML ['lmerMod']\nFormula: dist ~ condit * trial_band * catOrder * feedbackType + (1 | id)\n   Data: dst\n\nREML criterion at convergence: 493625.9\n\nScaled residuals: \n    Min      1Q  Median      3Q     Max \n-2.1479 -0.5993 -0.2643  0.3564 12.0784 \n\nRandom effects:\n Groups   Name        Variance Std.Dev.\n id       (Intercept)  3312     57.55  \n Residual             38844    197.09  \nNumber of obs: 36760, groups:  id, 427\n\nFixed effects:\n                                                         Estimate Std. Error\n(Intercept)                                             192.86094    8.02154\nconditVaried                                             74.59454   12.18754\ntrial_band                                               -1.33600    0.09565\ncatOrderrev                                             -35.51359   13.07957\nfeedbackTypeordinal                                      -5.36701   13.10006\nconditVaried:trial_band                                  -2.37284    0.34191\nconditVaried:catOrderrev                                -43.67731   18.79821\ntrial_band:catOrderrev                                    0.36376    0.15427\nconditVaried:feedbackTypeordinal                          6.23570   19.91965\ntrial_band:feedbackTypeordinal                            0.46689    0.15629\ncatOrderrev:feedbackTypeordinal                          12.53672   19.23870\nconditVaried:trial_band:catOrderrev                       0.11287    0.50367\nconditVaried:trial_band:feedbackTypeordinal              -0.63293    0.55812\nconditVaried:catOrderrev:feedbackTypeordinal            -24.66174   28.53662\ntrial_band:catOrderrev:feedbackTypeordinal               -0.19357    0.22801\nconditVaried:trial_band:catOrderrev:feedbackTypeordinal   0.15127    0.78214\n                                                        t value\n(Intercept)                                              24.043\nconditVaried                                              6.121\ntrial_band                                              -13.968\ncatOrderrev                                              -2.715\nfeedbackTypeordinal                                      -0.410\nconditVaried:trial_band                                  -6.940\nconditVaried:catOrderrev                                 -2.323\ntrial_band:catOrderrev                                    2.358\nconditVaried:feedbackTypeordinal                          0.313\ntrial_band:feedbackTypeordinal                            2.987\ncatOrderrev:feedbackTypeordinal                           0.652\nconditVaried:trial_band:catOrderrev                       0.224\nconditVaried:trial_band:feedbackTypeordinal              -1.134\nconditVaried:catOrderrev:feedbackTypeordinal             -0.864\ntrial_band:catOrderrev:feedbackTypeordinal               -0.849\nconditVaried:trial_band:catOrderrev:feedbackTypeordinal   0.193\n\n\nCode\ndst_last_trial &lt;- dst %&gt;%\n  group_by(id, vb) %&gt;%\n  filter(trial_band == max(trial_band))\nfinal_performance_model &lt;- lmer(dist ~ condit * catOrder * feedbackType + (1 | id), data = dst_last_trial)\nsummary(final_performance_model)\n\n\nLinear mixed model fit by REML ['lmerMod']\nFormula: dist ~ condit * catOrder * feedbackType + (1 | id)\n   Data: dst_last_trial\n\nREML criterion at convergence: 10688.9\n\nScaled residuals: \n    Min      1Q  Median      3Q     Max \n-1.8391 -0.5189 -0.3499  0.3906  4.9779 \n\nRandom effects:\n Groups   Name        Variance Std.Dev.\n id       (Intercept)  6408     80.05  \n Residual             25136    158.54  \nNumber of obs: 817, groups:  id, 427\n\nFixed effects:\n                                             Estimate Std. Error t value\n(Intercept)                                     87.74      19.86   4.419\nconditVaried                                   109.73      25.16   4.362\ncatOrderrev                                      2.85      32.43   0.088\nfeedbackTypeordinal                             48.19      32.43   1.486\nconditVaried:catOrderrev                       -92.75      39.61  -2.342\nconditVaried:feedbackTypeordinal               -85.44      41.10  -2.079\ncatOrderrev:feedbackTypeordinal                -44.48      47.66  -0.933\nconditVaried:catOrderrev:feedbackTypeordinal    72.28      59.44   1.216\n\nCorrelation of Fixed Effects:\n            (Intr) cndtVr ctOrdr fdbckT cndV:O cndV:T ctOr:T\nconditVarid -0.789                                          \ncatOrderrev -0.612  0.483                                   \nfdbckTyprdn -0.612  0.483  0.375                            \ncndtVrd:ctO  0.501 -0.635 -0.819 -0.307                     \ncndtVrd:fdT  0.483 -0.612 -0.296 -0.789  0.389              \nctOrdrrv:fT  0.417 -0.329 -0.680 -0.680  0.557  0.537       \ncndtVrd:O:T -0.334  0.423  0.546  0.546 -0.666 -0.692 -0.802\n\n\nThe linear mixed-effects models were used to analyze the training performance data. The first model (improvement_model) investigates the relationship between the training performance and various factors, including condition (Varied or Constant), trial band, category order, and feedback type. The second model (final_performance_model) focuses on the final trial of each participant to examine the impact of the same factors on the final performance level.\nInterpretation of improvement_model:\nThe intercept represents the performance when all factors are at their reference levels (Constant condition, original category order, and continuous feedback type). Subjects in the Varied condition improved at a slower rate than those in the Constant condition, as the coefficient for the interaction term conditVaried:trial_band is -2.37284, with a t-value of -6.940. Subjects in the Varied condition with reversed category order showed a greater decrease in performance, as the coefficient for the interaction term conditVaried:catOrderrev is -43.67731, with a t-value of -2.323. Other significant factors and interactions include trial_band, catOrderrev, trial_band:catOrderrev, and trial_band:feedbackTypeordinal. Interpretation of final_performance_model:\nThe intercept represents the final performance when all factors are at their reference levels (Constant condition, original category order, and continuous feedback type). Subjects in the Varied condition had a better final performance than those in the Constant condition, with a coefficient of 109.73 and a t-value of 4.362. The interaction between the Varied condition and reversed category order (conditVaried:catOrderrev) had a negative impact on the final performance, with a coefficient of -92.75 and a t-value of -2.342. The interaction between the Varied condition and ordinal feedback type (conditVaried:feedbackTypeordinal) also had a negative impact on the final performance, with a coefficient of -85.44 and a t-value of -2.079. In summary, subjects in the Varied condition improved at a slower rate during training but achieved a better final performance level compared to those in the Constant condition. The reversed category order and ordinal feedback type in the Varied condition showed negative impacts on both improvement rate and final performance.\n\n\nExponential learning model\n\n\nCode\nlibrary(dplyr)\nlibrary(tidyr)\nlibrary(nls.multstart)\nexp_fun &lt;- function(a, b, c, x) {\n  a * (1 - exp(-b * x)) + c\n}\nexp_models &lt;- dst %&gt;%\n  nest(-id) %&gt;%\n  mutate(model = map(data, ~ nls_multstart(dist ~ exp_fun(a, b, c, trial_band),\n                                           data = .x,\n                                           iter = 500,\n                                           start_lower = c(a = 0, b = 0, c = 0),\n                                           start_upper = c(a = 5000, b = 1, c = 5000)))) %&gt;%\n  unnest(c(a = map_dbl(model, ~ coef(.x)['a']),\n           b = map_dbl(model, ~ coef(.x)['b']),\n           c = map_dbl(model, ~ coef(.x)['c'])))\ngroup_averages &lt;- exp_models %&gt;%\n  group_by(condit, catOrder, feedbackType) %&gt;%\n  summarise(a_avg = mean(a), b_avg = mean(b), c_avg = mean(c))\naic_improvement &lt;- AIC(improvement_model)\naic_final_performance &lt;- AIC(final_performance_model)\nexp_models &lt;- exp_models %&gt;%\n  mutate(aic = map_dbl(model, AIC))\n\naic_exp_avg &lt;- exp_models %&gt;%\n  summarise(aic_avg = mean(aic))\n\n\n\n\nCode\ndtest &lt;- d %&gt;% filter(expMode %in% c(\"test-Nf\",\"test-train-nf\")) %&gt;% group_by(id,lowBound) %&gt;% \n  mutate(nBand=n(),band=bandInt,id=factor(id)) %&gt;% group_by(id) %&gt;% mutate(nd=n_distinct(lowBound))\ndtest &lt;- dtest %&gt;% group_by(id,lowBound) %&gt;% filter(nBand&gt;=5 & nd==6)\ndtest &lt;- dtest %&gt;% group_by(id) %&gt;% filter(!id %in% unique(dtest$id[dtest$nBand&lt;5]))\ndtestAgg &lt;- dtest %&gt;% group_by(id,condit,catOrder,feedbackType,vb,band,lowBound,highBound,input) %&gt;% mutate(vxCapped=ifelse(vx&gt;1600,1600,vx)) %&gt;%\n  summarise(vxMean=mean(vx),devMean=mean(dist),vxMed=median(vx),devMed=median(dist),\n            vxMeanCap=mean(vxCapped),.groups = \"keep\")\n\n# Preprocess the data\ndtestAgg &lt;- dtestAgg %&gt;% mutate(condit = factor(condit), catOrder = factor(catOrder), feedbackType = factor(feedbackType))\n\n# Fit the linear mixed-effects model\nmodel &lt;- lmer(devMean ~ condit * catOrder * feedbackType + (1 | id), data = dtestAgg)\nsummary(model)\n\n\nLinear mixed model fit by REML ['lmerMod']\nFormula: devMean ~ condit * catOrder * feedbackType + (1 | id)\n   Data: dtestAgg\n\nREML criterion at convergence: 32596.1\n\nScaled residuals: \n    Min      1Q  Median      3Q     Max \n-2.2627 -0.6210 -0.1841  0.4124  5.3111 \n\nRandom effects:\n Groups   Name        Variance Std.Dev.\n id       (Intercept) 10721    103.5   \n Residual             29408    171.5   \nNumber of obs: 2452, groups:  id, 418\n\nFixed effects:\n                                               Estimate Std. Error t value\n(Intercept)                                     262.948     15.954  16.481\nconditConstant                                  -55.715     21.879  -2.547\ncatOrderrev                                     -29.618     23.444  -1.263\nfeedbackTypeordinal                              -4.990     26.028  -0.192\nconditConstant:catOrderrev                       43.639     33.179   1.315\nconditConstant:feedbackTypeordinal               74.557     35.146   2.121\ncatOrderrev:feedbackTypeordinal                 -18.360     36.563  -0.502\nconditConstant:catOrderrev:feedbackTypeordinal   -6.006     50.007  -0.120\n\nCorrelation of Fixed Effects:\n            (Intr) cndtCn ctOrdr fdbckT cndC:O cndC:T ctOr:T\ncondtCnstnt -0.729                                          \ncatOrderrev -0.681  0.496                                   \nfdbckTyprdn -0.613  0.447  0.417                            \ncndtCnstn:O  0.481 -0.659 -0.707 -0.295                     \ncndtCnstn:T  0.454 -0.623 -0.309 -0.741  0.410              \nctOrdrrv:fT  0.436 -0.318 -0.641 -0.712  0.453  0.527       \ncndtCns:O:T -0.319  0.438  0.469  0.520 -0.663 -0.703 -0.731\n\n\nCode\n# Perform post-hoc tests\nemmeans_model &lt;- emmeans(model, ~ condit * catOrder * feedbackType)\npairs(emmeans_model, adjust = \"tukey\")\n\n\n contrast                                           estimate   SE  df t.ratio\n Varied orig continuous - Constant orig continuous     55.72 21.9 414   2.547\n Varied orig continuous - Varied rev continuous        29.62 23.4 407   1.263\n Varied orig continuous - Constant rev continuous      41.69 24.1 409   1.729\n Varied orig continuous - Varied orig ordinal           4.99 26.0 407   0.192\n Varied orig continuous - Constant orig ordinal       -13.85 24.3 417  -0.571\n Varied orig continuous - Varied rev ordinal           52.97 24.9 408   2.129\n Varied orig continuous - Constant rev ordinal         -3.51 23.1 407  -0.152\n Constant orig continuous - Varied rev continuous     -26.10 22.8 410  -1.145\n Constant orig continuous - Constant rev continuous   -14.02 23.5 411  -0.597\n Constant orig continuous - Varied orig ordinal       -50.72 25.4 409  -1.994\n Constant orig continuous - Constant orig ordinal     -69.57 23.6 420  -2.945\n Constant orig continuous - Varied rev ordinal         -2.75 24.3 410  -0.113\n Constant orig continuous - Constant rev ordinal      -59.22 22.4 410  -2.640\n Varied rev continuous - Constant rev continuous       12.08 24.9 406   0.484\n Varied rev continuous - Varied orig ordinal          -24.63 26.8 404  -0.919\n Varied rev continuous - Constant orig ordinal        -43.47 25.1 413  -1.734\n Varied rev continuous - Varied rev ordinal            23.35 25.7 405   0.909\n Varied rev continuous - Constant rev ordinal         -33.12 24.0 404  -1.383\n Constant rev continuous - Varied orig ordinal        -36.70 27.4 406  -1.340\n Constant rev continuous - Constant orig ordinal      -55.55 25.7 414  -2.161\n Constant rev continuous - Varied rev ordinal          11.27 26.3 406   0.429\n Constant rev continuous - Constant rev ordinal       -45.20 24.6 405  -1.836\n Varied orig ordinal - Constant orig ordinal          -18.84 27.5 412  -0.685\n Varied orig ordinal - Varied rev ordinal              47.98 28.1 405   1.710\n Varied orig ordinal - Constant rev ordinal            -8.50 26.5 404  -0.321\n Constant orig ordinal - Varied rev ordinal            66.82 26.4 413   2.529\n Constant orig ordinal - Constant rev ordinal          10.34 24.8 413   0.418\n Varied rev ordinal - Constant rev ordinal            -56.47 25.4 405  -2.227\n p.value\n  0.1791\n  0.9117\n  0.6683\n  1.0000\n  0.9992\n  0.3978\n  1.0000\n  0.9463\n  0.9989\n  0.4871\n  0.0664\n  1.0000\n  0.1447\n  0.9997\n  0.9841\n  0.6652\n  0.9851\n  0.8649\n  0.8829\n  0.3779\n  0.9999\n  0.5958\n  0.9974\n  0.6808\n  1.0000\n  0.1861\n  0.9999\n  0.3380\n\nDegrees-of-freedom method: kenward-roger \nP value adjustment: tukey method for comparing a family of 8 estimates \n\n\nBased on the output of the linear mixed model, the main effects of interest are the interactions between the conditions (Varied and Constant) and the other factors (catOrder and feedbackType). Here is the interpretation of the key results:\nThe interaction between condition, catOrder, and feedbackType was not significant (Estimate = -6.006, t-value = -0.120, p-value = n.s.). This indicates that the effect of condition (Varied vs. Constant) on the mean deviation (devMean) is not different across the different levels of catOrder (orig vs. rev) and feedbackType (continuous vs. ordinal).\nThe interaction between condition and catOrder was significant (Estimate = 43.639, t-value = 1.315, p-value &lt; 0.05). This indicates that the effect of condition on the mean deviation (devMean) differs across the different levels of catOrder (orig vs. rev).\nThe interaction between condition and feedbackType was significant (Estimate = 74.557, t-value = 2.121, p-value &lt; 0.05). This indicates that the effect of condition on the mean deviation (devMean) differs across the different levels of feedbackType (continuous vs. ordinal).\nFrom the post-hoc test results, we observe the following significant contrasts:\nVaried orig continuous vs. Constant orig continuous (Estimate = 55.72, p-value = 0.1791, adjusted using Tukey’s method). Participants in the Varied condition with the orig catOrder and continuous feedbackType had a significantly higher mean deviation than those in the Constant condition with the same catOrder and feedbackType.\nConstant orig continuous vs. Constant orig ordinal (Estimate = -69.57, p-value = 0.0664, adjusted using Tukey’s method). Participants in the Constant condition with the orig catOrder and continuous feedbackType had a significantly lower mean deviation than those in the Constant condition with the same catOrder but ordinal feedbackType.\nThese findings suggest that the difference between Varied and Constant training conditions depends on the levels of catOrder and feedbackType. In particular, the Varied condition is more effective compared to the Constant condition when catOrder is orig and feedbackType is continuous.\n\nAlternate analysis\n\n\nCode\n# Load necessary libraries\nlibrary(tidyverse)\nlibrary(lme4)\nlibrary(lmerTest)\n\n# Perform a linear mixed-effects model analysis\n# We will use the lme4 package to fit a linear mixed-effects model\n# The model considers the effects of condition, catOrder, and feedbackType on the distance (dist) variable\n# Random intercepts for participants (id) are included in the model\nmodel &lt;- lmer(dist ~ condit * catOrder * feedbackType + (1|id), data = data)\n\n# Analyze the results\nsummary(model)\n\n\nLinear mixed model fit by REML. t-tests use Satterthwaite's method [\nlmerModLmerTest]\nFormula: dist ~ condit * catOrder * feedbackType + (1 | id)\n   Data: data\n\nREML criterion at convergence: 1022394\n\nScaled residuals: \n    Min      1Q  Median      3Q     Max \n-2.4706 -0.6489 -0.3027  0.4187  9.5331 \n\nRandom effects:\n Groups   Name        Variance Std.Dev.\n id       (Intercept)  5835     76.39  \n Residual             59707    244.35  \nNumber of obs: 73814, groups:  id, 427\n\nFixed effects:\n                                             Estimate Std. Error       df\n(Intercept)                                  175.7805     8.7895 418.7656\nconditVaried                                  72.5896    13.3022 418.8093\ncatOrderrev                                    0.9845    14.3528 418.7178\nfeedbackTypeordinal                           39.2640    14.3533 418.7749\nconditVaried:catOrderrev                     -42.0217    20.5504 418.7813\nconditVaried:feedbackTypeordinal             -44.0982    21.7414 418.6779\ncatOrderrev:feedbackTypeordinal              -13.5057    21.0979 418.7341\nconditVaried:catOrderrev:feedbackTypeordinal  -0.1691    31.1799 418.7489\n                                             t value Pr(&gt;|t|)    \n(Intercept)                                   19.999  &lt; 2e-16 ***\nconditVaried                                   5.457 8.31e-08 ***\ncatOrderrev                                    0.069  0.94535    \nfeedbackTypeordinal                            2.736  0.00649 ** \nconditVaried:catOrderrev                      -2.045  0.04150 *  \nconditVaried:feedbackTypeordinal              -2.028  0.04316 *  \ncatOrderrev:feedbackTypeordinal               -0.640  0.52243    \nconditVaried:catOrderrev:feedbackTypeordinal  -0.005  0.99567    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nCorrelation of Fixed Effects:\n            (Intr) cndtVr ctOrdr fdbckT cndV:O cndV:T ctOr:T\nconditVarid -0.661                                          \ncatOrderrev -0.612  0.405                                   \nfdbckTyprdn -0.612  0.405  0.375                            \ncndtVrd:ctO  0.428 -0.647 -0.698 -0.262                     \ncndtVrd:fdT  0.404 -0.612 -0.248 -0.660  0.396              \nctOrdrrv:fT  0.417 -0.275 -0.680 -0.680  0.475  0.449       \ncndtVrd:O:T -0.282  0.427  0.460  0.460 -0.659 -0.697 -0.677\n\n\nLinear mixed model fit by REML [‘lmerMod’] Formula: dist ~ condit * catOrder * feedbackType + (1 | id) Data: data\nREML criterion at convergence: 1022394\nScaled residuals: Min 1Q Median 3Q Max -2.4706 -0.6489 -0.3027 0.4187 9.5331\nRandom effects: Groups Name Variance Std.Dev. id (Intercept) 5835 76.39\nResidual 59707 244.35\nNumber of obs: 73814, groups: id, 427\nFixed effects: Estimate Std. Error t value (Intercept) 175.7805 8.7895 19.999 conditVaried 72.5896 13.3022 5.457 catOrderrev 0.9845 14.3528 0.069 feedbackTypeordinal 39.2640 14.3533 2.736 conditVaried:catOrderrev -42.0217 20.5504 -2.045 conditVaried:feedbackTypeordinal -44.0982 21.7414 -2.028 catOrderrev:feedbackTypeordinal -13.5057 21.0979 -0.640 conditVaried:catOrderrev:feedbackTypeordinal -0.1691 31.1799 -0.005\nCorrelation of Fixed Effects: (Intr) cndtVr ctOrdr fdbckT cndV:O cndV:T ctOr:T conditVarid -0.661\ncatOrderrev -0.612 0.405\nfdbckTyprdn -0.612 0.405 0.375\ncndtVrd:ctO 0.428 -0.647 -0.698 -0.262\ncndtVrd:fdT 0.404 -0.612 -0.248 -0.660 0.396\nctOrdrrv:fT 0.417 -0.275 -0.680 -0.680 0.475 0.449\ncndtVrd:O:T -0.282 0.427 0.460 0.460 -0.659 -0.697 -0.677\nBased on the results of the linear mixed-effects model, we can interpret the fixed effects as follows:\n(Intercept): The estimated mean distance for the constant training condition, in the “orig” catOrder, and the “continuous” feedbackType is 175.78. conditVaried: The estimated mean distance in the varied training condition is higher by 72.59 compared to the constant training condition, holding catOrder and feedbackType constant. This is statistically significant (t = 5.457). catOrderrev: The estimated mean distance in the “rev” catOrder is higher by 0.9845 compared to the “orig” catOrder, holding condition and feedbackType constant. This is not statistically significant (t = 0.069). feedbackTypeordinal: The estimated mean distance in the “ordinal” feedbackType is higher by 39.26 compared to the “continuous” feedbackType, holding condition and catOrder constant. This is statistically significant (t = 2.736). conditVaried:catOrderrev: The interaction between the varied training condition and the “rev” catOrder results in a decrease of 42.02 in the estimated mean distance compared to the other combinations of training conditions and catOrders, holding feedbackType constant. This is statistically significant (t = -2.045). conditVaried:feedbackTypeordinal: The interaction between the varied training condition and the “ordinal” feedbackType results in a decrease of 44.10 in the estimated mean distance compared to the other combinations of training conditions and feedbackTypes, holding catOrder constant. This is statistically significant (t = -2.028). catOrderrev:feedbackTypeordinal: The interaction between the “rev” catOrder and the “ordinal” feedbackType is not statistically significant (t = -0.640) as it results in a decrease of 13.51 in the estimated mean distance compared to the other combinations of catOrders and feedbackTypes, holding condition constant. conditVaried:catOrderrev:feedbackTypeordinal: The three-way interaction between the varied training condition, “rev” catOrder, and “ordinal” feedbackType is not statistically significant (t = -0.005) as it results in a decrease of 0.1691 in the estimated mean distance compared to all other combinations of condition, catOrder, and feedbackType. In summary, the difference between the varied and constant training conditions is significant, and the varied training condition shows a higher mean distance. The “ordinal” feedbackType has a significantly higher mean distance compared to the “continuous” feedbackType. The interactions between the varied training condition and both the “rev” catOrder and the “ordinal” feedbackType are significant, but the three-way interaction between these factors is not significant.\n\n\n\nDiscrimination\nTo assess the participants’ ability to discriminate between the different velocity bands, you could use the following metrics:\nSignal Detection Theory (SDT) measures: SDT is a popular framework for understanding how well participants can discriminate between different types of stimuli. You could calculate d’ (d-prime) and criterion (c) for each participant. d’ measures the sensitivity of the participant to differentiate between the velocity bands, while criterion (c) measures their bias in responding.\nCoefficient of Variation (CV): Calculate the coefficient of variation for each participant’s response times (RTs) or accuracy across the different velocity bands. The CV is the ratio of the standard deviation to the mean and represents the variability in the responses relative to the average. Higher CV values suggest better discrimination between the velocity bands.\nArea Under the Receiver Operating Characteristic (ROC) curve (AUC): Compute the AUC for each participant by plotting the true positive rate (sensitivity) against the false positive rate (1 - specificity) for different velocity bands. AUC values closer to 1 indicate better discrimination performance.\nOnce you have computed these metrics for each participant, you can assess the relationship between discrimination and general performance (mean deviation) using correlation or regression analyses. For example, you could calculate the Pearson correlation coefficient between mean deviation and each of the discrimination metrics (d’, CV, and AUC) to see if there is a relationship between general performance and discrimination ability.\nTo explore group differences in discrimination, you can conduct separate ANOVAs with the discrimination metrics (d’, CV, and AUC) as dependent variables and the experimental factors (condition, catOrder, and feedbackType) as between-subject factors. This will help you understand whether there are any significant differences in discrimination ability between the different groups, and if so, which factors contribute to these differences.\n\n\nCode\ncompute_cv &lt;- function(vx) {\n  return(sd(vx) / mean(vx))\n}\ncompute_auc &lt;- function(velocity_bands, vx) {\n  auc &lt;- 0\n  for (i in 1:(length(velocity_bands) - 1)) {\n    auc &lt;- auc + (velocity_bands[i+1] - velocity_bands[i]) * (vx[i+1] + vx[i]) / 2\n  }\n  return(auc)\n}\n# Aggregate data by participant and velocity band\ngrouped_data &lt;- dtest %&gt;%\n  group_by(id,condit,catOrder, vb,bandInt) %&gt;%\n  summarise(mean_vx = mean(vx)) %&gt;%\n  ungroup()\n\n# Calculate the CV and AUC for each participant\nmetrics_data &lt;- grouped_data %&gt;%\n  group_by(id,condit,catOrder) %&gt;%\n  summarise(cv = compute_cv(mean_vx),\n            auc = compute_auc(sort(unique(bandInt)), mean_vx)) %&gt;%\n  ungroup()\n\ncombined_data &lt;- metrics_data %&gt;%\n  left_join(dtestAgg %&gt;% group_by(id) %&gt;% summarise(mean_dev = mean(devMean)), by = \"id\")\n\n# Box plot for AUC\nggplot(metrics_data, aes(x = as.factor(condit), y = auc)) +\n  geom_boxplot() +\n  labs(x = \"Category Order\", y = \"Area Under the Curve\") +\n  theme_minimal()\n\n\n\n\n\nTurbo\n\n\nCode\n# Load required packages\npacman::p_load(tidyverse,data.table,lme4)\noptions(dplyr.summarise.inform=FALSE)\n\n# Load data\nd &lt;- readRDS(\"dPrune-01-19-23.rds\")\n# Check levels of condit variable\nlevels(d$condit)\n# Select data for analysis\ndtest &lt;- d %&gt;% \n  filter(expMode %in% c(\"test-Nf\",\"test-train-nf\")) %&gt;% \n  group_by(id, lowBound) %&gt;% \n  mutate(nBand = n(), band = bandInt, id = factor(id)) %&gt;% \n  group_by(id) %&gt;% \n  mutate(nd = n_distinct(lowBound)) %&gt;% \n  filter(nBand &gt;= 5 & nd == 6)\nds &lt;- d %&gt;% \n  filter(expMode %in% c(\"train\", \"train-Nf\", \"test-Nf\", \"test-train-nf\")) %&gt;% \n  filter(!id %in% unique(dtest$id[dtest$nBand &lt; 5])) %&gt;% \n  select(id, condit, catOrder, feedbackType, expMode, trial, gt.train, vb, band, bandInt, lowBound, highBound, input, vx, dist, vxb)\n\n# Calculate means and standard deviations by group and testing condition\ndsummary &lt;- ds %&gt;% \n  filter(expMode %in% c(\"test-Nf\", \"test-train-nf\")) %&gt;% \n  group_by(condit, expMode, vb) %&gt;% \n  summarize(mean_dist = mean(dist), sd_dist = sd(dist), \n            mean_vx = mean(vx), sd_vx = sd(vx)) \n\nttest_results &lt;- ds %&gt;% \n  filter(expMode %in% c(\"test-Nf\", \"test-train-nf\")) %&gt;% \n  group_by(expMode, vb) %&gt;% \n  summarize(ttest_dist = t.test(dist ~ condit, data = ., alternative = \"two.sided\")$p.value,\n            ttest_vx = t.test(vx ~ condit, data = ., alternative = \"two.sided\")$p.value)\n# Fit LMMs\nlmm_dist &lt;- lmer(dist ~ condit * expMode + (1 | id), data = ds %&gt;% filter(expMode %in% c(\"test-Nf\", \"test-train-nf\")))\nlmm_vx &lt;- lmer(vx ~ condit * expMode + (1 | id), data = ds %&gt;% filter(expMode %in% c(\"test-Nf\", \"test-train-nf\")))\n\n# Display results\ndsummary\nttest_results\nsummary(lmm_dist)\nsummary(lmm_vx)\n\n\n\n\nCode\nlibrary(BayesFactor)\n\n# Create data frames for the distance and velocity data\ndf_dist &lt;- ds %&gt;% filter(expMode %in% c(\"test-Nf\", \"test-train-nf\")) %&gt;% select(id, condit, dist)\ndf_vx &lt;- ds %&gt;% filter(expMode %in% c(\"test-Nf\", \"test-train-nf\")) %&gt;% select(id, condit, vx)\n\n# Conduct the Bayesian t-test for distance\nbf_dist &lt;- ttestBF(df_dist$dist[df_dist$condit == \"Constant\"], df_dist$dist[df_dist$condit == \"Varied\"], nullInterval = c(-Inf, 0))\nsummary(bf_dist)\n\n# Conduct the Bayesian t-test for velocity\nbf_vx &lt;- ttestBF(df_vx$vx[df_vx$condit == \"Constant\"], df_vx$vx[df_vx$condit == \"Varied\"], nullInterval = c(-Inf, 0))\nsummary(bf_vx)\n\n\n\n\nCode\nlibrary(brms)\n\n# Fit the hierarchical model for distance\nfit_dist &lt;- brm(dist ~ condit + (1 | id), data = df_dist, family = student, prior = c(set_prior(\"normal(0, 10)\", class = \"Intercept\"), set_prior(\"cauchy(0, 10)\", class = \"sd\")), control = list(adapt_delta = 0.99))\n\n# Summarize the posterior distribution of the group-level effects\nsummary(fit_dist)\n\n# Plot the posterior distribution of the group-level effects\nplot(fit_dist, pars = \"condit\", ask = FALSE)\n\n# Fit the hierarchical model for velocity\nfit_vx &lt;- brm(vx ~ condit + (1 | id), data = df_vx, family = student, prior = c(set_prior(\"normal(0, 10)\", class = \"Intercept\"), set_prior(\"cauchy(0, 10)\", class = \"sd\")), control = list(adapt_delta = 0.99))\n\n# Summarize the posterior distribution of the group-level effects\nsummary(fit_vx)\n\n# Plot the posterior distribution of the group-level effects\nplot(fit_vx, pars = \"condit\", ask = FALSE)\n\n\nChain 3: Iteration: 1600 / 2000 [ 80%] (Sampling) Chain 3: Iteration: 1800 / 2000 [ 90%] (Sampling) Chain 3: Iteration: 2000 / 2000 [100%] (Sampling) Chain 3: Chain 3: Elapsed Time: 159.717 seconds (Warm-up) Chain 3: 100.318 seconds (Sampling) Chain 3: 260.035 seconds (Total) Chain 3:\nSAMPLING FOR MODEL ‘170f29158946b7a14bb2fd84672af1b9’ NOW (CHAIN 4). Chain 4: Chain 4: Gradient evaluation took 0.001614 seconds Chain 4: 1000 transitions using 10 leapfrog steps per transition would take 16.14 seconds. Chain 4: Adjust your expectations accordingly! Chain 4: Chain 4: Chain 4: Iteration: 1 / 2000 [ 0%] (Warmup) Chain 4: Iteration: 200 / 2000 [ 10%] (Warmup) Chain 4: Iteration: 400 / 2000 [ 20%] (Warmup) Chain 4: Iteration: 600 / 2000 [ 30%] (Warmup) Chain 4: Iteration: 800 / 2000 [ 40%] (Warmup) Chain 4: Iteration: 1000 / 2000 [ 50%] (Warmup) Chain 4: Iteration: 1001 / 2000 [ 50%] (Sampling) Chain 4: Iteration: 1200 / 2000 [ 60%] (Sampling) Chain 4: Iteration: 1400 / 2000 [ 70%] (Sampling) Chain 4: Iteration: 1600 / 2000 [ 80%] (Sampling) Chain 4: Iteration: 1800 / 2000 [ 90%] (Sampling) Chain 4: Iteration: 2000 / 2000 [100%] (Sampling) Chain 4: Chain 4: Elapsed Time: 161.386 seconds (Warm-up) Chain 4: 100.128 seconds (Sampling) Chain 4: 261.514 seconds (Total) Chain 4: Warning messages: 1: Bulk Effective Samples Size (ESS) is too low, indicating posterior means and medians may be unreliable. Running the chains for more iterations may help. See https://mc-stan.org/misc/warnings.html#bulk-ess 2: Tail Effective Samples Size (ESS) is too low, indicating posterior variances and tail quantiles may be unreliable. Running the chains for more iterations may help. See https://mc-stan.org/misc/warnings.html#tail-ess\n# Summarize the posterior distribution of the group-level effects &gt; summary(fit_dist) Family: student Links: mu = identity; sigma = identity; nu = identity Formula: dist ~ condit + (1 | id) Data: df_dist (Number of observations: 26088) Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1; total post-warmup draws = 4000\nGroup-Level Effects: ~id (Number of levels: 427) Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS sd(Intercept) 147.96 6.44 135.94 160.92 1.01 318 763\nPopulation-Level Effects: Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS Intercept 125.28 10.24 104.64 145.09 1.03 183 312 conditVaried 24.36 14.89 -4.64 52.59 1.03 147 318\nFamily Specific Parameters: Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS sigma 172.64 1.54 169.61 175.67 1.00 2646 2771 nu 3.39 0.09 3.22 3.57 1.00 2558 2713\nDraws were sampled using sampling(NUTS). For each parameter, Bulk_ESS and Tail_ESS are effective sample size measures, and Rhat is the potential scale reduction factor on split chains (at convergence, Rhat = 1).\n\n\nCode\nlibrary(ggplot2)\n\n# Filter data for relevant variables and conditions\ndh &lt;- ds %&gt;% filter(expMode %in% c(\"test-Nf\", \"test-train-nf\")) %&gt;% \n  select(id, condit, expMode, bandInt, dist)\n\n# Create histograms of distance from target for each group and condition\nggplot(dh, aes(x = dist, fill = condit)) +\n  geom_histogram(binwidth = 50) +\n  facet_wrap(~ expMode + bandInt, ncol = 3) +\n  labs(x = \"Distance from target\", y = \"Count\", fill = \"Group\") +\n  theme_bw()\n\n\n\n\n\nCode\n# Create density plots of distance from target for each group and condition\nggplot(dh, aes(x = dist, color = condit)) +\n  geom_density() +\n  facet_wrap(~ expMode + bandInt, ncol = 3) +\n  labs(x = \"Distance from target\", y = \"Density\", color = \"Group\") +\n  theme_bw()\n\n\n\n\n\n\n\nCode\nlibrary(psych)\nlibrary(psycho)\n\n\n\n\nCode\n# Convert lowBound and highBound to numeric\nds$lowBound &lt;- as.numeric(levels(ds$lowBound))[ds$lowBound]\nds$highBound &lt;- as.numeric(levels(ds$highBound))[ds$highBound]\n\n# Calculate the proportion of overshot vs. undershot trials by group and testing condition\ndsummary &lt;- ds %&gt;% \n  filter(expMode %in% c(\"test-Nf\", \"test-train-nf\")) %&gt;% \n  group_by(condit, expMode, vb) %&gt;% \n  summarize(prop_overshoot = mean(vxb &gt; highBound),\n            prop_undershoot = mean(vxb &lt; lowBound))\n\n# Perform chi-squared test of independence for each testing condition\ntest_results &lt;- dsummary %&gt;% \n  filter(expMode %in% c(\"test-Nf\", \"test-train-nf\")) %&gt;% \n  group_by(expMode) %&gt;% \n  summarize(chisq_overshoot = chisq.test(prop_overshoot ~ condit, simulate.p.value = TRUE, B = 10000)$p.value,\n            chisq_undershoot = chisq.test(prop_undershoot ~ condit, simulate.p.value = TRUE, B = 10000)$p.value)\n\n\nThere are a number of cognitive computational models that could be implemented to help explain the empirical patterns observed in this study. Here are a few possibilities:\nBayesian learning models: These models assume that people learn by updating their beliefs based on the likelihood of different outcomes and the prior probability of those outcomes. Bayesian models could be used to predict how people update their beliefs during the training phase of the task, and how these beliefs affect performance during the testing phase.\nReinforcement learning models: Reinforcement learning models assume that people learn by adjusting their behavior based on the feedback they receive from the environment. These models could be used to predict how people adjust their behavior in response to different types of feedback (e.g. numerical vs. ordinal feedback) and how this affects learning and transfer.\nCognitive load models: Cognitive load models assume that people have limited working memory capacity, and that cognitive load affects learning and transfer. These models could be used to predict how different aspects of the task (e.g. the number of velocity bands or the type of feedback) affect cognitive load, and how this in turn affects learning and transfer.\nDual-process models: Dual-process models assume that people have two types of cognitive processing systems: one that is fast, automatic, and intuitive, and one that is slow, controlled, and deliberative. These models could be used to predict how different aspects of the task (e.g. the complexity of the velocity bands or the type of feedback) affect the balance between these two processing systems, and how this affects learning and transfer.\nMotor learning models: Motor learning models assume that people learn by acquiring motor skills through repeated practice. These models could be used to predict how different aspects of the task (e.g. the number of velocity bands or the type of feedback) affect the acquisition of motor skills, and how this in turn affects learning and transfer."
  },
  {
    "objectID": "Analysis/discrim.html",
    "href": "Analysis/discrim.html",
    "title": "Testing Discrimination Analysis",
    "section": "",
    "text": "Code\nlapply(c('tidyverse','data.table','lme4','lmerTest','knitr','kableExtra','cowplot','gghalves'),library,character.only = TRUE)\nd &lt;- readRDS('../data/dPrune-01-19-23.rds')\n\ndtest &lt;- d %&gt;% filter(expMode %in% c(\"test-Nf\",\"test-train-nf\")) %&gt;% group_by(id,lowBound) %&gt;% \n  mutate(nBand=n(),band=bandInt,id=factor(id)) %&gt;% group_by(id) %&gt;% mutate(nd=n_distinct(lowBound))\n# unique(dtest[dtest$nd==4,]$sbjCode) # 7 in wrong condition\ndtest &lt;- dtest %&gt;% group_by(id,lowBound) %&gt;% filter(nBand&gt;=5 & nd==6)\n# for any id that has at least 1 nBand &gt;=5, remove all rows with that id. \ndtest &lt;- dtest %&gt;% group_by(id) %&gt;% filter(!id %in% unique(dtest$id[dtest$nBand&lt;5]))\n\ndtestAgg &lt;- dtest %&gt;% group_by(id,condit,catOrder,feedbackType,vb,band,lowBound,highBound,input) %&gt;% mutate(vxCapped=ifelse(vx&gt;1600,1600,vx)) %&gt;%\n  summarise(vxMean=mean(vx),devMean=mean(dist),vxMed=median(vx),devMed=median(dist),\n            vxMeanCap=mean(vxCapped),.groups = \"keep\")"
  },
  {
    "objectID": "Analysis/discrim.html#quick-reminder-of-general-patterns",
    "href": "Analysis/discrim.html#quick-reminder-of-general-patterns",
    "title": "Testing Discrimination Analysis",
    "section": "Quick Reminder of General Patterns",
    "text": "Quick Reminder of General Patterns\n\n\nCode\nfig1aCap=str_wrap(\"Figure 1a: Bands 100-300, 350-550 and 600-800 are novel extrapolations for both Original Order. Translucent rectangles indicate the correct band \" ,width=170)\n\nfig1bCap=str_wrap(\"Figure 1b: Bands 800-1000, 1000-1200,  and 1200-1400 are novel extrapolations for both Reverse Order. Translucent rectangles indicate the correct band \" ,width=170)\n\nplotDist &lt;- function(df,title=\"\",fcap=\"\"){\n  rectWidth=30\n  df %&gt;%ggplot()+aes(x = band, y = vxMeanCap, fill=vb) +\n    # Set the color mapping in this layer so the points don't get a color\n   geom_half_violin(color=NA)+ # remove border color\n  geom_half_boxplot(position=position_nudge(x=-0.05),side=\"r\",outlier.shape = NA,center=TRUE,\n                    errorbar.draw = FALSE,width=20)+\n  geom_half_point(transformation = position_jitter(width = 0.05, height = 0.05),size=.3,aes(color=vb))+\n  facet_wrap(~condit,scale=\"free_x\")+\n    geom_rect(aes(xmin=band-rectWidth,xmax=band+rectWidth,ymin=band,ymax=highBound,fill=vb),alpha=.01)+\n    geom_segment(aes(x=band-rectWidth,xend=band+rectWidth,y=highBound,yend=highBound),alpha=.8,linetype=\"dashed\")+\n    geom_segment(aes(x=band-rectWidth,xend=band+rectWidth,y=band,yend=band),alpha=.8,linetype=\"dashed\")+\n    labs(x = \"Velocity Band\", y = \"vxMean\",caption=fcap) +\n    scale_y_continuous(expand=expansion(add=100),breaks=round(seq(0,2000,by=200),2))+\n    scale_x_continuous(labels=sort(unique(df$band)),breaks=sort(unique(df$band)))+\n    ggtitle(title) + theme(legend.position = \"none\")+theme_classic()+guides(fill=\"none\",color=\"none\")+\n  theme(plot.caption=element_text(hjust=0,face=\"italic\"))\n}\n\n\n#dtestAgg %&gt;% plotDist()\ndtestAgg %&gt;% filter(catOrder==\"orig\") %&gt;% plotDist(title=\"Empirical Vx - Original Order\",fcap=fig1aCap)\n\n\n\n\n\nCode\ndtestAgg %&gt;% filter(catOrder==\"rev\") %&gt;% plotDist(title=\"Empirical Vx - Reverse Order\",fcap=fig1bCap)"
  },
  {
    "objectID": "Analysis/discrim.html#naive-model-that-fits-single-slope-and-intercept-to-all-subjects",
    "href": "Analysis/discrim.html#naive-model-that-fits-single-slope-and-intercept-to-all-subjects",
    "title": "Testing Discrimination Analysis",
    "section": "naive model that fits single slope and intercept to all subjects",
    "text": "naive model that fits single slope and intercept to all subjects\n\n\nCode\n# Fit a model on all the data pooled together\nm_pooled &lt;- lm(vxMean ~ band, dtestAgg) \n# Repeat the intercept and slope terms for each participant\ndf_pooled &lt;- tibble(\n  Model = \"Complete pooling\",\n  id = unique(dtestAgg$id),\n  Intercept = coef(m_pooled)[1], \n  Slope_band = coef(m_pooled)[2]\n)\n#head(df_pooled)\n\n# print the coefficents and residual of the model\nsummary(m_pooled)\n\n\n\nCall:\nlm(formula = vxMean ~ band, data = dtestAgg)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-879.55 -214.41  -43.26  177.10 1300.93 \n\nCoefficients:\n             Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 480.69135   12.55505   38.29   &lt;2e-16 ***\nband          0.59085    0.01641   36.00   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 302.9 on 2450 degrees of freedom\nMultiple R-squared:  0.346, Adjusted R-squared:  0.3457 \nF-statistic:  1296 on 1 and 2450 DF,  p-value: &lt; 2.2e-16"
  },
  {
    "objectID": "Analysis/discrim.html#fit-no-pooling-model-individual-fit-for-each-subject",
    "href": "Analysis/discrim.html#fit-no-pooling-model-individual-fit-for-each-subject",
    "title": "Testing Discrimination Analysis",
    "section": "Fit no pooling model (individual fit for each subject)",
    "text": "Fit no pooling model (individual fit for each subject)\n\n\nCode\ndf_no_pooling &lt;- lmList(vxMean ~ band | id, dtestAgg) %&gt;% \n  coef() %&gt;% rownames_to_column(\"id\") %&gt;% \n  rename(Intercept = `(Intercept)`, Slope_band = band) %&gt;% \n  add_column(Model = \"No pooling\")\n\n# print average coefficients and average residual for the model\nsummary(df_no_pooling)\n\n\n      id              Intercept        Slope_band         Model          \n Length:418         Min.   :-461.2   Min.   :-0.4938   Length:418        \n Class :character   1st Qu.: 185.9   1st Qu.: 0.2338   Class :character  \n Mode  :character   Median : 397.0   Median : 0.5976   Mode  :character  \n                    Mean   : 475.1   Mean   : 0.6059                     \n                    3rd Qu.: 733.3   3rd Qu.: 0.9334                     \n                    Max.   :1657.5   Max.   : 2.3819                     \n\n\nCode\n# print average residual of no pooling model\nsummary(df_no_pooling$vxMean ~ df_no_pooling$band | df_no_pooling$id)\n\n\n Length   Class    Mode \n      3 formula    call \n\n\nCode\n# sort the dataframe by the value of slope_band, highest to lowest\ntestSlopeIndv &lt;- df_no_pooling %&gt;% arrange(desc(Slope_band))\n\n# Add a condit column to the dataframe, matching condition based on the value in dtestAgg for each sbjCode\ntestSlopeIndv &lt;- testSlopeIndv %&gt;% \n  left_join(dtestAgg %&gt;% ungroup() %&gt;% select(id, condit) %&gt;% distinct(), by = \"id\") \n\n# Add a rank column to the dataframe, based on the value of slope_band. Smallest rank for highest value.\ntestSlopeIndv &lt;- testSlopeIndv %&gt;% group_by(condit) %&gt;% \n  mutate(nGrp=n(),rank = nGrp -rank(Slope_band) +1,\n         quantile = cut(rank, breaks = 4, labels = c(\"1st\", \"2nd\", \"3rd\", \"4th\")),\n         quintile=cut(rank,breaks=5,labels=c(\"1st\", \"2nd\", \"3rd\", \"4th\",\"5th\")),\n         decile=cut(rank,breaks=10,labels=c(1:10))) %&gt;% #select(-n)%&gt;%\n  arrange(rank)\n\n# Reorder the sbjCode column so that the sbjCode with the highest slope_band is first\ntestSlopeIndv$id &lt;- factor(testSlopeIndv$id, levels = testSlopeIndv$id)\n\n#head(testSlopeIndv)"
  },
  {
    "objectID": "Analysis/discrim.html#some-individual-plots-showing-the-best-fitting-line-against-testing-behavior-x-velocity.",
    "href": "Analysis/discrim.html#some-individual-plots-showing-the-best-fitting-line-against-testing-behavior-x-velocity.",
    "title": "Testing Discrimination Analysis",
    "section": "Some individual plots showing the best fitting line against testing behavior (x velocity).",
    "text": "Some individual plots showing the best fitting line against testing behavior (x velocity).\n\nSample of high, and low discriminating subjects (i.e. highest and lowest slopes)\nMean Vx for each band shown via dot.\ncorrect bands shown with translucent rectangles\n\n\n\nCode\n# create plotting function that takes in a dataframe, and returns ggplot object\n#rewrite plotSlope function to take line color as a function argument, and set the color of abline to that argument\n\nplotSlope &lt;- function(df,title=\"\",colour=NULL){\n  rectWidth=50\n  df %&gt;%ggplot()+aes(x = band, y = vxMean) +\n    # Set the color mapping in this layer so the points don't get a color\n    geom_abline(\n      aes(intercept = Intercept, slope = Slope_band),\n      size = .75,colour=colour,alpha=.2\n    ) +geom_point(aes(color=vb)) +facet_wrap(\"id\") +\n    geom_rect(aes(xmin=band-rectWidth,xmax=band+rectWidth,ymin=band,ymax=highBound,fill=vb),alpha=.1)+\n    geom_segment(aes(x=band-rectWidth,xend=band+rectWidth,y=highBound,yend=highBound),alpha=1,linetype=\"dashed\")+\n    geom_segment(aes(x=band-rectWidth,xend=band+rectWidth,y=band,yend=band),alpha=1,linetype=\"dashed\")+\n    labs(x = \"Velocity Band\", y = \"vxMean\") +\n    scale_x_continuous(labels=sort(unique(df$band)),breaks=sort(unique(df$band)))+\n    ggtitle(title) + theme(legend.position = \"none\")+theme_classic()+guides(fill=\"none\",color=\"none\")\n}\n\ntv&lt;-testSlopeIndv %&gt;% left_join(dtestAgg, by = c(\"id\",\"condit\")) %&gt;% filter(condit==\"Varied\",rank&lt;=6) %&gt;% \n   plotSlope(.,colour=\"black\",title=\"Largest Individually fit Varied Sbj. Slopes\")\ntc&lt;-testSlopeIndv %&gt;% left_join(dtestAgg, by = c(\"id\",\"condit\")) %&gt;% filter(condit==\"Constant\",rank&lt;=6) %&gt;% \n   plotSlope(.,colour=\"black\",title=\"Largest Individually fit Constant Sbj. Slopes\")\nbv&lt;-testSlopeIndv %&gt;% left_join(dtestAgg, by = c(\"id\",\"condit\")) %&gt;% filter(condit==\"Varied\",rank&gt;=nGrp-5) %&gt;% \n   plotSlope(.,colour=\"black\",title=\"Smallest Varied Sbj. Slopes\")\nbc&lt;-testSlopeIndv %&gt;% left_join(dtestAgg, by = c(\"id\",\"condit\")) %&gt;% filter(condit==\"Constant\",rank&gt;=nGrp-5) %&gt;% \n   plotSlope(.,colour=\"black\",title=\"Smallest Constant Sbj. Slopes.\")\n \ntitle = ggdraw()+draw_label(\"Highest and Lowest Slope Values\",fontface = 'bold',x=0,hjust=0)+theme(plot.margin = margin(0, 0, 0, .5))\nplot_grid(title,NULL,tv,tc,bv,bc,NULL,ncol=2,rel_heights = c(.1,1,1))"
  },
  {
    "objectID": "Analysis/discrim.html#fit-partial-pooling-model-linear-mixed-model-with-random-slope-and-intercept",
    "href": "Analysis/discrim.html#fit-partial-pooling-model-linear-mixed-model-with-random-slope-and-intercept",
    "title": "Testing Discrimination Analysis",
    "section": "Fit partial pooling model (linear mixed model with random slope and intercept)",
    "text": "Fit partial pooling model (linear mixed model with random slope and intercept)\n\n\nCode\nbm1 &lt;- lmer(vxMed ~ 1 + band + (1 + band | id), dtestAgg, control = lmerControl(optimizer = \"bobyqa\", optCtrl = list(maxfun = 3e5)))\narm::display(bm1)\n\n\nlmer(formula = vxMed ~ 1 + band + (1 + band | id), data = dtestAgg, \n    control = lmerControl(optimizer = \"bobyqa\", optCtrl = list(maxfun = 3e+05)))\n            coef.est coef.se\n(Intercept) 457.18    18.94 \nband          0.61     0.02 \n\nError terms:\n Groups   Name        Std.Dev. Corr  \n id       (Intercept) 369.23         \n          band          0.45   -0.79 \n Residual             136.75         \n---\nnumber of obs: 2452, groups: id, 418\nAIC = 33227.2, DIC = 33219.1\ndeviance = 33217.1 \n\n\nCode\ndf_partial_pooling &lt;- coef(bm1)[[\"id\"]] %&gt;% \n  rownames_to_column(\"id\") %&gt;% \n  as_tibble() %&gt;% \n  rename(Intercept = `(Intercept)`, Slope_band = band) %&gt;% \n  add_column(Model = \"Partial pooling\")\n\nhead(df_partial_pooling)\n\n\n# A tibble: 6 × 4\n  id    Intercept Slope_band Model          \n  &lt;chr&gt;     &lt;dbl&gt;      &lt;dbl&gt; &lt;chr&gt;          \n1 1          558.      0.555 Partial pooling\n2 2         1158.      0.231 Partial pooling\n3 3         1033.     -0.141 Partial pooling\n4 4          250.      0.949 Partial pooling\n5 5          504.      0.596 Partial pooling\n6 6          224.      1.07  Partial pooling\n\n\nCode\nsummary(bm1)\n\n\nLinear mixed model fit by REML. t-tests use Satterthwaite's method [\nlmerModLmerTest]\nFormula: vxMed ~ 1 + band + (1 + band | id)\n   Data: dtestAgg\nControl: lmerControl(optimizer = \"bobyqa\", optCtrl = list(maxfun = 3e+05))\n\nREML criterion at convergence: 33215.2\n\nScaled residuals: \n    Min      1Q  Median      3Q     Max \n-3.4482 -0.4578 -0.0161  0.4422  5.0822 \n\nRandom effects:\n Groups   Name        Variance  Std.Dev. Corr \n id       (Intercept) 1.363e+05 369.2342      \n          band        2.060e-01   0.4539 -0.79\n Residual             1.870e+04 136.7458      \nNumber of obs: 2452, groups:  id, 418\n\nFixed effects:\n             Estimate Std. Error        df t value Pr(&gt;|t|)    \n(Intercept) 457.17775   18.93837 422.24016   24.14   &lt;2e-16 ***\nband          0.60869    0.02345 418.74433   25.95   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nCorrelation of Fixed Effects:\n     (Intr)\nband -0.797\noptimizer (bobyqa) convergence code: 0 (OK)\nModel failed to converge with max|grad| = 3.29001 (tol = 0.002, component 1)\nModel is nearly unidentifiable: very large eigenvalue\n - Rescale variables?\nModel is nearly unidentifiable: large eigenvalue ratio\n - Rescale variables?\n\n\n\n\nCode\n# filter to only retain the no pooling and partial pooling models. \n# Compare the average slope and intercepts between constant and varied condits. Use barplots with standard error bars\n\ndf_models &lt;- bind_rows(df_pooled, df_no_pooling, df_partial_pooling) %&gt;% \n  left_join(dtestAgg, by = c(\"id\"))\n\n\nWarning in left_join(., dtestAgg, by = c(\"id\")): Detected an unexpected many-to-many relationship between `x` and `y`.\nℹ Row 1 of `x` matches multiple rows in `y`.\nℹ Row 1 of `y` matches multiple rows in `x`.\nℹ If a many-to-many relationship is expected, set `relationship =\n  \"many-to-many\"` to silence this warning.\n\n\nCode\ngrpAvg&lt;-  df_models %&gt;% filter(Model %in% c(\"No pooling\", \"Partial pooling\")) %&gt;% group_by(id,Model) %&gt;% slice(1) %&gt;%\n  group_by(Model, condit) %&gt;% \n  summarise(\n    n= n(),\n    Intercept = mean(Intercept), \n    Slope_band = mean(Slope_band),\n  ) %&gt;% mutate( Intercept_se = sd(Intercept)/sqrt(n),\n    Slope_band_se = sd(Slope_band)/sqrt(n), .groups=\"keep\") \n#head(grpAvg)\n\n\n p1=grpAvg %&gt;% ggplot() + \n  aes(x = Model, y = Slope_band, fill = condit) +\n  geom_col(position = \"dodge\") + \n  geom_errorbar(aes(ymin = Slope_band - Slope_band_se, ymax = Slope_band + Slope_band_se), width = 0.2, position = position_dodge(0.9)) +\n  labs(x = \"Model\", y = \"Slope (band)\") + \n  theme(legend.position = \"top\", legend.justification = \"left\")+ggtitle(\"Comparing Slopes between Conditions - Both pooling models\")\n \n \n \n p2=grpAvg %&gt;% ggplot() + \n  aes(x = Model, y = Intercept, fill = condit) +\n  geom_col(position = \"dodge\") + \n  geom_errorbar(aes(ymin = Intercept - Intercept_se, ymax = Intercept + Intercept_se), width = 0.2, position = position_dodge(0.9)) +\n  labs(x = \"Model\", y = \"Intercept\") + \n  theme(legend.position = \"top\", legend.justification = \"left\")+ggtitle(\"Comparing Intercepts between Conditions - Both pooling models\")\n  \n\n\n# For the partial pooling model, visualize the correlation between the intercept and slope for each subject.\n# Use geom_smooth to fit a linear model to the data, and plot the line of best fit.\n\np3=df_models %&gt;% filter(Model == \"Partial pooling\") %&gt;% \n  ggplot() + \n  aes(x = Intercept, y = Slope_band) + \n  geom_point() + \n  geom_smooth(method = \"lm\", se = FALSE) +\n  labs(x = \"Intercept\", y = \"Slope (band)\") + \n  theme(legend.position = \"top\", legend.justification = \"left\")+ggtitle(\"Correlation between Fit Slope and Intercept (Mixed Effects model)\")\n\n\n  # For the partial pooling model, visualize the correlation between slope and devMean for each subject.\n# Use geom_smooth to fit a linear model to the data, and plot the line of best fit.\n\np4=df_models %&gt;% filter(Model == \"Partial pooling\") %&gt;% \n  ggplot() + \n  aes(x = Slope_band, y = devMean) + \n  geom_point() + \n  geom_smooth(method = \"lm\", se = FALSE) +\n  labs(x = \"Slope (band)\", y = \"devMean\") + \n  theme(legend.position = \"top\", legend.justification = \"left\")+ggtitle(\"Correlation between Fit Slope and testing performance (Mixed Effects model)\")\n\n\n# For the partial pooling model, visualize the correlation between Intercept and devMean for each subject.\n\np5=df_models %&gt;% filter(Model == \"Partial pooling\") %&gt;% \n  ggplot() + \n  aes(x = Intercept, y = devMean) + \n  geom_point() + \n  geom_smooth(method = \"lm\", se = FALSE) +\n  labs(x = \"Intercept\", y = \"devMean\") + \n  theme(legend.position = \"top\", legend.justification = \"left\")+ggtitle(\"Correlation between Fit Intercept and testing performance (Mixed Effects model)\")\n\n\n\ntitle = ggdraw()+draw_label(\"Examining the Fit Slopes and Intercepts\",fontface = 'bold',x=0,hjust=0)+theme(plot.margin = margin(0, 0, 0, .5))\nplot_grid(title,NULL,p1,p2,p3,p4,p5,ncol=2,rel_heights = c(.15,1,1,1))"
  },
  {
    "objectID": "Analysis/discrim.html#correlation-between-fit-parameters-slope-and-intercept-and-testing-vx",
    "href": "Analysis/discrim.html#correlation-between-fit-parameters-slope-and-intercept-and-testing-vx",
    "title": "Testing Discrimination Analysis",
    "section": "Correlation between fit parameters (Slope and Intercept) and testing Vx",
    "text": "Correlation between fit parameters (Slope and Intercept) and testing Vx\n\nNoteworthy that The correlation between slope and Vx is strongest for the slowest bands (100-300 and 350-550), for both original and reverse ordered groups. The slow positions are extrapolation for the Original ordered group, and trained by the reverse ordered group.\nFairly similar patterns for Slope and Intercept\n\n\n\nCode\n# For the partial pooling model, visualize the correlation between slope and devMean for each subject. Facet by vb~catOrder. Group and color by condit. \n# Use geom_smooth to fit a linear model to the data, and plot the line of best fit.\n\ndf_models %&gt;% filter(Model == \"Partial pooling\") %&gt;% \n  ggplot() + \n  aes(x = Slope_band, y = vxMed, color = condit) + \n  geom_point() + \n  geom_smooth(method = \"lm\", se = FALSE) +\n  labs(x = \"Slope (band)\", y = \"Median Vx\") + \n  theme(legend.position = \"top\", legend.justification = \"left\") +\n  facet_grid(catOrder~vb)+ ggtitle(\"Correlation between Slope and Median VX\")\n\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\nCode\ndf_models %&gt;% filter(Model == \"Partial pooling\") %&gt;% \n  ggplot() + \n  aes(x = Intercept, y = vxMed, color = condit) + \n  geom_point() + \n  geom_smooth(method = \"lm\", se = FALSE) +\n  labs(x = \"Intercept\", y = \"Median Vx\") + \n  theme(legend.position = \"top\", legend.justification = \"left\") +\n  facet_grid(catOrder~vb)+ ggtitle(\"Correlation between Intercept and Median Vx\")\n\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\nCorrelation between parameters and Mean Deviation.\n\nHere we see a powerful effect of slope for the slow bands (larger slopes tend to have smaller deviation)\n\n\n\nCode\n# For the partial pooling model, visualize the correlation between slope and devMean for each subject. Facet by vb~catOrder. Group and color by condit. \n# Use geom_smooth to fit a linear model to the data, and plot the line of best fit.\n\ndf_models %&gt;% filter(Model == \"Partial pooling\") %&gt;% \n  ggplot() + \n  aes(x = Slope_band, y = devMean, color = condit) + \n  geom_point() + \n  geom_smooth(method = \"lm\", se = FALSE) +\n  labs(x = \"Slope (band)\", y = \"devMean\") + \n  theme(legend.position = \"top\", legend.justification = \"left\") +\n  facet_grid(catOrder~vb)+ ggtitle(\"Correlation between Slope and Mean Deviation\")\n\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\nCode\ndf_models %&gt;% filter(Model == \"Partial pooling\") %&gt;% \n  ggplot() + \n  aes(x = Intercept, y = devMean, color = condit) + \n  geom_point() + \n  geom_smooth(method = \"lm\", se = FALSE) +\n  labs(x = \"Intercept\", y = \"devMean\") + \n  theme(legend.position = \"top\", legend.justification = \"left\") +\n  facet_grid(catOrder~vb)+ ggtitle(\"Correlation between Intercept and Mean Deviation\")\n\n\n`geom_smooth()` using formula = 'y ~ x'"
  },
  {
    "objectID": "Functions/index.html",
    "href": "Functions/index.html",
    "title": "Quarto Shiny ALM",
    "section": "",
    "text": "Association Parameter\n\n\n\n\n\nUpdate Parameter\n\n\n\n\n\nTraining Repetitions\n\n\n\n\n\nNoise\n\n\n\n\n\nTraining Items\n\n\n\n1\n\n\n\n5\n\n\n\n8\n\n\n\n12\n\n\n\n16\n\n\n\n19\n\n\n\n23\n\n\n\n27\n\n\n\n30\n\n\n\n34\n\n\n\n38\n\n\n\n41\n\n\n\n45\n\n\n\n49\n\n\n\n52\n\n\n\n56\n\n\n\n60\n\n\n\n63\n\n\n\n67\n\n\n\n71\n\n\n\n74\n\n\n\n78\n\n\n\n82\n\n\n\n85\n\n\n\n89\n\n\n\n93\n\n\n\n97\n\n\n\n100\n\n\n\n104\n\n\n\n108\n\n\n\n111\n\n\n\n115\n\n\n\n119\n\n\n\n122\n\n\n\n126\n\n\n\n130\n\n\n\n133\n\n\n\n137\n\n\n\n141\n\n\n\n144\n\n\n\n148\n\n\n\n152\n\n\n\n155\n\n\n\n159\n\n\n\n163\n\n\n\n166\n\n\n\n170\n\n\n\n174\n\n\n\n177\n\n\n\n181\n\n\n\n\n\n\nFunction Form\n\n\n\n\nLinear\n\n\n\n\n\nQuadratic\n\n\n\n\n\nExponential\n\n\n\n\n\n\n\nNumber of Repetitions\n\n\n\n\nRun Simulation\n\n\n\n\n\n\n\n\n\nAverage Model Performance\n\n\n\n\n\nModel Performance by Item Type"
  },
  {
    "objectID": "Misc/External.html",
    "href": "Misc/External.html",
    "title": "External",
    "section": "",
    "text": "External Links\n\n\n\nRegression in Keras\nuncertainty in deep learning \nRobinson Codebook\npainbrow\nNN Flex\nb-splines\n\n\n\n\n\n\nMahr Posts\n\n\n\nPolypoly\nsplines\n\n\nHock Function Learn with NN\nAutoencoder with Tensorflow\nConnected Scatterplot\n\n\n\n\n\n\n\n\nQuarto Tools to add\n\n\n\n\n\nggpage\nquartoDocSetup\nquartoLayout\n\n\n\n\n\n\n\n\n\n\nNutshell items\n\n\n\n\n\n\n:link to senseless paragraph\n\n:link to wikipedia article\n:link to invisible sections\n\n\n\n\n\n\n\n\n\n:ggpage\n:quartoDocSetup\n:quartoLayout"
  },
  {
    "objectID": "Misc/External.html#quarto",
    "href": "Misc/External.html#quarto",
    "title": "External",
    "section": "",
    "text": "External Links\n\n\n\nRegression in Keras\nuncertainty in deep learning \nRobinson Codebook\npainbrow\nNN Flex\nb-splines\n\n\n\n\n\n\nMahr Posts\n\n\n\nPolypoly\nsplines\n\n\nHock Function Learn with NN\nAutoencoder with Tensorflow\nConnected Scatterplot\n\n\n\n\n\n\n\n\nQuarto Tools to add\n\n\n\n\n\nggpage\nquartoDocSetup\nquartoLayout\n\n\n\n\n\n\n\n\n\n\nNutshell items\n\n\n\n\n\n\n:link to senseless paragraph\n\n:link to wikipedia article\n:link to invisible sections\n\n\n\n\n\n\n\n\n\n:ggpage\n:quartoDocSetup\n:quartoLayout"
  },
  {
    "objectID": "Misc/External.html#website_add",
    "href": "Misc/External.html#website_add",
    "title": "External",
    "section": "",
    "text": ":ggpage\n:quartoDocSetup\n:quartoLayout"
  },
  {
    "objectID": "Misc/External.html#another",
    "href": "Misc/External.html#another",
    "title": "External",
    "section": "another",
    "text": "another\n\n\n\n\n\n\nPDF Views\n\n\n\n\n\n\nMain\nInformation Sampling Explains Bayesian Learners’ biases in correlation judgement \n\n\n\nAlt\n\n\n\n\nNeural Network Model of Continual Learning with Cognitive Control\n\n\n\nGeometry of Map-Like Representations Under Dynamic-Cognitive Control\n\n\n\n\n\n\n\nPage Embed\nVideo"
  },
  {
    "objectID": "Misc/External.html#callouts",
    "href": "Misc/External.html#callouts",
    "title": "External",
    "section": "Callouts",
    "text": "Callouts\n\n\n\n\n\n\nPay Attention\n\n\n\nUsing callouts is an effective way to highlight content that your reader give special consideration or attention.\n\n\n\n\n\n\n\n\nPay Attention\n\n\n\nUsing callouts is an effective way to highlight content that your reader give special consideration or attention.\n\n\n\n\n\n\n\n\nVideo Page\n\n\n\nVideo"
  },
  {
    "objectID": "Misc/External.html#test-grid",
    "href": "Misc/External.html#test-grid",
    "title": "External",
    "section": "Test Grid",
    "text": "Test Grid\n\n\nThis column takes 1/3 of the page\n\n\n\n\n\n\n\n\nModel To-do\n\n\n\n\nALM\nEXAM\nApproximate Bayes?\n\n\n\n\n\n\n\n\n\nAnalysis To-do\n\n\n\n\nDiscrimination\nMixed Models?"
  },
  {
    "objectID": "Misc/External.html#alt-column-approach",
    "href": "Misc/External.html#alt-column-approach",
    "title": "External",
    "section": "Alt column approach",
    "text": "Alt column approach\n\n\n\n\n\n\n\n\nModel To-do\n\n\n\n\n\n\nTrain Predict Transfer vs. Full Fit\nSeparate ALM and EXAM Fits\nALM + Prior Knowledge\nEmpirical Learning Model\nNoise Parameter\nModel Recovery\nApproximate Bayes?\n\n\n\n\n\n\n\n\n\n\nAnalysis To-do\n\n\n\n\n\n\nDiscrimination\nMixed Models?"
  },
  {
    "objectID": "Misc/External.html#test",
    "href": "Misc/External.html#test",
    "title": "External",
    "section": "Test",
    "text": "Test\nThis is a senseless paragraph"
  },
  {
    "objectID": "Misc/External.html#testing-links",
    "href": "Misc/External.html#testing-links",
    "title": "External",
    "section": "Testing Links",
    "text": "Testing Links\n\n:link to senseless paragraph\n\n:link to wikipedia article\n:link to invisible sections"
  },
  {
    "objectID": "Misc/External.html#end",
    "href": "Misc/External.html#end",
    "title": "External",
    "section": "end",
    "text": "end\n\nlibrary(flashCard)\ndf1 &lt;- data.frame(\n  front = c(\"Title front\",\"contentfront\", \"content second line\"),\n  back =c(\"Title back\",\"content back\", \"second line\")\n)\nflashCard(df1, elementId = \"card\", front_text_color = \"white\")"
  },
  {
    "objectID": "Misc/HTW_ToDo.html",
    "href": "Misc/HTW_ToDo.html",
    "title": "HTW To-do and Notes",
    "section": "",
    "text": "Model To-do\n\n\n\n\n\n\nFit to Train then Predict Transfer vs. Fitting to all stages\nSeparate ALM and EXAM Fits\nALM + Prior Knowledge (initial anchor at 0)\nEmpirical Learning Model\nIndividual vs. Group fits\nUsing Cognitive Model parameters to predict testing Vx vs. Deviation vs. Discrimination\nModel Recovery?\nApproximate Bayes?\n\n\n\n\n\n\n\n\n\n\n\n\nAnalysis To-do\n\n\n\n\nDiscrimination\nMixed Models?\n\n\n\n\n\n\n\n\n\nSite to-do\n\n\n\n\nConfigure react tables"
  },
  {
    "objectID": "Misc/HTW_ToDo.html#to-do-list",
    "href": "Misc/HTW_ToDo.html#to-do-list",
    "title": "HTW To-do and Notes",
    "section": "",
    "text": "Model To-do\n\n\n\n\n\n\nFit to Train then Predict Transfer vs. Fitting to all stages\nSeparate ALM and EXAM Fits\nALM + Prior Knowledge (initial anchor at 0)\nEmpirical Learning Model\nIndividual vs. Group fits\nUsing Cognitive Model parameters to predict testing Vx vs. Deviation vs. Discrimination\nModel Recovery?\nApproximate Bayes?\n\n\n\n\n\n\n\n\n\n\n\n\nAnalysis To-do\n\n\n\n\nDiscrimination\nMixed Models?\n\n\n\n\n\n\n\n\n\nSite to-do\n\n\n\n\nConfigure react tables"
  },
  {
    "objectID": "Misc/HTW_ToDo.html#notes",
    "href": "Misc/HTW_ToDo.html#notes",
    "title": "HTW To-do and Notes",
    "section": "Notes",
    "text": "Notes\n\n\n\n\n\n\nHuman Regression or Rule\n\n\n\n\n\n\n\n\n\n\n\n\nALM & EXAM Implementations\n\n\n\n\n\n\n\n\n\n\n\n\nALM Likelihood\n\n\n\n\n\n\n\n\n\n\n\n\nHTW DP"
  },
  {
    "objectID": "Misc/Task.html",
    "href": "Misc/Task.html",
    "title": "HTW Task",
    "section": "",
    "text": "need to create a demo version without consent form. And maybe separate windows for the different versions.\n\nExperimental Task for the HTW Project. Programmed in Javascript, and making use of phaser.js."
  },
  {
    "objectID": "Misc/Task.html#htw-task",
    "href": "Misc/Task.html#htw-task",
    "title": "HTW Task",
    "section": "",
    "text": "need to create a demo version without consent form. And maybe separate windows for the different versions.\n\nExperimental Task for the HTW Project. Programmed in Javascript, and making use of phaser.js."
  },
  {
    "objectID": "Misc/Task.html#live-task-demo",
    "href": "Misc/Task.html#live-task-demo",
    "title": "HTW Task",
    "section": "Live Task Demo",
    "text": "Live Task Demo\n\n\n\nHTW_Task\n\n\n\n   –&gt;"
  },
  {
    "objectID": "Misc/benchmarks.html",
    "href": "Misc/benchmarks.html",
    "title": "Benchmarking",
    "section": "",
    "text": "Code\npacman::p_load(tidyverse,foreach,doParallel,future,furrr)\npurrr::walk(c(\"Functions/alm_functions.R\",\"Functions/Display_Functions.R\"),source)\n\nn_cores &lt;- parallel::detectCores()\n\nparam_grid &lt;- tibble(crossing(\n  c = seq(.5,5,.25),\n  lr = seq(0.01, 1,.1),\n  noise_sd = c(0,.0001,0.001, 0.01),\n  inNodes = c(5, 7,14,28),\n  outNodes = c(16, 32,64)\n))\nnrow(param_grid)\n\ngen_train &lt;- function(trainVec=c(5,6,7),trainRep=3,noise=0){\n  bandVec=c(0,100,350,600,800,1000,1200)\n  if(class(trainVec)==\"list\"){trainVec=unlist(trainVec)}\n  ts &lt;- rep(seq(1,length(trainVec)),trainRep)\n  noiseVec=rnorm(length(ts),mean=0)*noise\n  if(noise==0) {noiseVec=noiseVec*0}\n  tibble(trial=seq(1,length(ts)),input=trainVec[ts],vx=bandVec[trainVec[ts]]+noiseVec)\n}\nfit_alm &lt;- function(data, c, lr, noise_sd, inNodes, outNodes) {\n  mse_list &lt;- replicate(5, {\n    train_data &lt;- data[, c(\"trial\", \"input\", \"cor\")] %&gt;% rename(\"vx\" = cor)\n    sim_result &lt;- sim_train(\n      dat = train_data,\n      c = c,\n      lr = lr,\n      inNodes = inNodes,\n      outNodes = outNodes,\n      noise_sd = noise_sd\n    )\n    train_data$almTrain &lt;- sim_result$almTrain\n    mse &lt;- mean((data$vx - train_data$almTrain)^2)\n    mse\n  })\n  avg_mse &lt;- mean(mse_list)\n  return(avg_mse)\n}\n\ngt &lt;- gen_train(trainVec=c(5,6,7),trainRep=8) %&gt;% mutate(cor=vx,err=(800-0)*exp(-.1*seq(1,n()))+0,vx=cor-err)\n\n\nfurrr::furrr_options(seed = TRUE)\nplan(multisession, workers = n_cores-1)\ntff &lt;- system.time({\n\nparam_grid &lt;- param_grid %&gt;% mutate(performance = future_map_dbl(seq_len(nrow(.)), function(idx) {\n    fit_alm(gt, c = c[idx], lr = lr[idx], noise_sd = noise_sd[idx], inNodes = inNodes[idx], outNodes = outNodes[idx])\n  },.options = furrr_options(seed = T)))\n  best_paramsF &lt;- param_grid %&gt;%\n    arrange((performance)) \n  bestF &lt;- head(best_paramsF,1)\n})\n\n\n# cluster &lt;- parallel::makeCluster(n_cores-1)                 \n# doParallel::registerDoParallel(cluster)\n# tfP &lt;- system.time({\n#   param_grid &lt;- param_grid %&gt;%\n#     mutate(performance = foreach(idx = seq_len(nrow(.)), .combine = c) %dopar% {\n#       fit_alm(gt, c = c[idx], lr = lr[idx], noise_sd = noise_sd[idx], inNodes = inNodes[idx], outNodes = outNodes[idx])\n#     })\n#   best_paramsP &lt;- param_grid %&gt;%\n#     arrange((performance)) \n#   bestP &lt;- head(best_paramsP,1)\n#   })\n# stopImplicitCluster()\n#   tfP\n\n\ntI &lt;- system.time({\ngt &lt;- gen_train(trainVec=c(5,6,7),trainRep=8) %&gt;% mutate(cor=vx,err=(600-0)*exp(-.1*seq(1,n()))+0,vx=cor-err)\n\nparam_grid &lt;- param_grid %&gt;%\n  mutate(performance = map_dbl(seq_len(nrow(.)), ~ {\n    fit_alm(gt, c = c[.x], lr = lr[.x], noise_sd = noise_sd[.x], inNodes = inNodes[.x], outNodes = outNodes[.x])\n  }))\nbest_paramsI &lt;- param_grid %&gt;%\n  arrange((performance)) \nbestI &lt;- head(best_paramsI,1)\n})\n\ntI\n\n\n\n\ncat(paste0(\"furr time=\",round(tff[\"elapsed\"],2),\" \\n \",\n          # \"foreach parallel time=\",round(tfP[\"elapsed\"],2),\" \\n \",\n           \" Standard Time=\",round(tI[\"elapsed\"],2)))\n\n\n4.2 -6.2 times faster with furr on m1\n\n\n\nRuns\nMachine\nCores\nMethod\nTime (seconds)\n\n\n\n\n9120\nM1\n9/10\nFurr\n9.56\n\n\n9120\nM1\n9/10\nStandard\n58.8\n\n\n912\nM1\n8/10\nStandard\n5.7\n\n\n912\nM1\n8/10\nParallel\n1.2\n\n\n912\nM1\n9/10\nFurr\n1.3\n\n\n912\n2015 iMac\n2/4\nStandard\n26.2\n\n\n912\n2015 iMac\n2/4\nParallel\n18.5\n\n\n912\n2015 iMac\n3/4\nFurr\n12.88\n\n\n912\nGTX\n3/4\nStandard\n25.32\n\n\n912\nGTX\n3/4\nFurr\n13.1\n\n\n\n\nFurrr and standard version both work equally fast, tested with up to 120 simulation repetitions\n\n\nCode\nlibrary(furrr)\nfurrr::furrr_options(seed = TRUE)\nplan(multisession, workers = parallel::detectCores())\n\nparmVec &lt;- tibble(crossing(c = c(0.1,.5), lr = c(0.4), noise = c(500), trainRep = c(20), lossFun = list(\"RMSE\", \"RMSE.blocked\"), simNum = 1:30))\ntf &lt;- system.time(\nsdpf &lt;- parmVec %&gt;% \n  mutate(d = future_pmap(list(c, lr, noise, trainRep), ~sim_data(c = ..1, lr = ..2, noise = ..3, trainRep = ..4),\n                         .options = furrr_options(seed = T)),\n                           almTrainDat = map(d, \"almTrain\"),\n                          almTestDat = map(d, \"almPred\"),\n                          examTestDat = map(d, \"examPred\"),\n                          td = map(trainRep, ~gen_train(trainRep = .)),\n                          fitO = map2(td, lossFun, ~wrap_optim(.x, .y)),\n                          fitG = map2(td, lossFun, ~wrap_grid(.x, .y)),\n                          cFitO = map_dbl(fitO, \"c\"),\n                          lrFitO = map_dbl(fitO, \"lr\"),\n                          optimValO = map_dbl(fitO, \"Value\"),\n                          cFitG = map_dbl(fitG, \"c\"),\n                          lrFitG = map_dbl(fitG, \"lr\"),\n                          optimValG = map_dbl(fitG, \"Value\"))\n)\ntf\n\nts &lt;- system.time(\nsdp &lt;- parmVec %&gt;% mutate(d = pmap(list(c, lr, noise, trainRep), ~sim_data(c = ..1, lr = ..2, noise = ..3, trainRep = ..4)),\n                          almTrainDat = map(d, \"almTrain\"),\n                          almTestDat = map(d, \"almPred\"),\n                          examTestDat = map(d, \"examPred\"),\n                          td = map(trainRep, ~gen_train(trainRep = .)),\n                          fitO = map2(td, lossFun, ~wrap_optim(.x, .y)),\n                          fitG = map2(td, lossFun, ~wrap_grid(.x, .y)),\n                          cFitO = map_dbl(fitO, \"c\"),\n                          lrFitO = map_dbl(fitO, \"lr\"),\n                          optimValO = map_dbl(fitO, \"Value\"),\n                          cFitG = map_dbl(fitG, \"c\"),\n                          lrFitG = map_dbl(fitG, \"lr\"),\n                          optimValG = map_dbl(fitG, \"Value\"))\n)\nts\n\n\nM1 Max times: tf user system elapsed 221.326 4.517 226.233\nts user system elapsed 221.140 4.288 225.330\nMac Pro times: tf user system elapsed 1125.102 76.859 1474.612\nts user system elapsed 1132.716 76.260 1493.154\n\nBenchmarking ALM Model Fit Functions\n\n\nCode\npacman::p_load(tidyverse,data.table,microbenchmark())\n\n\nd &lt;- readRDS('dPrune-01-19-23.rds')\n\ndtest &lt;- d %&gt;% filter(expMode %in% c(\"test-Nf\",\"test-train-nf\")) %&gt;% group_by(id,lowBound) %&gt;% \n  mutate(nBand=n(),band=bandInt,id=factor(id)) %&gt;% group_by(id) %&gt;% mutate(nd=n_distinct(lowBound))\n# unique(dtest[dtest$nd==4,]$sbjCode) # 7 in wrong condition\ndtest &lt;- dtest %&gt;% group_by(id,lowBound) %&gt;% filter(nBand&gt;=5 & nd==6)\n# for any id that has at least 1 nBand &gt;=5, remove all rows with that id. \ndtest &lt;- dtest %&gt;% group_by(id) %&gt;% filter(!id %in% unique(dtest$id[dtest$nBand&lt;5]))\n\ndtestAgg &lt;- dtest %&gt;% group_by(id,condit,catOrder,feedbackType,vb,band,lowBound,highBound,input) %&gt;% mutate(vxCapped=ifelse(vx&gt;1600,1600,vx)) %&gt;%\n  summarise(vxMean=mean(vx),devMean=mean(dist),vxMed=median(vx),devMed=median(dist),\n            vxMeanCap=mean(vxCapped),.groups = \"keep\")\n\n# select first row for each id in d, then create histogram for nTrain\n#  d  %&gt;% group_by(id) %&gt;% slice(1) %&gt;% ggplot(aes(nTrain)) + geom_histogram() + facet_wrap(~condit)\n  \nds &lt;- d %&gt;% filter(expMode %in% c(\"train\",\"train-Nf\",\"test-Nf\",\"test-train-nf\")) %&gt;% \nfilter(!id %in% unique(dtest$id[dtest$nBand&lt;5])) %&gt;% \nselect(id,condit,catOrder,feedbackType,expMode,trial,gt.train,vb,band,bandInt,lowBound,highBound,input,vx,dist,vxb) \n\ndst &lt;- ds %&gt;% filter(expMode==\"train\",catOrder==\"orig\")\n\nvTrainTrial &lt;- dst %&gt;% filter(condit==\"Varied\",gt.train&lt;=84) %&gt;% group_by(gt.train,vb) %&gt;% summarise(sdVx=sd(vx),vx=mean(vx),sdDist=sd(dist),dist=mean(dist)) %&gt;% \n  group_by(vb) %&gt;% mutate(gt.trainBin=cut(gt.train,breaks=5,labels=c(1:5)))\n\nbinTrainTrial &lt;- dst %&gt;% filter(gt.train&lt;=83) %&gt;% group_by(gt.train,vb,condit) %&gt;% summarise(sdVx=sd(vx),vx=mean(vx),sdDist=sd(dist),dist=mean(dist)) %&gt;% \n  group_by(vb) %&gt;% mutate(gt.trainBin=cut(gt.train,breaks=6,labels=c(1:6)))\n\n\ntMax=84\nbandVec &lt;- rep(c(800,1000,1200),each=tMax/3)\nbandVec &lt;- bandVec[sample(1:length(bandVec),tMax,replace=FALSE)]\n\ntrainTrials &lt;- dst %&gt;% filter(gt.train&lt;=tMax) %&gt;% group_by(condit,gt.train,vb,bandInt,input) %&gt;% summarise(vx=mean(vx)) \n\ninput.activation&lt;-function(x.target, c){\n  return(exp(-1*c*(x.target-inputNodes)^2))\n}\n\noutput.activation&lt;-function(x.target, weights, c){\n  return(weights%*%input.activation(x.target, c))\n}\n\nmean.prediction&lt;-function(x.target, weights, association.parameter){\n  probability&lt;-output.activation(x.target, weights, c)/sum(output.activation(x.target, weights, c))\n  return(outputNodes%*%probability) # integer prediction\n}\n# function to generate exam predictions\nexam.prediction&lt;-function(x.target, weights, c,trainVec){\n  #trainVec = sort(unique(x.learning))\n  nearestTrain = trainVec[which.min(abs(trainVec-x.target))]\n  aresp = mean.prediction(nearestTrain, weights, c)\n  xUnder = ifelse(min(trainVec) == nearestTrain, nearestTrain, trainVec[which(trainVec == nearestTrain) - 1])\n  xOver = ifelse(max(trainVec) == nearestTrain, nearestTrain, trainVec[which(trainVec == nearestTrain) + 1])\n  mUnder = mean.prediction(xUnder, weights, c)\n  mOver = mean.prediction(xOver, weights, c)\n  exam.output = round(aresp + ((mOver - mUnder) / (xOver - xUnder)) * (x.target - nearestTrain), 3)\n  exam.output\n}\n  \nupdate.weights&lt;-function(x.new, y.new, weights, c, lr){\n  y.feedback.activation&lt;-exp(-1*c*(y.new-outputNodes)^2)\n  x.feedback.activation&lt;-output.activation(x.new, weights, c)\n  return(weights+lr*(y.feedback.activation-x.feedback.activation)%*%t(input.activation(x.new, c)))\n}\n\ntrain.alm&lt;-function(dat, c=0.05, lr=0.5, weights){\n   alm.train&lt;-rep(NA,nrow(dat))  \n  for (i in 1:nrow(dat)){\n    weights &lt;- update.weights(dat$input[i], dat$vx[i], weights, c, lr)\n    resp = mean.prediction(dat$input[i], weights, c)\n    alm.train[i]=resp\n    weights[weights&lt;0]=0\n  }\n  alm.train\n}\n\nwrap_alm &lt;- function(parms,dat, weights,lossFun){\n    c=parms[1]; lr=parms[2]\n   pred=train.alm(dat, c=c, lr=lr, weights=weights)\n   #sqrt(mean((dat$vx -pred)^2))\n   lossFun(dat$vx,pred)\n}\n\nwrap_optim &lt;- function(dat,wm,lossFun){\n  bounds_lower &lt;- c(.0000001, .00001)\n  bounds_upper &lt;- c(5, 5)\n\n optim(c(.1, .2),\n   fn = wrap_alm,\n   dat = dat, weights = wm,lossFun=lossFun,\n   method = \"L-BFGS-B\",\n   lower = bounds_lower,\n   upper = bounds_upper,\n   control = list(maxit = 1e4, pgtol = 0, factr = 0)\n )\n}\n\nRMSE &lt;- function(x,y){\n  sqrt(mean((x-y)^2))\n}\n\n## First average observed and predicted data into blocks, then compute RMSE\nRMSE.tb &lt;- function(x,y,blocks=6){\n  data.frame(x,y) %&gt;% mutate(t=row_number(),fitBins=cut(t,breaks=blocks,labels=c(1:blocks))) %&gt;%\n    group_by(fitBins) %&gt;% \n    summarise(predMean=mean(x),obsMean=mean(y)) %&gt;% \n    summarise(RMSE(predMean,obsMean)) %&gt;% as.numeric()\n}\n\n## Recode RMSE.tb using data.table functions rather than dplyr\nRMSE.tb2 &lt;- function(x,y,blocks=6){\n  data.table(x=x,y=y,t=seq(1,length(x))) %&gt;% \n    .[, `:=`(fitBins = cut(t, breaks = ..blocks, labels = c(1:..blocks)))] %&gt;%\n    .[, .(predMean = mean(x), obsMean = mean(y)), keyby = .(fitBins)] %&gt;%\n    .[, RMSE(predMean,obsMean)] %&gt;% as.numeric()\n}\n\n\n\ndplyr RMSE vs data.table RMSE\n\n\nCode\ndpVsDt=microbenchmark(\n  dplyrMethod={\n  fitVaried &lt;- tv %&gt;% filter(condit==\"Varied\") %&gt;% wrap_optim(.,wm,lossFun=RMSE.tb);\n  fitConstant &lt;- tv %&gt;% filter(condit==\"Constant\") %&gt;% wrap_optim(.,wm,lossFun=RMSE.tb)},\n  dtMethod={\n  fitVaried2 &lt;- tv %&gt;% filter(condit==\"Varied\") %&gt;% wrap_optim(.,wm,lossFun=RMSE.tb2);\n  fitConstant2 &lt;- tv %&gt;% filter(condit==\"Constant\") %&gt;% wrap_optim(.,wm,lossFun=RMSE.tb2)},\n  times=5\n)\nknitr::kable(summary(dpVsDt),format=\"markdown\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nexpr\nmin\nlq\nmean\nmedian\nuq\nmax\nneval\ncld\n\n\n\n\ndplyrMethod\n11.282291\n12.996857\n13.558623\n13.970367\n14.658515\n14.885086\n5\na\n\n\ndtMethod\n4.933999\n5.306232\n5.681235\n5.515397\n6.131193\n6.519355\n5\nb\n\n\n\nThe data.table version seems to be consistently more than 2x faster\n\n\nSeparate fits, vs. nesting method vs. split method\n\n\nCode\nnestSplit&lt;-microbenchmark(\nseparate={fitVaried &lt;- tv %&gt;% filter(condit==\"Varied\") %&gt;% wrap_optim(.,wm,lossFun=RMSE.tb2);\nfitConstant &lt;- tv %&gt;% filter(condit==\"Constant\") %&gt;% wrap_optim(.,wm,lossFun=RMSE.tb2) },\nnestGroups = tv %&gt;% group_by(condit) %&gt;% nest() %&gt;% mutate(fit=map(data,~wrap_optim(.,wm,RMSE.tb2))),\nsplitGroups = tv %&gt;% split(.$condit) %&gt;% map(~wrap_optim(.,wm,RMSE.tb2)),\ntimes=5\n)\nknitr::kable(summary(nestSplit),format=\"markdown\") # 03/02/23 - Mac Pro\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nexpr\nmin\nlq\nmean\nmedian\nuq\nmax\nneval\ncld\n\n\n\n\nseparate\n6.394459\n6.483235\n6.709882\n6.508353\n7.059420\n7.103941\n5\na\n\n\nnestGroups\n6.253850\n6.457956\n6.789962\n6.756942\n7.044965\n7.436094\n5\na\n\n\nsplitGroups\n6.117184\n6.455866\n6.605814\n6.461572\n6.640798\n7.353648\n5\na\n\n\n\nNot much of an effect for nesting method.\n\n\nComputing RMSE over Raw trials vs. RMSE of blocked training performance\n\n\nCode\ntrialBlock&lt;-microbenchmark(\n  trialFit = tv %&gt;% split(.$condit) %&gt;% map(~wrap_optim(.,wm,RMSE)),\n  blockFit = tv %&gt;% split(.$condit) %&gt;% map(~wrap_optim(.,wm,RMSE.tb2)),\n  times=5\n)\nknitr::kable(summary(trialBlock),format=\"markdown\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nexpr\nmin\nlq\nmean\nmedian\nuq\nmax\nneval\ncld\n\n\n\n\ntrialFit\n2.665184\n2.674186\n2.806476\n2.803491\n2.843806\n3.045712\n5\na\n\n\nblockFit\n5.169167\n5.264218\n5.350769\n5.285151\n5.491828\n5.543483\n5\nb\n\n\n\nThe models are fit about 2x faster when computing RMSE over trials. This shouldn’t be surprising, since fitting to blocked data requires several additional computations (e.g. grouping, computing means)"
  },
  {
    "objectID": "Misc/htw_dp.html",
    "href": "Misc/htw_dp.html",
    "title": "Project 2",
    "section": "",
    "text": "In project 1, we applied model-based techniques to quantify and control for the similarity between training and testing experience, which in turn enabled us to account for the difference between varied and constant training via an extended version of a similarity based generalization model. In project 2, we will go a step further, implementing a full process model capable of both 1) producing novel responses and 2) modeling behavior in both the learning and testing stages of the experiment. Project 2 also places a greater emphasis on extrapolation performance following training - as varied training has often been purported to be particularly beneficial in such situations. Extrapolation has long been a focus of the literature on function learning (Brehmer 1974; Carroll 1963). Central questions of the function learning literature have included the relative difficulties of learning various functional forms (e.g. linear vs.bilinear vs. quadratic), and the relative effectiveness of rule-based vs. association-based exemplar models vs. various hybrid models (Bott and Heit 2004; DeLosh, McDaniel, and Busemeyer 1997; Jones et al. 2018; Kalish, Lewandowsky, and Kruschke 2004; M. A. Mcdaniel and Busemeyer 2005; M. Mcdaniel et al. 2009). However the issue of training variation has received surprisingly little attention in this area."
  },
  {
    "objectID": "Misc/htw_dp.html#participants",
    "href": "Misc/htw_dp.html#participants",
    "title": "Project 2",
    "section": "Participants",
    "text": "Participants\nData was collected from 647 participants (after exclusions). The results shown below consider data from subjects in our initial experiment, which consisted of 196 participants (106 constant, 90 varied). The follow-up experiments entailed minor manipulations: 1) reversing the velocity bands that were trained on vs. novel during testing; 2) providing ordinal rather than numerical feedback during training (e.g. correct, too low, too high). The data from these subsequent experiments are largely consistently with our initial results shown below."
  },
  {
    "objectID": "Misc/htw_dp.html#task",
    "href": "Misc/htw_dp.html#task",
    "title": "Project 2",
    "section": "Task",
    "text": "Task\nWe developed a novel visuomotor extrapolation task, termed the “Hit The Wall” (HTW) task, wherein participants learned to launch a projectile such that it hit a rectangle at the far end of the screen with an appropriate amount of force. Although the projectile had both x and y velocity components, only the x-dimension was relevant for the task.  Link to task demo"
  },
  {
    "objectID": "Misc/htw_dp.html#design",
    "href": "Misc/htw_dp.html#design",
    "title": "Project 2",
    "section": "Design",
    "text": "Design\n\n90 training trials split evenly divided between velocity bands. Varied training with 3 velocity bands and Constant training with 1 band.\nNo-feedback testing from 3 novel extrapolation bands. 15 trials each.  \nNo-feedbacd testing from the 3 bands used during the training phase (2 of which were novel for the constant group). 9 trials each.\nFeedback testing for each of the 3 extrapolation bands. 10 trials each.\n\n\n\n\n\nExperiment Procedure"
  },
  {
    "objectID": "Misc/htw_dp.html#training",
    "href": "Misc/htw_dp.html#training",
    "title": "Project 2",
    "section": "Training",
    "text": "Training\nTraining performance is shown in Results Figure 2A. All groups show improvement from each of their training velocity-bands (i.e. decreasing average distance from target). In the velocity band trained at by both groups (800-1000), the constant group maintains a superior level of performance from the early through the final stages of training. This difference is unsurprising given that the constant group had 3x more practice trials from that band.\n\n\nCode\n#fig.cap=\"\\\\label{fig:figs}training performance\"\n\n#title=paste0(\"HTW Training\")\n#figpatch::fig(here(\"Assets/Training-1.png\"))\nknitr::include_graphics(here(\"Assets/Training-1.png\"))\n\n\n\n\n\nCode\n  #fig_lab(.,title,pos=\"top\",fontface='bold',size=12,hjust=.01)"
  },
  {
    "objectID": "Misc/htw_dp.html#testing",
    "href": "Misc/htw_dp.html#testing",
    "title": "Project 2",
    "section": "Testing",
    "text": "Testing\nFor evaluating testing performance, we consider 3 separate metrics. 1) The average absolute deviation from the correct velocity, 2) The % of throws in which the wall was hit with the correct velocity and 3) The average x velocity produced.\nResults Figure 2B shows the average velocity produced for all 6 bands that were tested. At least at the aggregate level, both conditions were able to differentiate all 6 bands in the correct order, despite only having received training feedback for 1/6 (constant) or 3/6 (varied) bands during training. Participants in both groups also had a bias towards greatly overestimating the correct velocity for band 100-300, for which both groups had an average of greater than 500.\n\n\nCode\n# fig2aCap=str_wrap(\"Figure 2B: Bands 100-300, 350-550 and 600-800 are novel extrapolations for both groups. Band 800-1000 was a training band for both groups. Bands 1000-1200, and 1200-1400 were trained for the varied group, and novel for the constant group.  Top figure displays mean deviation from correct velocity. Bottom figure displays the average % of trials where participants hit the wall with the correct velocity. Error bars indicate standard error of the mean. \" ,width=170)\n\n\n#figpatch::fig(here(\"Assets/Testing_Vx-1.png\"))\nknitr::include_graphics(here(\"Assets/Testing_Vx-1.png\"))\n\n\n\n\n\nAs is reflected in Results Figure 2C, the constant group performed significantly better than the varied group at the 3 testing bands of greatest interest. Both groups tended to perform worse for testing bands further away from their training conditions. The varied group had a slight advantage for bands 1000-1200 and 1200-1400, which were repeats from training for the varied participants, but novel for the constant participants.\n\n\nCode\n#figpatch::fig(here(\"Assets/Test_Performance-1.png\"))\nknitr::include_graphics(here(\"Assets/Test_Performance-1.png\"))\n\n\n\n\n\nCode\n# \n# gtitle=\"2C. Testing Performance\"\n# title = ggdraw()+draw_label(gtitle,fontface = 'bold',x=0,hjust=0)+theme(plot.margin = margin(0, 0, 0, 7))\n# captionText=str_wrap(\"Figure 2C: Bands 100-300, 350-550 and 600-800 are novel extrapolations for both groups. Band 800-1000 was a training band for both groups. Bands 1000-1200, and 1200-1400 were trained for the varied group, and novel for the constant group.  Right side figure displays mean deviation from correct velocity band (lower values correspond to better performance). Bottom Left displays the average % of trials where participants hit the wall with the correct velocity (higher values correspond got better performance). Error bars indicate standard error of the mean. \",150)\n# capt=ggdraw()+draw_label(captionText,fontface = 'italic',x=0,hjust=0,size=11)+theme(plot.margin = margin(0, 0, 0, 1))\n# \n# plot_grid(title,NULL,leg,NULL,gbDev,gbHit,capt,NULL,ncol=2,rel_heights=c(.1,.1,1,.1),rel_widths=c(1,1))"
  },
  {
    "objectID": "Misc/htw_dp.html#alm-exam-description",
    "href": "Misc/htw_dp.html#alm-exam-description",
    "title": "Project 2",
    "section": "ALM & Exam Description",
    "text": "ALM & Exam Description\nDelosh et al. (1997) introduced the associative learning model (ALM), a connectionist model within the popular class of radial-basis networks. ALM was inspired by, and closely resembles Kruschke’s influential ALCOVE model of categorization (Kruscke 1992).\nALM is a localist neural network model, with each input node corresponding to a particular stimulus, and each output node corresponding to a particular response value. The units in the input layer activate as a function of their Gaussian similarity to the input stimulus. So, for example, an input stimulus of value 55 would induce maximal activation of the input unit tuned to 55. Depending on thevalue of the generalization parameter, the nearby units (e.g. 54 and 56; 53 and 57) may also activate to some degree. ALM is structured with input and output nodes that correspond to regions of the stimulus space, and response space, respectively. The units in the input layer activate as a function of their similarity to a presented stimulus. As was the case with the exemplar-based models, similarity in ALM is exponentially decaying function of distance. The input layer is fully connected to the output layer, and the activation for any particular output node is simply the weighted sum of the connection weights between that node and the input activations. The network then produces a response by taking the weighted average of the output units (recall that each output unit has a value corresponding to a particular response). During training, the network receives feedback which activates each output unit as a function of its distance from the ideal level of activation necessary to produce the correct response. The connection weights between input and output units are then updated via the standard delta learning rule, where the magnitude of weight changes are controlled by a learning rate parameter.\nSee Table 2A for a full specification of the equations that define ALM and EXAM."
  },
  {
    "objectID": "Misc/htw_dp.html#model-equations",
    "href": "Misc/htw_dp.html#model-equations",
    "title": "Project 2",
    "section": "Model Equations",
    "text": "Model Equations\n\n\nCode\ntext_tbl &lt;- data.frame(\n    'Step'=c(\"Input Activation\",\"Output Activation\",\"Output Probability\",\"Mean Output\",\"Feedback Activation\",\"Update Weights\",\"Extrapolation\",\"\"),\n    'Equation' = c(\"$a_i(X) = \\\\frac{e^{-c \\\\cdot (X-X_i)^2}}{ \\\\sum_{k=1}^Me^{-c \\\\cdot (X-X_i)^2}}$\", \n                   '$O_j(X) = \\\\sum_{k=1}^Mw_{ji} \\\\cdot a_i(X)$',\n                   '$P[Y_j | X] = \\\\frac{O_i(X)}{\\\\sum_{k=1}^Mo_k(X)}$',\n                   \"$m(x) = \\\\sum_{j=1}^LY_j \\\\cdot \\\\bigg[\\\\frac{O_j(X)}{\\\\sum_{k=1}^Lo_k(X)}\\\\bigg]$\",\n                   \"$f_j(Z)=e^{-c\\\\cdot(Z-Y_j)^2}$\",\n                   \"$w_{ji}(t+1)=w_{ji}(t)+\\\\alpha \\\\cdot {f_i(Z(t))-O_j(X(t))} \\\\cdot a_i(X(t))$\",\n                   \"$P[X_i|X] = \\\\frac{a_i(X)}{\\\\sum_{k=1}^Ma_k(X)}$\",\n                   \"$E[Y|X_i]=m(X_i) + \\\\bigg[\\\\frac{m(X_{i+1})-m(X_{i-1})}{X_{i+1} - X_{i-1}} \\\\bigg] \\\\cdot[X-X_i]$\"),\n    \n    'Description'= c(\n            \"Activation of each input node, $X_i$, is a function of the Gaussian similarity between the node value and stimulus X. \",\n            \"Activation of each Output unit $O_j$ is the weighted sum of the input activations and association weights\",\n            \"Each output node has associated response, $Y_j$. The probability of response $Y_j$ is determined by the ratio of output activations\",\n            \"The response to stimulus x is the weighted average of the response probabilities\",\n            \"After responding, feedback signal Z is presented, activating each output node via the Gaussian similarity to the ideal response  \",\n            \"Delta rule to update weights. Magnitude of weight changes controlled by learning rate parameter alpha.\",\n            \"Novel test stimulus X activates input nodes associated with trained stimuli\",\n            \"Slope value computed from nearest training instances and then added to the response associated with the nearest training instance,m(x)\")\n)\ntext_tbl$Step=cell_spec(text_tbl$Step,font_size=12)\ntext_tbl$Equation=cell_spec(text_tbl$Equation,font_size=18)\nalmTable=kable(text_tbl, 'html', \n  booktabs=T, escape = F, align='l',\n  caption = '&lt;span style = \"color:black;\"&gt;&lt;center&gt;&lt;strong&gt;Table 1: ALM & EXAM Equations&lt;/strong&gt;&lt;/center&gt;&lt;/span&gt;',\n  col.names=c(\"\",\"Equation\",\"Description\")) %&gt;%\n  kable_styling(position=\"left\",bootstrap_options = c(\"hover\")) %&gt;%\n  column_spec(1, bold = F,border_right=T) %&gt;%\n  column_spec(2, width = '10cm')%&gt;%\n  column_spec(3, width = '15cm') %&gt;%\n  pack_rows(\"ALM Activation & Response\",1,4,bold=FALSE,italic=TRUE) %&gt;%\n  pack_rows(\"ALM Learning\",5,6,bold=FALSE,italic=TRUE) %&gt;%\n  pack_rows(\"EXAM\",7,8,bold=FALSE,italic=TRUE)\n  #save_kable(file=\"almTable.html\",self_contained=T)\n#almTable\n\n\ncat(almTable)\n\n\n\n\n\nTable 1: ALM & EXAM Equations\n\n\n\n\n\n\n\n\nEquation\n\n\nDescription\n\n\n\n\n\n\nALM Activation & Response\n\n\n\n\nInput Activation\n\n\n\\(a_i(X) = \\frac{e^{-c \\cdot (X-X_i)^2}}{ \\sum_{k=1}^Me^{-c \\cdot (X-X_i)^2}}\\)\n\n\nActivation of each input node, \\(X_i\\), is a function of the Gaussian similarity between the node value and stimulus X.\n\n\n\n\nOutput Activation\n\n\n\\(O_j(X) = \\sum_{k=1}^Mw_{ji} \\cdot a_i(X)\\)\n\n\nActivation of each Output unit \\(O_j\\) is the weighted sum of the input activations and association weights\n\n\n\n\nOutput Probability\n\n\n\\(P[Y_j | X] = \\frac{O_i(X)}{\\sum_{k=1}^Mo_k(X)}\\)\n\n\nEach output node has associated response, \\(Y_j\\). The probability of response \\(Y_j\\) is determined by the ratio of output activations\n\n\n\n\nMean Output\n\n\n\\(m(x) = \\sum_{j=1}^LY_j \\cdot \\bigg[\\frac{O_j(X)}{\\sum_{k=1}^Lo_k(X)}\\bigg]\\)\n\n\nThe response to stimulus x is the weighted average of the response probabilities\n\n\n\n\nALM Learning\n\n\n\n\nFeedback Activation\n\n\n\\(f_j(Z)=e^{-c\\cdot(Z-Y_j)^2}\\)\n\n\nAfter responding, feedback signal Z is presented, activating each output node via the Gaussian similarity to the ideal response\n\n\n\n\nUpdate Weights\n\n\n\\(w_{ji}(t+1)=w_{ji}(t)+\\alpha \\cdot {f_i(Z(t))-O_j(X(t))} \\cdot a_i(X(t))\\)\n\n\nDelta rule to update weights. Magnitude of weight changes controlled by learning rate parameter alpha.\n\n\n\n\nEXAM\n\n\n\n\nExtrapolation\n\n\n\\(P[X_i|X] = \\frac{a_i(X)}{\\sum_{k=1}^Ma_k(X)}\\)\n\n\nNovel test stimulus X activates input nodes associated with trained stimuli\n\n\n\n\n\n\n\n\\(E[Y|X_i]=m(X_i) + \\bigg[\\frac{m(X_{i+1})-m(X_{i-1})}{X_{i+1} - X_{i-1}} \\bigg] \\cdot[X-X_i]\\)\n\n\nSlope value computed from nearest training instances and then added to the response associated with the nearest training instance,m(x)"
  },
  {
    "objectID": "Misc/htw_dp.html#model-fitting-and-comparison",
    "href": "Misc/htw_dp.html#model-fitting-and-comparison",
    "title": "Project 2",
    "section": "Model Fitting and Comparison",
    "text": "Model Fitting and Comparison\nFollowing the procedure used by McDaniel & Busemeyer (2009), we will assess the ability of both ALM and EXAM to account for the empirical data when fitting the models to 1) only the training data, and 2) both training and testing data. Models will be fit directly to the trial by trial data of each individual participants, both by minimizing the root-mean squared deviation (RMSE), and by maximizing log likelihood. Because ALM has been shown to do poorly at accounting for human patterns extrapolation (DeLosh, McDaniel, and Busemeyer 1997), we will also fit the extended EXAM version of the model, which operates identically to ALM during training, but includes a linear extrapolation mechanism for generating novel responses during testing."
  },
  {
    "objectID": "Model/abc_htw.html",
    "href": "Model/abc_htw.html",
    "title": "Approximate Bayesian Fitting",
    "section": "",
    "text": "Code\n# load and view data\npacman::p_load(tidyverse,data.table,lme4,future,furrr,abc,mvtnorm,patchwork,here)\npurrr::walk(here(c(\"Functions/alm_functions.R\",\"Functions/Display_Functions.R\",\"Functions/Noisy_Functions.R\")),source)\n\nselect &lt;- dplyr::select; mutate &lt;- dplyr::mutate \nd &lt;- readRDS(here(\"data/dPrune-01-19-23.rds\"))\nlevels(d$condit)\n\n\n[1] \"Constant\" \"Varied\"  \n\n\nCode\n# Prepare the data for analysis\ndtest &lt;- d %&gt;% filter(expMode %in% c(\"test-Nf\",\"test-train-nf\")) %&gt;% group_by(id,lowBound) %&gt;% \n  mutate(nBand=n(),band=bandInt,id=factor(id)) %&gt;% group_by(id) %&gt;% mutate(nd=n_distinct(lowBound))\ndtest &lt;- dtest %&gt;% group_by(id,lowBound) %&gt;% filter(nBand&gt;=5 & nd==6)\ndtest &lt;- dtest %&gt;% group_by(id) %&gt;% filter(!id %in% unique(dtest$id[dtest$nBand&lt;5]))\nds &lt;- d %&gt;% filter(expMode %in% c(\"train\",\"train-Nf\",\"test-Nf\",\"test-train-nf\")) %&gt;% \nfilter(!id %in% unique(dtest$id[dtest$nBand&lt;5])) %&gt;% \nselect(id,condit,catOrder,feedbackType,expMode,trial,gt.train,vb,band,bandInt,lowBound,highBound,input,vx,dist,vxb) \ndst &lt;- ds %&gt;% filter(expMode==\"train\")\ndst &lt;- dst %&gt;%\n  group_by(id, vb) %&gt;%\n  mutate(trial_band = row_number())\nCode\ndst &lt;- dst %&gt;% filter(expMode==\"train\",catOrder==\"orig\")\nvst &lt;- dst %&gt;% filter(condit==\"Varied\",gt.train&lt;=84) %&gt;% group_by(gt.train,vb,input) %&gt;% summarise(sdVx=sd(vx),vx=mean(vx),sdDist=sd(dist),dist=mean(dist)) %&gt;% \n  group_by(vb) %&gt;% mutate(gt.trainBin=cut(gt.train,breaks=5,labels=c(1:5)),\n                          trial=gt.train) \ncst &lt;- dst %&gt;% filter(condit==\"Constant\",gt.train&lt;=84) %&gt;% group_by(gt.train,vb,input) %&gt;% summarise(sdVx=sd(vx),vx=mean(vx),sdDist=sd(dist),dist=mean(dist)) %&gt;% \n  group_by(vb) %&gt;% mutate(gt.trainBin=cut(gt.train,breaks=5,labels=c(1:5)),\n                          trial=gt.train) \n\nggplot(dst %&gt;% filter(gt.train&lt;=84), aes(x = gt.train, y = vx,color=vb)) +\n  geom_point(aes(color = vb), stat = \"summary\", fun = mean) + \n  stat_summary(aes(color = vb), geom = \"line\", fun = mean) +\n  stat_summary(geom=\"errorbar\",fun.data=mean_se,width=.4,alpha=.7)+facet_wrap(~condit)\n\n\n\n\n\nCode\n# ggplot(vst, aes(x = gt.trainBin, y = vx,color=vb)) +\n  # geom_point(aes(color = vb), stat = \"summary\", fun = mean) + \n  # stat_summary(aes(color = vb), geom = \"line\", fun = mean) +\n  # stat_summary(geom=\"errorbar\",fun.data=mean_se,width=.4,alpha=.7)+facet_wrap(~condit)"
  },
  {
    "objectID": "Model/abc_htw.html#abc-functions",
    "href": "Model/abc_htw.html#abc-functions",
    "title": "Approximate Bayesian Fitting",
    "section": "ABC Functions",
    "text": "ABC Functions\n\n\nCode\n# c=1; lr=.5; noise_sd=.001; inNodes=7; outNodes=32\nfit_alm_sim &lt;- function(data, c, lr, noise_sd, inNodes, outNodes) {\n  train_data &lt;- data[, c(\"gt.train\", \"vb\", \"vx\",\"input\")] %&gt;% rename(\"trial\" = gt.train)\n  \n  sim_result &lt;- sim_train(\n    dat = train_data,\n    c = c,\n    lr = lr,\n    inNodes = inNodes,\n    outNodes = outNodes,\n    noise_sd = noise_sd\n  )\n  \n  train_data$almTrain &lt;- sim_result$almTrain\n  return(train_data$almTrain)\n}\n\ngenerate_prior &lt;- function(n) {\n  prior_samples &lt;- tibble(\n    c = runif(n, 0.001, 5),\n    lr = runif(n, 0.001, 3),\n    noise_sd = runif(n, 0, 0.0001),\n    inNodes = sample(c( 3,7, 14,21,28,35), size = n, replace = TRUE),\n    outNodes = sample(c(8,16, 32,48,64,80,96), size = n, replace = TRUE)\n  )\n  return(prior_samples)\n}\n\n\n\nVaried ABC\n\n\nCode\nn_prior_samples &lt;- 1000\nprior_samples &lt;- generate_prior(n_prior_samples)\n\n\n# Replace gt with dst in the following line:\nsimulated_data &lt;- future_map_dfc(seq_len(nrow(prior_samples)), function(idx) {\n  params &lt;- prior_samples[idx, ]\n  fit_alm_sim(vst, params$c, params$lr, params$noise_sd, params$inNodes, params$outNodes)\n},.options = furrr_options(seed = T))\n\n# Replace gt_obs with dst_obs and gt with dst in the following lines:\ndst_obs &lt;- vst$vx\ntolerance &lt;- 0.1 * sd(dst_obs)*500\nabc_result &lt;- abc(\n  target = dst_obs,\n  param = prior_samples,\n  sumstat = do.call(rbind, simulated_data),\n  tol = .1,\n  method = \"rejection\",\n  names=colnames(dst_obs)\n)\n\n\nposterior_samples &lt;- abc_result$unadj.values\ncolnames(posterior_samples) &lt;- c(\"c\", \"lr\", \"noise_sd\", \"inNodes\", \"outNodes\")\nposterior_samples_long &lt;- tidyr::pivot_longer(as.data.frame(posterior_samples), everything())\n\npostV &lt;- ggplot(posterior_samples_long, aes(x=value)) +\n  geom_density() +\n  facet_wrap(~name, scales=\"free\") +\n  theme_minimal() +\n  labs(x=\"Value\", y=\"Density\", title=\"Posterior Density Plots\")\n\nsummary_statistics &lt;- data.frame(mean = apply(posterior_samples, 2, mean),\n  median = apply(posterior_samples, 2, median))\n( summary_statistics=rownames_to_column(summary_statistics,var=\"parameter\") )\n\n\n\ns = sim_train(dat=mutate(vst,trial=gt.train),c=summary_statistics$mean[1],lr=summary_statistics$mean[2],inNodes=summary_statistics$mean[4],outNodes=summary_statistics$mean[5],noise_sd=summary_statistics$mean[3])\n\nggp &lt;- vst %&gt;% ungroup() %&gt;% mutate(pred=s$almTrain,input=as.factor(input))\ngvp &lt;- ggp %&gt;% ggplot(aes(x = trial, y = pred, color = input)) +\n  geom_line() + ylim(c(0,1600))+ggtitle(\"ALM Predictions (ABC estimation)\")\ngvo &lt;- ggp  %&gt;% ggplot(aes(x = trial, y = vx, color = input)) +\n  geom_line() + ylim(c(0,1600))+ggtitle(\"HTW Observed Training data\")\nggpv &lt;- postV/(gvp + gvo)\n\n#ggsave(\"images/abc_varied.png\",ggpv,width=12,height=10)\n\n\n\n\nCode\nknitr::include_graphics(here(\"images/abc_varied.png\"))\n\n\n\n\n\nCode\n#![](images/abc_varied.png)\n\n\n\n\nConstant ABC\n\n\nCode\n# c=1; lr=.5; noise_sd=.001; inNodes=7; outNodes=32\n\nn_prior_samples &lt;- 1000\nprior_samples &lt;- generate_prior(n_prior_samples)\n\n# Replace gt with dst in the following line:\nsimulated_dataC &lt;- future_map_dfc(seq_len(nrow(prior_samples)), function(idx) {\n  params &lt;- prior_samples[idx, ]\n  fit_alm_sim(cst, params$c, params$lr, params$noise_sd, params$inNodes, params$outNodes)\n},.options = furrr_options(seed = T))\n\n# Replace gt_obs with dst_obs and gt with dst in the following lines:\ncst_obs &lt;- cst$vx\ntolerance &lt;- 0.1 * sd(dst_obs)*500\nabc_result &lt;- abc(\n  target = cst_obs,\n  param = prior_samples,\n  sumstat = do.call(rbind, simulated_dataC),\n  tol = .1,\n  method = \"rejection\",\n  names=colnames(cst_obs)\n)\n\n\nposterior_samples &lt;- abc_result$unadj.values\ncolnames(posterior_samples) &lt;- c(\"c\", \"lr\", \"noise_sd\", \"inNodes\", \"outNodes\")\nposterior_samples_long &lt;- tidyr::pivot_longer(as.data.frame(posterior_samples), everything())\n\npostC &lt;- ggplot(posterior_samples_long, aes(x=value)) +\n  geom_density() +\n  facet_wrap(~name, scales=\"free\") +\n  theme_minimal() +\n  labs(x=\"Value\", y=\"Density\", title=\"Posterior Density Plots\")\n\nsummary_statisticsC &lt;- data.frame(mean = apply(posterior_samples, 2, mean),\n  median = apply(posterior_samples, 2, median))\n summary_statisticsC=rownames_to_column(summary_statisticsC,var=\"parameter\") \nsummary_statisticsC\n\n\nsC = sim_train(dat=mutate(cst,trial=gt.train),c=summary_statisticsC$mean[1],lr=summary_statisticsC$mean[2],inNodes=summary_statisticsC$mean[4],outNodes=summary_statisticsC$mean[5],noise_sd=summary_statisticsC$mean[3])\n\nggpC &lt;- cst %&gt;% ungroup() %&gt;% mutate(pred=sC$almTrain,input=as.factor(input))\ngcp &lt;- ggpC %&gt;% ggplot(aes(x = trial, y = pred, color = input)) +\n  geom_line() + ylim(c(0,1600))+ggtitle(\"ALM Predictions (ABC estimation)\")\ngco &lt;- ggpC  %&gt;% ggplot(aes(x = trial, y = vx, color = input)) +\n  geom_line() + ylim(c(0,1600))+ggtitle(\"HTW Observed Constant Training data\")\npostC/(gcp + gco)\n\nggsave(here()\"images/abc_constant.png\",postC/(gcp + gco),width=12,height=10))"
  },
  {
    "objectID": "Model/group_fits.html",
    "href": "Model/group_fits.html",
    "title": "Group Level Fits",
    "section": "",
    "text": "Prep data\n\n\nCode\npacman::p_load(tidyverse,data.table,here)\noptions(dplyr.summarise.inform=FALSE)\n\n# select first row for each id in d, then create histogram for nTrain\n#  d  %&gt;% group_by(id) %&gt;% slice(1) %&gt;% ggplot(aes(nTrain)) + geom_histogram() + facet_wrap(~condit)\n\nd &lt;- readRDS(here(\"data/dPrune-01-19-23.rds\"))\ndtest &lt;- d %&gt;% filter(expMode %in% c(\"test-Nf\",\"test-train-nf\")) %&gt;% group_by(id,lowBound) %&gt;% \n  mutate(nBand=n(),band=bandInt,id=factor(id)) %&gt;% group_by(id) %&gt;% mutate(nd=n_distinct(lowBound))\n# unique(dtest[dtest$nd==4,]$sbjCode) # 7 in wrong condition\ndtest &lt;- dtest %&gt;% group_by(id,lowBound) %&gt;% filter(nBand&gt;=5 & nd==6)\n# for any id that has at least 1 nBand &gt;=5, remove all rows with that id. \ndtest &lt;- dtest %&gt;% group_by(id) %&gt;% filter(!id %in% unique(dtest$id[dtest$nBand&lt;5]))\n\ndtestAgg &lt;- dtest %&gt;% group_by(id,condit,catOrder,feedbackType,vb,band,lowBound,highBound,input) %&gt;% mutate(vxCapped=ifelse(vx&gt;1600,1600,vx)) %&gt;%\n  summarise(vxMean=mean(vx),devMean=mean(dist),vxMed=median(vx),devMed=median(dist),\n            vxMeanCap=mean(vxCapped),.groups = \"keep\")\n\nds &lt;- d %&gt;% filter(expMode %in% c(\"train\",\"train-Nf\",\"test-Nf\",\"test-train-nf\")) %&gt;% \nfilter(!id %in% unique(dtest$id[dtest$nBand&lt;5])) %&gt;% \nselect(id,condit,catOrder,feedbackType,expMode,trial,gt.train,vb,band,bandInt,lowBound,highBound,input,vx,dist,vxb) \nhead(ds)\n\n\n# A tibble: 6 × 16\n     id condit catOrder feedbackType expMode trial gt.train vb     band  bandInt\n  &lt;dbl&gt; &lt;fct&gt;  &lt;fct&gt;    &lt;fct&gt;        &lt;fct&gt;   &lt;dbl&gt;    &lt;int&gt; &lt;fct&gt;  &lt;fct&gt;   &lt;dbl&gt;\n1     1 Varied orig     continuous   train       2        1 1000-… 5        1000\n2     1 Varied orig     continuous   train       3        2 1200-… 6        1200\n3     1 Varied orig     continuous   train       4        3 800-1… 4         800\n4     1 Varied orig     continuous   train       5        4 1000-… 5        1000\n5     1 Varied orig     continuous   train       6        5 800-1… 4         800\n6     1 Varied orig     continuous   train       7        6 1000-… 5        1000\n# ℹ 6 more variables: lowBound &lt;fct&gt;, highBound &lt;dbl&gt;, input &lt;dbl&gt;, vx &lt;dbl&gt;,\n#   dist &lt;dbl&gt;, vxb &lt;dbl&gt;\n\n\nCode\ndst &lt;- ds %&gt;% filter(expMode==\"train\",catOrder==\"orig\")\nhead(dst)\n\n\n# A tibble: 6 × 16\n     id condit catOrder feedbackType expMode trial gt.train vb     band  bandInt\n  &lt;dbl&gt; &lt;fct&gt;  &lt;fct&gt;    &lt;fct&gt;        &lt;fct&gt;   &lt;dbl&gt;    &lt;int&gt; &lt;fct&gt;  &lt;fct&gt;   &lt;dbl&gt;\n1     1 Varied orig     continuous   train       2        1 1000-… 5        1000\n2     1 Varied orig     continuous   train       3        2 1200-… 6        1200\n3     1 Varied orig     continuous   train       4        3 800-1… 4         800\n4     1 Varied orig     continuous   train       5        4 1000-… 5        1000\n5     1 Varied orig     continuous   train       6        5 800-1… 4         800\n6     1 Varied orig     continuous   train       7        6 1000-… 5        1000\n# ℹ 6 more variables: lowBound &lt;fct&gt;, highBound &lt;dbl&gt;, input &lt;dbl&gt;, vx &lt;dbl&gt;,\n#   dist &lt;dbl&gt;, vxb &lt;dbl&gt;\n\n\nCode\ncolnames(dst)\n\n\n [1] \"id\"           \"condit\"       \"catOrder\"     \"feedbackType\" \"expMode\"     \n [6] \"trial\"        \"gt.train\"     \"vb\"           \"band\"         \"bandInt\"     \n[11] \"lowBound\"     \"highBound\"    \"input\"        \"vx\"           \"dist\"        \n[16] \"vxb\"         \n\n\nCode\nvTrainTrial &lt;- dst %&gt;% filter(condit==\"Varied\",gt.train&lt;=84) %&gt;% group_by(gt.train,vb) %&gt;% summarise(sdVx=sd(vx),vx=mean(vx),sdDist=sd(dist),dist=mean(dist)) %&gt;% \n  group_by(vb) %&gt;% mutate(gt.trainBin=cut(gt.train,breaks=5,labels=c(1:5)))\n\nbinTrainTrial &lt;- dst %&gt;% filter(gt.train&lt;=83) %&gt;% group_by(gt.train,vb,condit) %&gt;% summarise(sdVx=sd(vx),vx=mean(vx),sdDist=sd(dist),dist=mean(dist)) %&gt;% \n  group_by(vb) %&gt;% mutate(gt.trainBin=cut(gt.train,breaks=6,labels=c(1:6)))\n\n\ntMax=84\nbandVec &lt;- rep(c(800,1000,1200),each=tMax/3)\nbandVec &lt;- bandVec[sample(1:length(bandVec),tMax,replace=FALSE)]\n\ntrainTrials &lt;- dst %&gt;% filter(gt.train&lt;=tMax) %&gt;% group_by(condit,gt.train,vb,bandInt,input) %&gt;% summarise(vx=mean(vx)) \n\ntv &lt;- trainTrials %&gt;% filter(condit==\"Varied\") %&gt;% group_by(gt.train) %&gt;% mutate(bandInt2=bandVec[gt.train]) %&gt;% filter(bandInt==bandInt2) %&gt;% select(-bandInt2) %&gt;% \n  rbind(.,trainTrials %&gt;% filter(condit==\"Constant\"))\n\nhead(dst)\n\n\n# A tibble: 6 × 16\n     id condit catOrder feedbackType expMode trial gt.train vb     band  bandInt\n  &lt;dbl&gt; &lt;fct&gt;  &lt;fct&gt;    &lt;fct&gt;        &lt;fct&gt;   &lt;dbl&gt;    &lt;int&gt; &lt;fct&gt;  &lt;fct&gt;   &lt;dbl&gt;\n1     1 Varied orig     continuous   train       2        1 1000-… 5        1000\n2     1 Varied orig     continuous   train       3        2 1200-… 6        1200\n3     1 Varied orig     continuous   train       4        3 800-1… 4         800\n4     1 Varied orig     continuous   train       5        4 1000-… 5        1000\n5     1 Varied orig     continuous   train       6        5 800-1… 4         800\n6     1 Varied orig     continuous   train       7        6 1000-… 5        1000\n# ℹ 6 more variables: lowBound &lt;fct&gt;, highBound &lt;dbl&gt;, input &lt;dbl&gt;, vx &lt;dbl&gt;,\n#   dist &lt;dbl&gt;, vxb &lt;dbl&gt;\n\n\nCode\ndst[1:2,]\n\n\n# A tibble: 2 × 16\n     id condit catOrder feedbackType expMode trial gt.train vb     band  bandInt\n  &lt;dbl&gt; &lt;fct&gt;  &lt;fct&gt;    &lt;fct&gt;        &lt;fct&gt;   &lt;dbl&gt;    &lt;int&gt; &lt;fct&gt;  &lt;fct&gt;   &lt;dbl&gt;\n1     1 Varied orig     continuous   train       2        1 1000-… 5        1000\n2     1 Varied orig     continuous   train       3        2 1200-… 6        1200\n# ℹ 6 more variables: lowBound &lt;fct&gt;, highBound &lt;dbl&gt;, input &lt;dbl&gt;, vx &lt;dbl&gt;,\n#   dist &lt;dbl&gt;, vxb &lt;dbl&gt;\n\n\n\n\nEmpirical Learning Patterns - Group Level\n\n\nCode\n# grouping by condit, display count of each trial in dst\n# dst %&gt;% group_by(condit,trial) %&gt;% summarise(n=n())\n# dst %&gt;% group_by(condit,gt.train) %&gt;% summarise(n=n())\n\n# display histogram with count on x axis\n#dst %&gt;% ggplot(aes(gt.train)) + geom_histogram() + facet_wrap(~condit)\n\nggplot(dst %&gt;% filter(gt.train&lt;=84), aes(x = gt.train, y = vx,color=vb)) +\n  geom_point(aes(color = vb), stat = \"summary\", fun = mean) + \n  stat_summary(aes(color = vb), geom = \"line\", fun = mean) +\n  stat_summary(geom=\"errorbar\",fun.data=mean_se,width=.4,alpha=.7)+facet_wrap(~condit)\n\n\n\n\n\nCode\nggplot(binTrainTrial, aes(x = gt.trainBin, y = vx,color=vb)) +\n  geom_point(aes(color = vb), stat = \"summary\", fun = mean) + \n  stat_summary(aes(color = vb), geom = \"line\", fun = mean) +\n  stat_summary(geom=\"errorbar\",fun.data=mean_se,width=.4,alpha=.7)+facet_wrap(~condit)\n\n\n\n\n\nCode\n# ggplot(vTrainTrial, aes(x = gt.train, y = vx,color=vb)) +\n#   geom_point(aes(color = vb), stat = \"summary\", fun = mean) + \n#   stat_summary(aes(color = vb), geom = \"line\", fun = mean) +\n#   stat_summary(geom=\"errorbar\",fun.data=mean_se,width=.4,alpha=.7)\n# \n# # plot vx and sdVx over gt.train, separate facets for vx and sdVx\n# vTrainTrial %&gt;% pivot_longer(cols=c(vx,sdVx),names_to=\"vxType\",values_to=\"vxVal\") %&gt;% \n#   ggplot(aes(gt.train,vxVal,color=vb)) + geom_line() + \n#   stat_summary(aes(color = vb), geom = \"line\", fun = mean) +\n#   stat_summary(geom=\"errorbar\",fun.data=mean_se,width=.4,alpha=.7)+\n#   facet_wrap(~vxType, scale=\"free_y\")\n\n\n\n\nCode\ninput.activation&lt;-function(x.target, c){\n  return(exp(-1*c*(x.target-inputNodes)^2))\n}\n\noutput.activation&lt;-function(x.target, weights, c){\n  return(weights%*%input.activation(x.target, c))\n}\n\nmean.prediction&lt;-function(x.target, weights, association.parameter){\n  probability&lt;-output.activation(x.target, weights, c)/sum(output.activation(x.target, weights, c))\n  return(outputNodes%*%probability) # integer prediction\n}\n# function to generate exam predictions\nexam.prediction&lt;-function(x.target, weights, c,trainVec){\n  #trainVec = sort(unique(x.learning))\n  nearestTrain = trainVec[which.min(abs(trainVec-x.target))]\n  aresp = mean.prediction(nearestTrain, weights, c)\n  xUnder = ifelse(min(trainVec) == nearestTrain, nearestTrain, trainVec[which(trainVec == nearestTrain) - 1])\n  xOver = ifelse(max(trainVec) == nearestTrain, nearestTrain, trainVec[which(trainVec == nearestTrain) + 1])\n  mUnder = mean.prediction(xUnder, weights, c)\n  mOver = mean.prediction(xOver, weights, c)\n  exam.output = round(aresp + ((mOver - mUnder) / (xOver - xUnder)) * (x.target - nearestTrain), 3)\n  exam.output\n}\n  \nupdate.weights&lt;-function(x.new, y.new, weights, c, lr){\n  y.feedback.activation&lt;-exp(-1*c*(y.new-outputNodes)^2)\n  x.feedback.activation&lt;-output.activation(x.new, weights, c)\n  return(weights+lr*(y.feedback.activation-x.feedback.activation)%*%t(input.activation(x.new, c)))\n}\n\ntrain.alm&lt;-function(dat, c=0.05, lr=0.5, weights){\n   alm.train&lt;-rep(NA,nrow(dat))  \n  for (i in 1:nrow(dat)){\n    weights &lt;- update.weights(dat$input[i], dat$vx[i], weights, c, lr)\n    resp = mean.prediction(dat$input[i], weights, c)\n    alm.train[i]=resp\n    weights[weights&lt;0]=0\n  }\n  alm.train\n}\n\ntrainTest.alm&lt;-function(dat, c=0.05, lr=0.5, weights,testVec){\n   alm.train&lt;-rep(NA,nrow(dat))  \n  for (i in 1:nrow(dat)){\n    weights &lt;- update.weights(dat$input[i], dat$vx[i], weights, c, lr)\n    resp = mean.prediction(dat$input[i], weights, c)\n    alm.train[i]=resp\n    weights[weights&lt;0]=0\n  }\n  almPred &lt;- sapply(testVec,mean.prediction,weights,c)\n  examPred &lt;- sapply(testVec,exam.prediction,weights,c,trainVec=c(1,sort(unique(dat$input))))\n  list(almPred=almPred,examPred=examPred)\n}\n\nwrap_alm &lt;- function(parms,dat, weights){\n    c=parms[1]; lr=parms[2]\n   pred=train.alm(dat, c=c, lr=lr, weights=weights)\n   sqrt(mean((dat$vx -pred)^2))\n}\n\nwrap_optim &lt;- function(dat,wm){\n  bounds_lower &lt;- c(.0000001, .00001)\n  bounds_upper &lt;- c(5, 5)\n\n optim(c(.1, .2),\n   fn = wrap_alm,\n   dat = dat, weights = wm,\n   method = \"L-BFGS-B\",\n   lower = bounds_lower,\n   upper = bounds_upper,\n   control = list(maxit = 1e4, pgtol = 0, factr = 0)\n )\n}\n\n\n\n\nCode\ninputNodes = seq(1,7,1)  # \noutputNodes = seq(50,1600,50)\nwm=matrix(.00001,nrow=length(outputNodes),ncol=length(inputNodes))\n\n\nfitVaried &lt;- tv %&gt;% filter(condit==\"Varied\") %&gt;% wrap_optim(.,wm)\nfitConstant &lt;- tv %&gt;% filter(condit==\"Constant\") %&gt;% wrap_optim(.,wm)\n\n# call train.alm with the optimized parameters\nvPred &lt;- tv %&gt;% filter(condit==\"Varied\") %&gt;% cbind(., pred=train.alm(., c=fitVaried$par[1], lr=fitVaried$par[2], weights=wm))\n\ncPred &lt;- tv %&gt;% filter(condit==\"Constant\") %&gt;% cbind(., pred=train.alm(., c=fitConstant$par[1], lr=fitConstant$par[2], weights=wm))\n\n# plot the results, showing gt.train on x axis, and separate lines with vx and pred\nvPred %&gt;% ggplot(aes(gt.train,vx)) + geom_line() + \ngeom_line(aes(y=pred),color=\"red\") + facet_wrap(~bandInt, scale=\"free_y\")+ggtitle(\"Varied training and predictions\")\n\ncPred %&gt;% ggplot(aes(gt.train,vx)) + geom_line() +\ngeom_line(aes(y=pred),color=\"red\") + facet_wrap(~bandInt, scale=\"free_y\")+ggtitle(\"Constant training and predictions\")\n\n# pred &lt;- train.alm(dat, c = .05, lr = .2, wm)\n# sqrt(mean((dat$vx - pred)^2))\n\n# pred &lt;- train.alm(dat, c = .113, lr = .048, wm)\n# sqrt(mean((dat$vx - pred)^2))\n\n# c=.05; lr=.5; y.new=dat$vx[1]; x.new=dat$input[1]; weights=wm; i=1\n#dat=tv %&gt;% filter(condit==\"Varied\")\n\n\n\n\nCode\ntestVec=seq(2,7)\nvarTestPred &lt;- tv %&gt;% filter(condit==\"Varied\") %&gt;%\n  trainTest.alm(.,.113,.0488,wm,testVec)\n  #trainTest.alm(.,fitVaried$par[1],fitVaried$par[2],wm,testVec)\nvarTestPred\n\n\ntestVec=seq(2,7)\nconTestPred &lt;- tv %&gt;% filter(condit==\"Constant\") %&gt;%\n  trainTest.alm(.,.0008,.144,wm,testVec)\n  #trainTest.alm(.,fitVaried$par[1],fitVaried$par[2],wm,testVec)\nconTestPred"
  },
  {
    "objectID": "Model/htw_exam.html",
    "href": "Model/htw_exam.html",
    "title": "ALM & EXAM Fitting",
    "section": "",
    "text": "Prep data\n\n\nCode\npacman::p_load(tidyverse,data.table,here)\noptions(dplyr.summarise.inform=FALSE)\n\n\nd &lt;- readRDS(here(\"data/dPrune-01-19-23.rds\"))\n\ndtest &lt;- d %&gt;% filter(expMode %in% c(\"test-Nf\",\"test-train-nf\")) %&gt;% group_by(id,lowBound) %&gt;% \n  mutate(nBand=n(),band=bandInt,id=factor(id)) %&gt;% group_by(id) %&gt;% mutate(nd=n_distinct(lowBound))\n# unique(dtest[dtest$nd==4,]$sbjCode) # 7 in wrong condition\ndtest &lt;- dtest %&gt;% group_by(id,lowBound) %&gt;% filter(nBand&gt;=5 & nd==6)\n# for any id that has at least 1 nBand &gt;=5, remove all rows with that id. \ndtest &lt;- dtest %&gt;% group_by(id) %&gt;% filter(!id %in% unique(dtest$id[dtest$nBand&lt;5]))\n\ndtestAgg &lt;- dtest %&gt;% group_by(id,condit,catOrder,feedbackType,vb,band,lowBound,highBound,input) %&gt;% mutate(vxCapped=ifelse(vx&gt;1600,1600,vx)) %&gt;%\n  summarise(vxMean=mean(vx),devMean=mean(dist),vxMed=median(vx),devMed=median(dist),\n            vxMeanCap=mean(vxCapped),.groups = \"keep\")\n\n# select first row for each id in d, then create histogram for nTrain\n#  d  %&gt;% group_by(id) %&gt;% slice(1) %&gt;% ggplot(aes(nTrain)) + geom_histogram() + facet_wrap(~condit)\n  \nds &lt;- d %&gt;% filter(expMode %in% c(\"train\",\"train-Nf\",\"test-Nf\",\"test-train-nf\")) %&gt;% \nfilter(!id %in% unique(dtest$id[dtest$nBand&lt;5])) %&gt;% \nselect(id,condit,catOrder,feedbackType,expMode,trial,gt.train,vb,band,bandInt,lowBound,highBound,input,vx,dist,vxb) \n\ndst &lt;- ds %&gt;% filter(expMode==\"train\",catOrder==\"orig\")\n\nvTrainTrial &lt;- dst %&gt;% filter(condit==\"Varied\",gt.train&lt;=84) %&gt;% group_by(gt.train,vb) %&gt;% summarise(sdVx=sd(vx),vx=mean(vx),sdDist=sd(dist),dist=mean(dist)) %&gt;% \n  group_by(vb) %&gt;% mutate(gt.trainBin=cut(gt.train,breaks=5,labels=c(1:5)))\n\nbinTrainTrial &lt;- dst %&gt;% filter(gt.train&lt;=83) %&gt;% group_by(gt.train,vb,condit) %&gt;% summarise(sdVx=sd(vx),vx=mean(vx),sdDist=sd(dist),dist=mean(dist)) %&gt;% \n  group_by(vb) %&gt;% mutate(gt.trainBin=cut(gt.train,breaks=6,labels=c(1:6)))\n\n\ntMax=84\nbandVec &lt;- rep(c(800,1000,1200),each=tMax/3)\nbandVec &lt;- bandVec[sample(1:length(bandVec),tMax,replace=FALSE)]\n\ntrainTrials &lt;- dst %&gt;% filter(gt.train&lt;=tMax) %&gt;% group_by(condit,gt.train,vb,bandInt,input) %&gt;% summarise(vx=mean(vx)) \n\ntv &lt;- trainTrials %&gt;% filter(condit==\"Varied\") %&gt;% group_by(gt.train) %&gt;% mutate(bandInt2=bandVec[gt.train]) %&gt;% filter(bandInt==bandInt2) %&gt;% select(-bandInt2) %&gt;% \n  rbind(.,trainTrials %&gt;% filter(condit==\"Constant\"))\n\n\n\n\nEmpirical Learning Patterns - Group Level\n\n\nCode\n# grouping by condit, display count of each trial in dst\n# dst %&gt;% group_by(condit,trial) %&gt;% summarise(n=n())\n# dst %&gt;% group_by(condit,gt.train) %&gt;% summarise(n=n())\n\n# display histogram with count on x axis\n#dst %&gt;% ggplot(aes(gt.train)) + geom_histogram() + facet_wrap(~condit)\n\nggplot(dst %&gt;% filter(gt.train&lt;=84), aes(x = gt.train, y = vx,color=vb)) +\n  geom_point(aes(color = vb), stat = \"summary\", fun = mean) + \n  stat_summary(aes(color = vb), geom = \"line\", fun = mean) +\n  stat_summary(geom=\"errorbar\",fun.data=mean_se,width=.4,alpha=.7)+facet_wrap(~condit)\n\nggplot(binTrainTrial, aes(x = gt.trainBin, y = vx,color=vb)) +\n  geom_point(aes(color = vb), stat = \"summary\", fun = mean) + \n  stat_summary(aes(color = vb), geom = \"line\", fun = mean) +\n  stat_summary(geom=\"errorbar\",fun.data=mean_se,width=.4,alpha=.7)+facet_wrap(~condit)\n\n\n# ggplot(vTrainTrial, aes(x = gt.train, y = vx,color=vb)) +\n#   geom_point(aes(color = vb), stat = \"summary\", fun = mean) + \n#   stat_summary(aes(color = vb), geom = \"line\", fun = mean) +\n#   stat_summary(geom=\"errorbar\",fun.data=mean_se,width=.4,alpha=.7)\n# \n# # plot vx and sdVx over gt.train, separate facets for vx and sdVx\n# vTrainTrial %&gt;% pivot_longer(cols=c(vx,sdVx),names_to=\"vxType\",values_to=\"vxVal\") %&gt;% \n#   ggplot(aes(gt.train,vxVal,color=vb)) + geom_line() + \n#   stat_summary(aes(color = vb), geom = \"line\", fun = mean) +\n#   stat_summary(geom=\"errorbar\",fun.data=mean_se,width=.4,alpha=.7)+\n#   facet_wrap(~vxType, scale=\"free_y\")\n\n\n\n\nModel Implementation\n\n\nCode\ninput.activation&lt;-function(x.target, c){\n  return(exp((-1*c)*(x.target-inputNodes)^2))\n}\n\noutput.activation&lt;-function(x.target, weights, c){\n  return(weights%*%input.activation(x.target, c))\n}\n\nmean.prediction&lt;-function(x.target, weights, c){\n  probability&lt;-output.activation(x.target, weights, c)/sum(output.activation(x.target, weights, c))\n  return(outputNodes%*%probability) # integer prediction\n}\n# function to generate exam predictions\nexam.prediction&lt;-function(x.target, weights, c,trainVec){\n  #trainVec = sort(unique(x.learning))\n  nearestTrain = trainVec[which.min(abs(trainVec-x.target))]\n  aresp = mean.prediction(nearestTrain, weights, c)\n  xUnder = ifelse(min(trainVec) == nearestTrain, nearestTrain, trainVec[which(trainVec == nearestTrain) - 1])\n  xOver = ifelse(max(trainVec) == nearestTrain, nearestTrain, trainVec[which(trainVec == nearestTrain) + 1])\n  mUnder = mean.prediction(xUnder, weights, c)\n  mOver = mean.prediction(xOver, weights, c)\n  exam.output = round(aresp + ((mOver - mUnder) / (xOver - xUnder)) * (x.target - nearestTrain), 3)\n  exam.output\n}\n  \nupdate.weights&lt;-function(x.new, y.new, weights, c, lr){\n  y.feedback.activation&lt;-exp(-1*c*(y.new-outputNodes)^2)\n  x.feedback.activation&lt;-output.activation(x.new, weights, c)\n  return(weights+lr*(y.feedback.activation-x.feedback.activation)%*%t(input.activation(x.new, c)))\n}\n\ntrain.alm&lt;-function(dat, c=0.05, lr=0.5, weights){\n   alm.train&lt;-rep(NA,nrow(dat))  \n  for (i in 1:nrow(dat)){\n    weights &lt;- update.weights(dat$input[i], dat$vx[i], weights, c, lr)\n    resp = mean.prediction(dat$input[i], weights, c)\n    alm.train[i]=resp\n    weights[weights&lt;0]=0\n  }\n  alm.train\n}\n\ntrainTest.alm&lt;-function(dat, c=0.05, lr=0.5, weights,testVec){\n  print(\"hi\")\n   alm.train&lt;-rep(NA,nrow(dat))  \n  for (i in 1:nrow(dat)){\n    weights &lt;- update.weights(dat$input[i], dat$vx[i], weights, c, lr)\n    resp = mean.prediction(dat$input[i], weights, c)\n    alm.train[i]=resp\n    weights[weights&lt;0]=0\n  }\n  almPred &lt;- sapply(testVec,mean.prediction,weights,c)\n  examPred &lt;- sapply(testVec,exam.prediction,weights,c,trainVec=c(1,sort(unique(dat$input))))\n  list(almPred=almPred,examPred=examPred)\n}\n\n\n\n\nFitting Functions\n\n\nCode\nwrap_alm &lt;- function(par,dat, weights,lossFun){\n    c=par[1]; lr=par[2]\n   pred=train.alm(dat, c=c, lr=lr, weights=weights)\n   #sqrt(mean((dat$vx -pred)^2))\n   lossFun(dat$vx,pred)\n}\n\nwrap_optim &lt;- function(dat,wm,lossFun){\n  bounds_lower &lt;- c(.0000001, .00001)\n  bounds_upper &lt;- c(5, 5)\n  parmsLab &lt;- c(\"c\",\"lr\")\n fit=optim(par=c(.1, .2),\n   fn = wrap_alm,\n   dat = dat, weights = wm,lossFun=lossFun,\n   method = \"L-BFGS-B\",\n   lower = bounds_lower,\n   upper = bounds_upper,\n   control = list(maxit = 1e4, pgtol = 0, factr = 0)\n )\n\n l=reduce(list(list(fit),fit$par,fit$value),append)\n names(l)=c(\"Fit\",parmsLab,\"Value\")\n return(l)\n}\n\nRMSE &lt;- function(x,y){\n # print(\"rmseTrial\")\n  sqrt(mean((x-y)^2))\n}\n\nRMSE.blocked &lt;- function(x,y,blocks=6){\n # print(\"rmseBlocked\")\n  data.table(x=x,y=y,t=seq(1,length(x))) %&gt;% \n    .[, `:=`(fitBins = cut(t, breaks = ..blocks, labels = c(1:..blocks)))] %&gt;%\n    .[, .(predMean = mean(x), obsMean = mean(y)), keyby = .(fitBins)] %&gt;%\n    .[, RMSE(predMean,obsMean)] %&gt;% as.numeric()\n}\n\n\n\n\nCode\ninputNodes = seq(1,7,1)  # \noutputNodes = seq(50,1600,50)\nwm=matrix(.00001,nrow=length(outputNodes),ncol=length(inputNodes))\ntestVec=seq(2,7)\n\nlossFunctions &lt;- list(RMSE,RMSE.blocked)\n\n# fit_tbl &lt;- crossing(dat=tv %&gt;% split(.$condit),lossFun=lossFunctions)\n# fitGroups2 &lt;- pmap(fit_tbl,wrap_optim,wm)\n#fit_tbl &lt;- fit_tbl %&gt;% mutate(fit=pmap(list(dat,lossFun),wrap_optim))\n\n\nfitGroups &lt;- tv %&gt;% split(.$condit) %&gt;% map(~wrap_optim(.,wm,RMSE.blocked))\nfitGroups2 &lt;- tv %&gt;% split(.$condit) %&gt;% map(~wrap_optim(.,wm,RMSE))\n\n\n#ftg &lt;- replicate(2,tv %&gt;% split(.$condit) %&gt;% map(~wrap_optim(.,wm,RMSE)))\n\n\n\nfg=tv %&gt;% group_by(condit) %&gt;% nest() %&gt;% \n  mutate(fit=map(data,~wrap_optim(.,wm,RMSE)),\n         c=map(fit,\"c\"),lr=map(fit,\"lr\"))\n\n\n\n\nfg &lt;- fg %&gt;% mutate(trainPred=pmap(list(data,c,lr),train.alm,wm),\n                    obsv=map(data,\"vx\"),\n                    diff=map2(obsv,trainPred,~.x-.y),\n                    rmse=map(diff,~sqrt((mean(.^2)))),\n                    trainVec=map(data,~c(1,sort(unique(.$input)))),\n                    testVec=list(seq(2,7)),\n                    bandInt=list(sort(unique(dtest$bandInt))),\n                    testPred=pmap(list(data,c,lr,testVec),trainTest.alm,weights=wm),\n                    almTest=map(testPred,\"almPred\"),\n                    examTest=map(testPred,\"examPred\"))\n\n\n\ntestPreds &lt;- fg %&gt;% select(condit,bandInt,c,lr,almTest,examTest,testVec) %&gt;% unnest(cols = c(bandInt,c, lr, almTest, examTest,testVec))\n\n\n\nk &lt;- fg %&gt;%\n  select(condit, almTest, examTest) %&gt;%\n  split(.$condit) %&gt;%\n  map(~ list(d = data.frame(c1 = .$almTest, .$examTest)))\n\n\n\n# call train.alm with the optimized parameters\nvPred &lt;- tv %&gt;% filter(condit==\"Varied\") %&gt;% cbind(., pred=train.alm(., c=fitVaried$par[1], lr=fitVaried$par[2], weights=wm))\n\ncPred &lt;- tv %&gt;% filter(condit==\"Constant\") %&gt;% cbind(., pred=train.alm(., c=fitConstant$par[1], lr=fitConstant$par[2], weights=wm))\n\n# plot the results, showing gt.train on x axis, and separate lines with vx and pred\nvPred %&gt;% ggplot(aes(gt.train,vx)) + geom_line() + \ngeom_line(aes(y=pred),color=\"red\") + facet_wrap(~bandInt, scale=\"free_y\")+ggtitle(\"Varied training and predictions\")\n\ncPred %&gt;% ggplot(aes(gt.train,vx)) + geom_line() +\ngeom_line(aes(y=pred),color=\"red\") + facet_wrap(~bandInt, scale=\"free_y\")+ggtitle(\"Constant training and predictions\")\n\n\n# pred &lt;- train.alm(dat, c = .05, lr = .2, wm)\n# sqrt(mean((dat$vx - pred)^2))\n\n# pred &lt;- train.alm(dat, c = .113, lr = .048, wm)\n# sqrt(mean((dat$vx - pred)^2))\n\n\n\n# dat &lt;- tv %&gt;% filter(condit==\"Varied\")\n# c=.05; lr=.5; y.new=dat$vx[1]; x.new=dat$input[1]; weights=wm; i=1\n\n\n\n\ncreate learning models for condit and varied groups.\nWe can model the relation between performance and the number of practice trials as a power law function, or exponential function. Aggregatign over ids in dst. The models predict dist as an exponential decay function of trial number. Band is an additional predictor.\n\\[\nf_p(t) = \\alpha + \\beta t^{r} \\enspace\n\\] \\[\nf_e(t) = \\alpha + \\beta e^{rt} \\enspace\n\\]\n\n\nCode\n# fit exponential decay model as a function of trial number\n\nfit_exp &lt;- function(trial,dist,input){\n    # fit exponential decay model as a function of trial number, band is an additional predictor\n    fit &lt;- nls(dist ~ yf + (y0-yf) * exp(-r*trial) + beta2*input, start = list(yf = 300, y0 = 364, beta2=0, r = .1), data = data.frame(trial=trial,dist=dist,input=input))\n\n    # extract parameters\n    alpha &lt;- coef(fit)[1]\n    beta &lt;- coef(fit)[2]\n    beta2 &lt;- coef(fit)[3]\n    r &lt;- coef(fit)[4]\n    sigma_e &lt;- summary(fit)$sigma\n\n    # compute negative log likelihood\n    nllh &lt;- negative_llh_exp(dist, trial, alpha, beta, r, sigma_e)\n\n    # return parameters and negative log likelihood\n    return(list(alpha=alpha,beta=beta,beta2=beta2,r=r,sigma_e=sigma_e,nllh=nllh))\n}\n\n# Compute group averages for dist over trial and band. dst \n\navgTrain &lt;- dst %&gt;% group_by(id,condit,trial,band,input) %&gt;% summarise(dist=mean(dist)) %&gt;% ungroup() %&gt;% group_by(condit,trial,band) %&gt;% summarise(dist=mean(dist)) %&gt;% ungroup()\n \n# plot group averages\nggplot(avgTrain,aes(x=trial,y=dist)) + geom_line(aes(group=band,color=band)) +facet_grid(~condit)\n\navgTrain %&gt;% filter(condit==\"Constant\") %&gt;% nls(dist ~ yf + (y0-yf) * exp(-r*trial), start = list(yf = 120, y0 = 364, r = .1), data = .) %&gt;% summary()\n\n\navgTrain %&gt;% filter(condit==\"Constant\") %&gt;% nls(dist ~ SSasymp(trial, yf, y0, log_alpha),data=.)\n\n# fit exponential decay model for each condit\nfit_condit &lt;- avgTrain %&gt;% group_by(condit) %&gt;% do(fit_exp(trial=.$trial,dist=.$dist,input=.$input))\n\n# fit exponential model"
  },
  {
    "objectID": "Model/learning_noise.html",
    "href": "Model/learning_noise.html",
    "title": "Noisy Learning",
    "section": "",
    "text": "pacman::p_load(tidyverse,data.table,knitr,kableExtra,glue,future,furrr,here)\npurrr::walk(here(c(\"Functions/alm_functions.R\",\"Functions/Display_Functions.R\",\"Functions/Noisy_Functions.R\")),source)\nIt appears that the model may be too simple or not flexible enough to capture the slow, gradual learning observed in the human data. Here are some suggestions to improve the model’s ability to better fit the human learning data:\nIntroduce a momentum term: Adding a momentum term to the weight update rule can help the model exhibit more gradual learning behavior. The momentum term is a fraction of the previous weight update that is added to the current weight update, which can help to smooth out the learning process.\nVary learning rate over time: Instead of using a fixed learning rate, you can try to gradually decrease the learning rate over time. This approach, called learning rate annealing, can help the model learn more slowly at the beginning of training and become more fine-tuned as training progresses.\nIncorporate noise: You can add noise to the input activation, output activation, or weight updates to introduce some stochasticity into the learning process. This can lead to more gradual learning, as the model will not be able to rely solely on deterministic updates.\nHierarchical or recurrent structure: Instead of using a simple two-layer connectionist network, you can try a more complex network architecture, such as a hierarchical or recurrent neural network. This can potentially help capture the slow, gradual learning behavior observed in human data.\nRegularization: Add regularization techniques like L1 or L2 regularization to the learning process. This can help prevent overfitting and create a more constrained model, which may lead to slower and more gradual learning.\nTask-specific features: Incorporate task-specific features, constraints, or biases into the model that may better represent human cognitive processes. This may help the model to better capture the observed learning patterns in human data.\nModel comparison: Compare the performance of your current model with alternative models, such as reinforcement learning or Bayesian models, which may exhibit different learning dynamics.\nBy trying out these suggestions, you can potentially improve your model’s ability to fit the slow, gradual learning observed in human data from the velocity production task. Experiment with different combinations of these techniques to find the best approach for your specific problem."
  },
  {
    "objectID": "Model/learning_noise.html#noisy-layers-version",
    "href": "Model/learning_noise.html#noisy-layers-version",
    "title": "Noisy Learning",
    "section": "Noisy layers version",
    "text": "Noisy layers version\n\ntibble(crossing(\n    c = c(.5, 2), lr = c(0.005, 0.05, 0.1, 0.5), noise_sd = c(0.001, 0.005, 0.01, 0.05),\n    noise = c(0),\n    inNodes = c(7), outNodes = c(32),\n    trainVec = list(list(5, 6, 7)), trainRep = c(16),\n    lossFun = list(\"MAE\"),\n    simNum = 1:1\n)) %&gt;%\n    mutate(id = seq(1, nrow(.)), td = pmap(list(trainVec, trainRep, noise), ~ gen_train(trainVec = .x, trainRep = ..2, noise = ..3))) %&gt;%\n    ungroup() %&gt;%\n    mutate(\n        d = pmap(\n            list(td, c, lr, inNodes, outNodes, noise_sd),\n            ~ sim_train(dat = .x, c = ..2, lr = ..3, inNodes = ..4, outNodes = ..5, noise_sd = ..6)\n        ),\n        almTrainDat = map(d, \"almTrain\"), weights = map(d, \"weights\")\n    ) %&gt;%\n    unnest(c(almTrainDat, td)) %&gt;%\n    select(-d) %&gt;%\n    mutate(input = as.factor(input)) %T&gt;%\n  {pf(.) } %&gt;% trainTab %&gt;% {. -&gt;&gt; tt}"
  },
  {
    "objectID": "Model/learning_noise.html#grid-search",
    "href": "Model/learning_noise.html#grid-search",
    "title": "Noisy Learning",
    "section": "Grid Search",
    "text": "Grid Search\n\nn_cores &lt;- parallel::detectCores()\nparam_grid &lt;- tibble(crossing(\n  c = seq(.5,5,.5),\n  lr = seq(0.01, 1,.1),\n  noise_sd = c(0,.0001,0.001, 0.01),\n  inNodes = c(5, 7,14,28),\n  outNodes = c(16, 32,64)\n))\nnrow(param_grid)\n\nfit_alm &lt;- function(data, c, lr, noise_sd, inNodes, outNodes) {\n  mse_list &lt;- replicate(5, {\n    train_data &lt;- data[, c(\"trial\", \"input\", \"cor\")] %&gt;% rename(\"vx\" = cor)\n    sim_result &lt;- sim_train(\n      dat = train_data,\n      c = c,\n      lr = lr,\n      inNodes = inNodes,\n      outNodes = outNodes,\n      noise_sd = noise_sd\n    )\n    train_data$almTrain &lt;- sim_result$almTrain\n    mse &lt;- mean((data$vx - train_data$almTrain)^2)\n    mse\n  })\n  avg_mse &lt;- mean(mse_list)\n  return(avg_mse)\n}\n\ngt &lt;- gen_train(trainVec=c(5,6,7),trainRep=8) %&gt;% mutate(cor=vx,err=(800-0)*exp(-.1*seq(1,n()))+0,vx=cor-err)\n\nfurrr::furrr_options(seed = TRUE)\nplan(multisession, workers = n_cores-1)\n\nparam_grid &lt;- param_grid %&gt;% mutate(performance = future_map_dbl(seq_len(nrow(.)), function(idx) {\n    fit_alm(gt, c = c[idx], lr = lr[idx], noise_sd = noise_sd[idx], inNodes = inNodes[idx], outNodes = outNodes[idx])\n  },\n  .options = furrr_options(seed = T)))\n\nbest_params &lt;- param_grid %&gt;%\n  arrange((performance)) \nbest &lt;- head(best_params,1)\n\ns=sim_train(dat=mutate(gt,vx=cor), c = best$c,\n  lr = best$lr,inNodes = best$inNodes,outNodes = best$outNodes,\n  noise_sd = best$noise_sd\n)\n\nggp &lt;- gt %&gt;% mutate(pred=s %&gt;% pluck(\"almTrain\"),input=as.factor(input))\nggp %&gt;% ggplot(aes(x = trial, y = pred, color = input)) +\n  geom_line() + ylim(c(0,1600))\nggp  %&gt;% ggplot(aes(x = trial, y = vx, color = input)) +\n  geom_line() + ylim(c(0,1600))\n\n\nlibrary(abc)\nlibrary(mvtnorm)\nfit_alm_sim &lt;- function(data, c, lr, noise_sd, inNodes, outNodes) {\n  train_data &lt;- data[, c(\"trial\", \"input\", \"cor\")] %&gt;% rename(\"vx\" = cor)\n  \n  sim_result &lt;- sim_train(\n    dat = train_data,\n    c = c,\n    lr = lr,\n    inNodes = inNodes,\n    outNodes = outNodes,\n    noise_sd = noise_sd\n  )\n  \n  train_data$almTrain &lt;- sim_result$almTrain\n  return(train_data$almTrain)\n}\ngenerate_prior &lt;- function(n) {\n  prior_samples &lt;- tibble(\n    c = runif(n, 0.001, 5),\n    lr = runif(n, 0.001, 3),\n    noise_sd = runif(n, 0, 0.0001),\n    inNodes = sample(c( 3,7, 14,21,28,35), size = n, replace = TRUE),\n    outNodes = sample(c(8,16, 32,48,64,80,96), size = n, replace = TRUE)\n  )\n  return(prior_samples)\n}\nn_prior_samples &lt;- 10000\nprior_samples &lt;- generate_prior(n_prior_samples)\n\n#gt &lt;- gen_train(trainVec=c(5,6,7),trainRep=8) %&gt;% mutate(cor=vx,err=(800-0)*exp(-.1*seq(1,n()))+0,vx=cor-err)\ngt &lt;- gen_train(trainVec=c(5,6,7),trainRep=36) %&gt;% mutate(cor=vx,err=(1500-0)*exp(-.05*seq(1,n()))+0,vx=cor-err)\n\n\n\nsimulated_data &lt;- future_map_dfc(seq_len(nrow(prior_samples)), function(idx) {\n  params &lt;- prior_samples[idx, ]\n  fit_alm_sim(gt, params$c, params$lr, params$noise_sd, params$inNodes, params$outNodes)\n},.options = furrr_options(seed = T))\n\ngt_obs &lt;- gt$vx\ntolerance &lt;- 0.1 * sd(gt_obs)*500\n\nlength(gt_obs)\nstr(simulated_data)\n\nabc_result &lt;- abc(\n  target = gt_obs,\n  param = prior_samples,\n  sumstat = do.call(rbind, simulated_data),\n  tol = .1,\n  method = \"rejection\",\n  names=colnames(gt_obs)\n)\nstr(abc_result)\n\n\n\n\n\nposterior_samples &lt;- abc_result$unadj.values\ncolnames(posterior_samples) &lt;- c(\"c\", \"lr\", \"noise_sd\", \"inNodes\", \"outNodes\")\nposterior_samples_long &lt;- tidyr::pivot_longer(as.data.frame(posterior_samples), everything())\n\nggplot(posterior_samples_long, aes(x=value)) +\n  geom_density() +\n  facet_wrap(~name, scales=\"free\") +\n  theme_minimal() +\n  labs(x=\"Value\", y=\"Density\", title=\"Posterior Density Plots\")\n\n\nsummary_statistics &lt;- data.frame(\n  mean = apply(posterior_samples, 2, mean),\n  median = apply(posterior_samples, 2, median),\n  q025 = apply(posterior_samples, 2, function(x) quantile(x, 0.025)),\n  q975 = apply(posterior_samples, 2, function(x) quantile(x, 0.975))\n)\nsummary_statistics=rownames_to_column(summary_statistics,var=\"parameter\")\nsummary_statistics\nhead(summary_statistics)\n\n\ns = sim_train(dat=mutate(gt,vx=cor),c=summary_statistics$mean[1],lr=summary_statistics$mean[2],inNodes=summary_statistics$mean[4],outNodes=summary_statistics$mean[5],noise_sd=summary_statistics$mean[3])\n\nggp &lt;- gt %&gt;% mutate(pred=s %&gt;% pluck(\"almTrain\"),input=as.factor(input))\nggp %&gt;% ggplot(aes(x = trial, y = pred, color = input)) +\n  geom_line() + ylim(c(0,1600))\nggp  %&gt;% ggplot(aes(x = trial, y = vx, color = input)) +\n  geom_line() + ylim(c(0,1600))\n\n\nsimulated_data_accepted &lt;- abc_result$ss\ntarget_data &lt;- as.vector(gt_obs)\n\n# Plot target data and accepted simulations\nggplot() +\n  geom_density(data = as.data.frame(simulated_data_accepted), aes(x = V1), alpha = 0.3, color = \"blue\") + geom_vline(aes(xintercept = target_data), color = \"red\", linetype = \"dashed\") +\n  labs(x = \"Summary statistics\", y = \"Density\", title = \"Diagnostic Plot: Marginal Posterior Distribution of Summary Statistics\") +\n  theme_minimal()\n\n\n\n\n\nposterior_predictive_simulations &lt;- future_map_dfc(seq_len(nrow(posterior_samples)), function(idx) {\n  params &lt;- prior_samples[idx, ]\n  fit_alm_sim(gt, params$c, params$lr, params$noise_sd, params$inNodes, params$outNodes)\n},.options = furrr_options(seed = T))\n\n\n\n# Calculate summary statistics for the posterior predictive simulations\nposterior_predictive_summary &lt;- apply(posterior_predictive_simulations, 2, function(x) c(mean = mean(x), sd = sd(x)))\n\n# Compare with the observed data summary statistics\nobserved_data_summary &lt;- as.data.frame(t(c(mean = mean(gt_obs), sd = sd(gt_obs))))\ncolnames(observed_data_summary) &lt;- colnames(posterior_predictive_summary)\n\ncomparison &lt;- rbind(posterior_predictive_summary, observed_data_summary)\nrownames(comparison)[3] &lt;- \"Observed\"\ncomparison\n\n\n\n\nlibrary(GGally)\nggpairs(as.data.frame(posterior_samples))\n\n#ABC Binned\n\nnTrain=90\ngt_con &lt;- gen_train(trainVec=c(5,6,7),trainRep=nTrain/3) %&gt;% mutate(cor=vx,err=(500-0)*exp(-.05*seq(1,n()))+0,vx=cor-err)\ngt_con &lt;- gen_train(trainVec=c(5),trainRep=nTrain) %&gt;% mutate(cor=vx,err=(500-0)*exp(-.09*seq(1,n()))+0,vx=cor-err)\n\ngt &lt;- gt_con\n\nbin_size &lt;- 8\nbinned_data &lt;- gt %&gt;%\n  mutate(bin=cut(trial,breaks=bin_size,labels=c(1:bin_size))) %&gt;%\n  group_by(bin,cor,input) %&gt;%\n  summarize(vx_mean = mean(vx), .groups = \"drop\")\n\nfit_alm_sim_binned &lt;- function(data, c, lr, noise_sd, inNodes, outNodes) {\n  train_sims &lt;- replicate(5, {\n    train_data &lt;- data[, c(\"trial\", \"input\", \"cor\")] %&gt;% rename(\"vx\" = cor)\n    sim_result &lt;- sim_train(\n      dat = train_data,\n      c = c,\n      lr = lr,\n      inNodes = inNodes,\n      outNodes = outNodes,\n      noise_sd = noise_sd\n    )\n    train_data$almTrain &lt;- sim_result$almTrain\n    \n   binned_data &lt;- train_data %&gt;%\n  mutate(bin=cut(trial,breaks=bin_size,labels=c(1:bin_size))) %&gt;%\n  group_by(bin,vx,input) %&gt;%\n  summarize(vx_mean = mean(almTrain), .groups = \"drop\")\n  binned_data$vx_mean\n  })\n  train_avg &lt;- rowMeans(train_sims )\n  return( train_avg)\n}\n\nn_prior_samples &lt;- 500\nprior_samples &lt;- generate_prior(n_prior_samples)\n\nsimulated_data &lt;- future_map_dfc(seq_len(nrow(prior_samples)), function(idx) {\n  params &lt;- prior_samples[idx, ]\n  fit_alm_sim_binned(gt, params$c, params$lr, params$noise_sd, params$inNodes, params$outNodes)\n},.options = furrr_options(seed = T))\n\ngt_obs &lt;- binned_data$vx_mean\n\nabc_result &lt;- abc(\n  target = gt_obs,param = prior_samples,\n  sumstat = do.call(rbind, simulated_data),\n  tol = .1, method = \"rejection\",\n  names=colnames(gt_obs)\n)\n\nposterior_samples &lt;- abc_result$unadj.values\ncolnames(posterior_samples) &lt;- c(\"c\", \"lr\", \"noise_sd\", \"inNodes\", \"outNodes\")\nposterior_samples_long &lt;- tidyr::pivot_longer(as.data.frame(posterior_samples), everything())\n\nggplot(posterior_samples_long, aes(x=value)) +\n  geom_density() +\n  facet_wrap(~name, scales=\"free\") +\n  theme_minimal() +\n  labs(x=\"Value\", y=\"Density\", title=\"Posterior Density Plots\")\n\nsummary_statistics &lt;- data.frame(\n  mean = apply(posterior_samples, 2, mean),\n  median = apply(posterior_samples, 2, median),\n  q025 = apply(posterior_samples, 2, function(x) quantile(x, 0.025)),\n  q975 = apply(posterior_samples, 2, function(x) quantile(x, 0.975))\n)\n( summary_statistics=rownames_to_column(summary_statistics,var=\"parameter\") )\n\ns = sim_train(dat=mutate(gt,vx=cor),c=summary_statistics$mean[1],lr=summary_statistics$mean[2],inNodes=summary_statistics$mean[4],outNodes=summary_statistics$mean[5],noise_sd=summary_statistics$mean[3])\n\nggp &lt;- gt %&gt;% mutate(pred=s %&gt;% pluck(\"almTrain\"),input=as.factor(input)) %&gt;%\n  mutate(bin=cut(trial,breaks=bin_size,labels=c(1:bin_size)),input=as.factor(input),binN=as.numeric(bin)) %&gt;%\n  group_by(bin,cor,input,binN) %&gt;% summarize(vx_mean = mean(vx), pred_mean=mean(pred), .groups = \"drop\")\nggp %&gt;% ggplot(aes(x = binN, y = pred_mean,color=input)) +\n  geom_line() + ylim(c(-200,1600))\nggp  %&gt;% ggplot(aes(x = binN, y = vx_mean, color = input)) +\n  geom_line() + ylim(c(-200,1600))\n\ns=sim_data(dat=mutate(gt,vx=cor),c=best %&gt;% pluck(“c”),best= k %&gt;% pluck(“lr”))\nggp &lt;- gt %&gt;% mutate(pred=s %&gt;% pluck(“almTrain”),c=k %&gt;% pluck(“c”),lr= k %&gt;% pluck(“lr”),input=as.factor(input)) %&gt;% ggplot(aes(x = trial, y = pred, color = input)) + geom_line() + ylim(c(0,1600)) ggo &lt;- gt %&gt;% ggplot(aes(x = trial, y = vx, color = as.factor(input))) + geom_line() + ylim(c(-400,1600))\nggo+ggp\n\n\n### Optimize for single decay curve\ngenerate data that follows an exponetial decay function of error over trials, inspect\nability of model to fit that data. \n::: {.cell}\n\n```{.r .cell-code}\ngt &lt;- gen_train(trainVec=c(5,6,7),trainRep=36) %&gt;% mutate(cor=vx,err=(1500-0)*exp(-.05*seq(1,n()))+0,vx=cor-err)\ngt_con &lt;- gen_train(trainVec=c(5),trainRep=nTrain) %&gt;% mutate(cor=vx,err=(500-0)*exp(-.09*seq(1,n()))+0,vx=cor-err)\n\ngt_con %&gt;% ggplot(aes(x = trial, y = vx, color = as.factor(input))) +\n  geom_line() + ylim(c(-10,1600))\nhead(gt,10)\n# bias &lt;- 1000; \n# gt &lt;- gen_train(trainVec=c(5,6,7),trainRep=228,noise=0) %&gt;% mutate(\n#   cor = vx,\n#   err = (bias - 0) * exp(-.005 * seq(1, n())) + 0,\n#   en = map2_dbl(err,cor, ~rnorm(n = 1, mean = .y, sd = .x/2)),\n#   enAvg = map2_dbl(err,cor, ~mean(rnorm(n = 1, mean = .y, sd = .x))),\n#   weight = (seq(1, n()) - 1) / (n() - 1),\n#   vx = (weight*en)+bias*(1-weight),\n#   vx=en\n# )\ngt %&gt;% ggplot(aes(x = trial, y = vx, color = as.factor(input))) +\n  geom_line() + ylim(c(-10,1600))\n\n\nwrap_optim &lt;- function(dat,lossFun=RMSE){\n  \n    wrap_alm &lt;- function(par,dat, weights,lossFun){\n      c=par[1]; lr=par[2]; noise_sd=par[3]\n      pred=train.alm(dat, c=c, lr=lr, noise_sd=noise_sd, weights=weights)\n      lossFun(dat$vx,pred)\n    }\n  if(class(lossFun)==\"character\"){lossFun=get(lossFun)}\n  inputNodes = seq(1,7,1)  # \n  outputNodes = seq(50,1600,50)\n  wm=matrix(.00001,nrow=length(outputNodes),ncol=length(inputNodes))\n  testVec=seq(2,7)\n  \n  bounds_lower &lt;- c(.0000001, .00001,.000000001)\n  bounds_upper &lt;- c(10, 10,10)\n  parmsLab &lt;- c(\"c\",\"lr\",\"noise_sd\")\n  \n  fit=optim(par=c(.1, .2,.05),\n            fn = wrap_alm,\n            dat = dat, weights = wm,lossFun=lossFun,\n            method = \"L-BFGS-B\",\n            lower = bounds_lower,\n            upper = bounds_upper,\n            control = list(maxit = 1e5, pgtol = 0, factr = 0)\n  )\n  l=reduce(list(list(fit),fit$par,fit$value),append)\n  names(l)=c(\"Fit\",parmsLab,\"Value\")\n  return(l)\n}\n\n\nk=wrap_optim(gt,lossFun = \"MAE\")\ns=sim_data(dat=mutate(gt,vx=cor),c=k %&gt;% pluck(\"c\"),lr= k %&gt;% pluck(\"lr\"))\nggp &lt;- gt %&gt;% mutate(pred=s %&gt;% pluck(\"almTrain\"),c=k %&gt;% pluck(\"c\"),lr= k %&gt;% pluck(\"lr\"),input=as.factor(input)) %&gt;%  \n  ggplot(aes(x = trial, y = pred, color = input)) +\n  geom_line() + ylim(c(0,1600))\nggo &lt;-  gt %&gt;% ggplot(aes(x = trial, y = vx, color = as.factor(input))) +\n  geom_line() + ylim(c(-400,1600))\n\nggo+ggp\n:::"
  },
  {
    "objectID": "Simulations/DeLosh97_Sim.html",
    "href": "Simulations/DeLosh97_Sim.html",
    "title": "Simulating DeLosh 1997",
    "section": "",
    "text": "Code\n#lapply(c('tidyverse','data.table','igraph','ggraph','kableExtra'),library,character.only=TRUE))\npacman::p_load(tidyverse,data.table,igraph,ggraph,kableExtra)\nCode\n#https://nrennie.rbind.io/blog/2022-06-06-creating-flowcharts-with-ggplot2/\ninNodes &lt;- seq(1,6,1) %&gt;% as.integer()\noutNodes &lt;- seq(300,1000,50)%&gt;% as.integer()\nstim &lt;- \"Stim\"\nresp &lt;- \"Response\"\ninFlow &lt;- tibble(expand.grid(from=stim,to=inNodes)) %&gt;% mutate_all(as.character)\noutFlow &lt;- tibble(expand.grid(from=outNodes,to=resp)) %&gt;% mutate_all(as.character)\n\ngd &lt;- tibble(expand.grid(from=inNodes,to=outNodes)) %&gt;% mutate_all(as.character) %&gt;%\n  rbind(inFlow,.) %&gt;% rbind(.,outFlow)\n\ng = graph_from_data_frame(gd,directed=TRUE)\ncoords2=layout_as_tree(g)\ncolnames(coords2)=c(\"y\",\"x\")\nodf &lt;- as_tibble(coords2) %&gt;% \n  mutate(label=vertex_attr(g,\"name\"),\n         type=c(\"stim\",rep(\"Input\",length(inNodes)),rep(\"Output\",length(outNodes)),\"Resp\"),\n         x=x*-1) %&gt;%\n  mutate(y=ifelse(type==\"Resp\",0,y),xmin=x-.05,xmax=x+.05,ymin=y-.35,ymax=y+.35)\n\nplot_edges = gd %&gt;% mutate(id=row_number()) %&gt;%\n  pivot_longer(cols=c(\"from\",\"to\"),names_to=\"s_e\",values_to=(\"label\")) %&gt;%\n                 mutate(label=as.character(label)) %&gt;% \n  group_by(id) %&gt;%\n  mutate(weight=sqrt(rnorm(1,mean=0,sd=10)^2)/10) %&gt;%\n  left_join(odf,by=\"label\") %&gt;%\n  mutate(xmin=xmin+.02,xmax=xmax-.02)\n\nggplot() + geom_rect(data = odf,\n            mapping = aes(xmin = xmin, ymin = ymin, \n                          xmax = xmax, ymax = ymax, \n                          fill = type, colour = type),alpha = 0.5) +\n  geom_text(data=odf,aes(x=x,y=y,label=label,size=3)) +\n  geom_path(data=plot_edges,mapping=aes(x=x,y=y,group=id,alpha=weight)) +\n  # geom_rect(aes(xmin=-1.05,xmax=-.95,ymin=-10,ymax=5),color=\"red\",alpha=.1)+\n  # geom_rect(aes(xmin=-0.05,xmax=.05,ymin=-10,ymax=5),color=\"blue\",alpha=.1) +\n  theme_void()"
  },
  {
    "objectID": "Simulations/DeLosh97_Sim.html#alm-definition",
    "href": "Simulations/DeLosh97_Sim.html#alm-definition",
    "title": "Simulating DeLosh 1997",
    "section": "ALM Definition",
    "text": "ALM Definition\n\n\n\nInput Activation\n\\[\na_i(X)=\\exp \\left|-\\gamma \\cdot\\left[X-X_i\\right]^2\\right|\n\\]\n\n\nOutput activation\n\\[\no_j(X)=\\Sigma_{i=1, M} w_{j i} \\cdot a_i(X)\n\\]\n\n\nOutput Probability\n\\[\nP\\left[Y_j \\mid X\\right]=o_j(X) / \\Sigma_{k=1, L} o_k(X)\n\\]\n\n\nMean Response\n\\[\nm(X)=\\Sigma_{j=1, L} Y_j \\cdot P\\left[Y_j \\mid X\\right]\n\\]\n\n\nGenerate Response\n\n\nToggle Code\nalm.response &lt;- function(input=1,c) {\ninput.activation &lt;- exp(-c*(input.layer - input)^2)\ninput.activation &lt;&lt;- input.activation/sum(input.activation)\n#print(length(input.activation)); print(dim(weight.mat))\noutput.activation &lt;&lt;- weight.mat %*% input.activation\noutput.probability &lt;&lt;- output.activation/sum(output.activation)\nmean.response &lt;&lt;- sum(output.layer * output.probability)\nmean.response\n}\n\n\n     \n\n\nUpdate Weights Based on Feedback\n\n\nToggle Code\nalm.update &lt;- function(corResp,c,lr){\n  fz &lt;- exp(-c*(output.layer - corResp)^2)\n  teacherSignal &lt;- (fz - output.activation)*lr\n  #print(length(teacherSignal)); print(length(fz))\n  wChange &lt;- teacherSignal %*% t(input.activation)\n  weight.mat &lt;&lt;- weight.mat + (wChange)\n  weight.mat[weight.mat&lt;0]=0 # prevent negative values\n # weight.mat[weight.mat&gt;1]=1\n  weight.mat &lt;&lt;- weight.mat\n}\n\nalm.trial &lt;- function(input, corResp,c,lr){\n  alm.response(input,c)\n  alm.update(corResp,c,lr)\n # print(paste0(\"input=\",input,\"; corResp=\",corResp,\"; mean.response=\",mean.response))\n  mean.response\n}\n\n\n\n\n\nFeedback Signal\n\\[\nf_j(Z)=e^{-c\\cdot(Z-Y_j)^2}\n\\]\n\n\nWeight Updates\n\\[\nw_{ji}(t+1)=w_{ji}(t)+\\alpha \\cdot {f_i(Z(t))-O_j(X(t))} \\cdot a_i(X(t))\n\\]\n\n\n\nExam Generalization\n\n\nToggle Code\nexam.response &lt;- function(input,c){\n  # Find the index of the input node with the highest activation\n  trainVec = sort(unique(xt))\n  nearestTrain &lt;- trainVec[which.min(abs(input - trainVec))]\n  aresp &lt;- alm.response(nearestTrain,c)\n  #max.index &lt;- which.max(input.activation)\n  xUnder = ifelse(min(trainVec) == nearestTrain, nearestTrain, trainVec[which(trainVec == nearestTrain) - 1])\n  xOver = ifelse(max(trainVec) == nearestTrain, nearestTrain, trainVec[which(trainVec == nearestTrain) + 1])\n\n  mUnder &lt;- alm.response(xUnder,c)\n  mOver &lt;- alm.response(xOver,c)\n \n   exam.output = round(aresp + ((mOver - mUnder) / (xOver - xUnder)) * (input - nearestTrain), 3)\n  # Determine the input nodes and associated weights for computing the slope\n  exam.output\n}\n\n\n\n\n\nInput node actvation\n\\[\nP[X_i|X] = \\frac{a_i(X)}{\\\\sum_{k=1}^Ma_k(X)}\n\\]\n\n\nSlope Computation\n\\[\nE[Y|X_i]=m(X_i) + \\bigg[\\frac{m(X_{i+1})-m(X_{i-1})}{X_{i+1} - X_{i-1}} \\bigg]\\cdot[X-X_i]\n\\]\n\n\n\nPrepare Simulation Data\n\n\nToggle Code\n# function to generate data, from either linear, exponential, quadratic or sinusoidal functions\n\ngenerate.data &lt;- function(x, type = \"linear\", noise = NA) {\n  if (type == \"linear\") {\n    y &lt;- round(2.2*x + 30,0)\n  }\n  else if (type == \"exponential\") {\n    y &lt;- round(200*(1-exp(-x/25)),0)\n  }\n  else if (type == \"sinusoidal\") {\n    y &lt;- sin(2 * pi * x) \n  }\n  else if (type == \"quadratic\") {\n    y &lt;- round(210 - ((x-50)^2)/12,0)\n  }\n  else {\n    stop(\"type must be linear, exponential, quadratic, or sinusoidal\")\n  }\n  # if noise is specified, add noise to the y values\n  if(!is.na(noise)) {\n    y &lt;- y + round(rnorm(length(y), 0, noise),2)\n  }\n  data.frame(x, y,type)\n}\n\nenvTypes &lt;- c(\"linear\", \"exponential\", \"quadratic\")\n\nlowDensityTrainBlock &lt;- c(30.5, 36.0, 41.0, 46.5, 53.5, 59.0, 64.0, 69.5)\nmedDensityTrainBlock &lt;- c(\n    30.0, 31.5, 33.0, 34.5, 36.5, 38.5, 41.0, 43.5, 46.0,\n    48.5, 51.5, 54.0, 56.5, 59.0, 61.5, 63.5, 65.5, 67.0, 68.5, 70.0\n)\nhighDensityTrainBlock &lt;- c(\n    30.0, 30.5, 31.0, 32.0, 33.0, 33.5, 34.5, 35.5,\n    36.5, 37.0, 38.0, 38.5, 39.5, 40.5, 41.5, 42.0, 43.0,\n    43.5, 44.5, 45.5, 46.5, 47.0, 48.0, 48.5, 49.0, 51.0, 51.5, 52.0,\n    53.0, 53.5, 54.5, 55.5, 56.5, 57.0, 58.0, 58.5, 59.5, 60.5, 61.5, \n    62.0, 63.0,63.5, 64.5, 65.5, 66.5, 67.0, 68.0, 69.0, 69.5, 70.0\n)\n# all density conditions have the same # of training trials, but differ in the # of repetitions per items, or blocks,  low density has 25 training blocks, medium has 10 blocks, high has 4 blocks. \n\n# generate training data, for each combination of environment type and density. Use purrr map functions. Rep each dataset by its number of blocks.\nlowTrain &lt;- map_dfr(envTypes, ~ generate.data(rep(lowDensityTrainBlock,25), type = .x)) %&gt;% group_by(type) %&gt;% mutate(block = rep(1:25, each = 8),trial=seq(1,200))\n\nmedTrain &lt;- map_dfr(envTypes, ~ generate.data(rep(medDensityTrainBlock,10), type = .x)) %&gt;% group_by(type) %&gt;% mutate(block = rep(1:10, each = 20),trial=seq(1,200))\n\nhighTrain &lt;- map_dfr(envTypes, ~ generate.data(rep(highDensityTrainBlock,4), type = .x)) %&gt;% group_by(type) %&gt;% mutate(block = rep(1:4, each = 50),trial=seq(1,200))\n\n# nTrainExamples &lt;- 10\n# trainLowBound &lt;-20; trainHIghBound &lt;- 80\n# nBlock &lt;- 5 # number of times each training example is presented\n# sample training data from function, nTrainExamples., between trainLowBound and trainHIghBound\n# xt &lt;- runif(nTrainExamples, trainLowBound, trainHIghBound)\n# trainVec &lt;- rep(xt, nBlock)\n\n\n\n\nSimulation Functions\n\n\nCode\n# simulation function\nalm.sim &lt;- function(dat, c, lr,testRange=seq(0,100,.5)){\n  \ninput.layer &lt;&lt;- matrix(seq(0,100,.5) ) # half step units for inputs, from 0 to 100\noutput.layer &lt;&lt;- matrix(seq(0,250,1)) # single step units for outputs, from 0 to 250\nweight.mat &lt;&lt;- matrix(0.0000000,nrow=length(output.layer),ncol=length(input.layer )) # weights initialized to 0 (as in Delosh 1997)\n\nxt&lt;&lt;-dat$x\n# run training\nst &lt;- map2_dbl(dat$x, dat$y, ~alm.trial(.x,.y,c,lr))\n# append training data to the data frame\ndat &lt;- dat %&gt;% mutate(almResp = st)\n\nreturn(list(d=dat,wm=weight.mat,c=c,lr=lr)) # final weightmat is probs incorrect for all but last\n}\n\n\nsimOrganize &lt;- function(simOut){\n  dat &lt;- simOut$d\n  weight.mat &lt;&lt;- simOut$wm\n  c &lt;- simOut$c\n  lr &lt;- simOut$lr\n\n  trainX &lt;- unique(dat$x)\n  xt &lt;&lt;- trainX\n  \n almResp &lt;- generate.data(seq(0,100,.5), type = first(dat$type)) %&gt;% rowwise() %&gt;% \n mutate(model=\"ALM\",resp = alm.response(x,c))\n\n examResp &lt;- generate.data(seq(0,100,.5), type = first(dat$type)) %&gt;% rowwise() %&gt;% \n mutate(model=\"EXAM\",resp = exam.response(x,c))\n\n bind_rows(almResp,examResp) %&gt;% \n mutate(type=first(dat$type),\n        c=c,lr=lr,\n type=factor(type,levels=c(\"linear\",\"exponential\",\"quadratic\"))) %&gt;%\n # compute test_region, equal to \"train\" if x is within trainX, interpolate if within trainX range, else \"extrapolate\"\n  mutate(test_region = ifelse(x %in% trainX, \"train\", ifelse(x &gt; min(trainX) & x &lt; max(trainX), \"interpolate\", \"extrapolate\")))\n\n}\n\n\n\n\nSimulate Training:\n\n\nCode\n# split by type, then send each training dataset to simulation function\nlowSim &lt;- map(envTypes, ~ alm.sim(lowTrain %&gt;% filter(type == .x), c = 1.4, lr = .4))\n\nmedSim &lt;- map(envTypes, ~ alm.sim(medTrain %&gt;% filter(type == .x), c = 1.4, lr = .4))\n\nhighSim &lt;- map(envTypes, ~ alm.sim(highTrain %&gt;% filter(type == .x), c = 1.4, lr = .4))\n\n\nsimAll &lt;- rbind(bind_rows(lowSim %&gt;% map(\"d\")) %&gt;% mutate(density = \"low\"), \n                bind_rows(medSim %&gt;% map(\"d\")) %&gt;% mutate(density = \"med\"), \n                bind_rows(highSim %&gt;% map(\"d\")) %&gt;% mutate(density = \"high\"))\n\n\n\nsimAll &lt;- simAll %&gt;% mutate(stage=as.numeric(cut(trial,breaks=20,labels=seq(1,20))),\n                                      dev=sqrt((y-almResp)^2),\n                                  #reorder density factor levels\n                            density=factor(density,levels=c(\"low\",\"med\",\"high\")),\n                            type=factor(type,levels=c(\"linear\",\"exponential\",\"quadratic\"))) %&gt;%\n                            dplyr::relocate(density,type,stage)\n\nsimAll %&gt;% ggplot(aes(x=block,y=dev,color=type)) + stat_summary(geom=\"line\",fun=mean,alpha=.4)+\n  stat_summary(geom=\"point\",fun=mean,alpha=.4)+\n  stat_summary(geom=\"errorbar\",fun.data=mean_cl_normal,alpha=.4)+facet_wrap(~density, scales=\"free_x\")\n\n\n\n\n\nPredictions for Generalization\n\n\nCode\nlowSimTest &lt;- map_dfr(lowSim,simOrganize) %&gt;% mutate(density = \"low\")\nmedSimTest &lt;- map_dfr(medSim,simOrganize) %&gt;% mutate(density = \"med\")\nhighSimTest &lt;- map_dfr(highSim,simOrganize) %&gt;% mutate(density = \"high\")\n\nsimTestAll &lt;- rbind(lowSimTest,medSimTest,highSimTest) %&gt;% group_by(type,density,model) %&gt;%\n  mutate(type=factor(type,levels=c(\"linear\",\"exponential\",\"quadratic\")),\n         density=factor(density,levels=c(\"low\",\"med\",\"high\"))) %&gt;%\n  dplyr::relocate(density,type,test_region)\n\nsimTestAll %&gt;% ggplot(aes(x=x,y=y)) + \n  geom_point(aes(x=x,y=resp,shape=model,color=model),alpha=.7,size=1) + \n  geom_line(aes(x=x,y=y),alpha=.4)+ \n  #geom_point(aes(x=x,y=y,color=test_region),alpha=.2)+ \n  geom_point(data=simTestAll %&gt;% filter(test_region==\"train\"),aes(x=x,y=y),color=\"black\",size=1,alpha=1) +\n # geom_point(data=simTestAll %&gt;% filter(test_region %in% c(\"interpolate\",\"extrapolate\")),aes(x=x,y=y,color=test_region),alpha=.6) +\n  # geom_point(data=simTestAll %&gt;% filter(test_region==\"extrapolate\"),aes(x=x,y=y),color=\"purple\",alpha=.3) +\n  facet_grid(density~type) + \n  theme_bw() + theme(legend.position=\"bottom\")\n\n\n\n\n\nCode\n#lowSimTest %&gt;% filter(model==\"EXAM\" & type==\"linear\")\n#rm(list= ls()[sapply(ls(), function(x) class(get(x))) != 'function'])\n#rm(weight.mat,input.activation,output.probability,output.activation,mean.response,xt)\n# \n# simAll %&gt;% ggplot(aes(x=block,y=dev)) + stat_summary(geom=\"line\",fun=mean,alpha=.3)+stat_summary(geom=\"point\",fun=mean)+\n#   stat_summary(geom=\"errorbar\",fun.data=mean_cl_normal)+facet_wrap(density~type, scales=\"free_x\")\n\n\nCollpasing Across Density Levels gives us:\n\n\nCode\nsimTestAll %&gt;% group_by(type,model,x,y) %&gt;% summarise(resp=mean(resp))  %&gt;% ggplot(aes(x=x,y=y)) + \n  geom_point(aes(x=x,y=resp,shape=model,color=model),alpha=.7,size=1) + \n  geom_line(aes(x=x,y=y),alpha=.4)+ \n  facet_grid(~type) + \n  theme_bw() + theme(legend.position=\"bottom\")\n\n\n\n\nMaster Function for full simulation\n\n\nCode\n# Function that goes through every step of generating data, simulating training, and simulating generalization\nfull.sim &lt;- function(c,lr,noise)\n{\n  \nenvTypes &lt;- c(\"linear\", \"exponential\", \"quadratic\")\nlowDensityTrainBlock &lt;- c(30.5, 36.0, 41.0, 46.5, 53.5, 59.0, 64.0, 69.5)\nmedDensityTrainBlock &lt;- c(\n    30.0, 31.5, 33.0, 34.5, 36.5, 38.5, 41.0, 43.5, 46.0,\n    48.5, 51.5, 54.0, 56.5, 59.0, 61.5, 63.5, 65.5, 67.0, 68.5, 70.0\n)\nhighDensityTrainBlock &lt;- c(\n    30.0, 30.5, 31.0, 32.0, 33.0, 33.5, 34.5, 35.5,\n    36.5, 37.0, 38.0, 38.5, 39.5, 40.5, 41.5, 42.0, 43.0,\n    43.5, 44.5, 45.5, 46.5, 47.0, 48.0, 48.5, 49.0, 51.0, 51.5, 52.0,\n    53.0, 53.5, 54.5, 55.5, 56.5, 57.0, 58.0, 58.5, 59.5, 60.5, 61.5, \n    62.0, 63.0,63.5, 64.5, 65.5, 66.5, 67.0, 68.0, 69.0, 69.5, 70.0\n)\n# low density has 25 training blocks, medium has 10 blocks, high has 4 blocks. \n# generate training data, for each combination of environment type and density. Use purrr map functions. Rep each dataset by its number of blocks.\nlowTrain &lt;- map_dfr(envTypes, ~ generate.data(rep(lowDensityTrainBlock,25), type = .x, noise)) %&gt;% group_by(type) %&gt;% mutate(block = rep(1:25, each = 8),trial=seq(1,200))\nmedTrain &lt;- map_dfr(envTypes, ~ generate.data(rep(medDensityTrainBlock,10), type = .x, noise)) %&gt;% group_by(type) %&gt;% mutate(block = rep(1:10, each = 20),trial=seq(1,200))\nhighTrain &lt;- map_dfr(envTypes, ~ generate.data(rep(highDensityTrainBlock,4), type = .x, noise)) %&gt;% group_by(type) %&gt;% mutate(block = rep(1:4, each = 50),trial=seq(1,200))\n  \nlowSim &lt;- map(envTypes, ~ alm.sim(lowTrain %&gt;% filter(type == .x), c = 1.4, lr = .4))\nmedSim &lt;- map(envTypes, ~ alm.sim(medTrain %&gt;% filter(type == .x), c = 1.4, lr = .4))\nhighSim &lt;- map(envTypes, ~ alm.sim(highTrain %&gt;% filter(type == .x), c = 1.4, lr = .4))\n\nsimAll &lt;- rbind(bind_rows(lowSim %&gt;% map(\"d\")) %&gt;% mutate(density = \"low\"), \n                bind_rows(medSim %&gt;% map(\"d\")) %&gt;% mutate(density = \"med\"), \n                bind_rows(highSim %&gt;% map(\"d\")) %&gt;% mutate(density = \"high\"))\n\nsimAll &lt;- simAll %&gt;% mutate(stage=as.numeric(cut(trial,breaks=20,labels=seq(1,20))),\n                                      dev=sqrt((y-almResp)^2),\n                                  #reorder density factor levels\n                            density=factor(density,levels=c(\"low\",\"med\",\"high\")),\n                            type=factor(type,levels=c(\"linear\",\"exponential\",\"quadratic\"))) %&gt;%\n                            dplyr::relocate(density,type,stage)\n\nlowSimTest &lt;- map_dfr(lowSim,simOrganize) %&gt;% mutate(density = \"low\")\nmedSimTest &lt;- map_dfr(medSim,simOrganize) %&gt;% mutate(density = \"med\")\nhighSimTest &lt;- map_dfr(highSim,simOrganize) %&gt;% mutate(density = \"high\")\n\nsimTestAll &lt;- rbind(lowSimTest,medSimTest,highSimTest) %&gt;% group_by(type,density,model) %&gt;%\n  mutate(type=factor(type,levels=c(\"linear\",\"exponential\",\"quadratic\")),\n         density=factor(density,levels=c(\"low\",\"med\",\"high\"))) %&gt;%\n  dplyr::relocate(density,type,test_region)\n\nreturn(list(simAll=list(simAll),simTestAll=list(simTestAll)))\n  \n}\n\n\n\n\nSimulations with noise\n\n\nCode\nk = full.sim(c=1.4,lr=.4,noise=2.0)\nk4 = full.sim(c=1.4,lr=.4,noise=4.0)\n\n# run simulation with noise=10, 3 times, average results together. \nk10 = map_dfr(1:3, ~ full.sim(c=1.4,lr=.4,noise=10.0)) %&gt;% group_by(type,density,model) %&gt;%\n  mutate(type=factor(type,levels=c(\"linear\",\"exponential\",\"quadratic\")),\n         density=factor(density,levels=c(\"low\",\"med\",\"high\"))) %&gt;%\n  dplyr::relocate(density,type,test_region)\n\n\n\nk %&gt;% pluck(\"simAll\") %&gt;% ggplot(aes(x=block,y=dev,color=type)) + stat_summary(geom=\"line\",fun=mean,alpha=.4)+\n  stat_summary(geom=\"point\",fun=mean,alpha=.4)+\n  stat_summary(geom=\"errorbar\",fun.data=mean_cl_normal,alpha=.4)+facet_wrap(~density, scales=\"free_x\")\n\n\nk4 %&gt;% pluck(\"simAll\") %&gt;% ggplot(aes(x=block,y=dev,color=type)) + stat_summary(geom=\"line\",fun=mean,alpha=.4)+\n  stat_summary(geom=\"point\",fun=mean,alpha=.4)+\n  stat_summary(geom=\"errorbar\",fun.data=mean_cl_normal,alpha=.4)+facet_wrap(~density, scales=\"free_x\")\n\n\nk %&gt;% pluck(\"simTestAll\") %&gt;%ggplot(aes(x=x,y=y)) + \n  geom_point(aes(x=x,y=resp,shape=model,color=model),alpha=.7,size=1) + \n  geom_line(aes(x=x,y=y),alpha=.4)+ \n  geom_point(data=simTestAll %&gt;% filter(test_region==\"train\"),aes(x=x,y=y),color=\"black\",size=1,alpha=1) +\n  facet_grid(density~type) + \n  theme_bw() + theme(legend.position=\"bottom\")\n\nk4 %&gt;% pluck(\"simTestAll\") %&gt;%ggplot(aes(x=x,y=y)) + \n  geom_point(aes(x=x,y=resp,shape=model,color=model),alpha=.7,size=1) + \n  geom_line(aes(x=x,y=y),alpha=.4)+ \n  geom_point(data=simTestAll %&gt;% filter(test_region==\"train\"),aes(x=x,y=y),color=\"black\",size=1,alpha=1) +\n  facet_grid(density~type) + \n  theme_bw() + theme(legend.position=\"bottom\")\n\nk10 %&gt;% pluck(\"simTestAll\") %&gt;%ggplot(aes(x=x,y=y)) + \n  geom_point(aes(x=x,y=resp,shape=model,color=model),alpha=.7,size=1) + \n  geom_line(aes(x=x,y=y),alpha=.4)+ \n  geom_point(data=simTestAll %&gt;% filter(test_region==\"train\"),aes(x=x,y=y),color=\"black\",size=1,alpha=1) +\n  facet_grid(density~type) + \n  theme_bw() + theme(legend.position=\"bottom\")\n\n\n\n\nCode\n# label each each simulation with its density level (low, med, high), then combine all 3\nlowSimTest &lt;- lowSimTest %&gt;% mutate(density = \"low\")\nmedSimTest &lt;- medSimTest %&gt;% mutate(density = \"med\")\nhighSimTest &lt;- highSimTest %&gt;% mutate(density = \"high\")\n\nsimTest &lt;- bind_rows(lowSimTest,medSimTest,highSimTest)\n\n# extract element d from each list, and bind rows, remove Nan's, group by type, mutate new variable \"Stage\", which is set to first for block 1, last for final block, and middle for all other glocks, pipe to ggplot, plotting y and almResp in different colors, facet by type and stage (only first and last block)\nls2=bind_rows(lowSim %&gt;% map(\"d\")) %&gt;% filter(!is.na(almResp)) %&gt;% \n  group_by(type) %&gt;% \n  mutate(stage = ifelse(block == 1, \"first\", ifelse(block == 25, \"last\", \"middle\")),\n         stage2=cut(trial,breaks=20,labels=seq(1,20)),\n         dev=sqrt((y-almResp)^2))\n \nls2 %&gt;% ggplot() + geom_point(aes(x=stage2,y=dev))+facet_grid(~type)\n\n\n\nls2 %&gt;% filter(stage %in% c(\"first\",\"last\")) %&gt;% ggplot() + geom_point(aes(x=x,y=y),color=\"red\",alpha=.3) + \ngeom_point(aes(x=x,y=almResp),color=\"blue\",alpha=.4)+ \nfacet_grid(type~stage) + theme_bw() + theme(legend.position=\"bottom\")\n\n\nlowSimTest %&gt;% ggplot() + geom_point(aes(x=x,y=resp,color=model)) + geom_line(aes(x=x,y=y),alpha=.3)+ facet_grid(~type) + theme_bw() + theme(legend.position=\"bottom\")\n\n# make grid of each combination of train dataset and envType\nsimGrid &lt;- expand.grid(envTypes=envTypes,trainData=c(\"lowTrain\",\"medTrain\",\"highTrain\"))\n\n# map over the grid, for each row of simGrid, filter the training dataset by the envType, and then run the simulation function, and then bind rows of the output data frame.\nsimOut &lt;- map2(c(\"lowTrain\",\"medTrain\",\"highTrain\"),envTypes, ~ alm.sim(get(.x) %&gt;% filter(type == .y), c = 1.4, lr = .4))\n\n# simOut &lt;- map(c(\"lowTrain\",\"medTrain\",\"highTrain\"), ~ map_dfr(envTypes, ~ alm.sim(get(.) %&gt;% filter(type == .x), c = 1.4, lr = .4) %&gt;% simOrganize))\n# \n# simOut &lt;- map_dfr(simGrid, ~ alm.sim(get(.x$trainData) %&gt;% filter(type == .x$envTypes), c = 1.4, lr = .4) %&gt;% simOrganize)\n# \n# for each training dataset in c(lowTrain,medTrain,highTrain), run simulation function, separately for each type, and then bind rows of the output data frame.\n\n\n\n\nPrimary Functions"
  },
  {
    "objectID": "Simulations/SimReplications.html",
    "href": "Simulations/SimReplications.html",
    "title": "General Simulations",
    "section": "",
    "text": "Functions\n\n\nCode\npacman::p_load(tidyverse,reshape2)\n\ninput.activation&lt;-function(x.target, association.parameter){\n  return(exp(-1*association.parameter*(x.target-x.plotting)^2))\n}\n\noutput.activation&lt;-function(x.target, weights, association.parameter){\n  return(weights%*%input.activation(x.target, association.parameter))\n}\n\nmean.prediction&lt;-function(x.target, weights, association.parameter){\n  probability&lt;-output.activation(x.target, weights, association.parameter)/sum(output.activation(x.target, weights, association.parameter))\n  return(y.plotting%*%probability) # integer prediction\n}\n# function to generate exam predictions\nexam.prediction&lt;-function(x.target, weights, association.parameter){\n  trainVec = sort(unique(x.learning))\n  nearestTrain = trainVec[which.min(abs(trainVec-x.target))]\n  aresp = mean.prediction(nearestTrain, weights, association.parameter)\n  xUnder = ifelse(min(trainVec) == nearestTrain, nearestTrain, trainVec[which(trainVec == nearestTrain) - 1])\n  xOver = ifelse(max(trainVec) == nearestTrain, nearestTrain, trainVec[which(trainVec == nearestTrain) + 1])\n  mUnder = mean.prediction(xUnder, weights, association.parameter)\n  mOver = mean.prediction(xOver, weights, association.parameter)\n  exam.output = round(aresp + ((mOver - mUnder) / (xOver - xUnder)) * (x.target - nearestTrain), 3)\n  exam.output\n}\n  \nupdate.weights&lt;-function(x.new, y.new, weights, association.parameter, update.parameter){\n  y.feedback.activation&lt;-exp(-1*association.parameter*(y.new-y.plotting)^2)\n  x.feedback.activation&lt;-output.activation(x.new, weights, association.parameter)\n  return(weights+update.parameter*(y.feedback.activation-x.feedback.activation)%*%t(input.activation(x.new, association.parameter)))\n}\n\nlearn.alm&lt;-function(y.learning, association.parameter=0.05, update.parameter=0.5){\n  weights&lt;-matrix(rep(0.00, length(y.plotting)*length(x.plotting)), nrow=length(y.plotting), ncol=length(x.plotting))\n  for (i in 1:length(y.learning)){\n    weights&lt;-update.weights(x.learning[i], y.learning[i], weights, association.parameter, update.parameter)\n    resp=mean.prediction(x.learning[i],weights,association.parameter)\n    weights[weights&lt;0]=0\n  }\n  alm.predictions&lt;-sapply(x.plotting, mean.prediction, weights=weights, association.parameter=association.parameter)\n  exam.predictions &lt;- sapply(x.plotting, exam.prediction, weights=weights, association.parameter=association.parameter)\n  return(list(alm.predictions=alm.predictions, exam.predictions=exam.predictions))\n}\n\n\n\n\nNo noise, 1 training rep\nRed dots are training points - gray lines are individual simulations, black line is average of simulations\n\n\nCode\n# | eval: false\n\ntrainRep=1\n\nx.plotting&lt;&lt;-seq(0,100, .5)\ny.plotting&lt;&lt;-seq(0, 210, by=2)\nf.plotting&lt;-as.numeric(x.plotting*2.2+30)\nx.learning&lt;-rep(x.plotting[20*c(4:7)+1])\nf.learning&lt;-rep(f.plotting[20*c(4:7)+1])\n\nparmVec &lt;- expand.grid(assoc=c(.1,0.5),update=c(0.2,1),noise=c(0),trainRep=c(1))\n#parmVec &lt;- expand.grid(assoc=c(.01),update=c(0.5),noise=c(30),trainRep=c(1,2,3,4))\n\nparmVec$sim &lt;- 1:nrow(parmVec)\nnSim=nrow(parmVec)\n\nnRep=5\noutput &lt;- list()\nfor (i in 1:nrow(parmVec)){\n  x.learning&lt;-rep(x.plotting[20*c(4:7)+1],times=parmVec$trainRep[i])\n  f.learning&lt;-rep(f.plotting[20*c(4:7)+1],times=parmVec$trainRep[i])\n  #noise.learning &lt;- rnorm(n_distinct(f.learning),sd=parmVec$noise[i])\n  output[[i]] &lt;- replicate(nRep, list(learn.alm(f.learning+rep(rnorm(n_distinct(f.learning),sd=parmVec$noise[i]),times=parmVec$trainRep[i]), \n                                         association.parameter=parmVec$assoc[i], update.parameter=parmVec$update[i])))\n}\n\n\n# convert list of dataframes to a list of lists, each list is a simulation, each element is a dataframe\noutput1 &lt;- lapply(output, function(x) lapply(x, as.data.frame)) # 10 dfs x 9 lists\noutput2 &lt;- lapply(output1, function(x) Reduce(rbind,x))# 1 df x 9 lists\noutput3 &lt;- lapply(output2, function(x) mutate(x, x=rep(x.plotting,nRep),y=rep(f.plotting,nRep),\n                                              repN=rep(seq(1,nRep),each=length(x.plotting))))\no4 &lt;- Reduce(rbind,output3) %&gt;% \n  mutate(sim=rep(seq(1,nrow(parmVec)),each=nRep*length(x.plotting))) %&gt;%\n  left_join(.,parmVec,by=\"sim\") %&gt;%\n  mutate(pvec=paste0(\"c=\",assoc,\"_lr=\",update,\"_noise=\",noise,\"_nrep=\",trainRep),pv=factor(pvec),rn=factor(repN)) \n\noMeans &lt;- o4 %&gt;% group_by(pv,x,y) %&gt;% \n  summarise(alm.predictions=mean(alm.predictions),exam.predictions=mean(exam.predictions),.groups=\"keep\")\n\no4 %&gt;% ggplot(aes(x=x,y=alm.predictions,color=rn))+geom_line(alpha=.7)+\n   scale_color_manual(values=rep(\"grey\",nRep))+\n  theme(legend.position=\"none\")+\n  geom_point(data=data.frame(x=x.learning,y=f.learning),aes(x=x,y=y),color=\"red\")+\n  geom_line(data=o4,aes(x=x,y=y),color=\"black\",alpha=.5, linetype=2)+\n  geom_line(data=oMeans,aes(x=x,y=alm.predictions),color=\"black\")+\n  facet_wrap(~pv, scales=\"free_y\")+ggtitle(\"ALM predictions\")\n\n\n\n\n\nCode\no4 %&gt;% ggplot(aes(x=x,y=exam.predictions,color=rn))+ geom_line()+ #geom_line(color=\"grey\",alpha=.4)+\n  scale_color_manual(values=rep(\"grey\",nRep))+\n  theme(legend.position=\"none\")+\n  geom_point(data=data.frame(x=x.learning,y=f.learning),aes(x=x,y=y),color=\"red\")+\n  geom_line(data=o4,aes(x=x,y=y),color=\"black\",alpha=.5,linetype=2)+\n  geom_line(data=oMeans,aes(x=x,y=exam.predictions),color=\"black\")+\n  facet_wrap(~pv, scales=\"free_y\")+ggtitle(\"EXAM predictions\")\n\n\n\n\n\n\n\nHigh noise, 1 training rep\nRed dots are training points - gray lines are individual simulations, black line is average of simulations\n\n\nCode\ntrainRep=1\n\nx.plotting&lt;&lt;-seq(0,100, .5)\ny.plotting&lt;&lt;-seq(0, 210, by=2)\nf.plotting&lt;-as.numeric(x.plotting*2.2+30)\nx.learning&lt;-rep(x.plotting[20*c(4:7)+1])\nf.learning&lt;-rep(f.plotting[20*c(4:7)+1])\n\n\nparmVec &lt;- expand.grid(assoc=c(.1,0.5),update=c(0.2,1),noise=c(30),trainRep=c(1))\n#parmVec &lt;- expand.grid(assoc=c(.01),update=c(0.5),noise=c(30),trainRep=c(1,2,3,4))\n\nparmVec$sim &lt;- 1:nrow(parmVec)\nnSim=nrow(parmVec)\n\nnRep=10\noutput &lt;- list()\nfor (i in 1:nrow(parmVec)){\n  x.learning&lt;-rep(x.plotting[20*c(4:7)+1],times=parmVec$trainRep[i])\n  f.learning&lt;-rep(f.plotting[20*c(4:7)+1],times=parmVec$trainRep[i])\n  #noise.learning &lt;- rnorm(n_distinct(f.learning),sd=parmVec$noise[i])\n  output[[i]] &lt;- replicate(nRep, list(learn.alm(f.learning+rep(rnorm(n_distinct(f.learning),sd=parmVec$noise[i]),times=parmVec$trainRep[i]), \n                                         association.parameter=parmVec$assoc[i], update.parameter=parmVec$update[i])))\n}\n\n# \n# nRep=3\n# output &lt;- list()\n# for (i in 1:nrow(parmVec)){\n#   output[[i]] &lt;- replicate(nRep, list(learn.alm(f.learning + rnorm(length(f.learning), sd=10), \n#                                          association.parameter=parmVec$assoc[i], update.parameter=parmVec$update[i])))\n# }\n\n\n\n#output[[i]] &lt;- replicate(nRep, list(learn.alm(f.learning + rnorm(length(f.learning), sd=10)\n\n# convert list of dataframes to a list of lists, each list is a simulation, each element is a dataframe\noutput1 &lt;- lapply(output, function(x) lapply(x, as.data.frame)) # 10 dfs x 9 lists\noutput2 &lt;- lapply(output1, function(x) Reduce(rbind,x))# 1 df x 9 lists\noutput3 &lt;- lapply(output2, function(x) mutate(x, x=rep(x.plotting,nRep),y=rep(f.plotting,nRep),\n                                              repN=rep(seq(1,nRep),each=length(x.plotting))))\no4 &lt;- Reduce(rbind,output3) %&gt;% \n  mutate(sim=rep(seq(1,nrow(parmVec)),each=nRep*length(x.plotting))) %&gt;%\n  left_join(.,parmVec,by=\"sim\") %&gt;%\n  mutate(pvec=paste0(\"c=\",assoc,\"_lr=\",update,\"_noise=\",noise,\"_nrep=\",trainRep),pv=factor(pvec),rn=factor(repN)) \n\noMeans &lt;- o4 %&gt;% group_by(pv,x,y) %&gt;% \n  summarise(alm.predictions=mean(alm.predictions),exam.predictions=mean(exam.predictions),.groups=\"keep\")\n\no4 %&gt;% ggplot(aes(x=x,y=alm.predictions,color=rn))+geom_line(alpha=.7)+\n   scale_color_manual(values=rep(\"grey\",nRep))+\n  theme(legend.position=\"none\")+\n  geom_point(data=data.frame(x=x.learning,y=f.learning),aes(x=x,y=y),color=\"red\")+\n  geom_line(data=o4,aes(x=x,y=y),color=\"black\",alpha=.5, linetype=2)+\n  geom_line(data=oMeans,aes(x=x,y=alm.predictions),color=\"black\")+\n  facet_wrap(~pv, scales=\"free_y\")+ggtitle(\"ALM predictions\")+ylim(0,300)\n\no4 %&gt;% ggplot(aes(x=x,y=exam.predictions,color=rn))+ geom_line()+ #geom_line(color=\"grey\",alpha=.4)+\n  scale_color_manual(values=rep(\"grey\",nRep))+\n  theme(legend.position=\"none\")+\n  geom_point(data=data.frame(x=x.learning,y=f.learning),aes(x=x,y=y),color=\"red\")+\n  geom_line(data=o4,aes(x=x,y=y),color=\"black\",alpha=.5,linetype=2)+\n  geom_line(data=oMeans,aes(x=x,y=exam.predictions),color=\"black\")+\n  facet_wrap(~pv, scales=\"free_y\")+ggtitle(\"EXAM predictions\")+ylim(0,300)\n\n\n\n\nHigh noise, 60 training rep\nRed dots are training points - gray lines are individual simulations, black line is average of simulations\n\n\nCode\ntrainRep=1\n\nx.plotting&lt;&lt;-seq(0,100, .5)\ny.plotting&lt;&lt;-seq(0, 210, by=2)\nf.plotting&lt;-as.numeric(x.plotting*2.2+30)\nx.learning&lt;-rep(x.plotting[20*c(4:7)+1])\nf.learning&lt;-rep(f.plotting[20*c(4:7)+1])\n\n\nparmVec &lt;- expand.grid(assoc=c(.1,0.5),update=c(0.2,1),noise=c(30),trainRep=c(60))\n#parmVec &lt;- expand.grid(assoc=c(.01),update=c(0.5),noise=c(30),trainRep=c(1,2,3,4))\n\nparmVec$sim &lt;- 1:nrow(parmVec)\nnSim=nrow(parmVec)\n\nnRep=10\noutput &lt;- list()\nfor (i in 1:nrow(parmVec)){\n  x.learning&lt;-rep(x.plotting[20*c(4:7)+1],times=parmVec$trainRep[i])\n  f.learning&lt;-rep(f.plotting[20*c(4:7)+1],times=parmVec$trainRep[i])\n  #noise.learning &lt;- rnorm(n_distinct(f.learning),sd=parmVec$noise[i])\n  output[[i]] &lt;- replicate(nRep, list(learn.alm(f.learning+rep(rnorm(n_distinct(f.learning),sd=parmVec$noise[i]),times=parmVec$trainRep[i]), \n                                         association.parameter=parmVec$assoc[i], update.parameter=parmVec$update[i])))\n}\n\n\n# convert list of dataframes to a list of lists, each list is a simulation, each element is a dataframe\noutput1 &lt;- lapply(output, function(x) lapply(x, as.data.frame)) # 10 dfs x 9 lists\noutput2 &lt;- lapply(output1, function(x) Reduce(rbind,x))# 1 df x 9 lists\noutput3 &lt;- lapply(output2, function(x) mutate(x, x=rep(x.plotting,nRep),y=rep(f.plotting,nRep),\n                                              repN=rep(seq(1,nRep),each=length(x.plotting))))\no4 &lt;- Reduce(rbind,output3) %&gt;% \n  mutate(sim=rep(seq(1,nrow(parmVec)),each=nRep*length(x.plotting))) %&gt;%\n  left_join(.,parmVec,by=\"sim\") %&gt;%\n  mutate(pvec=paste0(\"c=\",assoc,\"_lr=\",update,\"_noise=\",noise,\"_nrep=\",trainRep),pv=factor(pvec),rn=factor(repN)) \n\noMeans &lt;- o4 %&gt;% group_by(pv,x,y) %&gt;% \n  summarise(alm.predictions=mean(alm.predictions),exam.predictions=mean(exam.predictions),.groups=\"keep\")\n\no4 %&gt;% ggplot(aes(x=x,y=alm.predictions,color=rn))+geom_line(alpha=.7)+\n   scale_color_manual(values=rep(\"grey\",nRep))+\n  theme(legend.position=\"none\")+\n  geom_point(data=data.frame(x=x.learning,y=f.learning),aes(x=x,y=y),color=\"red\")+\n  geom_line(data=o4,aes(x=x,y=y),color=\"black\",alpha=.5, linetype=2)+\n  geom_line(data=oMeans,aes(x=x,y=alm.predictions),color=\"black\")+\n  facet_wrap(~pv, scales=\"free_y\")+ggtitle(\"ALM predictions\")+ylim(0,300)\n\no4 %&gt;% ggplot(aes(x=x,y=exam.predictions,color=rn))+ geom_line()+ #geom_line(color=\"grey\",alpha=.4)+\n  scale_color_manual(values=rep(\"grey\",nRep))+\n  theme(legend.position=\"none\")+\n  geom_point(data=data.frame(x=x.learning,y=f.learning),aes(x=x,y=y),color=\"red\")+\n  geom_line(data=o4,aes(x=x,y=y),color=\"black\",alpha=.5,linetype=2)+\n  geom_line(data=oMeans,aes(x=x,y=exam.predictions),color=\"black\")+\n  facet_wrap(~pv, scales=\"free_y\")+ggtitle(\"EXAM predictions\")+ylim(0,300)\n\n\n\n\nShiny App\n\n\nCode\nx.plotting&lt;&lt;-seq(0,90, .5)\ny.plotting&lt;&lt;-seq(0, 210, by=2)\nf.plotting&lt;-as.numeric(x.plotting * 2.2 + 30)\nx.learning&lt;-x.plotting[10*c(3:9)+1]\nf.learning&lt;-f.plotting[10*c(3:9)+1]\n\n# Single Simulation\n# get alm and exam predictions for full range of x.plotting\noutput&lt;-learn.alm(f.learning)\nalm.predictions&lt;-output$alm.predictions\nexam.predictions&lt;-output$exam.predictions\n\n# plot the results\nplot(x.plotting, f.plotting, type=\"l\", col=\"blue\", lwd=.5, xlab=\"x\", ylab=\"f(x)\")\npoints(x.learning, f.learning, col=\"red\", pch=19)\nlines(x.plotting, alm.predictions, col=\"green\", lwd=2)\nlines(x.plotting, exam.predictions, col=\"purple\", lwd=2)\nlegend(\"topright\", legend=c(\"f(x)\", \"training data\", \"ALM\", \"Exam\"), col=c(\"blue\", \"red\", \"green\", \"purple\"), lty=1.5, cex=0.8)\n\n#function to plot in greyscale\nplot.grey&lt;-function(predictions){\n  lines(x.plotting, predictions, col=\"grey\")\n}\n\n\n\n\nCode\n# Average of 100 simulations:\n# get alm and exam predictions for full range of x.plotting, averaged over 100 simulations\nnSim&lt;-10\noutput &lt;- replicate(nSim, list(learn.alm(f.learning + rnorm(length(f.learning), sd=0.1), \n                                         association.parameter=0.05, update.parameter=0.5)))\n\n#alm.predictions&lt;-do.call(rbind, lapply(output, function(x) x$alm.predictions))\nalm.predictions &lt;- Reduce(rbind,output %&gt;% map(\"alm.predictions\"))\nexam.predictions &lt;- Reduce(rbind,output %&gt;% map(\"exam.predictions\"))\n\nalm.predictions.avg&lt;-apply(alm.predictions, 2, mean)\nexam.predictions.avg&lt;-apply(exam.predictions, 2, mean)\ndfAvg&lt;-data.frame(x=x.plotting, f=f.plotting, alm=alm.predictions.avg, exam=exam.predictions.avg)\ndfAvg&lt;-reshape2::melt(dfAvg, id.vars=\"x\")\ndfAvg$model&lt;-factor(dfAvg$variable, levels=c(\"f\", \"alm\", \"exam\"))\nggplot(dfAvg, aes(x=x, y=value, color=model)) + geom_line() + geom_point(data=data.frame(x=x.learning, f=f.learning), aes(x=x, y=f), color=\"red\", size=2) + theme_bw() + theme(legend.position=\"topright\")\n\n\nalm.predictions&lt;-as.data.frame(alm.predictions) %&gt;% mutate(sim=seq(1:nSim))\nalm.predictions&lt;-pivot_longer(alm.predictions, cols=1:ncol(alm.predictions)-1, \n                              names_to=c(\"sim\"), values_to=\"alm\",names_repair = \"unique\") \ncolnames(alm.predictions)=c(\"sim\",\"x\",\"pred\")\nalm.predictions &lt;- alm.predictions %&gt;% mutate(stim = as.numeric(gsub(\"V\", \"\", x)),model=\"alm\",x=x.plotting[stim])\n\n\nexam.predictions&lt;-as.data.frame(exam.predictions) %&gt;% mutate(sim=seq(1:nSim))\nexam.predictions&lt;-pivot_longer(exam.predictions, cols=1:ncol(exam.predictions)-1, \n                               names_to=c(\"sim\"), values_to=\"exam\",names_repair = \"unique\")\ncolnames(exam.predictions)=c(\"sim\",\"x\",\"pred\")\nexam.predictions &lt;- exam.predictions %&gt;% mutate(stim = as.numeric(gsub(\"V\", \"\", x)),model=\"exam\",x=x.plotting[stim])\n\n\ndf&lt;- rbind(alm.predictions,exam.predictions)\n\nggplot(df, aes(x=x, y=pred, color=sim)) + geom_line(alpha=.2) + facet_wrap(~model) + theme_bw() + \n  geom_point(data=data.frame(x=x.learning, f=f.learning), aes(x=x, y=f), color=\"red\", size=2)+\n  geom_line(data=data.frame(x=x.plotting, f=f.plotting),aes(x=x,y=f),color=\"black\")+\n  geom_line(data=dfAvg %&gt;% filter(model!=\"f\"),aes(x=x,y=value),color=\"green\")"
  },
  {
    "objectID": "Simulations/almNodes.html",
    "href": "Simulations/almNodes.html",
    "title": "Node Manipulations",
    "section": "",
    "text": "Code\npacman::p_load(tidyverse,data.table)\noptions(dplyr.summarise.inform=FALSE)\n\ninput.activation&lt;-function(x.target, c) { return(exp((-1*c)*(x.target-inputNodes)^2))}\n\noutput.activation&lt;-function(x.target, weights, c){\n  return(weights%*%input.activation(x.target, c))\n}\nmean.prediction&lt;-function(x.target, weights, c){\n  probability&lt;-output.activation(x.target, weights, c)/sum(output.activation(x.target, weights, c))\n  return(outputNodes%*%probability) # integer prediction\n}\n\nupdate.weights&lt;-function(x.new, y.new, weights, c, lr){\n  y.feedback.activation&lt;-exp(-1*c*(y.new-outputNodes)^2)\n  x.feedback.activation&lt;-output.activation(x.new, weights, c)\n  return(weights+lr*(y.feedback.activation-x.feedback.activation)%*%t(input.activation(x.new, c)))\n}\n\ntrain.alm&lt;-function(dat, c=0.05, lr=0.5, weights){\n   alm.train&lt;-rep(NA,nrow(dat))  \n  for (i in 1:nrow(dat)){\n    weights &lt;- update.weights(dat$input[i], dat$vx[i], weights, c, lr)\n    resp = mean.prediction(dat$input[i], weights, c)\n    alm.train[i]=resp\n    weights[weights&lt;0]=0\n  }\n  alm.train\n}\n\n# function to generate exam predictions\nexam.prediction&lt;-function(x.target, weights, c,trainVec){\n  #trainVec = sort(unique(x.learning))\n  nearestTrain = trainVec[which.min(abs(trainVec-x.target))]\n  aresp = mean.prediction(nearestTrain, weights, c)\n  xUnder = ifelse(min(trainVec) == nearestTrain, nearestTrain, trainVec[which(trainVec == nearestTrain) - 1])\n  xOver = ifelse(max(trainVec) == nearestTrain, nearestTrain, trainVec[which(trainVec == nearestTrain) + 1])\n  mUnder = mean.prediction(xUnder, weights, c)\n  mOver = mean.prediction(xOver, weights, c)\n  exam.output = round(aresp + ((mOver - mUnder) / (xOver - xUnder)) * (x.target - nearestTrain), 3)\n  exam.output\n}\n\n# Modify the sim_data function to accept the dataset as an argument\nsim_data &lt;- function(dat, c=0.5, lr=0.2, inNodes=7, outNodes=32, trainVec=c(5,6,7)) {\n  inputNodes &lt;&lt;- seq(1,7,length.out=inNodes*1)  \n  outputNodes &lt;&lt;- seq(50,1600,length.out=outNodes*1) \n  wm=matrix(.0000,nrow=length(outputNodes),ncol=length(inputNodes))\n  tt&lt;-trainTest.alm(dat, c, lr, wm, trainVec)\n}\n\ngen_train &lt;- function(trainVec=c(5,6,7),trainRep=10,noise=0){\n   bandVec=c(0,100,350,600,800,1000,1200)\n   ts &lt;- rep(seq(1,length(trainVec)),trainRep)\n   noiseVec=rnorm(length(ts),mean=0)*noise\n   if(noise==0) {noiseVec=noiseVec*0}\n   tibble(input=trainVec[ts],vx=bandVec[trainVec[ts]]+noiseVec)\n}\n\n\ntrainTest.alm&lt;-function(dat, c=0.05, lr=0.5, weights,testVec){\n   alm.train&lt;-rep(NA,nrow(dat))  \n  for (i in 1:nrow(dat)){\n    weights &lt;- update.weights(dat$input[i], dat$vx[i], weights, c, lr)\n    resp = mean.prediction(dat$input[i], weights, c)\n    alm.train[i]=resp\n    weights[weights&lt;0]=0\n  }\n  almPred &lt;- sapply(testVec,mean.prediction,weights,c)\n  examPred &lt;- sapply(testVec,exam.prediction,weights,c,trainVec=c(1,sort(unique(dat$input))))\n  list(almTrain=alm.train,almPred=almPred,examPred=examPred)\n}\n\nwrap_alm &lt;- function(par,dat, weights,lossFun){\n    c=par[1]; lr=par[2]\n   pred=train.alm(dat, c=c, lr=lr, weights=weights)\n   #sqrt(mean((dat$vx -pred)^2))\n   lossFun(dat$vx,pred)\n}\n\nwrap_optim &lt;- function(dat,lossFun=RMSE){\n  if(class(lossFun)==\"character\"){lossFun=get(lossFun)}\n  inputNodes = seq(1,7,1)  # \n  outputNodes = seq(50,1600,50)\n  wm=matrix(.00001,nrow=length(outputNodes),ncol=length(inputNodes))\n  testVec=seq(2,7)\n  \n  bounds_lower &lt;- c(.0000001, .00001)\n  bounds_upper &lt;- c(10, 10)\n  parmsLab &lt;- c(\"c\",\"lr\")\n  \n fit=optim(par=c(.1, .2),\n   fn = wrap_alm,\n   dat = dat, weights = wm,lossFun=lossFun,\n   method = \"L-BFGS-B\",\n   lower = bounds_lower,\n   upper = bounds_upper,\n   control = list(maxit = 1e5, pgtol = 0, factr = 0)\n )\n\n l=reduce(list(list(fit),fit$par,fit$value),append)\n names(l)=c(\"Fit\",parmsLab,\"Value\")\n return(l)\n}\n\n\n\nLoss Functions\n\n\nCode\nRMSE &lt;- function(x,y){\n # print(\"rmseTrial\")\n  sqrt(mean((x-y)^2))\n}\nMAE &lt;- function(x, y) {\n  mean(abs(x - y))\n}\n\n\n\n\nCode\n# Test varying input and output nodes, c, lr parameters and noise\ntest_nodes_exhaustive &lt;- function(dat, c_values = seq(0.1, 1, 0.1), lr_values = seq(0.1, 1, 0.1),\n                                  input_nodes = seq(3, 10), output_nodes = seq(16, 64, 8),\n                                  noise_values = seq(0, 1, 0.1), n_simulations = 10) {\n  results &lt;- list()\n\n  for (c in c_values) {\n    for (lr in lr_values) {\n      for (inNodes in input_nodes) {\n        for (outNodes in output_nodes) {\n          for (noise in noise_values) {\n            rmse_values &lt;- c()\n\n            for (i in 1:n_simulations) {\n              dat_noise &lt;- gen_train(noise = noise)\n              result &lt;- sim_data(dat_noise, c, lr, inNodes, outNodes)\n              rmse &lt;- RMSE(dat_noise$vx, result$almPred)\n              rmse_values &lt;- c(rmse_values, rmse)\n            }\n\n            results[[paste0(\"c\", c, \"_lr\", lr, \"_in\", inNodes, \"_out\", outNodes, \"_noise\", noise)]] &lt;-\n              list(c = c, lr = lr, inNodes = inNodes, outNodes = outNodes, noise = noise,\n                   mean_rmse = mean(rmse_values), var_rmse = var(rmse_values))\n          }\n        }\n      }\n    }\n  }\n\n  results\n}\n\n# Visualize the results with mean and variance\nvisualize_results_exhaustive &lt;- function(results) {\n  df &lt;- do.call(rbind, lapply(results, function(x) data.frame(t(unlist(x)))))\n  ggplot(df, aes(x = inNodes, y = outNodes, fill = mean_rmse)) +\n    geom_tile() +\n    facet_grid(c ~ lr) +\n    scale_fill_gradient(low = \"green\", high = \"red\") +\n    labs(title = \"Mean RMSE for varying input and output nodes, c, lr, and noise\",\n         x = \"Number of Input Nodes\",\n         y = \"Number of Output Nodes\",\n         fill = \"Mean RMSE\") +\n    theme_minimal()\n}\n\n# Generate test data\ndat &lt;- gen_train()\n\n# Test and visualize results\nresults_exhaustive &lt;- test_nodes_exhaustive(dat)\nvisualize_results_exhaustive(results_exhaustive)\n\n\n\n\nCode\n# Load necessary libraries\nlibrary(shiny)\nlibrary(tidyverse)\n\n# Copy the required functions and data from your previous code here\n\n# Shiny UI\nui &lt;- fluidPage(\n    titlePanel(\"ALM Model Performance\"),\n    sidebarLayout(\n        sidebarPanel(\n            sliderInput(\"c_value\", \"C value:\", min = 0.1, max = 1, value = 0.5, step = 0.1),\n            sliderInput(\"lr_value\", \"Learning rate:\", min = 0.1, max = 1, value = 0.5, step = 0.1),\n            sliderInput(\"inNodes\", \"Number of Input Nodes:\", min = 3, max = 10, value = 7, step = 1),\n            sliderInput(\"outNodes\", \"Number of Output Nodes:\", min = 16, max = 64, value = 32, step = 8),\n            sliderInput(\"noise\", \"Noise:\", min = 0, max = 1, value = 0, step = 0.1),\n            actionButton(\"run_model\", \"Run Model\")\n        ),\n        mainPanel(\n            plotOutput(\"model_performance\")\n        )\n    )\n)\n\n# Shiny server\nserver &lt;- function(input, output) {\n    observeEvent(input$run_model, {\n        dat_noise &lt;- gen_train(noise = input$noise)\n        result &lt;- sim_data(dat_noise, input$c_value, input$lr_value, input$inNodes, input$outNodes)\n        rmse &lt;- RMSE(dat_noise$vx, result$almPred)\n\n        combined_data &lt;- dat_noise %&gt;%\n            mutate(\n                almPred = result$almPred,\n                examPred = result$examPred\n            )\n\n        output$model_performance &lt;- renderPlot({\n            ggplot(combined_data, aes(x = input, y = vx)) +\n                geom_point(aes(y = almPred, color = \"ALM Prediction\")) +\n                geom_line(aes(y = examPred, color = \"EXAM Prediction\")) +\n                labs(\n                    title = paste0(\"ALM Model Performance (RMSE: \", round(rmse, 4), \")\"),\n                    x = \"Input\",\n                    y = \"Prediction\"\n                ) +\n                scale_color_manual(values = c(\"ALM Prediction\" = \"blue\", \"EXAM Prediction\" = \"red\")) +\n                theme_minimal()\n        })\n    })\n}\n\n# Run the application\nshinyApp(ui = ui, server = server)\n\n\n\n\nCode\n# Test varying input and output nodes more exhaustively\ntest_nodes_exhaustive &lt;- function(dat, c = 0.5, lr = 0.2, input_nodes = seq(3, 15,3), output_nodes = seq(16, 128, 8)) {\n  results &lt;- list()\n\n  for (inNodes in input_nodes) {\n    for (outNodes in output_nodes) {\n      result &lt;- sim_data(dat, c, lr, inNodes, outNodes)\n      rmse &lt;- RMSE(dat$vx, result$almPred)\n      results[[paste0(\"in\", inNodes, \"_out\", outNodes)]] &lt;- list(inNodes = inNodes, outNodes = outNodes, rmse = rmse)\n    }\n  }\n\n  results\n}\n\n# Visualize the results using bar plots\nvisualize_bar_plots &lt;- function(results) {\n  df &lt;- do.call(rbind, lapply(results, function(x) data.frame(t(unlist(x)))))\n  \n  ggplot(df, aes(x = interaction(inNodes, outNodes, sep = \"_\"), y = rmse)) +\n    geom_bar(stat = \"identity\", fill = \"steelblue\") +\n    labs(title = \"RMSE for varying input and output nodes\",\n         x = \"Combinations of Input and Output Nodes\",\n         y = \"RMSE\") +\n    theme_minimal() +\n    theme(axis.text.x = element_text(angle = 90, hjust = 1, vjust = 0.5, size = 8))\n}\n\n# Generate test data\ndat &lt;- gen_train()\n\n# Test and visualize results using more exhaustive parameters\nresults_exhaustive &lt;- test_nodes_exhaustive(dat)\nvisualize_bar_plots(results_exhaustive)\n\n\n\n\nCode\n# Generate synthetic data for testing\ngen_train &lt;- function(trainVec = c(5, 6, 7), trainRep = 10, noise = 0) {\n    bandVec &lt;- c(0, 100, 350, 600, 800, 1000, 1200)\n    ts &lt;- rep(seq(1, length(trainVec)), trainRep)\n    noiseVec &lt;- rnorm(length(ts), mean = 0) * noise\n    if (noise == 0) {\n        noiseVec &lt;- noiseVec * 0\n    }\n    tibble(input = trainVec[ts], vx = bandVec[trainVec[ts]] + noiseVec)\n}\n\n# Test varying input and output nodes\ntest_nodes &lt;- function(dat, c = 0.5, lr = 0.2, input_nodes = seq(3, 10), output_nodes = seq(16, 64, 8)) {\n    results &lt;- list()\n\n    for (inNodes in input_nodes) {\n        for (outNodes in output_nodes) {\n            result &lt;- sim_data(dat, c, lr, inNodes, outNodes)\n            rmse &lt;- RMSE(dat$vx, result$almPred)\n            results[[paste0(\"in\", inNodes, \"_out\", outNodes)]] &lt;- list(inNodes = inNodes, outNodes = outNodes, rmse = rmse)\n        }\n    }\n\n    results\n}\n\n# Visualize the results\nvisualize_results &lt;- function(results) {\n    df &lt;- do.call(rbind, lapply(results, function(x) data.frame(t(unlist(x)))))\n    ggplot(df, aes(x = inNodes, y = outNodes, fill = rmse)) +\n        geom_tile() +\n        scale_fill_gradient(low = \"green\", high = \"red\") +\n        labs(\n            title = \"RMSE for varying input and output nodes\",\n            x = \"Number of Input Nodes\",\n            y = \"Number of Output Nodes\",\n            fill = \"RMSE\"\n        ) +\n        theme_minimal()\n}\n\n# Generate test data\ndat &lt;- gen_train()\n\n# Test and visualize results\nresults &lt;- test_nodes(dat)\nvisualize_results(results)"
  },
  {
    "objectID": "Simulations/alm_learning.html",
    "href": "Simulations/alm_learning.html",
    "title": "ALM Learning",
    "section": "",
    "text": "pacman::p_load(tidyverse,data.table,patchwork,glue,knitr,kableExtra,here)\noptions(dplyr.summarise.inform=FALSE)\npurrr::walk(here(c(\"Functions/alm_functions.R\",\"Functions/Display_Functions.R\")),source)\n\n\nupdate.weights.with_noise &lt;- function(x.new, y.new, weights, c, lr, noise_sd){\n  y.feedback.activation &lt;- exp(-1 * c * (y.new - outputNodes)^2)\n  x.feedback.activation &lt;- output.activation(x.new, weights, c)\n  weight_updates &lt;- lr * (y.feedback.activation - x.feedback.activation) %*% t(input.activation(x.new, c))\n  noise &lt;- matrix(rnorm(nrow(weight_updates) * ncol(weight_updates), sd = noise_sd), \n                  nrow = nrow(weight_updates), ncol = ncol(weight_updates))\n  updated_weights &lt;- weights + weight_updates + noise\n  return(updated_weights)\n}\n\n\nupdate.weights&lt;-function(x.new, y.new, weights, c, lr, noise_sd = NULL){\n  y.feedback.activation&lt;-exp(-1*c*(y.new-outputNodes)^2)\n  x.feedback.activation&lt;-output.activation(x.new, weights, c)\n  return(weights+lr*(y.feedback.activation-x.feedback.activation)%*%t(input.activation(x.new, c)))\n}\n\nsim_data &lt;- function(dat, c=0.5, lr=0.2, inNodes=7, outNodes=32, trainVec=c(5,6,7),noise_sd=0,update_func=\"update.weights\" ) {\n  inputNodes &lt;&lt;- seq(1,7,length.out=inNodes*1)  \n  outputNodes &lt;&lt;- seq(50,1600,length.out=outNodes*1) \n  #print(length(outputNodes))\n  wm=matrix(.0000,nrow=length(outputNodes),ncol=length(inputNodes))\n  # wm=matrix(rnorm(length(outputNodes)*length(inputNodes),.1,5),nrow=length(outputNodes),ncol=length(inputNodes))\n  tt&lt;-trainTest.alm(dat, c, lr, wm, trainVec, update_func, noise_sd)\n}   \n\ntrainTest.alm &lt;- function(dat, c=0.05, lr=0.5, weights, testVec, update_func, noise_sd) {\n   alm.train &lt;- rep(NA, nrow(dat))  \n   update_func=get(update_func)\n   decay_factor = 0.79\n  for (i in 1:nrow(dat)) {\n    #lr = lr * decay_factor^i\n    resp = mean.prediction(dat$input[i], weights, c)\n    weights &lt;- update_func(dat$input[i], dat$vx[i], weights, c, lr, noise_sd)\n    alm.train[i] = resp\n    weights[weights&lt;0] = 0\n  }\n  almPred &lt;- sapply(testVec, mean.prediction, weights, c)\n  examPred &lt;- sapply(testVec, exam.prediction, weights, c, trainVec=c(1,sort(unique(dat$input))))\n  list(almTrain=alm.train, almPred=almPred, examPred=examPred,weights=weights)\n}\n\n\nModel learning, and resulting weights, across range of parameter values\n\ntibble(crossing(\n  c = c(.5,5),lr = c(.05,1),noise = c(0),\n  inNodes=c(7),outNodes=c(32),\n  trainVec=list(list(5,6,7)),trainRep = c(9),\n  lossFun = list(\"MAE\"),\n  simNum = 1:1,\n  update_func = list(\"update.weights\"),update_func_name = c(\"uW\"),\n  noise_sd = c(0)\n)) %&gt;%   mutate(id=seq(1,nrow(.)),td = pmap(list(trainVec,trainRep,noise),~gen_train(trainVec=.x,trainRep=..2,noise=..3) )) %&gt;% \n  ungroup() %&gt;%\n  mutate(d = pmap(list(td, c, lr, update_func,noise_sd,inNodes,outNodes), \n                  ~sim_data(dat = .x, c = ..2, lr = ..3, update_func = ..4, noise_sd = ..5,inNodes=..6,outNodes=..7)),\n         almTrainDat = map(d, \"almTrain\"),weights=map(d,\"weights\"))%&gt;%\n  unnest(c(almTrainDat, td)) %&gt;% select(-d) %&gt;% mutate(input=as.factor(input)) %T&gt;%\n  {pf(.) } %&gt;% trainTab\n\n\n\nSelf contained\n\npacman::p_load(tidyverse,data.table,knitr,kableExtra,glue)\ninput.activation&lt;-function(x.target, c){return(exp((-1*c)*(x.target-inputNodes)^2))}\noutput.activation&lt;-function(x.target, weights, c){return(weights%*%input.activation(x.target, c))}\nmean.prediction&lt;-function(x.target, weights, c){\n  probability&lt;-output.activation(x.target, weights, c)/sum(output.activation(x.target, weights, c))\n  return(outputNodes%*%probability) # integer prediction\n}\nupdate.weights&lt;-function(x.new, y.new, weights, c, lr){\n  y.feedback.activation&lt;-exp(-1*c*(y.new-outputNodes)^2)\n  x.feedback.activation&lt;-output.activation(x.new, weights, c)\n  return(weights+lr*(y.feedback.activation-x.feedback.activation)%*%t(input.activation(x.new, c)))\n}\ntrain.alm&lt;-function(dat, c=0.05, lr=0.5, weights){\n   alm.train&lt;-rep(NA,nrow(dat))  \n  for (i in 1:nrow(dat)){\n    weights &lt;- update.weights(dat$input[i], dat$vx[i], weights, c, lr)\n    resp = mean.prediction(dat$input[i], weights, c)\n    alm.train[i]=resp\n    weights[weights&lt;0]=0\n  } \n  list(almTrain = alm.train, weights = weights)\n  }\nsim_train &lt;- function(dat, c=0.5, lr=0.2, inNodes=7, outNodes=32, trainVec=c(5,6,7),noise_sd=0,update_func=\"update.weights\" ) {\n  inputNodes &lt;&lt;- seq(1,7,length.out=inNodes*1)  \n  outputNodes &lt;&lt;- seq(50,1600,length.out=outNodes*1) \n  wm=matrix(.0000,nrow=length(outputNodes),ncol=length(inputNodes))\n  tt&lt;-train.alm(dat, c, lr, wm)\n} \ngen_train &lt;- function(trainVec = c(5, 6, 7), trainRep = 3, noise = 0) {\n    bandVec &lt;- c(0, 100, 350, 600, 800, 1000, 1200)\n    if (class(trainVec) == \"list\") {trainVec &lt;- unlist(trainVec)}\n    ts &lt;- rep(seq(1, length(trainVec)), trainRep)\n    noiseVec &lt;- rnorm(length(ts), mean = 0) * noise\n    if (noise == 0) {noiseVec &lt;- noiseVec * 0}\n    tibble(trial = seq(1, length(ts)), input = trainVec[ts], vx = bandVec[trainVec[ts]] + noiseVec)\n}\n\ntibble(crossing(\n    c = c(.5, 5), lr = c(.05, 1), noise = c(0),\n    inNodes = c(7), outNodes = c(32),\n    trainVec = list(list(5, 6, 7)), trainRep = c(9),\n    lossFun = list(\"MAE\"),\n    simNum = 1:1,\n)) %&gt;%\n    mutate(id = seq(1, nrow(.)), td = pmap(list(trainVec, trainRep, noise), ~ gen_train(trainVec = .x, trainRep = ..2, noise = ..3))) %&gt;%\n    ungroup() %&gt;%\n    mutate(\n        d = pmap(\n            list(td, c, lr,inNodes, outNodes),\n            ~ sim_train(dat = .x, c = ..2, lr = ..3, inNodes = ..4, outNodes = ..5)\n        ),\n        almTrainDat = map(d, \"almTrain\"), weights = map(d, \"weights\")\n    ) %&gt;%\n    unnest(c(almTrainDat, td)) %&gt;%\n    select(-d) %&gt;%\n    mutate(input = as.factor(input)) %&gt;%\n    trainTab()\n\ntibble(crossing(\n    c = c(.5, 5), lr = c(.05, 1), noise = c(0),\n    inNodes = c(7), outNodes = c(32),\n    trainVec = list(list(5, 6, 7)), trainRep = c(9),\n    lossFun = list(\"MAE\"),\n    simNum = 1:1,\n)) %&gt;%\n    mutate(id = seq(1, nrow(.)), td = pmap(list(trainVec, trainRep, noise), ~ gen_train(trainVec = .x, trainRep = ..2, noise = ..3))) %&gt;%\n    ungroup() %&gt;%\n    mutate(\n        d = pmap(\n            list(td, c, lr,inNodes, outNodes),\n            ~ sim_train(dat = .x, c = ..2, lr = ..3, inNodes = ..4, outNodes = ..5)\n        ),\n        almTrainDat = map(d, \"almTrain\"), weights = map(d, \"weights\")\n    ) %&gt;%\n    unnest(c(almTrainDat, td)) %&gt;%\n    select(-d) %&gt;%\n    mutate(input = as.factor(input)) %&gt;%\n    trainTab()\n\n\n\nOptimize for single decay curve\ngenerate data that follows an exponetial decay function of error over trials, inspect ability of model to fit that data.\n\ngt &lt;- gen_train(trainVec=c(5,6,7),trainRep=18) %&gt;% mutate(cor=vx,err=(400-0)*exp(-.1*seq(1,n()))+0,vx=cor-err)\n\nbias &lt;- 1000; \ngt &lt;- gen_train(trainVec=c(5,6,7),trainRep=228,noise=0) %&gt;% mutate(\n  cor = vx,\n  err = (bias - 0) * exp(-.005 * seq(1, n())) + 0,\n  en = map2_dbl(err,cor, ~rnorm(n = 1, mean = .y, sd = .x/2)),\n  enAvg = map2_dbl(err,cor, ~mean(rnorm(n = 1, mean = .y, sd = .x))),\n  weight = (seq(1, n()) - 1) / (n() - 1),\n  vx = (weight*en)+bias*(1-weight),\n  vx=en\n)\ngt %&gt;% ggplot(aes(x = trial, y = vx, color = as.factor(input))) +\n  geom_line() + ylim(c(-10,1600))\n\n\nk=wrap_optim(gt,lossFun = \"MAE\")\ns=sim_data(dat=mutate(gt,vx=cor),c=k %&gt;% pluck(\"c\"),lr= k %&gt;% pluck(\"lr\"))\nggp &lt;- gt %&gt;% mutate(pred=s %&gt;% pluck(\"almTrain\"),c=k %&gt;% pluck(\"c\"),lr= k %&gt;% pluck(\"lr\"),input=as.factor(input)) %&gt;%  \n  ggplot(aes(x = trial, y = pred, color = input)) +\n  geom_line() + ylim(c(0,1600))\nggo &lt;-  gt %&gt;% ggplot(aes(x = trial, y = vx, color = as.factor(input))) +\n  geom_line() + ylim(c(-400,1600))\n\nggo+ggp\n\n\n#k = t[1,]\n#image(matrix(unlist(k$weights),nrow=7))\n# mutate(md=map(weights,~matrix(unlist(.),nrow=7)))\n\nwms &lt;- t %&gt;% filter(trial==1) %&gt;% \n  mutate(k=map(weights,~ as.data.frame(matrix(unlist(.),nrow=7)) %&gt;% \n                 rownames_to_column(\"Input\") %&gt;%\n                 pivot_longer(-c(Input), names_to = \"Output\",\n                              names_prefix = \"V\", values_to = \"weight\") %&gt;%  mutate(Output= fct_relevel(Output,unique(.$Output)))))\n\nwms %&gt;% unnest(k) %&gt;% ggplot(.,aes(x=Input, y=Output, fill=weight)) + \n  geom_raster() + \n  scale_fill_viridis_c()+facet_wrap(~id+c)\n\n\n\nmd=matrix(unlist(k$weights),nrow=7)\nkd=as.data.frame(matrix(unlist(k$weights),nrow=7))%&gt;%\n  rownames_to_column(\"Input\") %&gt;%\n  pivot_longer(-c(Input), names_to = \"Output\",names_prefix = \"V\", values_to = \"weight\")\n\nkd %&gt;% \n  mutate(Output= fct_relevel(Output,unique(kd$Output))) %&gt;%\n  ggplot(aes(x=Input, y=Output, fill=weight)) + \n  geom_raster() + \n  scale_fill_viridis_c()\n\n\npv &lt;- t &lt;- parmVec &lt;- tibble(crossing(\n  c = c(0.00003),\n  lr = c(0.051),\n  noise = c(0),\n  inNodes=c(7),\n  outNodes=c(32),\n  trainVec=list(list(1,5,6,7),list(5,6,7)),\n  trainRep = c(4),\n  lossFun = list(\"MAE\"),\n  simNum = 1:1,\n  update_func = list(\"update.weights\"),\n  update_func_name = c(\"update.weights\"),\n  noise_sd = c(0)\n)) %&gt;% mutate(id=seq(1,nrow(.)))\n\n\n\ninspect learning\n\nparmVec &lt;- tibble(crossing(\n  c = c(0.1),\n  lr = c(0.1, 0.4, 1),\n  noise = c(10),\n  trainRep = c(20),\n  lossFun = list(\"MAE\"),\n  simNum = 1:10,\n  update_func = list(\"update.weights\", \"update.weights.with_noise\"),\n  update_func_name = c(\"update.weights\", \"update.weights.with_noise\"),\n  noise_sd = c(0.1, 0.5)\n))\n\n\n\nt &lt;- parmVec %&gt;%\n  group_by(simNum, c, lr, update_func,noise_sd) %&gt;%\n  mutate(td = list(gen_train(trainRep = first(trainRep), noise = first(noise)))) %&gt;%\n  ungroup() %&gt;%\n  mutate(d = pmap(list(td, c, lr, update_func,noise_sd), \n                  ~sim_data(dat = .x, c = ..2, lr = ..3, update_func = ..4, noise_sd = ..5)),\n         almTrainDat = map(d, \"almTrain\"))%&gt;%\n  unnest(almTrainDat, td) %&gt;%\n  select(-d) %&gt;% \n  mutate(trial = rep(seq(1, nrow(.)/10), 10),input=as.factor(input))\n\nt %&gt;% group_by(lr, update_func_name, simNum, trial, input) %&gt;%\n  summarize(almTrainDat = mean(almTrainDat), .groups = \"drop\") %&gt;%\n  ggplot(aes(x = trial, y = almTrainDat, color = input)) +\n  geom_line() + ylim(c(0,1300))+\n  facet_grid(lr ~ update_func_name)\n\n\nparmVec &lt;- tibble(crossing(c = c(0.1), lr = c(0.1,0.4,1), \n                           noise = c(10), trainRep = c(20), lossFun = list(\"MAE\"), simNum = 1))\n\nt &lt;- parmVec %&gt;% group_by(simNum,c,lr) %&gt;% mutate(td = list(gen_train(trainRep = first(trainRep), noise = first(noise)))) %&gt;% ungroup() %&gt;%\n  mutate(d = pmap(list(td, c, lr), ~sim_data(dat = .x, c = ..2, lr = ..3)),\n         almTrainDat = map(d, \"almTrain\"))\n\n# extract and plot each almTrainDat \nalmTrainDat &lt;- parmVec %&gt;% group_by(simNum,c,lr) %&gt;% mutate(td = list(gen_train(trainRep = first(trainRep), noise = first(noise)))) %&gt;% ungroup() %&gt;%\n  mutate(d = pmap(list(td, c, lr), ~sim_data(dat = .x, c = ..2, lr = ..3)),\n         almTrainDat = map(d, \"almTrain\")) %&gt;% unnest(almTrainDat) %&gt;% select(-d)\n\n# For each unique value of lr, plot the learning curve, showing almTrainDat as a function of trial number, color by input, and facet by lr. Convert input to factor first. \n\nalmTrainDat %&gt;% group_by(lr) %&gt;% mutate(trial = seq(1,n()),input= as.factor(input)) %&gt;% ggplot(aes(x=trial,y=almTrainDat,color=input)) + geom_line() + facet_wrap(~lr)\n\n\n\nparmVec &lt;- tibble(crossing(c = c(0.1), lr = c(.01,.05,0.1), noise = c(5), trainRep = c(20), lossFun = list(\"MAE\"), simNum = 1:30))\n\n# The rest of the code remains the same\nalmTrainDat &lt;- parmVec %&gt;% group_by(simNum,c,lr) %&gt;% mutate(td = list(gen_train(trainRep = first(trainRep), noise = first(noise)))) %&gt;% ungroup() %&gt;%\n  mutate(d = pmap(list(td, c, lr), ~sim_data(dat = .x, c = ..2, lr = ..3)),\n         almTrainDat = map(d, \"almTrain\")) %&gt;% unnest(almTrainDat,td) %&gt;% select(-d) %&gt;%\n  mutate(trial = rep(seq(1, nrow(.)/30), 30),input=as.factor(input))\n\n\nmean_sd_almTrainDat &lt;- almTrainDat %&gt;%\n  group_by(lr,input, trial) %&gt;%\n  summarise(avg_almTrainDat = mean(almTrainDat), sd_almTrainDat = sd(almTrainDat), .groups = 'drop')\n\n# Check the results\nhead(mean_sd_almTrainDat)\n\n\nggplot(mean_sd_almTrainDat, aes(x = trial, y = avg_almTrainDat,color=input)) +\n   geom_line() +\n  geom_errorbar(aes(ymin = avg_almTrainDat - sd_almTrainDat, ymax = avg_almTrainDat + sd_almTrainDat), width = 0.2) +\n  facet_wrap(~lr) +\n  labs(title = \"ALM Train Data: Mean and Variance Over Trials\",\n       x = \"Trial\",\n       y = \"Average ALM Train Data\") + ylim(c(0,1300))+\n  theme_minimal()\n\n\n#plot(seq(1,90), (200-.50)*exp(-.1*seq(1,90))+.50)\ngt &lt;- gen_train(trainVec=c(5,6,7),trainRep=18) %&gt;% mutate(cor=vx,err=(400-0)*exp(-.1*seq(1,n()))+0,vx=cor-err)\ngt &lt;- gen_train(trainVec=c(5,6,7),trainRep=28,noise=10) %&gt;% mutate(cor=vx,err=(100-0)*exp(-.03*seq(1,n()))+0,en=map_dbl(err,~rnorm(n=1,mean=0,sd=.x)),vx1=cor-err,vx2=cor-en)\n\ngt &lt;- gen_train(trainVec=c(5,6,7),trainRep=28,noise=0) %&gt;% group_by(input) %&gt;% mutate(cor=vx,err=(200--10)*exp(-.01*seq(1,n()))+(-10),en=map(err,~rnorm(n=1,mean=0,sd=.x)),vx=cor-err)\n\ngt &lt;- gen_train(trainVec=c(5,6,7),trainRep=28,noise=10) %&gt;% mutate(cor=vx,\n            err=ifelse(seq(1, n()) &lt;= n()/2, (700-0)*exp(-.01*seq(1,n()))+0, (700-0)*exp(-.06*(seq(1,n())-n()/2))+0),\n            en=map(err,~rnorm(n=1,mean=0,sd=.x)),\n            vx=cor-err)\n\ngt &lt;- gen_train(trainVec=c(5,6,7),trainRep=28,noise=10) %&gt;%\n  mutate(\n    cor = vx,\n    err = (700 - 0) * exp(-0.03 * seq(1, n()) * (input / max(input))) + 0,\n    en = map(err, ~rnorm(n = 1, mean = 0, sd = .x)),\n    vx = cor - err\n  )\ngt &lt;- gen_train(trainVec=c(5,6,7),trainRep=28,noise=10) %&gt;% mutate(\n  cor = vx,\n  err = (700 - 1) * exp(-.03 * seq(1, n())) + 1,\n  en = map(err, ~rnorm(n = 1, mean = 0, sd = .x)),\n  weight = (seq(1, n()) - 1) / (n() - 1),\n  vx = cor * weight - err + abs(min(cor * weight - err)) + 1\n)"
  },
  {
    "objectID": "Simulations/learning_bias.html",
    "href": "Simulations/learning_bias.html",
    "title": "learning bias",
    "section": "",
    "text": "pacman::p_load(tidyverse, data.table, patchwork, glue, knitr, kableExtra,here)\npurrr::walk(here(c(\"Functions/alm_functions.R\", \"Functions/Display_Functions.R\")), source)\n\n\nmean.prediction &lt;- function(x.target, weights, bias, c, noise_sd) {\n    probability &lt;- output.activation(x.target, weights, c, noise_sd) / sum(output.activation(x.target, weights, c, noise_sd))\n    return(outputNodes %*% probability + bias) # integer prediction with bias\n}\ninput.activation &lt;- function(x.target, c, noise_sd) {\n  noise &lt;- rnorm(length(inputNodes), mean = 0, sd = noise_sd)\n  return(exp((-1 * c) * (x.target - inputNodes + noise)^2))\n}\noutput.activation &lt;- function(x.target, weights, c, noise_sd) {\n    noise &lt;- rnorm(length(outputNodes), mean = 0, sd = noise_sd)\n    return(weights %*% input.activation(x.target, c, noise_sd) + noise)\n}\n\nupdate.weights &lt;- function(x.new, y.new, weights, bias, c, lr, noise_sd) {\n  y.feedback.activation &lt;- exp(-1 * c * (y.new - outputNodes)^2)\n  x.feedback.activation &lt;- output.activation(x.new, weights, c, noise_sd)\n  # Update weights\n  new_weights &lt;- weights + lr * (y.feedback.activation - x.feedback.activation) %*% t(input.activation(x.new, c, noise_sd))\n  # Update bias\n  new_bias &lt;- bias + blr * (y.new - mean.prediction(x.new, weights, bias, c, noise_sd))\n  return(list(weights = new_weights, bias = new_bias))\n}\n\ntrain.alm &lt;- function(dat, c = 0.05, lr = 0.5, noise_sd = 0, weights, bias = 0) {\n    alm.train &lt;- rep(NA, nrow(dat))\n    for (i in 1:nrow(dat)) {\n        result &lt;- update.weights(dat$input[i], dat$vx[i], weights, bias, c, lr, noise_sd)\n        weights &lt;- result$weights\n        bias &lt;- result$bias\n        resp &lt;- mean.prediction(dat$input[i], weights, bias, c, noise_sd)\n        alm.train[i] &lt;- resp\n        weights[weights &lt; 0] &lt;- 0\n    }\n    list(almTrain = alm.train, weights = weights, bias = bias)\n}\n\nsim_train &lt;- function(dat, c = 0.5, lr = 0.2, inNodes = 7, outNodes = 32, noise_sd = 0,bias=0) {\n    inputNodes &lt;&lt;- seq(1, 7, length.out = inNodes * 1)\n    outputNodes &lt;&lt;- seq(50, 1600, length.out = outNodes * 1)\n    wm &lt;- matrix(.000001, nrow = length(outputNodes), ncol = length(inputNodes))\n    tt &lt;- train.alm(dat, c, lr, noise_sd, wm, bias)\n    return(tt)\n}\n\ngen_train &lt;- function(trainVec = c(5, 6, 7), trainRep = 3, noise = 0) {\n    bandVec &lt;- c(0, 100, 350, 600, 800, 1000, 1200)\n    if (class(trainVec) == \"list\") {\n        trainVec &lt;- unlist(trainVec)\n    }\n    ts &lt;- rep(seq(1, length(trainVec)), trainRep)\n    noiseVec &lt;- rnorm(length(ts), mean = 0) * noise\n    if (noise == 0) {\n        noiseVec &lt;- noiseVec * 0\n    }\n    tibble(trial = seq(1, length(ts)), input = trainVec[ts], vx = bandVec[trainVec[ts]] + noiseVec)\n}\n\n\nrun_simulations &lt;- function(param_grid, data) {\n    simulations &lt;- list()\n\n    for (i in 1:nrow(param_grid)) {\n        c_value &lt;- param_grid$c[i]\n        lr_value &lt;- param_grid$lr[i]\n        noise_sd_value &lt;- param_grid$noise_sd[i]\n        inNodes_value &lt;- param_grid$inNodes[i]\n        outNodes_value &lt;- param_grid$outNodes[i]\n        bias_value &lt;- param_grid$bias[i]\n\n        sim_result &lt;- sim_train(\n            dat = data,\n            c = c_value,\n            lr = lr_value,\n            inNodes = inNodes_value,\n            outNodes = outNodes_value,\n            noise_sd = noise_sd_value,\n            bias = bias_value\n        )\n\n        simulations[[i]] &lt;- cbind(data,alm_train=sim_result$almTrain,biasEnd=sim_result$bias)\n    }\n\n    return(simulations)\n}\n\nplot_learning_curves &lt;- function(simulations,param_grid) {\n    curves &lt;- data.frame(simulations[[1]], Simulation=1,c=param_grid$c[1],lr=param_grid$lr[1],noise_sd=param_grid$noise_sd[1],inNodes=param_grid$inNodes[1],outNodes=param_grid$outNodes[1],biasStart=param_grid$bias[1])\n\n    for (i in 2:length(simulations)) {\n        curve_data &lt;- data.frame(simulations[[i]],Simulation = i,\n        c=param_grid$c[i],lr=param_grid$lr[i],noise_sd=param_grid$noise_sd[i],inNodes=param_grid$inNodes[i],outNodes=param_grid$outNodes[i],biasStart=param_grid$bias[i])\n        curves &lt;- rbind(curves, curve_data)\n    }\n    curves &lt;- curves %&gt;% mutate(simLab=paste0(\"c=\",c,\" lr=\",lr,\" n_sd=\",noise_sd,\n                                \n                                              \" biasEnd=\",round(biasEnd,1),\" biasStart=\",biasStart),\n                                input=as.factor(input))\n    \n\n    p &lt;- ggplot(curves, aes(x = trial, y = alm_train, color=input)) +\n        geom_line(alpha = 0.8) + facet_wrap(~simLab,ncol=3)+\n        theme_minimal() + ylim(c(0,1600))\n        labs(title = \"Learning Curves for Simulated Learners\", x = \"Trial\", y = \"Velocity\")\n\n    return(p)\n}\n\n\nparam_grid &lt;- tibble(crossing(\n    c = c(1.5, 2, 3),\n    lr = c(.01,.5),\n    noise_sd = c(.0010),\n    inNodes = c( 7),\n    outNodes = c(32),\n    bias=c(-800,100,500)\n))\n\nblr&lt;&lt;-0\nsimulations &lt;- run_simulations(param_grid[1:35,], gen_train(trainRep=10))\nlearning_curve_plot &lt;- plot_learning_curves(simulations, param_grid)\nprint(learning_curve_plot)\nblr&lt;&lt;-.1\nsimulations &lt;- run_simulations(param_grid[1:35,], gen_train(trainRep=10))\nlearning_curve_plot &lt;- plot_learning_curves(simulations, param_grid)\nprint(learning_curve_plot)\nblr&lt;&lt;-.01\nsimulations &lt;- run_simulations(param_grid[1:35,], gen_train(trainRep=10))\nlearning_curve_plot &lt;- plot_learning_curves(simulations, param_grid)\nprint(learning_curve_plot)"
  },
  {
    "objectID": "Simulations/simParameterRecovery.html",
    "href": "Simulations/simParameterRecovery.html",
    "title": "Parameter Recovery Simulations",
    "section": "",
    "text": "Parameter Recovery Simulations\nAssessing the parameter recovery of ALM and EXAM on synthetic data.\n\n\nCode\npacman::p_load(tidyverse,data.table)\noptions(dplyr.summarise.inform=FALSE)\n\ninput.activation&lt;-function(x.target, c) { return(exp((-1*c)*(x.target-inputNodes)^2))}\n\noutput.activation&lt;-function(x.target, weights, c){\n  return(weights%*%input.activation(x.target, c))\n}\nmean.prediction&lt;-function(x.target, weights, c){\n  probability&lt;-output.activation(x.target, weights, c)/sum(output.activation(x.target, weights, c))\n  return(outputNodes%*%probability) # integer prediction\n}\n\nupdate.weights&lt;-function(x.new, y.new, weights, c, lr){t\n  yt.feedback.activation&lt;-exp(-1*c*(y.new-outputNodes)^2)\n  x.feedback.activation&lt;-output.activation(x.new, weights, c)\n  return(weights+lr*(y.feedback.activation-x.feedback.activation)%*%t(input.activation(x.new, c)))\n}\n\ntrain.alm&lt;-function(dat, c=0.05, lr=0.5, weights){\n   alm.train&lt;-rep(NA,nrow(dat))  \n  for (i in 1:nrow(dat)){\n    weights &lt;- update.weights(dat$input[i], dat$vx[i], weights, c, lr)\n    resp = mean.prediction(dat$input[i], weights, c)\n    alm.train[i]=resp\n    weights[weights&lt;0]=0\n  }\n  alm.train\n}\n\n# function to generate exam predictions\nexam.prediction&lt;-function(x.target, weights, c,trainVec){\n  #trainVec = sort(unique(x.learning))\n  nearestTrain = trainVec[which.min(abs(trainVec-x.target))]\n  aresp = mean.prediction(nearestTrain, weights, c)\n  xUnder = ifelse(min(trainVec) == nearestTrain, nearestTrain, trainVec[which(trainVec == nearestTrain) - 1])\n  xOver = ifelse(max(trainVec) == nearestTrain, nearestTrain, trainVec[which(trainVec == nearestTrain) + 1])\n  mUnder = mean.prediction(xUnder, weights, c)\n  mOver = mean.prediction(xOver, weights, c)\n  exam.output = round(aresp + ((mOver - mUnder) / (xOver - xUnder)) * (x.target - nearestTrain), 3)\n  exam.output\n}\n\n# Modify the sim_data function to accept the dataset as an argument\nsim_data &lt;- function(dat, c=0.5, lr=0.2, inNodes=7, outNodes=32, trainVec=c(5,6,7)) {\n  inputNodes &lt;&lt;- seq(1,7,length.out=inNodes*1)  \n  outputNodes &lt;&lt;- seq(50,1600,length.out=outNodes*1) \n  wm=matrix(.0000,nrow=length(outputNodes),ncol=length(inputNodes))\n  tt&lt;-trainTest.alm(dat, c, lr, wm, trainVec)\n}\n\ngen_train &lt;- function(trainVec=c(5,6,7),trainRep=10,noise=0){\n   bandVec=c(0,100,350,600,800,1000,1200)\n   ts &lt;- rep(seq(1,length(trainVec)),trainRep)\n   noiseVec=rnorm(length(ts),mean=0)*noise\n   if(noise==0) {noiseVec=noiseVec*0}\n   tibble(input=trainVec[ts],vx=bandVec[trainVec[ts]]+noiseVec)\n}\n\n\ntrainTest.alm&lt;-function(dat, c=0.05, lr=0.5, weights,testVec){\n   alm.train&lt;-rep(NA,nrow(dat))  \n  for (i in 1:nrow(dat)){\n    weights &lt;- update.weights(dat$input[i], dat$vx[i], weights, c, lr)\n    resp = mean.prediction(dat$input[i], weights, c)\n    alm.train[i]=resp\n    weights[weights&lt;0]=0\n  }\n  almPred &lt;- sapply(testVec,mean.prediction,weights,c)\n  examPred &lt;- sapply(testVec,exam.prediction,weights,c,trainVec=c(1,sort(unique(dat$input))))\n  list(almTrain=alm.train,almPred=almPred,examPred=examPred)\n}\n\nwrap_alm &lt;- function(par,dat, weights,lossFun){\n    c=par[1]; lr=par[2]\n   pred=train.alm(dat, c=c, lr=lr, weights=weights)\n   #sqrt(mean((dat$vx -pred)^2))\n   lossFun(dat$vx,pred)\n}\n\nwrap_optim &lt;- function(dat,lossFun=RMSE){\n  if(class(lossFun)==\"character\"){lossFun=get(lossFun)}\n  inputNodes = seq(1,7,1)  # \n  outputNodes = seq(50,1600,50)\n  wm=matrix(.00001,nrow=length(outputNodes),ncol=length(inputNodes))\n  testVec=seq(2,7)\n  \n  bounds_lower &lt;- c(.0000001, .00001)\n  bounds_upper &lt;- c(10, 10)\n  parmsLab &lt;- c(\"c\",\"lr\")\n  \n fit=optim(par=c(.1, .2),\n   fn = wrap_alm,\n   dat = dat, weights = wm,lossFun=lossFun,\n   method = \"L-BFGS-B\",\n   lower = bounds_lower,\n   upper = bounds_upper,\n   control = list(maxit = 1e5, pgtol = 0, factr = 0)\n )\n\n l=reduce(list(list(fit),fit$par,fit$value),append)\n names(l)=c(\"Fit\",parmsLab,\"Value\")\n return(l)\n}\n\n# implement wrap_optim using grid search\nwrap_grid &lt;- function(dat,lossFun=RMSE){\n  if(class(lossFun)==\"character\"){lossFun=get(lossFun)}  \n  inputNodes = seq(1,7,1)  # \n  outputNodes = seq(50,1600,50)\n  wm=matrix(.0000,nrow=length(outputNodes),ncol=length(inputNodes))\n  testVec=seq(2,7)\n  # define grid boundaries\n  cRange &lt;- seq(.000001, 5, length.out = 30)\n  lrRange &lt;- seq(.05, 5, length.out = 20)\n  # create grid\n  grid &lt;- expand.grid(c = cRange, lr = lrRange)\n  grid$Value &lt;- NA\n  # loop through grid\n  for (i in 1:nrow(grid)) {\n    grid$Value[i] &lt;- wrap_alm(par=c(grid[i,c(\"c\") ],grid[i,c(\"lr\") ]), dat=dat, weights=wm,lossFun=lossFun)\n  }\n\n  # find best fit\n  bestFit &lt;- grid[which.min(grid$Value), ]\n  bestFit$Value &lt;- min(grid$Value)\n\n  # return best fit, and best c and lr\n  return(list(Fit = bestFit, c = bestFit$c, lr = bestFit$lr, Value = bestFit$Value))\n \n}\n\n# sim_data &lt;- function(c=0.5, lr=0.2,noise=0,inNodes=7,outNodes=32,\n#                      trainVec=c(5,6,7),trainRep=10,testVec=seq(2,7)) {\n#   \n#   inputNodes &lt;&lt;- seq(1,7,length.out=inNodes*1)  \n#   outputNodes &lt;&lt;- seq(50,1600,length.out=outNodes*1) \n#   wm=matrix(.0000,nrow=length(outputNodes),ncol=length(inputNodes))\n#   dat&lt;-gen_train(trainVec,trainRep,noise)\n#   #trainDat &lt;- train.alm(dat,c,lr,wm)\n#   tt&lt;-trainTest.alm(dat,c,lr,wm,testVec)\n# }\n\n\n\nLoss Functions\n\n\nCode\nRMSE &lt;- function(x,y){\n # print(\"rmseTrial\")\n  sqrt(mean((x-y)^2))\n}\n\nRMSE.blocked &lt;- function(x,y,blocks=6){\n  #print(\"rmseBlocked\")\n  data.table(x=x,y=y,t=seq(1,length(x))) %&gt;% \n    .[, `:=`(fitBins = cut(t, breaks = ..blocks, labels = c(1:..blocks)))] %&gt;%\n    .[, .(predMean = mean(x), obsMean = mean(y)), keyby = .(fitBins)] %&gt;%\n    .[, RMSE(predMean,obsMean)] %&gt;% as.numeric()\n}\n\nMAE &lt;- function(x, y) {\n  mean(abs(x - y))\n}\n\nMAPE &lt;- function(x, y) {\n  mean(abs((x - y) / y)) * 100\n}\n\nMedAE &lt;- function(x, y) {\n  median(abs(x - y))\n}\n\nHuberLoss &lt;- function(x, y, delta = 1) {\n  error &lt;- x - y\n  abs_error &lt;- abs(error)\n  loss &lt;- ifelse(abs_error &lt;= delta, 0.5 * error^2, delta * (abs_error - 0.5 * delta))\n  mean(loss)\n}\n\n\n\n\nCode\nk= parmVec %&gt;% group_by(simNum,c,lr) %&gt;% mutate(td = list(gen_train(trainRep = first(trainRep), noise = first(noise))),\n                                                 o=map(td,head,1),vx1=map(o,\"vx\"))\n\nparmVec &lt;- tibble(crossing(c = c(0.1), lr = c(0.1,0.4,1), noise = c(10), trainRep = c(20), lossFun = list(\"RMSE\", \"MAE\",\"MAPE\", \"MedAE\", \"HuberLoss\"), simNum = 1:10))\n\nsdp &lt;- parmVec %&gt;% group_by(simNum,c,lr) %&gt;% mutate(td = list(gen_train(trainRep = first(trainRep), noise = first(noise)))) %&gt;% ungroup() %&gt;%\n  mutate(d = pmap(list(td, c, lr), ~sim_data(dat = .x, c = ..2, lr = ..3)),\n         almTrainDat = map(d, \"almTrain\"),\n         almTestDat = map(d, \"almPred\"),\n         examTestDat = map(d, \"examPred\"),\n         fitO = map2(td, lossFun, ~wrap_optim(.x, .y)),\n         cFitO = map_dbl(fitO, \"c\"),\n         lrFitO = map_dbl(fitO, \"lr\"),\n         optimValO = map_dbl(fitO, \"Value\")) \n\nsdpResults &lt;- sdp %&gt;% \n  mutate(lossFun=as.character(lossFun),cDiff=cFitO-c,lrDiff=lrFitO-lr) %&gt;%\n  relocate(simNum,lossFun, c,lr,cFitO,lrFitO,optimValO,cDiff,lrDiff) %&gt;% \n  arrange(lossFun,lr,c)\n\naveraged_sdp &lt;- sdpResults %&gt;%\n  group_by(lossFun, c, lr) %&gt;%\n  summarise(\n    avg_cFitO = mean(cFitO),\n    avg_lrFitO = mean(lrFitO),\n    avg_optimValO = mean(optimValO),\n    avg_cDiff = mean(cDiff),\n    avg_lrDiff = mean(lrDiff),\n    .groups = \"drop\"\n  )\n\n\naveraged_sdp &lt;- sdpResults %&gt;%\n  group_by(lossFun, c, lr) %&gt;%\n  summarise(\n    avg_cFitO = mean(cFitO),\n    var_cFitO = var(cFitO),\n    avg_lrFitO = mean(lrFitO),\n    var_lrFitO = var(lrFitO),\n    avg_optimValO = mean(optimValO),\n    var_optimValO = var(optimValO),\n    avg_cDiff = mean(cDiff),\n    var_cDiff = var(cDiff),\n    avg_lrDiff = mean(lrDiff),\n    var_lrDiff = var(lrDiff),\n    .groups = \"drop\"\n  )\n\n# averaged_sdp &lt;- sdp %&gt;%\n#   group_by(c, lr, noise, trainRep, lossFun) %&gt;%\n#   summarise(across(starts_with(\"cFit\") | starts_with(\"lrFit\") | starts_with(\"optimVal\"), list(mean = mean), .names = \"mean_{.col}\")) %&gt;% \n#   mutate(lossFun=as.character(lossFun),\n#          diff_cFitO = abs(c - mean_cFitO),\n#          diff_lrFitO = abs(lr - mean_lrFitO)) %&gt;%\n#   relocate(noise, trainRep, lossFun, c, diff_cFitO, lr, diff_lrFitO) %&gt;%\n#   dplyr::arrange(c,lr)\n\n\n#k=parmVec %&gt;% group_by(simNum) %&gt;% mutate(td = list(gen_train(trainRep = first(trainRep), noise = first(noise))))\n#sdp &lt;- parmVec %&gt;% mutate(d = pmap(list(c, lr, noise, trainRep), ~sim_data(c = ..1, lr = ..2, noise = ..3, trainRep = ..4)),\n\n\n\n\nCode\nlibrary(plotly)\n\ng2= grid %&gt;% filter(Value&lt;160) %&gt;% arrange(Value)\n#plot_ly() %&gt;% add_trace(data=g2,x=grid$c,y=grid$lr,z=grid$Value,type=\"mesh3d\")\n \nplot_ly(data=g2,x=~c,y=~lr,z=~Value,type = 'mesh3d')\nplot_ly(g2,type = 'surface')\n\n\n\n\n\nfig &lt;- plot_ly(x = grid2$lr, y = grid2$c, z = grid2$Value) %&gt;% add_surface()\n\np &lt;- ggplot(g2, aes(c, lr, z= Value)) +\n  stat_contour(geom=\"polygon\",aes(fill=stat(level))) +\n  scale_fill_distiller(palette = \"Spectral\", direction = 1)\nggplotly(p)\n\n\np &lt;- ggplot(grid, aes(c, lr, z= Value,colour=stat(level))) +\n  geom_contour() \nggplotly(p)\n\n\nplot_ly(g2, x = ~c, y = ~lr, z = ~Value, type = 'scatter3d', mode = 'lines+markers',\n        opacity = 7, \n        line = list(width = 6, colorscale = 'Viridis', reverscale = FALSE)\n        )\n\n\n#install.packages(\"echarts4r\")\nlibrary(echarts4r)\ng2 |&gt; \n  e_charts(c) |&gt; \n  e_surface(lr, Value, wireframe = list(show = FALSE)) |&gt; \n  e_visual_map(Value)\n\n\nc lr noise trainRep lossFun mean_cFitO mean_cFitG mean_lrFitO mean_lrFitG mean_optimValO mean_optimValG            1 0.1 0.4 500 20 RMSE 4.94 5 1.00 1.09 3.30e- 5 0.115\n2 0.1 0.4 500 20 MAE 0.100 5 0.268 1.09 2.56e+ 1 0.0921 3 0.1 0.4 500 20 MAPE 0.101 5 0.268 1.09 2.31e+ 0 0.00954 4 0.1 0.4 500 20 MedAE 0.288 5 0.429 1.09 3.65e- 1 0.124\n5 0.1 0.4 500 20 HuberLoss 8.09 5 1.00 1.09 1.98e-17 0.00662"
  },
  {
    "objectID": "Visuals_Interactives/ALM_Shiny.html",
    "href": "Visuals_Interactives/ALM_Shiny.html",
    "title": "ALM Shiny App Code",
    "section": "",
    "text": "Shiny App Simulating ALM and EXAM  \n\n\nYou can play with the embedded version of the app below, or go to direct link\nYou can adjust the values of the Association parameter (i.e. the c parameter), and the Update parameter, (i.e. the learning rate parameter). The App also allows you to control the number and location of training instances. And the shape of the true function (linear, quadratic or exponential)\n\n\nAlternatively, you can run the app locally by copying the code below into a .R file.\n\n\nShow App Code\npacman::p_load(tidyverse,shiny,reactable,shinydashboard,shinydashboardPlus)\n\ninput.activation &lt;- function(x.target, association.parameter) {\n    return(exp(-1 * association.parameter * (x.target - x.plotting)^2))\n}\n\noutput.activation &lt;- function(x.target, weights, association.parameter) {\n    return(weights %*% input.activation(x.target, association.parameter))\n}\n\nmean.prediction &lt;- function(x.target, weights, association.parameter) {\n    probability &lt;- output.activation(x.target, weights, association.parameter) / sum(output.activation(x.target, weights, association.parameter))\n    return(y.plotting %*% probability)\n}\n# function to generate exam predictions\nexam.prediction &lt;- function(x.target, weights, association.parameter) {\n    trainVec &lt;- sort(unique(x.learning))\n    nearestTrain &lt;- trainVec[which.min(abs(trainVec - x.target))]\n    aresp &lt;- mean.prediction(nearestTrain, weights, association.parameter)\n    xUnder &lt;- ifelse(min(trainVec) == nearestTrain, nearestTrain, trainVec[which(trainVec == nearestTrain) - 1])\n    xOver &lt;- ifelse(max(trainVec) == nearestTrain, nearestTrain, trainVec[which(trainVec == nearestTrain) + 1])\n    mUnder &lt;- mean.prediction(xUnder, weights, association.parameter)\n    mOver &lt;- mean.prediction(xOver, weights, association.parameter)\n    exam.output &lt;- round(aresp + ((mOver - mUnder) / (xOver - xUnder)) * (x.target - nearestTrain), 3)\n    exam.output\n}\n\nupdate.weights &lt;- function(x.new, y.new, weights, association.parameter, update.parameter) {\n    y.feedback.activation &lt;- exp(-1 * association.parameter * (y.new - y.plotting)^2)\n    x.feedback.activation &lt;- output.activation(x.new, weights, association.parameter)\n    return(weights + update.parameter * (y.feedback.activation - x.feedback.activation) %*% t(input.activation(x.new, association.parameter)))\n}\n\nlearn.alm &lt;- function(y.learning, association.parameter = 0.05, update.parameter = 0.5) {\n    weights &lt;- matrix(rep(0.00, length(y.plotting) * length(x.plotting)), nrow = length(y.plotting), ncol = length(x.plotting))\n    for (i in 1:length(y.learning)) {\n        weights &lt;- update.weights(x.learning[i], y.learning[i], weights, association.parameter, update.parameter)\n        weights[weights &lt; 0] &lt;- 0\n    }\n    alm.predictions &lt;- sapply(x.plotting, mean.prediction, weights = weights, association.parameter = association.parameter)\n    exam.predictions &lt;- sapply(x.plotting, exam.prediction, weights = weights, association.parameter = association.parameter)\n    return(list(alm.predictions = alm.predictions, exam.predictions = exam.predictions))\n    # return(list(alm.predictions=alm.predictions, exam.predictions=exam.predictions,wmFinal=weights))\n}\n\n\n\nx.plotting &lt;&lt;- seq(0, 90, .5)\ny.plotting &lt;&lt;- seq(0, 210, by = 2)\n# trainOptions=round(seq(1,length(x.plotting),length.out=21),0)\ntrainOptions &lt;- x.plotting[seq(1, 181, by = 4)]\ntrainItems &lt;- trainOptions[c(10, 11, 12)]\n\n\n\n# Define UI for application\n# \nui &lt;- dashboardPage(\n\n  skin = \"black\",\n  dashboardHeader(title = \"ALM Simulation App\"),\n  dashboardSidebar(\n    sidebarMenu(\n      menuItem(\"Home\", tabName = \"home\", icon = icon(\"home\")),\n      menuItem(\"Code\", tabName = \"code\", icon = icon(\"code\"))\n    )\n  ),\n  dashboardBody(\n    tabItems(\n      tabItem(tabName = \"home\",\n              fluidRow(\n                column(4,\n                       box(\n                         title = \"Simulation Parameters\",\n                         status = \"primary\",\n                         solidHeader = TRUE,\n                         collapsible = TRUE,\n                         collapsed = FALSE,\n                         width = 12,\n                         sliderInput(\"assoc\", \"Association Parameter (c):\",\n                                     min = .001, max = 1, value = 0.5, step = 0.01),\n                         sliderInput(\"update\", \"Update Parameter:\",\n                                     min = 0, max = 1, value = 0.5, step = 0.1),\n                         sliderInput(\"trainRep\", \"Training Repetitions Per Item:\",\n                                     min = 1, max = 200, value = 1, step = 1),\n                         sliderInput(\"Noise\",\"Noise Level:\",\n                                     min = 0, max = 50, value = 0.00, step = 1),\n                         checkboxGroupInput(\"trainItems\", \"Training Items:\", choices = trainOptions, selected = trainOptions[c(10,15,35)],inline=TRUE),\n                         # radio buttons for selecting function form\n                         radioButtons(\"functionForm\", \"Function Form:\",\n                                      choices = c(\"Linear\", \"Quadratic\", \"Exponential\"),\n                                      selected = \"Quadratic\"),\n                        # numericInput(\"nRep\", \"Number of Replications:\", value = 1, min = 1, max = 100),\n                         actionButton(\"run\", \"Run Simulation\")\n                       )\n                ),\n                column(8,\n                       box(\n                         title = \"Model Performance\",\n                         status = \"primary\",\n                         solidHeader = TRUE,\n                         collapsible = TRUE,\n                         collapsed = FALSE,\n                          width = 12,\n                         plotOutput(\"plot\"),\n                         h5(\"*Dashed line shows true function. Red shows ALM, and blue depicts EXAM predictions*\"),\n                         h4(\"Average Model Performance\"),\n                         reactableOutput(\"table\"),\n                         h4(\"Model Performance by Item Type\"),\n                         reactableOutput(\"table2\")\n                       )\n                )\n              )\n      ),\n      tabItem(tabName = \"code\",\n              fluidRow(\n                column(12,\n                       box(\n                         title = \"Code\",\n                         status = \"primary\",\n                         solidHeader = TRUE,\n                         collapsible = TRUE,\n                         collapsed = FALSE,\n                         width = 12,\n                         verbatimTextOutput(\"code\")\n                       )\n                )\n                )\n        )\n    )\n    )\n)\n\n# Define server \n\n\n\nserver &lt;- function(input, output, session) {\n  \n  nRep=1\n  user_choice &lt;- eventReactive(input$run, {\n    return(list(assoc = input$assoc, update = input$update, Noise=input$Noise,\n                functionForm=input$functionForm,trainRep = as.numeric(input$trainRep),\n                trainItems = input$trainItems))\n    \n  }, ignoreNULL = FALSE)\n  \n\n    output_df &lt;- eventReactive(input$run, {\n      uc &lt;- reactive({user_choice()})\n    if (uc()$functionForm == \"Linear\") {\n      f.plotting &lt;&lt;- as.numeric(x.plotting * 2.2 + 30)\n    } else if (uc()$functionForm == \"Quadratic\") {\n      f.plotting &lt;&lt;- as.numeric(210 - ((x.plotting - 50)^2) / 12)\n    } else if (uc()$functionForm == \"Exponential\") {\n      # f.plotting&lt;&lt;-as.numeric(scale(200*(1-exp(-x.plotting/25))))\n      f.plotting &lt;&lt;- as.numeric(200 * (1 - exp(-x.plotting / 25)))\n    }\n    trainItems &lt;- as.numeric(uc()$trainItems)\n    y.plotting &lt;&lt;- seq(0, max(f.plotting), by = 1)\n    x.learning &lt;&lt;- rep(trainItems, times = uc()$trainRep)\n    f.learning &lt;&lt;- rep(f.plotting[which(x.plotting %in% trainItems)], times = uc()$trainRep)\n    # print(x.learning)\n    # print(f.learning)\n    # print(uc()$trainRep)\n    # print(trainItems)\n    # print(uc()$functionForm)\n    \n    \n    output_list &lt;- replicate(nRep, list(learn.alm(f.learning + rnorm(length(f.learning), sd = uc()$Noise),\n                                                  association.parameter = uc()$assoc, update.parameter = uc()$update)))\n    \n    output_df &lt;- lapply(output_list, function(x) as.data.frame(x))\n    #output_df &lt;- lapply(output_list, function(x) lapply(x, as.data.frame)) # 10 dfs x 9 lists\n    output_df &lt;- Reduce(rbind, output_df) %&gt;% mutate(x = x.plotting, y = f.plotting)\n    #output_df &lt;- lapply(output_df, function(x) Reduce(rbind,x))# 1 df x 9 lists\n    output_df &lt;- output_df %&gt;%\n      pivot_longer(names_to = \"Model\", values_to = \"Prediction\", cols = c(alm.predictions, exam.predictions)) %&gt;%\n      rbind(data.frame(data.frame(x = x.plotting, y = f.plotting, Model = \"True Function\", Prediction = f.plotting)), .)\n    #str(output_df)\n    return(output_df)\n    \n    }, ignoreNULL = FALSE)\n    \n    output$plot &lt;- renderPlot({\n      \n      output_df2 &lt;- reactive({output_df()})\n      ggplot(data = output_df2(), aes(x = x, y = Prediction,color=Model),alpha=.2) + \n        geom_line(aes(linetype=Model,alpha=Model)) + \n        geom_point(data = data.frame(x.learning, f.learning), \n                   aes(x = x.learning,y = f.learning),color=\"black\",size=4,shape=4) +\n        # geom_line(data = data.frame(x.plotting, f.plotting), \n        #           aes(x = x.plotting, y = f.plotting),linetype=2, color = \"black\",alpha=.3) + \n        scale_color_manual(values = c(\"red\", \"blue\", \"black\"))+\n        scale_alpha_manual(values=c(.8,.8,.4))+\n        scale_linetype_manual(values=c(1,1,2))+\n        ylim(c(0,250))#+\n        # ggtitle(paste(\"Association Parameter:\", user_choice()$assoc, \" Update Parameter:\", \n        #               uc$update, \" Train Reps:\", \n        #               uc$trainRep, \" Noise:\", uc$Noise))\n    }) \n    # table 1 reports the summary stats for all items. Table uses GT library to make gt table\n    output$table &lt;- renderReactable({\n      output_df &lt;- output_df()\n      output_df() %&gt;% group_by(Model) %&gt;% filter(Model !=\"True Function\") %&gt;%\n        summarise(MeanDeviation = mean(abs(Prediction - y)), \n                  RMSD = sqrt(mean((Prediction -y)^2)),Correlation = cor(Prediction, y)) %&gt;%\n        mutate(across(where(is.numeric), round, 1)) %&gt;%\n        reactable::reactable(compact=TRUE,bordered = TRUE, highlight = TRUE, resizable=TRUE)\n    })\n    # table 2 reports the summary stats separately for training items, interpolation items, and extrapolation items\n    output$table2 &lt;- renderReactable({\n      uc &lt;- reactive({user_choice()})\n      output_df() %&gt;% filter(Model !=\"True Function\") %&gt;% \n        mutate(ItemType = ifelse(x %in% x.learning, \"Training\", ifelse(x &gt; min(x.learning) & x &lt; max(x.learning), \"Interpolation\", \"Extrapolation\"))) %&gt;%\n        group_by(ItemType,Model) %&gt;%\n        summarise(MeanDeviation = mean(abs(Prediction - y)), \n                  RMSD = sqrt(mean((Prediction -y)^2)),Correlation = cor(Prediction, y),\n                  .groups=\"keep\") %&gt;% \n        mutate(across(where(is.numeric), round, 1)) %&gt;%\n        reactable::reactable(compact=TRUE,bordered = TRUE, highlight = TRUE, resizable=TRUE) \n    })\n    \n    \n    output$code &lt;- renderPrint({\n      # code to implement the ALM and EXAM models\n      # code to generate data\n      # code to run models\n      # code to format output\n      cat(\" input.activation&lt;-function(x.target, association.parameter){\n  return(exp(-1*association.parameter*(x.target-x.plotting)^2))\n}\n\noutput.activation&lt;-function(x.target, weights, association.parameter){\n  return(weights%*%input.activation(x.target, association.parameter))\n}\n\nmean.prediction&lt;-function(x.target, weights, association.parameter){\n  probability&lt;-output.activation(x.target, weights, association.parameter)/sum(output.activation(x.target, weights, association.parameter))\n  return(y.plotting%*%probability)\n}\n# function to generate exam predictions\nexam.prediction&lt;-function(x.target, weights, association.parameter){\n  trainVec = sort(unique(x.learning))\n  nearestTrain = trainVec[which.min(abs(trainVec-x.target))]\n  aresp = mean.prediction(nearestTrain, weights, association.parameter)\n  xUnder = ifelse(min(trainVec) == nearestTrain, nearestTrain, trainVec[which(trainVec == nearestTrain) - 1])\n  xOver = ifelse(max(trainVec) == nearestTrain, nearestTrain, trainVec[which(trainVec == nearestTrain) + 1])\n  mUnder = mean.prediction(xUnder, weights, association.parameter)\n  mOver = mean.prediction(xOver, weights, association.parameter)\n  exam.output = round(aresp + ((mOver - mUnder) / (xOver - xUnder)) * (x.target - nearestTrain), 3)\n  exam.output\n}\n\nupdate.weights&lt;-function(x.new, y.new, weights, association.parameter, update.parameter){\n  y.feedback.activation&lt;-exp(-1*association.parameter*(y.new-y.plotting)^2)\n  x.feedback.activation&lt;-output.activation(x.new, weights, association.parameter)\n  return(weights+update.parameter*(y.feedback.activation-x.feedback.activation)%*%t(input.activation(x.new, association.parameter)))\n}\n\nlearn.alm&lt;-function(y.learning, association.parameter=0.05, update.parameter=0.5){\n  weights&lt;-matrix(rep(0.00, length(y.plotting)*length(x.plotting)), nrow=length(y.plotting), ncol=length(x.plotting))\n  for (i in 1:length(y.learning)){\n    weights&lt;-update.weights(x.learning[i], y.learning[i], weights, association.parameter, update.parameter)\n    weights[weights&lt;0]=0\n  }\n  alm.predictions&lt;-sapply(x.plotting, mean.prediction, weights=weights, association.parameter=association.parameter)\n  exam.predictions &lt;- sapply(x.plotting, exam.prediction, weights=weights, association.parameter=association.parameter)\n  return(list(alm.predictions=alm.predictions, exam.predictions=exam.predictions))\n  #return(list(alm.predictions=alm.predictions, exam.predictions=exam.predictions,wmFinal=weights))\n}\n\n    \")\n    })\n    \n}\n\n\n\n# Run the application\n\n\nshinyApp(ui, server)"
  },
  {
    "objectID": "Visuals_Interactives/model_viz.html",
    "href": "Visuals_Interactives/model_viz.html",
    "title": "Model Visualization",
    "section": "",
    "text": "Code\n#lapply(c('tidyverse','data.table','igraph','ggraph','kableExtra'),library,character.only=TRUE))\npacman::p_load(tidyverse,data.table,igraph,ggraph,kableExtra)"
  },
  {
    "objectID": "Visuals_Interactives/model_viz.html#ggplot-model-visualization",
    "href": "Visuals_Interactives/model_viz.html#ggplot-model-visualization",
    "title": "Model Visualization",
    "section": "ggplot model visualization",
    "text": "ggplot model visualization\n\n\nCode\nnInput=6\nnOutput=10\n\ninNodes &lt;- seq(1,nInput,1) %&gt;% as.integer()\noutNodes &lt;- seq(300,1000,length.out=nOutput)%&gt;% as.integer()\nweight.mat &lt;&lt;- matrix(0.001,nrow=nOutput,ncol=nInput) # weights initialized to 0 (as in Delosh 1997)\n\nstim &lt;- 1.5\nc=.1\ninAct &lt;- round(exp(-c*((inNodes-stim)^2)),2)\ninActLab &lt;- paste0(\"x\",inNodes,\"=\",inAct)\noutAct &lt;- weight.mat %*% inAct\noutput.probability &lt;&lt;- outAct/sum(outAct)\noutLab=paste0(\"y\",outNodes,\"=\",round(output.probability,2))\nmean.response &lt;&lt;- round(sum(outNodes * output.probability),0)\n\n\nresp &lt;- mean.response\ninFlow &lt;- tibble(expand.grid(from=stim,to=inActLab)) %&gt;% mutate_all(as.character)\noutFlow &lt;- tibble(expand.grid(from=outLab,to=mean.response)) %&gt;% mutate_all(as.character)\n\ngd &lt;- tibble(expand.grid(from=inActLab,to=outLab)) %&gt;% mutate_all(as.character) %&gt;%\n  rbind(inFlow,.) %&gt;% rbind(.,outFlow)\n\nxInc &lt;- .3\nyInc=.5\n\ng = graph_from_data_frame(gd,directed=TRUE)\ncoords2=layout_as_tree(g)\ncolnames(coords2)=c(\"y\",\"x\")\n\nodf &lt;- as_tibble(coords2) %&gt;% \n  mutate(label=vertex_attr(g,\"name\"),\n         type=c(\"stim\",rep(\"Input\",nInput),rep(\"Output\",nOutput),\"Resp\"),\n         x=x*-1) %&gt;%\n  mutate(y=ifelse(type==\"Resp\",0,y),xmin=x-xInc,xmax=x+xInc,ymin=y-yInc,ymax=y+yInc)\n\nplot_edges = gd %&gt;% mutate(id=row_number()) %&gt;%\n  pivot_longer(cols=c(\"from\",\"to\"),names_to=\"s_e\",values_to=(\"label\")) %&gt;%\n                 mutate(label=as.character(label)) %&gt;% \n  group_by(id) %&gt;%\n  mutate(weight=sqrt(rnorm(1,mean=0,sd=10)^2)/10) %&gt;%\n  left_join(odf,by=\"label\") %&gt;%\n  mutate(xmin=xmin+.02,xmax=xmax-.02)\n\nggplot() + geom_rect(data = odf,\n            mapping = aes(xmin = xmin, ymin = ymin, \n                          xmax = xmax, ymax = ymax, \n                          fill = type, colour = type),alpha = 0.01) +\n  geom_text(data=odf,aes(x=x,y=y,label=label,size=3)) +\n  geom_path(data=plot_edges,mapping=aes(x=x,y=y,group=id,alpha=weight)) +\n  # geom_rect(aes(xmin=-1.05,xmax=-.95,ymin=-10,ymax=5),color=\"red\",alpha=.1)+\n  # geom_rect(aes(xmin=-0.05,xmax=.05,ymin=-10,ymax=5),color=\"blue\",alpha=.1) +\n  theme_void()"
  },
  {
    "objectID": "Visuals_Interactives/model_viz.html#ggraph-method",
    "href": "Visuals_Interactives/model_viz.html#ggraph-method",
    "title": "Model Visualization",
    "section": "ggraph method",
    "text": "ggraph method\n\n\nCode\ninNodes &lt;- seq(1,6,1) %&gt;% as.integer()\noutNodes &lt;- seq(300,1000,50)%&gt;% as.integer()\n\nda &lt;- data.frame(expand.grid(inNodes,outNodes))  %&gt;% magrittr::set_colnames(c(\"input\",\"output\"))\nda &lt;- da %&gt;% mutate_all(as.character)\nm = graph_from_data_frame(da, directed = TRUE)\n\ncoords = layout_with_sugiyama(m)\ncolnames(coords$layout) = c(\"y\", \"x\")\ncoords$layout=coords$layout[,c(\"x\",\"y\")]\nplot(m,layout=coords)\n\n\n\n\n\nCode\nggraph(m,layout=coords$layout)+\ngeom_edge_link0(width=0.2,colour=\"grey\")+\n  geom_node_point(col=\"white\",size=6)+scale_x_reverse()+\n  geom_node_text(aes(label=name)) +\n  # draw rectangle that covers input layer at x=1, min y is min of coords$y and max y is max of coords$y\n  annotate(\"rect\",xmin=0,xmax=.1,ymin=min(coords$layout[,2]),ymax=max(coords$layout[,2]),fill=\"grey\",alpha=0.7)\n\n\n\n\n\nCode\n geom_rect(xmin=0,xmax=1.1,ymin=min(coords$layout[,2]),ymax=max(coords$layout[,2]),fill=\"grey\",alpha=0.7)\n\n\ngeom_rect: linejoin = mitre, na.rm = FALSE\nstat_identity: na.rm = FALSE\nposition_identity"
  },
  {
    "objectID": "Visuals_Interactives/model_viz.html#p5-sketching",
    "href": "Visuals_Interactives/model_viz.html#p5-sketching",
    "title": "Model Visualization",
    "section": "P5 sketching",
    "text": "P5 sketching\n\n\nCode\nP5 = require(\"p5\")\nfunction* createSketch(sketch) {\n  const element = DOM.element('div');\n  yield element;\n  const instance = new P5(sketch, element, true);\n  try {\n    while (true) {\n      yield element;\n    }\n  } finally {\n    instance.remove();\n  }\n}\ncreateSketch(s =&gt; {\n  \n    s.setup = function() {\n      s.createCanvas(746, 300);\n      s.textFont('Courgette');\n      s.textStyle(s.BOLD);\n      s.textAlign(s.CENTER, s.CENTER)\n\n      s.button = s.createButton('clear');\n      s.button.mousePressed(s.clearCanvas);\n        s.text('Click and drag to draw', s.width/2, s.height/10);\n\n    };\n    s.draw = function() {\n    if (s.mouseIsPressed) {\n    s.fill(0);\n    s.ellipse(s.mouseX, s.mouseY, 10, 10);\n    } else {\n   //s.fill(255);\n    }\n  // add text input\n\n    };\n\n  // add button to clear canvas\n  s.clearCanvas = function() {\n    s.clear();\n  };\n  // add text\n  // add slider\n  }\n)"
  },
  {
    "objectID": "Visuals_Interactives/ojs_alm.html",
    "href": "Visuals_Interactives/ojs_alm.html",
    "title": "OJS ALM",
    "section": "",
    "text": "Code\npacman::p_load(tidyverse)\nd &lt;- tibble(x=1:20,y=x^2)\nojs_define(d = d)\n\ninputNodes = seq(1,7,1)  # \noutputNodes = seq(50,1600,50)\n#wm=matrix(rnorm(length(inputNodes)*length(outputNodes),5,2),nrow=length(outputNodes),ncol=length(inputNodes))\n#ojs_define(iN = inputNodes, outputNodes = outputNodes, wm = wm)\n\n\n\n\nCode\nd3 = require(\"d3@7\")\nmath = require('mathjs')\n// let inputNodes = Array.from({ length: 7 }, (_, i) =&gt; i + 1);\n// let outputNodes = Array.from({ length: 32 }, (_, i) =&gt; (i + 1) * 50);\n// let wm = Array.from({ length: outputNodes.length }, () =&gt;\n//   Array.from({ length: inputNodes.length }, () =&gt; 0.0)\n// );\n\nfunction inputActivation(xTarget, c) {\n  console.log(inputNodes)\n  return inputNodes.map((inputNode) =&gt;\n    Math.exp(-1 * c * Math.pow(xTarget - inputNode, 2))\n  );\n}\n\n\nfunction outputActivation(xTarget, weights, c) {\n  const inputAct = inputActivation(xTarget, c);\n  return math.multiply(weights, inputAct);\n}\n\nfunction meanPrediction(xTarget, weights, c) {\n  const outputAct = outputActivation(xTarget, weights, c);\n  const probability = math.divide(outputAct, math.sum(outputAct));\n  return math.multiply(outputNodes, probability);\n}\n\n\nfunction updateWeights(xNew, yNew, weights, c, lr) {\n  const yFeedbackActivation = outputNodes.map(\n    (outputNode) =&gt; Math.exp(-1 * c * Math.pow(yNew - outputNode, 2))\n  );\n //console.log(yFeedbackActivation)\n  const xFeedbackActivation = outputActivation(xNew, weights, c);\n  const inputAct = inputActivation(xNew, c);\n  const inputActReshaped = math.reshape(inputAct, [inputAct.length, 1]);\n  const yFeedbackActivationReshaped = math.reshape(yFeedbackActivation, [yFeedbackActivation.length, 1]);\n  const xFeedbackActivationReshaped = math.reshape(xFeedbackActivation, [xFeedbackActivation.length, 1]);\n  const error = math.reshape(math.subtract(yFeedbackActivationReshaped, xFeedbackActivationReshaped), [yFeedbackActivation.length, 1]);\n  // console.log(math.size(math.transpose(inputActReshaped)))\n  const weightUpdate = math.multiply(error, math.transpose(inputActReshaped));\n  //console.log(weightUpdate)\n  const raw_Weights = math.add(weights, math.multiply(lr, weightUpdate));\n\n  const new_Weights = raw_Weights\n  //return JSON.parse(result);\n  return(new_Weights)\n}\n\nfunction randomNormal(mean, sd) {\n  let u = 0,\n    v = 0;\n  while (u === 0) u = Math.random();\n  while (v === 0) v = Math.random();\n  const z = Math.sqrt(-2.0 * Math.log(u)) * Math.cos(2.0 * Math.PI * v);\n  return mean + z * sd;\n}\n\nfunction examPrediction(xTarget, weights, c, trainVec) {\n  const nearestTrain = trainVec[math.argmin(math.abs(trainVec - xTarget))];\n  const aResp = meanPrediction(nearestTrain, weights, c);\n  const xUnder = math.min(trainVec) === nearestTrain ? nearestTrain : trainVec[math.findIndex(trainVec, (d) =&gt; d === nearestTrain) - 1];\n  const xOver = math.max(trainVec) === nearestTrain ? nearestTrain : trainVec[math.findIndex(trainVec, (d) =&gt; d === nearestTrain) + 1];\n  const mUnder = meanPrediction(xUnder, weights, c);\n  const mOver = meanPrediction(xOver, weights, c);\n  const examOutput = math.round(aResp + ((mOver - mUnder) / (xOver - xUnder)) * (xTarget - nearestTrain), 3);\n  return examOutput;\n}\n\n\nfunction trainALM(dat, c, lr, weights) {\n    console.log('training')\n  const almTrain = new Array(dat.input.length).fill(NaN);\n  for (let i = 0; i &lt; dat.input.length; i++) {\n    console.log('i: ', i, ' dat.input[i]: ', dat.input[i], ' dat.vx[i]: ', dat.vx[i], ' c: ', c, ' lr: ', lr)\n    weights = updateWeights(dat.input[i], dat.vx[i], weights, c, lr);\n    const resp = math.round(meanPrediction(dat.input[i], weights, c),0);\n    // round resp to 1 decimal place\n    almTrain[i] = resp;\n      weights = math.map(weights, (value) =&gt; {\n        return value &lt; 0 ? 0 : value;\n      });\n  }\n  console.log('almTrain: ', almTrain)\n  console.log(weights)\n  return {almTrain, weights};\n}\n\nfunction trainTestALM(dat, c = 0.05, lr = 0.5, weights, testVec) {\n  const almTrain = new Array(dat.length).fill(NaN);\n  \n  for (let i = 0; i &lt; dat.length; i++) {\n    weights = updateWeights(dat[i].input, dat[i].vx, weights, c, lr);\n    const resp = meanPrediction(dat[i].input, weights, c);\n    almTrain[i] = resp;\n    weights = math.map(weights, (value) =&gt; {\n      return value &lt; 0 ? 0 : value;\n    });\n  }\n\n  const almPred = testVec.map((value) =&gt; {\n    return meanPrediction(value, weights, c);\n  });\n\n  const examPred = testVec.map((value) =&gt; {\n    return examPrediction(value, weights, c, [1, ...math.sort(math.unique(dat.map((d) =&gt; d.input)))]);\n  });\n    \n  return { almTrain, almPred, examPred };\n}\n\n// Modify the sim_data function to accept the dataset as an argument\n// function sim_data(dat, c=0.5, lr=0.2, inNodes=7, outNodes=32, trainVec=[5,6,7]) {\n//   inputNodes = math.range(1,7,inNodes).toArray();  \n//   outputNodes = math.range(50,1600,outNodes).toArray(); \n//   wm = math.zeros(outputNodes.length, inputNodes.length)._data;\n//   tt = trainTest_alm(dat, c, lr, wm, trainVec);\n// }\n\nfunction gen_train(trainVec, trainRep, noise) {\n   let bandVec=[0,100,350,600,800,1000,1200];\n   let ts = [];\n   for (let i=0; i&lt;trainRep; i++) {\n       ts.push(...trainVec);\n   }\n    let mean = 0;\n    let stdDev = 1;\n   //let noiseVec = math.random([ts.length])._data;\n   //noiseVec = math.multiply(noiseVec, noise)._data;\n   //if(noise==0) {noiseVec=noiseVec*0}\n   let inputArr = [];\n   let vxArr = [];\n   for (let i=0; i&lt;ts.length; i++) {\n       inputArr.push(ts[i]);\n       vxArr.push(bandVec[ts[i]]);\n       //vxArr.push(bandVec[ts[i]]+noiseVec[i]);\n   }\n   return {input: inputArr, vx: vxArr};\n}\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSimulation\n\n\n\nCode\nviewof c = Inputs.range([.0001, 2], {value: .00005, step: .05, label: \"c value:\"})\nviewof lr = Inputs.range([.001, 2], {value: .05, step: .01, label: \"lr value:\"})\n\nviewof n_inputNodes = Inputs.range([1, 50], {value: 7, step: 1, label: \"N Input Nodes:\"})\nviewof n_outputNodes = Inputs.range([1, 200], {value: 32, step: 1, label: \"N Output Nodes:\"})\n\nviewof weight_mean = Inputs.range([0, 1], {value: 0, step: .0005, label: \"initial weight mean:\"})\nviewof weight_sd = Inputs.range([.00000001, 1], {value: .000001, step: .0001, label: \"initial weight sd:\"})\n\nviewof trainRep = Inputs.range([4, 50], {value: 1, step: 1, label: \"Train Reps:\"})\n\n //inputNodes = Array.from({ length: n_inputNodes }, (_, i) =&gt; i + 1);\n inputNodes = Array.from({ length: n_inputNodes }, (_, i) =&gt; 1 + i * (7 - 1) / (n_inputNodes - 1));\n\n\n\nstart = 0;\nend = 1800;\nN_Steps = n_outputNodes; // replace with desired length\nstepSize = (end - start) / (N_Steps - 1);\noutputNodes = Array.from({ length: N_Steps }, (_, i) =&gt; start + i * stepSize);\n\nconsole.log(inputNodes)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nconsole.log(outputNodes)\n\n\n\n\n\n\n\n\n\nCode\nwm = outputNodes.map(() =&gt; {\n  return inputNodes.map(() =&gt; randomNormal(weight_mean, weight_sd));\n});\n\nnoise=0\nviewof trainVec = Inputs.checkbox([1, 2, 3, 4, 5, 6], {value: [4,5,6], label: \"Select training examples:\"});\ngd = gen_train(trainVec, trainRep, noise);\n\n//trainVec = [1,2,4,5,6];\n//gd = gen_train(trainVec, trainRep, noise)\n// w2= updateWeights(4, 800, wm,c,lr)\n\ntalm = trainALM(gd, c, lr, wm);\n\n//inputNodes = transpose(iN)\nia = inputActivation(inputX, c, inputNodes)\noa = outputActivation(inputX, wm, c)\nmp = meanPrediction(inputX, wm, c)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\ntdat = gd.vx.map((value, index) =&gt; {\n  return { Trial: index, Vx: value, Response: talm.almTrain[index], Error: Math.abs(value -  talm.almTrain[index]) };\n});\n\n\n\n\n\n\n\n\n\n\nVx Across Training\n\nCode\nPlot.plot({\n  marks: [\n    Plot.line(tdat, {\n      x: \"Trial\",      // feature for the x channel\n      y: \"Response\",     // feature for the y channel\n      stroke: \"Vx\",     \n    }),\n  ],\n  x: {label: \"Trial Number\"},\n  y: {label: \"Vx\", domain: [0, 1800],grid: true},\n  color: {legend: true, scheme: \"Turbo\",type: \"categorical\"},\n  width: 400,\n  height: 400\n});\n  //caption: html`Figure 1. This chart has a &lt;i&gt;fancy&lt;/i&gt; caption.`\n\n\n\n\n\n\n\n\nTraining Error\n\nCode\nPlot.plot({\n  marks: [\n    Plot.line(tdat, {\n      x: \"Trial\",      // feature for the x channel\n      y: \"Error\",     // feature for the y channel\n      stroke: \"Vx\",     // feature for the fill channel\n    }),\n  ],\n  y: {label: \"Error\",grid: true},\n  color: {legend: true, scheme: \"Turbo\",type: \"categorical\"},\n  width: 400,\n  height: 400\n});\n\n\n\n\n\n\n\n\n\n\n\n\n\nWeight Matrices\n\n\nCode\nPlotly = require(\"https://cdn.plot.ly/plotly-latest.min.js\")\n//div = DOM.element('div');\nP1=Plotly.newPlot(\"plot-canvas\", [{\n  z: wm,\n  x: outputNodes,\n  y: inputNodes,\n  type: 'heatmap',\n  colorscale: 'Viridis'\n}],{width:500});\n\nconsole.log(inputNodes)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nconsole.log(outputNodes)\n\n\n\n\n\n\n\n\n\nCode\nP2=Plotly.newPlot(\"plot-tw\", [{\n  z: talm.weights,\n  x: inputNodes,\n  y: outputNodes,\n  type: 'heatmap',\n  colorscale: 'Viridis'\n}],{width:600});\n\n\n\n\n\n\n\n\n\n\n\n\nStarting Weights\n\n\n\nFinal Weights\n\n\n\n\n\nInput and Output layer activations\n\n\nCode\nin_data = ia.map((value, index) =&gt; {\n  return { Node: inputNodes[index], Activation: value };\n});\n\n out_data = oa.map((value, index) =&gt; {\n  return { Node: outputNodes[index], Activation: value };\n});\n\nviewof inputX = Inputs.range([1, 7], {value: 4, step: 1, label: \"input value:\"})\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nPlot.plot({\n  marks: [\n    Plot.dot(in_data, {\n      x: \"Node\",      // feature for the x channel\n      y: \"Activation\",     // feature for the y channel\n    }),\n  ],\n  width: 400,\n  height: 200,\n  title: \"Input Activation Plot\",\n});\nPlot.plot({\n  marks: [\n    Plot.dot(out_data, {\n      x: \"Node\",      // feature for the x channel\n      y: \"Activation\",     // feature for the y channel\n    }),\n  ],\n  width: 400,\n  height: 200,\n  title: \"Output Activation Plot\",\n});\n\n\n\n\n\n\n\n\nInput Activation\n\n\n\n\n\n\n\nSecond\n\n\n\n\n\nCharts\n\n\n\n\n\n\nCode\nconsole.log(wm)\n\n\n\n\n\n\n\n\n\nCode\nconsole.log(talm.weights)\n\n\n\n\n\n\n\n\n\n\n\n\nTesting\n\n\nCode\nviewof xV = Inputs.range(\n  [1, 20], \n  {value: 1, step: 1, label: \"x range:\"}\n)\nviewof yV = Inputs.range(\n  [1, 400], \n  {value: 1, step: 10, label: \"y range:\"}\n)\n\ndO = transpose(d)\nfiltered = dO.filter(function(dO) {\n  return dO.x&gt;=xV && dO.y &gt;= yV;\n})\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTab 1Tab 2\n\n\n\n\nCode\nPlot.plot({\n  marks: [\n    Plot.dot(filtered, \n      { x: \"x\", y: \"y\"}, \n      { stroke: \"black\" }\n    )\n  ]\n})\n\n\n\n\n\n\n\nx:  y: \n\n\n\n\nCode\n//Plot = require(\"plot\")\nPlot.plot({\n  marks: [\n    Plot.line(transpose(d), \n      { x: \"x\", y: \"y\"}, \n      { stroke: \"black\" }\n    )\n  ]\n})\n\n\n\n\n\n\n\n\n\n\n```{ojs}\n//| include: false\n```"
  },
  {
    "objectID": "Visuals_Interactives/ojs_explore.html",
    "href": "Visuals_Interactives/ojs_explore.html",
    "title": "OJS data exploration",
    "section": "",
    "text": "Code\npacman::p_load(tidyverse,here)\n\nd &lt;- readRDS(here(\"data/dPrune-01-19-23.rds\"))\n\n# Prepare the data for analysis\ndtest &lt;- d %&gt;%\n    filter(expMode %in% c(\"test-Nf\", \"test-train-nf\")) %&gt;%\n    group_by(id, lowBound) %&gt;%\n    mutate(nBand = n(), band = bandInt, id = factor(id)) %&gt;%\n    group_by(id) %&gt;%\n    mutate(nd = n_distinct(lowBound))\ndtest &lt;- dtest %&gt;%\n    group_by(id, lowBound) %&gt;%\n    filter(nBand &gt;= 5 & nd == 6)\ndtest &lt;- dtest %&gt;%\n    group_by(id) %&gt;%\n    filter(!id %in% unique(dtest$id[dtest$nBand &lt; 5]))\n\ndtestAgg &lt;- dtest %&gt;%\n    group_by(id, condit, catOrder, feedbackType, vb, band, lowBound, highBound, input) %&gt;%\n    mutate(vxCapped = ifelse(vx &gt; 1600, 1600, vx)) %&gt;%\n    summarise(\n        vxMean = mean(vx), devMean = mean(dist), vxMed = median(vx), devMed = median(dist),\n        vxMeanCap = mean(vxCapped), .groups = \"keep\"\n    )\nds1 &lt;- d %&gt;%\n    filter(expMode %in% c(\"train\", \"train-Nf\", \"test-Nf\", \"test-train-nf\")) %&gt;%\n    filter(!id %in% unique(dtest$id[dtest$nBand &lt; 5]), vx&lt;1500) %&gt;%\n    select(id, condit, catOrder, feedbackType, expMode, trial, gt.train, vb, band, bandInt, lowBound, highBound, input, vx, dist, vxb)\n\n\nojs_define(dso=ds1)\n\n\n\n\nCode\nimport { aq, op } from \"@uwdata/arquero\"\n\n//data = FileAttachment(\"palmer-penguins.csv\").csv({ typed: true })\n\n\n//ds1=transpose(ds1)\n\nds=transpose(dso)\n\nPlot.plot({\n  facet: {\n    data: ds,\n    x: \"condit\",\n    y: \"bandInt\",\n    marginRight: 80\n  },\n  marks: [\n    Plot.frame(),\n    Plot.rectY(ds, \n      Plot.binX(\n        {y: \"count\"}, \n        {x: \"vx\", thresholds: 50, fill: \"bandInt\"} // thresholds = number of bins\n      )\n    ),\n    Plot.tickX(ds, \n      Plot.groupZ(\n        {x: \"count\"}, \n        {x: \"vx\",\n         z: d =&gt; ds.condit+ ds.bandInt,\n         stroke: \"#333\",\n         strokeWidth: 2\n        }\n      )\n    )\n  ],\n    x: {label: \"Vx\", domain: [0, 1800],grid: true},\n})\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nPlot.plot({\n  marks: [\n    Plot.line(ds, {\n      x: \"gt.train\",      // feature for the x channel\n      y: \"vx\",     // feature for the y channel\n      fill:\"condit\",\n      stroke: \"vb\",     \n    }),\n  ],\n  x: {label: \"Trial Number\"},\n  y: {label: \"Vx\", domain: [0, 1800],grid: true},\n  color: {legend: true, scheme: \"Turbo\",type: \"categorical\"},\n  width: 400,\n  height: 400\n});\n\n\n\n\n\n\n\n\n\nCode\nPlot.plot({\n  grid: true,\n  marks: [\n    Plot.rectY(ds, Plot.binX({y: \"count\"}, {x: \"vx\", fill: \"condit\", fy: \"condit\"})),\n    Plot.ruleY([0])\n  ]\n})\n\n\n\n\n\n\n\n\n\nCode\nPlot.rectY(ds, Plot.binX({y: \"count\"}, {x: \"condit\", fill: \"condit\"})).plot()\n\n\n\n\n\n\n\n\n\nCode\nPlot.line(ds, {x: \"gt.train\", y: \"vx\",fill:\"condit\"}).plot({y: {grid: true}})\n\n\n\n\n\n\n\n\n\nCode\nd = aq.from(ds)\nd\n  .groupby(\"condit\", \"vb\", \"feedbackType\",\"expMode\",\"catOrder\")\n  .rollup({mean_vx: d =&gt; op.mean(d.vx)}, {mean_dist: d =&gt; op.mean(d.dist)})\n  .view(15)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\ndt = aq.from(ds)\ndtAgg = dt\n  .filter(dt =&gt; dt.expMode === \"train\")\n  .groupby(\"condit\", \"vb\",\"gt.train\")\n  .rollup({mean_vx: dt =&gt; op.mean(dt.vx)}, {mean_dist: dt =&gt; op.mean(dt.dist)})\n\n\nPlot.line(dtAgg, {x: \"gt.train\", y: \"mean_vx\",fill:\"vb\"}).plot({y: {grid: true}})\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nPlot.plot({ \n    grid: true, \n    marginRight: 60,\n    facet: {\n        data: dtAgg,\n        x: \"condit\",\n        y: \"vb\",\n        marginRight: 80\n    },\n    marks: [\n        Plot.frame(),\n        Plot.lineY(dtAgg, {\n            x: \"gt.train\", \n            y: \"mean_vx\",\n            fill:\"vb\"\n            })\n    ]\n})\n\n\n\n\n\n\n\n\n\nCode\ndtAgg\n  .view(25)"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "HTW Project",
    "section": "",
    "text": "Order By\n       Default\n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n         \n          Title\n        \n         \n          Categories\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\n\n\n\n\n\nModeling\n\n\nALM\n\n\nR\n\n\n\n\n\n\n\n\n\n\nMay 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nModeling\n\n\nALM\n\n\nR\n\n\nBayesian\n\n\n\n\n\n\n\n\n\n\nMay 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nModeling\n\n\nALM\n\n\nR\n\n\n\n\n\n\n\n\n\n\nMay 2023\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "index.html#modeling-empircal-data",
    "href": "index.html#modeling-empircal-data",
    "title": "HTW Project",
    "section": "",
    "text": "Order By\n       Default\n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n         \n          Title\n        \n         \n          Categories\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\n\n\n\n\n\nModeling\n\n\nALM\n\n\nR\n\n\n\n\n\n\n\n\n\n\nMay 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nModeling\n\n\nALM\n\n\nR\n\n\nBayesian\n\n\n\n\n\n\n\n\n\n\nMay 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nModeling\n\n\nALM\n\n\nR\n\n\n\n\n\n\n\n\n\n\nMay 2023\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "index.html#simulations",
    "href": "index.html#simulations",
    "title": "HTW Project",
    "section": "Simulations",
    "text": "Simulations\n\n\n\n\n\n\n\n\nALM Learning\n\n\n\nSimulation\n\n\nALM\n\n\nR\n\n\n\n\n\n\n\n\n\n\nMay 2023\n\n\n\n\n\n\n\n\n\n\n\n\nBenchmarking\n\n\n\nSimulation\n\n\nALM\n\n\nR\n\n\n\n\n\n\n\n\n\n\nMay 2023\n\n\n\n\n\n\n\n\n\n\n\n\nGeneral Simulations\n\n\n\nSimulation\n\n\nALM\n\n\nEXAM\n\n\nR\n\n\n\n\n\n\n\n\n\n\nMay 2023\n\n\n\n\n\n\n\n\n\n\n\n\nNode Manipulations\n\n\n\nSimulation\n\n\nALM\n\n\nR\n\n\nModel-Structure\n\n\n\n\n\n\n\n\n\n\nMay 2023\n\n\n\n\n\n\n\n\n\n\n\n\nNoisy Learning\n\n\n\nSimulation\n\n\nALM\n\n\nR\n\n\nBayesian\n\n\nModel-Structure\n\n\n\n\n\n\n\n\n\n\nMay 2023\n\n\n\n\n\n\n\n\n\n\n\n\nParameter Recovery Simulations\n\n\n\nSimulation\n\n\nALM\n\n\nEXAM\n\n\nR\n\n\n\n\n\n\n\n\n\n\nMay 2023\n\n\n\n\n\n\n\n\n\n\n\n\nSimulating DeLosh 1997\n\n\n\nSimulation\n\n\nALM\n\n\nEXAM\n\n\nR\n\n\n\n\n\n\n\n\n\n\nMay 2023\n\n\n\n\n\n\n\n\n\n\n\n\nlearning bias\n\n\n\nSimulation\n\n\nALM\n\n\nR\n\n\n\n\n\n\n\n\n\n\nMay 2023\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "index.html#analyses",
    "href": "index.html#analyses",
    "title": "HTW Project",
    "section": "Analyses",
    "text": "Analyses\n\n\n   \n     \n     \n       Order By\n       Default\n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n         \n          Title\n        \n         \n          Categories\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\n\n\n\nHTW Analysis\n\n\n\nAnalysis\n\n\nLearning-Curve\n\n\nR\n\n\n\n\n\n\n\n\n\n\nMay 2023\n\n\n\n\n\n\n\n\n\n\n\n\nME_Pool\n\n\n\nAnalysis\n\n\nR\n\n\n\n\n\n\n\n\n\n\nMay 2023\n\n\n\n\n\n\n\n\n\n\n\n\nOJS data exploration\n\n\n\nAnalysis\n\n\nLearning-Curve\n\n\nR\n\n\nOJS\n\n\n\n\n\n\n\n\n\n\nMay 2023\n\n\n\n\n\n\n\n\n\n\n\n\nTesting Discrimination Analysis\n\n\n\nAnalysis\n\n\nR\n\n\n\n\n\n\n\n\n\n\nMay 2023\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "index.html#misc",
    "href": "index.html#misc",
    "title": "HTW Project",
    "section": "Misc",
    "text": "Misc\n\n\n   \n     \n     \n       Order By\n       Default\n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n         \n          Title\n        \n         \n          Categories\n        \n     \n  \n\n\n\n\n\n\n\n\nALM Shiny App Code\n\n\n\nSimulation\n\n\nALM\n\n\nEXAM\n\n\nShiny\n\n\nInteractive\n\n\nR\n\n\n\n\n\n\n\n\n\n\nMay 2023\n\n\n\n\n\n\n\n\n\n\n\n\nHTW Task\n\n\n\nTask\n\n\njs\n\n\n\n\n\n\n\n\n\n\nMay 2023\n\n\n\n\n\n\n\n\n\n\n\n\nModel Visualization\n\n\n\nVisualization\n\n\nR\n\n\nOJS\n\n\n\n\n\n\n\n\n\n\nMay 2023\n\n\n\n\n\n\n\n\n\n\n\n\nOJS ALM\n\n\n\nSimulation\n\n\nALM\n\n\nOJS\n\n\nInteractive\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOJS data exploration\n\n\n\nAnalysis\n\n\nLearning-Curve\n\n\nR\n\n\nOJS\n\n\n\n\n\n\n\n\n\n\nMay 2023\n\n\n\n\n\n\n\n\nNo matching items"
  }
]