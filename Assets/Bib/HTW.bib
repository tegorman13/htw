@article{adkinsHeuristicsContributeSensorimotor2022,
  title = {Heuristics Contribute to Sensorimotor Decision-Making under Risk},
  author = {Adkins, Tyler and Lewis, Richard and Lee, Taraz},
  year = {2022},
  month = feb,
  journal = {Psychonomic Bulletin \& Review},
  volume = {29},
  number = {1},
  pages = {145--158},
  issn = {1531-5320},
  doi = {10.3758/s13423-021-01986-x},
  urldate = {2022-05-20},
  abstract = {Research in psychophysics argues that incentivized sensorimotor decisions (such as deciding where to reach to get a reward) maximize expected gain, suggesting that these decisions may be impervious to cognitive biases and heuristics. We tested this hypothesis in two experiments, directly comparing the predictive accuracy of an optimal model and plausible suboptimal models. We obtained strong evidence that people deviated from the optimal strategy by excessively avoiding loss regions when the potential loss was zero and failing to shift far enough away from loss regions when potential losses outweighed the potential gains. Although allowing nonlinear distortions of value and probability information improved the fit of value-maximizing models, behavior was best described by a model encapsulating a simple heuristic strategy. This suggests that visuomotor decisions are likely influenced by biases and heuristics observed in more classical economic decision-making tasks.},
  langid = {english},
  keywords = {judgment and decision making,motor control,motor planning/programming,reward},
  file = {/Users/thomasgorman/OneDrive - Indiana University/resources/Zotero/Adkins et al_2022_Heuristics contribute to sensorimotor decision-making under risk.pdf}
}

@article{agarwalContrastiveBehavioralSimilarity2021,
  title = {Contrastive {{Behavioral Similarity Embeddings}} for {{Generalization}} in {{Reinforcement Learning}}},
  author = {Agarwal, Rishabh and Machado, Marlos C. and Castro, Pablo Samuel and Bellemare, Marc G.},
  year = {2021},
  month = mar,
  journal = {arXiv:2101.05265 [cs, stat]},
  eprint = {2101.05265},
  primaryclass = {cs, stat},
  urldate = {2021-11-16},
  abstract = {Reinforcement learning methods trained on few environments rarely learn policies that generalize to unseen environments. To improve generalization, we incorporate the inherent sequential structure in reinforcement learning into the representation learning process. This approach is orthogonal to recent approaches, which rarely exploit this structure explicitly. Specifically, we introduce a theoretically motivated policy similarity metric (PSM) for measuring behavioral similarity between states. PSM assigns high similarity to states for which the optimal policies in those states as well as in future states are similar. We also present a contrastive representation learning procedure to embed any state similarity metric, which we instantiate with PSM to obtain policy similarity embeddings (PSEs). We demonstrate that PSEs improve generalization on diverse benchmarks, including LQR with spurious correlations, a jumping task from pixels, and Distracting DM Control Suite.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {/Users/thomasgorman/OneDrive - Indiana University/resources/Zotero/Agarwal et al_2021_Contrastive Behavioral Similarity Embeddings for Generalization in.pdf;/Users/thomasgorman/Zotero/storage/5VFEDY8D/2101.html}
}

@article{albrechtCompetitiveRetrievalStrategy2020,
  title = {Competitive Retrieval Strategy Causes Multimodal Response Distributions in Multiple-Cue Judgments.},
  author = {Albrecht, Rebecca and Hoffmann, Janina A. and Pleskac, Timothy J. and Rieskamp, J{\"o}rg and {von Helversen}, Bettina},
  year = {2020},
  journal = {Journal of Experimental Psychology: Learning, Memory, and Cognition},
  volume = {46},
  number = {6},
  pages = {1064},
  publisher = {{US: American Psychological Association}},
  issn = {1939-1285},
  doi = {10.1037/xlm0000772},
  urldate = {2020-12-21},
  file = {/Users/thomasgorman/OneDrive - Indiana University/resources/Zotero/Albrecht et al_2020_Competitive retrieval strategy causes multimodal response distributions in.pdf;/Users/thomasgorman/OneDrive - Indiana University/resources/Zotero/Albrecht et al_2020_Competitive retrieval strategy causes multimodal response distributions in2.pdf}
}

@article{almaatouqEmpiricaVirtualLab2021,
  title = {Empirica: A Virtual Lab for High-Throughput Macro-Level Experiments},
  shorttitle = {Empirica},
  author = {Almaatouq, Abdullah and Becker, Joshua and Houghton, James P. and Paton, Nicolas and Watts, Duncan J. and Whiting, Mark E.},
  year = {2021},
  month = oct,
  journal = {Behavior Research Methods},
  volume = {53},
  number = {5},
  pages = {2158--2171},
  issn = {1554-3528},
  doi = {10.3758/s13428-020-01535-9},
  urldate = {2021-12-06},
  abstract = {Virtual labs allow researchers to design high-throughput and macro-level experiments that are not feasible in traditional in-person physical lab settings. Despite the increasing popularity of online research, researchers still face many technical and logistical barriers when designing and deploying virtual lab experiments. While several platforms exist to facilitate the development of virtual lab experiments, they typically present researchers with a stark trade-off between usability and functionality. We introduce Empirica: a modular virtual lab that offers a solution to the usability\textendash functionality trade-off by employing a ``flexible defaults'' design strategy. This strategy enables us to maintain complete ``build anything'' flexibility while offering a development platform that is accessible to novice programmers. Empirica's architecture is designed to allow for parameterizable experimental designs, reusable protocols, and rapid development. These features will increase the accessibility of virtual lab experiments, remove barriers to innovation in experiment design, and enable rapid progress in the understanding of human behavior.},
  langid = {english},
  file = {/Users/thomasgorman/Documents/Zotero_Markdown/almaatouq_empirica_2021-zotero.md;/Users/thomasgorman/OneDrive - Indiana University/resources/Zotero/Almaatouq et al_2021_Empirica.pdf}
}

@techreport{andersonThreeAspectsSkill2018,
  type = {Preprint},
  title = {Three {{Aspects}} of {{Skill Acquisition}}},
  author = {Anderson, John and Betts, Shawn and Bothell, Daniel and Hope, Ryan M. and Lebiere, Christian},
  year = {2018},
  month = jun,
  institution = {{PsyArXiv}},
  doi = {10.31234/osf.io/rh6zt},
  urldate = {2020-05-07},
  abstract = {A theory is presented about how instruction and experience combine to produce competence in a complex skill.   The theory depends critically on three components of the ACT-R architecture.   The first component interprets declarative representations of instruction so that they lead to action.   The second component converts this knowledge into procedural form so that appropriate actions can be quickly executed.  The third component, newly added to the architecture, learns the setting of control parameters for actions through a process similar to reinforcement learning..  These three components are intermingled throughout the course of skill acquisition, providing an instantiation of Fitts' (1964) original characterization of skill acquisition as involving gradual shifts in the factor structure of skills. The overall theory is implemented in computational models that are capable of simulating human learning in different versions of the video game Space Fortress.  Other than humans, these models are the only agents, natural or artificial, capable of learning to play Space Fortress.},
  langid = {english},
  annotation = {https://bitbucket.org/andersonlab/c-spacefortress/branch/package},
  file = {/Users/thomasgorman/Documents/Zotero_Markdown/anderson_three_2018-zotero.md;/Users/thomasgorman/Zotero/storage/HR8NDHDW/Anderson et al. - 2018 - Three Aspects of Skill Acquisition.pdf}
}

@article{barnettWhenWhereWe2002,
  title = {When and Where Do We Apply What We Learn?: {{A}} Taxonomy for Far Transfer.},
  shorttitle = {When and Where Do We Apply What We Learn?},
  author = {Barnett, Susan M. and Ceci, Stephen J.},
  year = {2002},
  journal = {Psychological Bulletin},
  volume = {128},
  number = {4},
  pages = {612--637},
  issn = {0033-2909},
  doi = {10.1037//0033-2909.128.4.612},
  urldate = {2016-05-11},
  langid = {english},
  file = {/Users/thomasgorman/Zotero/storage/756DM237/Barnett and Ceci - 2002 - When and where do we apply what we learn A taxon.pdf}
}

@article{bechbergerGeneralizingPsychologicalSimilarity2020,
  title = {Generalizing {{Psychological Similarity Spaces}} to {{Unseen Stimuli}}},
  author = {Bechberger, Lucas and K{\"u}hnberger, Kai-Uwe},
  year = {2020},
  month = apr,
  journal = {arXiv:1908.09260 [cs, stat]},
  eprint = {1908.09260},
  primaryclass = {cs, stat},
  urldate = {2020-09-17},
  abstract = {The cognitive framework of conceptual spaces proposes to represent concepts as regions in psychological similarity spaces. These similarity spaces are typically obtained through multidimensional scaling (MDS), which converts human dissimilarity ratings for a fixed set of stimuli into a spatial representation. One can distinguish metric MDS (which assumes that the dissimilarity ratings are interval or ratio scaled) from nonmetric MDS (which only assumes an ordinal scale). In our first study, we show that despite its additional assumptions, metric MDS does not necessarily yield better solutions than nonmetric MDS. In this chapter, we furthermore propose to learn a mapping from raw stimuli into the similarity space using artificial neural networks (ANNs) in order to generalize the similarity space to unseen inputs. In our second study, we show that a linear regression from the activation vectors of a convolutional ANN to similarity spaces obtained by MDS can be successful and that the results are sensitive to the number of dimensions of the similarity space.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {/Users/thomasgorman/OneDrive - Indiana University/resources/Zotero/Bechberger_Kühnberger_2020_Generalizing Psychological Similarity Spaces to Unseen Stimuli.pdf;/Users/thomasgorman/Zotero/storage/54HP333C/1908.html}
}

@article{bedfordConstraintsLearningNew1989,
  title = {Constraints on {{Learning New Mappings Between Perceptual Dimensions}}},
  author = {Bedford, Felice L},
  year = {1989},
  journal = {Journal of Experimental Psychology \textendash{} Human Perception and Performance},
  pages = {17},
  abstract = {The constraints on learning new mappings between visual and proprioceptive spatial dimensions were assessed. Incomplete information was provided about a mapping by specifying only a few isolated visual\textendash proprioceptive pairs of locations. The nature of the generalization occurring to untrained locations was then inspected to reveal the internal constraints. A new technique was developed to allow individual visual\textendash proprioceptive pairs to be manipulated separately. In Experiment 1, training with only a single pair produced a rigid shift of one entire dimension with respect to the other. Training with two pairs caused linear interpolation to all untrained positions between the trained positions (Experiments 2 and 3). Finally, training with three new pairs also produced a linear change in behavior (Experiment 4), even though more adaptive solutions existed. The implications of these results for the learning process involved in acquiring new mappings are discussed.},
  langid = {english},
  file = {/Users/thomasgorman/Documents/Zotero_Markdown/bedford_constraints_1989-zotero.md;/Users/thomasgorman/OneDrive - Indiana University/resources/Zotero/Bedford_Constraints on Learning New Mappings Between Perceptual Dimensions.pdf}
}

@inproceedings{borjiBayesianOptimizationExplains2013,
  title = {Bayesian Optimization Explains Human Active Search},
  booktitle = {Advances in {{Neural Information Processing Systems}}},
  author = {Borji, Ali and Itti, Laurent},
  year = {2013},
  volume = {26},
  publisher = {{Curran Associates, Inc.}},
  urldate = {2022-06-03},
  abstract = {Many real-world problems have complicated objective functions. To optimize such functions, humans utilize sophisticated sequential decision-making strategies. Many optimization algorithms have also been developed for this same purpose, but how do they compare to humans in terms of both performance and behavior? We try to unravel the general underlying algorithm people may be using while searching for the maximum of an invisible 1D function. Subjects click on a blank screen and are shown the ordinate of the function at each clicked abscissa location. Their task is to find the function's maximum in as few clicks as possible. Subjects win if they get close enough to the maximum location. Analysis over 23 non-maths undergraduates, optimizing 25 functions from different families, shows that humans outperform 24 well-known optimization algorithms. Bayesian Optimization based on Gaussian Processes, which exploit all the x values tried and all the f(x) values obtained so far to pick the next x, predicts human performance and searched locations better. In 6 follow-up controlled experiments over 76 subjects, covering interpolation, extrapolation, and optimization tasks, we further confirm that Gaussian Processes provide a general and unified theoretical account to explain passive and active function learning and search in humans.},
  file = {/Users/thomasgorman/Documents/Zotero_Markdown/borji_bayesian_2013-zotero.md;/Users/thomasgorman/OneDrive - Indiana University/resources/Zotero/Borji_Itti_2013_Bayesian optimization explains human active search.pdf}
}

@article{bossensLinearNonLinearVisual2016,
  title = {Linear and {{Non-Linear Visual Feature Learning}} in {{Rat}} and {{Humans}}},
  author = {Bossens, Christophe and {Op de Beeck}, Hans P.},
  year = {2016},
  journal = {Frontiers in Behavioral Neuroscience},
  volume = {10},
  pages = {235},
  issn = {1662-5153},
  doi = {10.3389/fnbeh.2016.00235},
  urldate = {2021-11-17},
  abstract = {The visual system processes visual input in a hierarchical manner in order to extract relevant features that can be used in tasks such as invariant object recognition. Although typically investigated in primates, recent work has shown that rats can be trained in a variety of visual object and shape recognition tasks. These studies did not pinpoint the complexity of the features used by these animals. Many tasks might be solved by using a combination of relatively simple features which tend to be correlated. Alternatively, rats might extract complex features or feature combinations which are nonlinear with respect to those simple features. In the present study, we address this question by starting from a small stimulus set for which one stimulus-response mapping involves a simple linear feature to solve the task while another mapping needs a well-defined nonlinear combination of simpler features related to shape symmetry. We verified computationally that the nonlinear task cannot be trivially solved by a simple V1-model. We show how rats are able to solve the linear feature task but are unable to acquire the nonlinear feature. In contrast, humans are able to use the nonlinear feature and are even faster in uncovering this solution as compared to the linear feature. The implications for the computational capabilities of the rat visual system are discussed.},
  file = {/Users/thomasgorman/OneDrive - Indiana University/resources/Zotero/Bossens_Op de Beeck_2016_Linear and Non-Linear Visual Feature Learning in Rat and Humans.pdf}
}

@article{bottNonmonotonicExtrapolationFunction2004,
  title = {Nonmonotonic {{Extrapolation}} in {{Function Learning}}},
  author = {Bott, Lewis and Heit, Evan},
  year = {2004},
  journal = {Journal of Experimental Psychology: Learning, Memory, and Cognition},
  volume = {30},
  pages = {38--50},
  abstract = {This article reports the results of an experiment addressing extrapolation in function learning, in particular the issue of whether participants can extrapolate in a nonmonotonic manner. Existing models of function learning, including the extrapolation association model of function learning (EXAM; E. L. DeLosh, J. R. Busemeyer, \& M. A. McDaniel, 1997), cannot account for this type of extrapolation pattern. We present the results of an experiment in which participants were shown a series of paired stimulus\textendash response magnitudes where the relationship between these 2 dimensions conformed to a cyclic function. Participants were shown to extrapolate from these training data in a nonmonotonic way, contrary to predictions from EXAM. A new model of function learning is presented, which predicts responses more accurately than EXAM.},
  file = {/Users/thomasgorman/Documents/Zotero_Markdown/bottNonmonotonicExtrapolationFunction2004-zotero.md;/Users/thomasgorman/Downloads/bottNonmonotonicExtrapolationFunction2004-zotero.md;/Users/thomasgorman/Downloads/bottNonmonotonicExtrapolationFunction2004.md;/Users/thomasgorman/OneDrive - Indiana University/resources/Zotero/Bott et al_2004_Nonmonotonic Extrapolation in Function Learning.pdf;/Users/thomasgorman/Zotero/storage/98NPAPAL/summary.html}
}

@phdthesis{bottPriorKnowledgeStatistical2001,
  title = {Prior {{Knowledge}} and {{Statistical Models}} of {{Learning}}},
  author = {Bott, Lewis Andrew},
  year = {2001},
  abstract = {The research reported here describes the effects of prior knowledge on how people form categories and learn continuous mappings. Chapter 2 is a review of the past research on knowledge effects in the statistical and psychological literature. Chapter 3 presents simulations of a set of experiments carried out by Heit and Bott (2000) into how knowledge is selected in a category learning task. The model was shown to account for the results of Heit and Bott and generate several new predictions concerning blocking effects with the use of prior knowledge:. ;; 'However, empirical testing of these predictions failed to demonstrate these effects. Chapter 4 describes work testing Delosh, McDaniel and Busemeyer's (1997) model of function learning, the Extrapolation Associative Learning Model (EXAM). Experiments were carried out demonstrating that a model that assumes only linear extrapolation, such as EXAM, is inadequate as a generic model of function learning. An alternative model to EXAM is presented which is constructed of several components, each module applying different quantities of prior knowledge to the task. Chapter 5 presents experiments investigating the extent to which participants abstract and apply functions in transfer-tasks. The results demonstrate that models of function learning must be able to restrict their range of allowable solutions in psychologically plausible ways Figure 2.1 Four GCM models run with different c parameter values ................. 21 Figure 2.2 Example data set from the high-noise condition ............................... 25 Figure 3.1 Results from. Heit and Bott (2000) ..............................................:.... 68 Figure 3.2 Illustration of Baywatch model ....................................................... 72 Figure 3.3 Alternative version of Baywatch ..................................................... 76 Figure 3.4 Simulation of Heit and Bott (2000) ................................................. 80 Figure 3.5 Predictions with and without Prior Knowledge nodes ..................... 82 Figure Results of the simulations involving extra PK nodes ....................... 85 Fi ure 3.7 Predictions from training with incongruent features ........................ 88 Figure Illustration of Baywatch model with strong hint ............................. 90 Figure 3.9 Predictions from training flexible, pre-programmed weights........... 91 Figure 3.10 Results from Experiment 1 ........................................................ 103 Figure 3.11 Results from Heit (1998), illustrating the effects of length of presentation time on responses ...................................................................... 110 Figure 3.12 Results from experiment 2 ......................................................... 113 Figure 4.1. Participants' and models' responses to stimuli generated from an exponential curve (Waganaar \&'Sagaria, 1975) ................................ 127 Figure 4.2 Extrapolation mechanism of EXAM ............................................. 134 Figure 4 Scaled-down version of the bars that were used to represent input and output magnitudes ......................................................................................... 136 Figure 4.4 EXAM's predictions for the stimuli used in Experiment 1, as a function of X ................................................................................................. 13 8 Figure 4.5 Stimuli for Experiment 1 .............................................................. 141 iv  List of Figures Figure Mean absolute error as a function of Block and Stimulus Type. ... 145 Figure Mean absolute error as a function of Stimulus Type and Stimulus magnitude ..................................................................................................... 146 Figure 4.8 Mean deviation from linear extrapolation as a function of extrapolation region and stimulus set ............................................................. 146 Figure 4.9 Response magnitudes for EXAM, the linear interpolation model, and participants' mean responses at asymptote (Triangle condition) .................... 150 Figure 4.10 EXAM's responses to the training data as function of X .............. 154 Figure 4 . 11 Training and testing values for Experiment 2 ............................. 156 Figure 4.12 Mean Absolute Error as a function of Block and Participant for Experiment 2 ................................................................................................. 159 Figure 4.13 Participant l's responses to the training and testing data ............. 160 Figure 4.14 Participant 4's responses to the training and testing data ............. 162 Figure 4.15 Participant 7's responses to the training and testing data ............. 163 Figure 4.16 Participant 8's responses to the training and testing data ............. 164 Figure 4.17 Participant 12's responses to the training and testing data . .......... 165 figure 4.18 Distribution of a values based on 26 participants with 8 scores each from Experiment 3........................................................................................ 192 Figure 5.1 Stimulus and response magnitudes for three, between-subject Stage 1 conditions, that is lower quadratic, positive and negative linear functions...... 206 Figure 5.2 Response predictions from the ALM after being trained on the lower quadratic stimuli (see Figure 5.1) .................................................................. 209 Figure 5.3 Mean absolute error of ALM responses from target responses on Stage 2 .......................................................................................................... 210 V  List of Figures Figure 5.4 Learning curves for the functions learnt in Stage 1; either a Quadratic curve, Positive line or Negative line .............................................................. 215 Figure Learning curves for Stage 2. The three lines refer to the functions learnt by participants in Stage 1 ..................................................................... 215 Figure 5.6 MAE as a function of Block and function type for Stage 1, trimmed participants .................................................................................................... 217 Figure 5.7 MAE as a function of Block and Stage 1 function type for Stage 2, trimmed participants ...................................................................................... 218 Figure Training stimuli for Stage 1 and Stage 2. Also shown is EXAM's extrapolation pattern based on the Stage 2 training values ............................. 222 Figure Response magnitudes as a function of Stage and type of curve learnt in Stage 1...............................................................................},
  langid = {english},
  file = {/Users/thomasgorman/Documents/Zotero_Markdown/bottPriorKnowledgeStatistical2001-zotero.md;/Users/thomasgorman/Downloads/bott_prior_2001-zotero.md;/Users/thomasgorman/Downloads/bott_prior_2001.md;/Users/thomasgorman/Downloads/bottPriorKnowledgeStatistical2001.md;/Users/thomasgorman/OneDrive - Indiana University/resources/Zotero/Bott_2001_Prior Knowledge and Statistical Models of Learning.pdf}
}

@article{bowmanAgeEffectsCategory2021,
  title = {Age Effects on Category Learning, Categorical Perception, and Generalization},
  author = {Bowman, Caitlin R. and Ashby, Stefania R. and Zeithamova, Dagmar},
  year = {2021},
  month = nov,
  journal = {Memory},
  volume = {0},
  number = {0},
  pages = {1--18},
  publisher = {{Routledge}},
  issn = {0965-8211},
  doi = {10.1080/09658211.2021.2003818},
  urldate = {2021-12-08},
  abstract = {Age deficits in memory for individual episodes are well established. Less is known about how age affects another key memory function: the ability to form new conceptual knowledge. Here we studied age differences in concept formation in a category-learning paradigm with face-blend stimuli, using several metrics: direct learning of category members presented during training, generalisation of category labels to new examples, and shifts in perceived similarity between category members that often follow category learning. We found that older adults were impaired in direct learning of training examples, but that there was no significant age deficit in generalisation once we accounted for the deficit in direct learning. We also found that category learning affected the perceived similarity between members of the same versus opposing categories, and age did not significantly moderate this effect. Lastly, we compared traditional category learning to categorisation after a learning task in which a category label (shared last name) was presented alongside stimulus-specific information (unique first names that individuated category members). We found that simultaneously learning stimulus-specific and category information resulted in decreased category learning, and that this decrement was apparent in both age groups.},
  pmid = {34762020},
  keywords = {Aging,associative memory,categorical perception,category learning,generalisation},
  file = {/Users/thomasgorman/Zotero/storage/IMP4ENNF/09658211.2021.html}
}

@article{braithwaiteEffectsVariationPrior2015,
  title = {Effects of {{Variation}} and {{Prior Knowledge}} on {{Abstract Concept Learning}}},
  author = {Braithwaite, David W. and Goldstone, Robert L.},
  year = {2015},
  month = jul,
  journal = {Cognition and Instruction},
  volume = {33},
  number = {3},
  pages = {226--256},
  issn = {0737-0008, 1532-690X},
  doi = {10.1080/07370008.2015.1067215},
  urldate = {2017-09-07},
  langid = {english},
  keywords = {Benefit of Variability,Conceptual,Empirical,Generalization,Harm from Variability,Model,Prior Knowledge,Schema,Variability,Varied Manipulation},
  file = {/Users/thomasgorman/Zotero/storage/4UTT6HBC/Effects of Variation and Prior Knowledge on Abstract Concept Learning.pdf}
}

@article{braunMotorTaskVariation2009,
  title = {Motor {{Task Variation Induces Structural Learning}}},
  author = {Braun, Daniel A. and Aertsen, Ad and Wolpert, Daniel M. and Mehring, Carsten},
  year = {2009},
  month = feb,
  journal = {Current Biology},
  volume = {19},
  number = {4},
  pages = {352--357},
  issn = {09609822},
  doi = {10.1016/j.cub.2009.01.036},
  urldate = {2017-09-07},
  langid = {english},
  file = {/Users/thomasgorman/Zotero/storage/BNQRQ9NZ/Braun et al. - 2009 - Motor Task Variation Induces Structural Learning.pdf}
}

@article{brehmerEffectsFunctionForm1974,
  title = {Effects of Function Form and Cue Validity on the Subjects' Hypotheses in Probabilistic Inference Tasks},
  author = {Brehmer, Berndt and Kuylenstierna, Jan and Liljergren, Jan-Erik},
  year = {1974},
  month = jun,
  journal = {Organizational Behavior and Human Performance},
  volume = {11},
  number = {3},
  pages = {338--354},
  issn = {0030-5073},
  doi = {10.1016/0030-5073(74)90024-5},
  urldate = {2022-05-20},
  abstract = {The effects of the form of the function relating criterion values to cue values and of the validity of the cue upon the subjects' hypotheses in probabilistic inference tasks were studied in a factorial experiment with two levels of cue validity (rCE = .45, and rCE = .90), and four function forms (positive linear, negative linear, inversely U-shaped, and U-shaped). The results were consistent with a hypothesis sampling theory, and the relative frequencies of four basic hypotheses could be predicted from earlier results with respect to the relative strengths of those hypotheses. The results also showed that the correlation between the hypotheses stated by the subjects and the rules extracted from their judgments by means of polynomial regression was higher for linear hypotheses than for nonlinear hypotheses. The correlation was quite low, however, also for linear hypotheses.},
  langid = {english},
  file = {/Users/thomasgorman/Documents/Zotero_Markdown/brehmer_effects_1974-zotero.md;/Users/thomasgorman/Zotero/storage/PGQ3S8SN/0030507374900245.html}
}

@article{brehmerHypothesesRelationsScaled1974,
  title = {Hypotheses about Relations between Scaled Variables in the Learning of Probabilistic Inference Tasks},
  author = {Brehmer, Berndt},
  year = {1974},
  month = feb,
  journal = {Organizational Behavior and Human Performance},
  volume = {11},
  number = {1},
  pages = {1--27},
  issn = {0030-5073},
  doi = {10.1016/0030-5073(74)90002-6},
  urldate = {2022-05-20},
  abstract = {A hypothesis-testing model was developed to account for the effects of the form of the function relating criterion to cue values in cue probability learning (CPL) tasks. This model is built on the assumption that the subjects have a hierarchy of hypotheses about functional relations between scaled variables, and that they sample hypotheses from the hierarchy according to their strength when learning a CPL task. The model was tested in five experiments. The first three experiments were designed to measure the relative strengths of four specified hypotheses about functional relations by means of estimation and production, and showed that a positive linear function is more available than a negative linear function, which, in turn, is more available than an inversely U-shaped function. A U-shaped function is the least available function. The results of the fourth experiment, which compared rates of learning for the four functions, showed that the relative rates of learning were consistent with what could be predicted on the basis of the relative strengths of the four hypotheses. In the fift experiment, finally, the subjects' hypothesis testing behavior was studied by means of verbal reports. The results of this experiment showed that the subjects tested the hypotheses in the order predicted by the hierarchy.},
  langid = {english},
  file = {/Users/thomasgorman/Documents/Zotero_Markdown/brehmer_hypotheses_1974-zotero.md;/Users/thomasgorman/Zotero/storage/FZJNXQ7N/0030507374900026.html}
}

@article{briscoeConceptualComplexityBias2011,
  title = {Conceptual Complexity and the Bias/Variance Tradeoff},
  author = {Briscoe, Erica and Feldman, Jacob},
  year = {2011},
  month = jan,
  journal = {Cognition},
  volume = {118},
  number = {1},
  pages = {2--16},
  issn = {00100277},
  doi = {10.1016/j.cognition.2010.10.004},
  urldate = {2020-09-06},
  abstract = {In this paper we propose that the conventional dichotomy between exemplar-based and prototype-based models of concept learning is helpfully viewed as an instance of what is known in the statistical learning literature as the bias/variance tradeoff. The bias/variance tradeoff can be thought of as a sliding scale that modulates how closely any learning procedure adheres to its training data. At one end of the scale (high variance), models can entertain very complex hypotheses, allowing them to fit a wide variety of data very closely\textemdash but as a result can generalize poorly, a phenomenon called overfitting. At the other end of the scale (high bias), models make relatively simple and inflexible assumptions, and as a result may fit the data poorly, called underfitting. Exemplar and prototype models of category formation are at opposite ends of this scale: prototype models are highly biased, in that they assume a simple, standard conceptual form (the prototype), while exemplar models have very little bias but high variance, allowing them to fit virtually any combination of training data. We investigated human learners' position on this spectrum by confronting them with category structures at variable levels of intrinsic complexity, ranging from simple prototype-like categories to much more complex multimodal ones. The results show that human learners adopt an intermediate point on the bias/variance continuum, inconsistent with either of the poles occupied by most conventional approaches. We present a simple model that adjusts (regularizes) the complexity of its hypotheses in order to suit the training data, which fits the experimental data better than representative exemplar and prototype models.},
  langid = {english},
  keywords = {flag stimuli},
  file = {/Users/thomasgorman/Zotero/storage/R3PQVJVR/Briscoe and Feldman - 2011 - Conceptual complexity and the biasvariance tradeo.pdf}
}

@article{brouwersRoleCueUtilisation2017,
  title = {The Role of Cue Utilisation in Reducing the Workload in a Train Control Task},
  author = {Brouwers, Sue and Wiggins, Mark W. and Griffin, Barbara and Helton, William S. and O'Hare, David},
  year = {2017},
  month = nov,
  journal = {Ergonomics},
  volume = {60},
  number = {11},
  pages = {1500--1515},
  issn = {0014-0139, 1366-5847},
  doi = {10.1080/00140139.2017.1330494},
  urldate = {2021-06-27},
  abstract = {Skilled performance has been characterised, in part, by the capacity to accurately identify and respond to patterns as cues in the environment. The outcome is a reduction in cognitive load and a greater residual capacity to undertake concurrent tasks. The present study was designed to examine the relationship between cue utilisation and temporal pattern recognition in the context of a simulated, rail control task. Sixty-one university students undertook an assessment of cue utilisation and engaged in a rail control simulation. The appearance and movement of trains followed a consistent but implicit (undisclosed) pattern. Throughout the second half of the rail task, a secondary task was included. The results indicated that participants with relatively higher cue utilisation were more likely to identify the implicit pattern of rail movements, were more accurate and responded more rapidly under increased workload conditions. The results suggest that a propensity to identify patterns as cues may provide an opportunity to reduce cognitive demands, thereby facilitating performance in a novel task. Implications for selection and system design are discussed.},
  langid = {english},
  file = {/Users/thomasgorman/OneDrive - Indiana University/resources/Zotero/Brouwers et al_2017_The role of cue utilisation in reducing the workload in a train control task.pdf}
}

@article{browneRepresentationExtrapolationMultilayer2002,
  title = {Representation and {{Extrapolation}} in {{Multilayer Perceptrons}}},
  author = {Browne, Antony},
  year = {2002},
  month = jul,
  journal = {Neural Computation},
  volume = {14},
  number = {7},
  pages = {1739--1754},
  issn = {0899-7667, 1530-888X},
  doi = {10.1162/08997660260028692},
  urldate = {2021-10-09},
  abstract = {To give an adequate explanation of cognition and perform certain practical tasks, connectionist systems must be able to extrapolate. This work explores the relationship between input representation and extrapolation, using simulations of multilayer perceptrons trained to model the identity function. It has been discovered that representation has a marked effect on extrapolation.},
  langid = {english},
  file = {/Users/thomasgorman/Documents/Zotero_Markdown/browne_representation_2002-zotero.md;/Users/thomasgorman/OneDrive - Indiana University/resources/Zotero/Browne_2002_Representation and Extrapolation in Multilayer Perceptrons.pdf}
}

@article{brownUnderestimationLinearFunction2017,
  title = {Underestimation in Linear Function Learning: {{Anchoring}} to Zero or x-y Similarity?},
  shorttitle = {Underestimation in Linear Function Learning},
  author = {Brown, Mark A. and Lacroix, Guy},
  year = {2017},
  month = dec,
  journal = {Canadian Journal of Experimental Psychology/Revue canadienne de psychologie exp\'erimentale},
  volume = {71},
  number = {4},
  pages = {274--282},
  issn = {1878-7290, 1196-1961},
  doi = {10.1037/cep0000129},
  urldate = {2021-05-20},
  abstract = {Function learning research has shown that people tend to underestimate positive linear functions when extrapolating Y for X-values below the training range. Kwantes and Neal (2006) proposed that this underestimation occurs because people anchor their Y-estimates at zero. It is equally plausible, however, that people are biased to make Y-estimates similar to the presented X-value. To differentiate these 2 explanations, 135 participants extrapolated positive linear functions with a y-intercept either greater than or less than zero. In line with the anchoring hypothesis, participants underestimated in the lower extrapolation region when the y-intercept was positive, but overestimated when the y-intercept was negative. These results are consistent with a version of the extrapolation association model (EXAM; Delosh, Busemeyer, \& McDaniel, 1997), which proposes that people interpolate linearly between the training exemplars and zero in the lower extrapolation region.},
  langid = {english},
  file = {/Users/thomasgorman/Documents/Zotero_Markdown/brown_underestimation_2017-zotero.md;/Users/thomasgorman/OneDrive - Indiana University/resources/Zotero/Brown_Lacroix_2017_Underestimation in linear function learning.pdf}
}

@article{burknerBrmsPackageBayesian2017,
  title = {Brms: {{An R Package}} for {{Bayesian Multilevel Models Using Stan}}},
  shorttitle = {Brms},
  author = {B{\"u}rkner, Paul-Christian},
  year = {2017},
  month = aug,
  journal = {Journal of Statistical Software},
  volume = {80},
  pages = {1--28},
  issn = {1548-7660},
  doi = {10.18637/jss.v080.i01},
  urldate = {2023-08-15},
  abstract = {The brms package implements Bayesian multilevel models in R using the probabilistic programming language Stan. A wide range of distributions and link functions are supported, allowing users to fit  -  among others  -  linear, robust linear, binomial, Poisson, survival, ordinal, zero-inflated, hurdle, and even non-linear models all in a multilevel context. Further modeling options include autocorrelation of the response variable, user defined covariance structures, censored data, as well as meta-analytic standard errors. Prior specifications are flexible and explicitly encourage users to apply prior distributions that actually reflect their beliefs. In addition, model fit can easily be assessed and compared with the Watanabe-Akaike information criterion and leave-one-out cross-validation.},
  copyright = {Copyright (c) 2017 Paul-Christian B\"urkner},
  langid = {english},
  keywords = {Bayesian inference,MCMC,multilevel model,ordinal data,R,Stan},
  file = {/Users/thomasgorman/Library/CloudStorage/OneDrive-IndianaUniversity/Resources/Zotero/Bürkner_2017_brms.pdf}
}

@article{busemeyerAbstractionInterveningConcepts1997,
  title = {The {{Abstraction}} of {{Intervening Concepts}} from {{Experience}} with {{Multiple Input}}\textendash{{Multiple Output Causal Environments}}},
  author = {Busemeyer, Jerome and McDaniel, Mark A. and Byun, Eunhee},
  year = {1997},
  month = feb,
  journal = {Cognitive Psychology},
  volume = {32},
  number = {1},
  pages = {1--48},
  issn = {00100285},
  doi = {10.1006/cogp.1997.0644},
  urldate = {2020-05-29},
  abstract = {The purpose of this article is threefold: (a) introduce a new paradigm for investigating how intervening concepts are learned, (b) report four new experiments that provide converging evidence for the acquisition of intervening concepts, and (c) propose a simple associative learning mechanism to account for the results. The new paradigm utilizes a stimulus\textendash response\textendash feedback task in which subjects learn trial by trial how a multivariate set of inputs maps into a multivariate set of outputs. The first two experiments use evidence based on a principal component analysis to replicate the finding that intervening-concept learning occurs spontaneously, but only in environments that contain an intervening factor. The next experiment provides a second converging line of evidence for this conclusion by showing that subjects can use an intervening concept to make accurate inferences to a new fourth output during a transfer test. The last experiment provides a third line of evidence by showing that subjects can use an intervening concept to make accurate inferences from a new fourth input. The results are explained by a hidden-unit connectionist learning mechanism that includes both accuracy and parsimony as learning objectives},
  langid = {english},
  file = {/Users/thomasgorman/Documents/Zotero_Markdown/busemeyerAbstractionInterveningConcepts1997-zotero.md;/Users/thomasgorman/Zotero/storage/K845V7D8/Busemeyer et al. - 1997 - The Abstraction of Intervening Concepts from Exper.pdf}
}

@article{busemeyerCueCompetitionEffects1993,
  title = {Cue {{Competition Effects}}: {{Empirical Tests}} of {{Adaptive Network Learning Models}}},
  shorttitle = {Cue {{Competition Effects}}},
  author = {Busemeyer, Jerome R. and Myung, In Jae and McDaniel, Mark A.},
  year = {1993},
  month = may,
  journal = {Psychological Science},
  volume = {4},
  number = {3},
  pages = {190--195},
  publisher = {{SAGE Publications Inc}},
  issn = {0956-7976},
  doi = {10.1111/j.1467-9280.1993.tb00486.x},
  urldate = {2021-06-27},
  abstract = {The ability to predict future consequences on the basis of previous experience with the current set of environmental cues is one of the most fundamental of all cognitive processes. This study investigated how the validity of one cue influences the effectiveness of another cue for predicting a criterion. The results demonstrate a cue competition effect?increasing the validity of one cue decreased the effectiveness of another cue in a linear prediction task, even though the two cues were statistically independent.},
  file = {/Users/thomasgorman/OneDrive - Indiana University/resources/Zotero/Busemeyer et al_1993_Cue Competition Effects2.pdf}
}

@article{busemeyerCueCompetitionEffects1993a,
  title = {Cue {{Competition Effects}}: {{Theoretical Implications}} for {{Adaptive Network Learning Models}}},
  shorttitle = {Cue {{Competition Effects}}},
  author = {Busemeyer, Jerome R. and Jae Myung, In and McDaniel, Mark A.},
  year = {1993},
  month = may,
  journal = {Psychological Science},
  volume = {4},
  number = {3},
  pages = {196--202},
  publisher = {{SAGE Publications Inc}},
  issn = {0956-7976},
  doi = {10.1111/j.1467-9280.1993.tb00487.x},
  urldate = {2021-06-27},
  abstract = {A feature-free method for testing adaptive network learning models is presented. The test is based on a property called the mean matching law, a. property shared by many adaptive network models of learning. As an application of this method, we prove that cue competition effects obtained with statistically independent cues cannot be explained by many previous adaptive network learning models, including those based on the delta learning rule. These results point to the need to incorporate competitive learning properties into adaptive network learning models.},
  file = {/Users/thomasgorman/OneDrive - Indiana University/resources/Zotero/Busemeyer et al_1993_Cue Competition Effects.pdf}
}

@incollection{busemeyerLearningFunctionalRelations1997,
  title = {Learning {{Functional Relations Based}} on {{Experience}} with {{Input-output Pairs}} by {{Humans}} and {{Artificial Neural Networks}}},
  booktitle = {Knowledge {{Concepts}} and {{Categories}}},
  author = {Busemeyer, Jerome R. and Eunhee, Byun and DeLosh, Edward L and McDaniel, Mark A.},
  year = {1997},
  publisher = {{Psychology Press}},
  abstract = {I. DECISIONS, PREDICTIONS, AND ABSTRACT CONCEPTS Before making any serious decision, we normally try to anticipate how the effects of our action will vary depending on the action taken. For example, before an anaesthetist can decide the amount of anaesthetic to administer to a patient, she needs to predict how the analgesic effect will vary as a function of the amount injected. Before a father can decide the amount of money to invest in his son's college education, he needs to predict how the return will vary as a function of the size of the investment. The point is that prediction is essential to decision making. Predictions are thought to be based on knowledge of the functional relation between the strength of a cause and the magnitude of an effect. For this reason, there is a large body of empirical research by decision scientists investigating how people learn functional relations (Slovic\& Lichtenstein 1971, Klayman 1988). Much of this research, however, has been not been synthesized and integrated into coherent theory, and so this literature remains disconnected from mainstream cognitive psychology. From a cognitive perspective, functions can be viewed as abstract concepts that summarize cause-effect relationships. Cognitive psychologists have made great progress developing theories of how people learn abstract concepts (see Estes 1994). However, most of this theoretical effort has been restricted to one simple type of concept learning task called categorization. It is unclear whether or not theories of category learning can be extended for application to function leerning. The purpose of this chapter is to develop a concept learning model that can account for results from both categorization and function learning tasks. The remainder of the chapter is organized as follows: Section II discusses similarities and differences between category- and function-learning tasks, Section III synthesizes some basic findings on function-learning, Section IV describes an artificial neural network model of category learning and extends this model to function learning, and Section V shows how the extended model reproduces the basic findings from function learning.},
  isbn = {978-0-203-76541-8},
  file = {/Users/thomasgorman/Documents/Zotero_Markdown/busemeyerLearningFunctionalRelations1997-zotero.md;/Users/thomasgorman/Downloads/busemeyer_learning_1997-zotero.md;/Users/thomasgorman/Downloads/busemeyer_learning_1997.md;/Users/thomasgorman/Downloads/busemeyerLearningFunctionalRelations1997.md;/Users/thomasgorman/OneDrive - Indiana University/resources/Zotero/Busemeyer et al_1997_Learning Functional Relations Based on Experience with Input-output Pairs by.pdf}
}

@article{busemeyerModelComparisonsModel2000,
  title = {Model {{Comparisons}} and {{Model Selections Based}} on {{Generalization Criterion Methodology}}},
  author = {Busemeyer, Jerome R and Wang, Yi-Min},
  year = {2000},
  month = mar,
  journal = {Journal of Mathematical Psychology},
  volume = {44},
  number = {1},
  pages = {171--189},
  issn = {00222496},
  doi = {10.1006/jmps.1999.1282},
  urldate = {2021-07-06},
  langid = {english},
  file = {/Users/thomasgorman/OneDrive - Indiana University/resources/Zotero/Busemeyer_Wang_2000_Model Comparisons and Model Selections Based on Generalization Criterion.pdf}
}

@book{busemeyerOxfordHandbookComputational2015,
  title = {The {{Oxford}} Handbook of Computational and Mathematical Psychology},
  editor = {Busemeyer, Jerome R.},
  year = {2015},
  series = {Oxford Library of Psychology},
  publisher = {{Oxford University Press}},
  address = {{Oxford ; New York}},
  isbn = {978-0-19-995799-6},
  langid = {english},
  lccn = {BF311 .O945 2015},
  keywords = {Cognition,Cognitive science,Mathematical models,Psychology,Psychometrics},
  file = {/Users/thomasgorman/Documents/Zotero_Markdown/busemeyer_oxford_2015-zotero.md;/Users/thomasgorman/OneDrive - Indiana University/resources/Zotero/Busemeyer_2015_The Oxford handbook of computational and mathematical psychology.pdf}
}

@article{busemeyerResourceAllocationDecision1987,
  title = {Resource Allocation Decision Making in an Uncertain Environment},
  author = {Busemeyer, Jerome R. and Myung, In Jae},
  year = {1987},
  month = oct,
  journal = {Acta Psychologica},
  volume = {66},
  number = {1},
  pages = {1--19},
  issn = {0001-6918},
  doi = {10.1016/0001-6918(87)90015-1},
  urldate = {2020-08-16},
  abstract = {This experiment investigated how individuals learn to allocate limited resources across competing activities in order to maximize their objective when the form of the objective function is uncertain. On each of 25 trials, subjects selected an allocation policy and received a corresponding profit. The objective function that was used to assign profits to allocations was unknown initially and was learned through trial by trial outcome feedback. A total of 144 subjects were randomly assigned to nine groups constructed from a 3 (objective function form) by 3 (amount of error variability) factorial design. Several measures of learning were analyzed including (a) the distance between the current and optimal allocation policy as a function of training, (b) the magnitude of change in allocation as a function of past profits, and (c) the direction of change in allocations as a function of the direction of change in past profits. The results provide evidence for an integrated approach to learning \textemdash{} a functional learning process based on global information about the shape of the objective function and a hill-climbing learning process based on local information about trial to trial improvements in profit.},
  langid = {english},
  keywords = {Function Learning,Global vs. Local Search,Search Learning},
  file = {/Users/thomasgorman/Documents/Zotero_Markdown/busemeyer_resource_1987-zotero.md;/Users/thomasgorman/Zotero/storage/DQ6AZX7F/Busemeyer and Myung - 1987 - Resource allocation decision making in an uncertai.pdf;/Users/thomasgorman/Zotero/storage/B3UA57IM/0001691887900151.html}
}

@phdthesis{byunInteractionPriorKnowledge1995,
  title = {Interaction between Prior Knowledge and Type of Nonlinear Relationship on Function Learning},
  author = {Byun, Eunhee},
  year = {1995},
  abstract = {The purpose of this thesis was to examine subjects' prediction patterns during training and during interpolation and extrapolation when subjects learned a function with different degrees of correspondence to prior knowledge. Experiments la and lb showed that linear functions were easier to learn than power and other monotonic nonlinear functions. Experiment 2 indicated that prior knowledge interacted with function form during training. Experiment 3 replicated Experiment 2 but with an extrapolation test. one striking finding was subjects' tendency to fall back on prior knowledge when they made extrapolations even after they learned the training function very well. Finally, Experiment 4 examined whether or not subjects test hypotheses and found evidence for abrupt changes in hypotheses from trial to trial. None of the current major models accounts for the effects of prior knowledge on extrapolation adequately. INTRODUCTION ............................................... 1 Previous Studies ofFunction Learning...................4 Function F o r m ...................................... 4 Superiority of Linear Function ................... 7 Prior Knowledge......................................8 Major Learning Models.................................10 The Hypothesis Sampling Model ................. 13 The Adaptive Regression Model . 14 The ALCOVE Model...................................16 The EXAM Model ........................ 19 Overview of Experiments ............................ 20 EXPERIMENT 1 A ............................................. 27 M e t h o d ..................................................30 Subjects........................................... 30 D e s i g n .................................... 31 S t i m u l i ........................................... 31 Procedure...................................... 32 R e s u l t s ............................................... 33 Training Performance ............................ 35 Transfer Performance ............................ 39 Discussion............................................. 42 EXPERIMENT I B ............................................. 53 Method................................................. 54 Subjects........................................... 54 Design............................................. 54 S t i m u l i ........................................... 54 P r o c e d u r e ......................................... 56 R e s u l t s ............................................... 56 Training Performance ............................ 56 Transfer Performance ............................ 60 Discussion},
  langid = {english},
  file = {/Users/thomasgorman/Documents/Zotero_Markdown/byun_interaction_1995-zotero.md;/Users/thomasgorman/OneDrive - Indiana University/resources/Zotero/Byun_Interaction between prior knowledge and type of nonlinear relationship on.pdf}
}

@article{caddickMotivatedReasoningExploreExploit2021,
  title = {Motivated {{Reasoning}} in an {{Explore-Exploit Task}}},
  author = {Caddick, Zachary A. and Rottman, Benjamin M.},
  year = {2021},
  journal = {Cognitive Science},
  volume = {45},
  number = {8},
  pages = {e13018},
  issn = {1551-6709},
  doi = {10.1111/cogs.13018},
  urldate = {2021-10-09},
  abstract = {The current research investigates how prior preferences affect causal learning. Participants were tasked with repeatedly choosing policies (e.g., increase vs. decrease border security funding) in order to maximize the economic output of an imaginary country and inferred the influence of the policies on the economy. The task was challenging and ambiguous, allowing participants to interpret the relations between the policies and the economy in multiple ways. In three studies, we found evidence of motivated reasoning despite financial incentives for accuracy. For example, participants who believed that border security funding should be increased were more likely to conclude that increasing border security funding actually caused a better economy in the task. In Study 2, we hypothesized that having neutral preferences (e.g., preferring neither increased nor decreased spending on border security) would lead to more accurate assessments overall, compared to having a strong initial preference; however, we did not find evidence for such an effect. In Study 3, we tested whether providing participants with possible functional forms of the policies (e.g., the policy takes some time to work or initially has a negative influence but eventually a positive influence) would lead to a smaller influence of motivated reasoning but found little evidence for this effect. This research advances the field of causal learning by studying the role of prior preferences, and in doing so, integrates the fields of causal learning and motivated reasoning using a novel explore-exploit task.},
  langid = {english},
  keywords = {Causal learning,Dynamic,Economic decision making,Explore-Exploit,Motivated reasoning},
  file = {/Users/thomasgorman/Documents/Zotero_Markdown/caddick_motivated_2021-zotero.md;/Users/thomasgorman/OneDrive - Indiana University/resources/Zotero/Caddick_Rottman_2021_Motivated Reasoning in an Explore-Exploit Task.pdf;/Users/thomasgorman/Zotero/storage/G5UHE44F/cogs.html}
}

@article{candelieriModellingHumanActive2020,
  title = {Modelling Human Active Search in Optimizing Black-Box Functions},
  author = {Candelieri, Antonio and Perego, Riccardo and Giordani, Ilaria and Ponti, Andrea and Archetti, Francesco},
  year = {2020},
  month = dec,
  journal = {Soft Computing},
  volume = {24},
  number = {23},
  pages = {17771--17785},
  issn = {1433-7479},
  doi = {10.1007/s00500-020-05398-2},
  urldate = {2021-10-04},
  abstract = {Modelling human function learning has been the subject of intense research in cognitive sciences. The topic is relevant in black-box optimization where information about the objective and/or constraints is not available and must be learned through function evaluations. In this paper, we focus on the relation between the behaviour of humans searching for the maximum and the probabilistic model used in Bayesian optimization. As surrogate models of the unknown function, both Gaussian processes and random forest have been considered: the Bayesian learning paradigm is central in the development of active learning approaches balancing exploration/exploitation in uncertain conditions towards effective generalization in large decision spaces. In this paper, we analyse experimentally how Bayesian optimization compares to humans searching for the maximum of an unknown 2D function. A set of controlled experiments with 60 subjects, using both surrogate models, confirm that Bayesian optimization provides a general model to represent individual patterns of active learning in humans.},
  langid = {english},
  file = {/Users/thomasgorman/OneDrive - Indiana University/resources/Zotero/Candelieri et al_2020_Modelling human active search in optimizing black-box functions.pdf}
}

@article{candelieriUncertaintyQuantificationExplorationexploitation2021,
  title = {Uncertainty Quantification and Exploration-Exploitation Trade-off in Humans},
  author = {Candelieri, Antonio and Ponti, Andrea and Archetti, Francesco},
  year = {2021},
  month = feb,
  journal = {arXiv:2102.07647 [cs]},
  eprint = {2102.07647},
  primaryclass = {cs},
  urldate = {2021-10-04},
  abstract = {The main objective of this paper is to outline a theoretical framework to analyse how humans' decision-making strategies under uncertainty manage the trade-off between information gathering (exploration) and reward seeking (exploitation). A key observation, motivating this line of research, is the awareness that human learners are amazingly fast and effective at adapting to unfamiliar environments and incorporating upcoming knowledge: this is an intriguing behaviour for cognitive sciences as well as an important challenge for Machine Learning. The target problem considered is active learning in a black-box optimization task and more specifically how the exploration/exploitation dilemma can be modelled within Gaussian Process based Bayesian Optimization framework, which is in turn based on uncertainty quantification. The main contribution is to analyse humans' decisions with respect to Pareto rationality where the two objectives are improvement expected and uncertainty quantification. According to this Pareto rationality model, if a decision set contains a Pareto efficient (dominant) strategy, a rational decision maker should always select the dominant strategy over its dominated alternatives. The distance from the Pareto frontier determines whether a choice is (Pareto) rational (i.e., lays on the frontier) or is associated to "exasperate" exploration. However, since the uncertainty is one of the two objectives defining the Pareto frontier, we have investigated three different uncertainty quantification measures and selected the one resulting more compliant with the Pareto rationality model proposed. The key result is an analytical framework to characterize how deviations from "rationality" depend on uncertainty quantifications and the evolution of the reward seeking process.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Machine Learning},
  file = {/Users/thomasgorman/Documents/Zotero_Markdown/candelieri_uncertainty_2021-zotero.md;/Users/thomasgorman/OneDrive - Indiana University/resources/Zotero/Candelieri et al_2021_Uncertainty quantification and exploration-exploitation trade-off in humans.pdf;/Users/thomasgorman/Zotero/storage/D52WM2MT/2102.html}
}

@article{caoDevelopmentAutomaticityShortterm2017,
  title = {The Development of Automaticity in Short-Term Memory Search: {{Item-response}} Learning and Category Learning.},
  shorttitle = {The Development of Automaticity in Short-Term Memory Search},
  author = {Cao, Rui and Nosofsky, Robert M. and Shiffrin, Richard M.},
  year = {2017},
  month = may,
  journal = {Journal of Experimental Psychology: Learning, Memory, and Cognition},
  volume = {43},
  number = {5},
  pages = {669--679},
  issn = {1939-1285, 0278-7393},
  doi = {10.1037/xlm0000355},
  urldate = {2019-06-04},
  abstract = {In short-term-memory (STM)-search tasks, observers judge whether a test probe was present in a short list of study items. Here we investigated the long-term learning mechanisms that lead to the highly efficient STM-search performance observed under conditions of consistent-mapping (CM) training, in which targets and foils never switch roles across trials. In item-response learning, subjects learn long-term mappings between individual items and target versus foil responses. In category learning, subjects learn high-level codes corresponding to separate sets of items and learn to attach old versus new responses to these category codes. To distinguish between these 2 forms of learning, we tested subjects in categorized varied mapping (CV) conditions: There were 2 distinct categories of items, but the assignment of categories to target versus foil responses varied across trials. In cases involving arbitrary categories, CV performance closely resembled standard varied-mapping performance without categories and departed dramatically from CM performance, supporting the item-response-learning hypothesis. In cases involving prelearned categories, CV performance resembled CM performance, as long as there was sufficient practice or steps taken to reduce trial-to-trial category-switching costs. This pattern of results supports the category-coding hypothesis for sufficiently well-learned categories. Thus, item-response learning occurs rapidly and is used early in CM training; category learning is much slower but is eventually adopted and is used to increase the efficiency of search beyond that available from item-response learning.},
  langid = {english},
  file = {/Users/thomasgorman/Zotero/storage/227K5E3P/Cao et al. - 2017 - The development of automaticity in short-term memo.pdf}
}

@article{carrollFunctionalLearningLearning1963,
  title = {Functional {{Learning}}: {{The Learning}} of {{Continuous Functional Mappings Relating Stimulus}} and {{Response Continua}}},
  shorttitle = {Functional {{Learning}}},
  author = {Carroll, J. Douglas},
  year = {1963},
  journal = {ETS Research Bulletin Series},
  volume = {1963},
  number = {2},
  pages = {i-144},
  issn = {2333-8504},
  doi = {10.1002/j.2333-8504.1963.tb00958.x},
  urldate = {2022-05-20},
  abstract = {A general model was proposed in which it was assumed that, in learning situations involving scaled stimuli and responses, subjects will tend to establish continuous functional relations between stimuli and responses. In particular, it was assumed that each subject has available a general ``functional form'' dependent only on certain parameters (pi), and that in learning the subject effectively assigns specific values to these parameters, thus establishing a specific function defining a unique mapping of stimuli into responses. In the specialized case of the model, the more restrictive assumption is made that the general form is constituted of linear combinations of more basic functions, so that the parameters (pi) may be identified with the weights assigned to each of these primitive functions in establishing a particular stimulus-response mapping. This ``specialized'' model was assumed throughout the present study. Three hypotheses were derived from the postulates of the proposed model, and an experimental study was undertaken designed to test these hypotheses, as well as to answer a number of related questions. The hypotheses were: Subjects will reproduce responses which bear a continuous relation to stimuli (according to an index proposed as an operational measure of continuity) even when the stimulus-response pairs they are given to learn are randomly related. A set of stimulus-response connections related by a continuous function will be learned more efficiently than a randomly related set. A secondary hypothesis was that ``simple'' functional relations (defined by few parameters) will be learned more effectively than more ``complex'' functions (defined by a greater number of parameters). Subjects will respond to stimuli to which no response has been explicitly associated in learning by interpolating or extrapolating the functional relation to these stimuli. The experimental paradigm used consisted of a paired associates task involving 26 scaled stimuli (``V'' marks varying along the length of a narrow rectangle), only 15 of which were used in the learning phase of each trial, the remaining 11 being included in the reproduction phase to allow observation of interpolation and extrapolation effects. Six conditions were used, in three of which the response (a vertical mark on a line below the rectangular slot) was related to the stimulus according to a simple continuous function (linear in two cases, quadratic in the third), while in the other three conditions stimuli and responses were randomly related. All three hypotheses outlined above were verified. In addition, an analytic technique utilizing Fisher's method of orthogonal polynomials was applied, enabling determination of which polynomials significantly related to mean responses (averaged over six trials), and of which polynomials exhibited significant trial to trial variation in slope. It was found that the first four orthogonal polynomials were sufficient to account for most of the reliable variance in mean responses. Trial to trial variance was slight, but significantly present, while tending to be somewhat more heavily concentrated in the higher degree polynomials. The residual variance in the means, once significantly fitting polynomials were extracted, was generally non-significant, and no evidence was found that the residuals tended to represent discrete ``correction'' toward the veridical S-R pairings. The data were subjected to an Eckart-Young analysis with a rotation aimed at finding continuous structure. Three factors were found, very nearly identical with the first three orthogonal polynomials, but bearing a slightly closer resemblance to sinusoidal curves of varying frequency. These accounted for about 88\% of the variance in the mean responses, a fact taken as supporting the adequacy of the ``specialized'' model.},
  langid = {english},
  file = {/Users/thomasgorman/Documents/Zotero_Markdown/carrollFunctionalLearningLearning1963-zotero.md;/Users/thomasgorman/OneDrive - Indiana University/resources/Zotero/Carroll_1963_Functional Learning.pdf;/Users/thomasgorman/Zotero/storage/JYNI2TVD/j.2333-8504.1963.tb00958.html}
}

@article{catalanoDistantTransferCoincident1984a,
  title = {Distant {{Transfer}} in {{Coincident Timing}} as a {{Function}} of {{Variability}} of {{Practice}}},
  author = {Catalano, John F. and Kleiner, Brian M.},
  year = {1984},
  month = jun,
  journal = {Perceptual and Motor Skills},
  volume = {58},
  number = {3},
  pages = {851--856},
  issn = {0031-5125, 1558-688X},
  doi = {10.2466/pms.1984.58.3.851},
  urldate = {2019-03-06},
  abstract = {An assumption of Schmidt's schema theory is that variable practice will enhance the development of schema which will in turn facilitate transfer to situations requiring novel responses. This assumption has been supported in research with both open and closed tasks as defined by Poulton. In an open task-study the novel response was within the range of responses previously experienced by subjects. The present study using an open task concerned whether acquisition of novel responses outside the range of the subjects' past experience would be facilitated by variability of practice. The results confirmed schema theory. Subjects with variable practice showed greater transfer to a novel speed outside the range of training than subjects trained under constant practice. A generalization gradient was obtained. Further the novel conditions were from training conditions, the poorer the transfer a p peared to be. However, generalization decrement was attenuated with variable practice.},
  langid = {english},
  keywords = {{$>$}2 conditions,Benefit of Variability,constant control,Empirical,Generalization,Motor,Proximity Confound,Similarity,training hurt by variation,Variability,Varied Manipulation},
  file = {/Users/thomasgorman/Zotero/storage/VPT25NSC/Catalano and Kleiner - 1984 - Distant Transfer in Coincident Timing as a Functio.pdf}
}

@article{chamberlinMemoryRepresentationMotor1992,
  title = {The {{Memory Representation}} of {{Motor Skills}}: {{A Test}} of {{Schema Theory}}},
  shorttitle = {The {{Memory Representation}} of {{Motor Skills}}},
  author = {Chamberlin, Craig J. and Magill, Richard A.},
  year = {1992},
  month = dec,
  journal = {Journal of Motor Behavior},
  volume = {24},
  number = {4},
  pages = {309--319},
  issn = {0022-2895, 1940-1027},
  doi = {10.1080/00222895.1992.9941627},
  urldate = {2019-03-13},
  abstract = {Currently. a popular model for the central representation of motor skills is embodied in Schmidt's schema theory of discrete motor skill learning (Schmidt, 1975).Two experiments are reported here that contrast predictions from a schema abstraction model that is the basis for schema theory with those from an exemplar-based model of motor skill memory representation. In both experiments, subjects performed 300 trials per day of three variations of a three-segment timing task over 4 days of acquisition. The subjects then either immediately transferred to four novel variations of the same task (Experiment 1 ) that varied in degree of similarity to the exemplars experienced during acquisition; or performed two novel and two previously produced exemplars, following 24-h and I-week retention intervals (Experiment 2). The results indicated that novel task transfer was not affected by the degree of similarity between the acquisition and transfer exemplars, and that there was no advantage for a previously produced exemplar over a novel exemplar after either a 24-hr or 1week retention interval. Also, in both experiments, a consistent pattern of bias in responding was noted for novel task transfer and retention. These results are indicative of a schema abstraction model of memory representation for motor skills.},
  langid = {english},
  file = {/Users/thomasgorman/Zotero/storage/RRLGIQ6J/Chamberlin and Magill - 1992 - The Memory Representation of Motor Skills A Test .pdf}
}

@article{chamberlinNoteSchemaExemplar1992,
  title = {A {{Note}} on {{Schema}} and {{Exemplar Approaches}} to {{Motor Skill Representation}} in {{Memory}}},
  author = {Chamberlin, Craig J. and Magill, Richard A.},
  year = {1992},
  month = jun,
  journal = {Journal of Motor Behavior},
  volume = {24},
  number = {2},
  pages = {221--224},
  issn = {0022-2895, 1940-1027},
  doi = {10.1080/00222895.1992.9941617},
  urldate = {2019-03-13},
  abstract = {Given the need for a memory representation of well-learned motor skills, a common assumption in motor behavior is that this knowledge is stored in a central, abstracted form. Active production of motor skills has not been used in experimental designs that have provided empirical support for this view of representation, however. Much of the faith in centralized, abstracted forms of memory representation for motor skills is due to the popularity of Schmidt's schema theory, which has adapted the prototype abstraction model from category learning research to the representation of motor skills. Since schema theory was proposed, however, an alternative view that seriously questions the preeminence of the prototype abstraction model for the central representation of knowledge has arisen in the category learning literature. This particular view, termed the spec\& exemplar model, has led a number of researchers in cognition to develop mixed models that involve both prototypic abstraction and specific exemplar elements. This note. then, identifies what can be perceived as a gap in the empirical knowledge base in motor behavior and discusses the possibility of using the debate about representation for category learning as a stimulus for initiating a similar investigation into the representation of motor skills. A hypothetical specific exemplar model for the memory representation of motor skills is outlined, and possible empirical comparisons between this model and the schema abstraction model are suggested.},
  langid = {english},
  file = {/Users/thomasgorman/Zotero/storage/TH8YPEDV/Chamberlin and Magill - 1992 - A Note on Schema and Exemplar Approaches to Motor .pdf}
}

@article{chandrasekaranIndividualVariabilityCueweighting2010,
  title = {Individual Variability in Cue-Weighting and Lexical Tone Learning},
  author = {Chandrasekaran, Bharath and Sampath, Padma D. and Wong, Patrick C.M.},
  year = {2010},
  month = jul,
  journal = {The Journal of the Acoustical Society of America},
  volume = {128},
  number = {1},
  pages = {456--465},
  publisher = {{Acoustical Society of America}},
  issn = {0001-4966},
  doi = {10.1121/1.3445785},
  urldate = {2022-05-12},
  abstract = {Speech sound patterns can be discerned using multiple acoustic cues. The relative weighting of these cues is known to be language-specific. Speech-sound training in adults induces changes in cue-weighting such that relevant acoustic cues are emphasized. In the current study, the extent to which individual variability in cue weighting contributes to differential success in learning to use foreign sound patterns was examined. Sixteen English-speaking adult participants underwent a sound-to-meaning training paradigm, during which they learned to incorporate Mandarin linguistic pitch contours into words. In addition to cognitive tests, measures of pitch pattern discrimination and identification were collected from all participants. Reaction time data from the discrimination task was subjected to 3-way multidimensional scaling to extract dimensions underlying tone perception. Two dimensions relating to pitch height and pitch direction were found to underlie non-native tone space. Good learners attended more to pitch direction relative to poor learners, before and after training. Training increased the ability to identify and label pitch direction. The results demonstrate that variability in the ability to successfully learn to use pitch in lexical contexts can be explained by pre-training differences in cue-weighting.},
  file = {/Users/thomasgorman/OneDrive - Indiana University/resources/Zotero/Chandrasekaran et al_2010_Individual variability in cue-weighting and lexical tone learning.pdf}
}

@book{chaterProbabilisticMindProspects2008,
  title = {The {{Probabilistic Mind}}:: {{Prospects}} for {{Bayesian}} Cognitive Science},
  shorttitle = {The {{Probabilistic Mind}}},
  editor = {Chater, Nick and Oaksford, Mike},
  year = {2008},
  month = mar,
  publisher = {{Oxford University Press}},
  doi = {10.1093/acprof:oso/9780199216093.001.0001},
  urldate = {2022-06-28},
  isbn = {978-0-19-921609-3},
  langid = {english},
  file = {/Users/thomasgorman/Documents/Zotero_Markdown/chater_probabilistic_2008-zotero.md;/Users/thomasgorman/OneDrive - Indiana University/resources/Zotero/Chater_Oaksford_2008_The Probabilistic Mind.pdf}
}

@article{cheadleAdaptiveGainControl2014,
  title = {Adaptive {{Gain Control}} during {{Human Perceptual Choice}}},
  author = {Cheadle, Samuel and Wyart, Valentin and Tsetsos, Konstantinos and Myers, Nicholas and {de~Gardelle}, Vincent and Herce~Casta{\~n}{\'o}n, Santiago and Summerfield, Christopher},
  year = {2014},
  month = mar,
  journal = {Neuron},
  volume = {81},
  number = {6},
  pages = {1429--1441},
  issn = {0896-6273},
  doi = {10.1016/j.neuron.2014.01.020},
  urldate = {2020-09-07},
  abstract = {Neural systems adapt to background levels of stimulation. Adaptive gain control has been extensively studied in sensory systems but overlooked in decision-theoretic models. Here, we describe evidence for adaptive gain control during the serial integration of decision-relevant information. Human observers judged the average information provided by a rapid stream of visual events (samples). The impact that each sample wielded over choices depended on its consistency with the previous sample, with more consistent or expected samples wielding the greatest influence over choice. This bias was also visible in the encoding of decision information in pupillometric signals and in cortical responses measured with functional neuroimaging. These data can be accounted for with a serial sampling model in which the gain of information processing adapts rapidly to reflect the average of the available evidence.},
  langid = {english},
  file = {/Users/thomasgorman/Zotero/storage/9BIDD7XL/Cheadle et al. - 2014 - Adaptive Gain Control during Human Perceptual Choi.pdf;/Users/thomasgorman/Zotero/storage/2WWMGSBM/S0896627314000518.html}
}

@article{chenHowPeopleLearn2014,
  title = {How People Learn Features in the Absence of Classification Error},
  author = {Chen, Lin and Mo, Lei and Bott, Lewis},
  year = {2014},
  month = nov,
  journal = {Journal of Cognitive Psychology},
  volume = {26},
  number = {8},
  pages = {893--905},
  issn = {2044-5911, 2044-592X},
  doi = {10.1080/20445911.2014.965712},
  urldate = {2021-10-23},
  langid = {english},
  file = {/Users/thomasgorman/OneDrive - Indiana University/resources/Zotero/Chen et al_2014_How people learn features in the absence of classification error.pdf}
}

@article{chrabaszczCrowdsourcingPriorInformation2017,
  title = {Crowdsourcing Prior Information to Improve Study Design and Data Analysis},
  author = {Chrabaszcz, Jeffrey S. and Tidwell, Joe W. and Dougherty, Michael R.},
  year = {2017},
  month = nov,
  journal = {PLOS ONE},
  volume = {12},
  number = {11},
  pages = {e0188246},
  publisher = {{Public Library of Science}},
  issn = {1932-6203},
  doi = {10.1371/journal.pone.0188246},
  urldate = {2022-04-19},
  abstract = {Though Bayesian methods are being used more frequently, many still struggle with the best method for setting priors with novel measures or task environments. We propose a method for setting priors by eliciting continuous probability distributions from naive participants. This allows us to include any relevant information participants have for a given effect. Even when prior means are near-zero, this method provides a principle way to estimate dispersion and produce shrinkage, reducing the occurrence of overestimated effect sizes. We demonstrate this method with a number of published studies and compare the effect of different prior estimation and aggregation methods.},
  langid = {english},
  keywords = {Bayesian method,Maximum likelihood estimation,Normal distribution,Personality traits,Probability distribution,Psychology,Statistical distributions,Surveys},
  file = {/Users/thomasgorman/Documents/Zotero_Markdown/chrabaszcz_crowdsourcing_2017-zotero.md;/Users/thomasgorman/OneDrive - Indiana University/resources/Zotero/Chrabaszcz et al_2017_Crowdsourcing prior information to improve study design and data analysis.pdf;/Users/thomasgorman/Zotero/storage/5WIPM7R8/article.html}
}

@article{chuaPracticeVariabilityPromotes2019,
  title = {Practice Variability Promotes an External Focus of Attention and Enhances Motor Skill Learning},
  author = {Chua, Lee-Kuen and Dimapilis, Maria Katrina and Iwatsuki, Takehiro and Abdollahipour, Reza and Lewthwaite, Rebecca and Wulf, Gabriele},
  year = {2019},
  month = apr,
  journal = {Human Movement Science},
  volume = {64},
  pages = {307--319},
  issn = {01679457},
  doi = {10.1016/j.humov.2019.02.015},
  urldate = {2019-05-01},
  abstract = {Variability in practice has been shown to enhance motor skill learning. Benefits of practice variability have been attributed to motor schema formation (variable versus constant practice), or more effortful information processing (random versus blocked practice). We hypothesized that, among other mechanisms, greater practice variability might promote an external focus of attention on the intended movement effect, while less variability would be more conducive to a less effective internal focus on body movements. In Experiment 1, the learning of a throwing task was enhanced by variable versus constant practice, and variable group participants reported focusing more on the distance to the target (external focus), while constant group participants focused more on their posture (internal focus). In Experiment 2, golf putting was learned more effectively with a random compared with a blocked practice schedule. Furthermore, random group learners reported using a more effective distal external focus (i.e., distance to the target) to a greater extent, whereas blocked group participants used a less effective proximal focus (i.e., putter) more often. While attentional focus was assessed through questionnaires in the first two experiments, learners in Experiment 3 were asked to report their current attentional focus at any time during practice. Again, the learning of a throwing task was more effective after random relative to blocked practice. Also, random practice learners reported using more external focus cues, while in blocked practice participants used more internal focus cues. The findings suggest that the attentional foci induced by different practice schedules might be at least partially responsible for the learning differences.},
  langid = {english},
  keywords = {{$>$}2 conditions,Benefit of Variability,constant control,Delayed Test,Empirical,Motor,Neural Comments,no training difference,projectile throwing,Schema,Sequence,Variability,Varied Manipulation},
  file = {/Users/thomasgorman/Zotero/storage/P54AU5VI/Chua et al. - 2019 - Practice variability promotes an external focus of.pdf}
}

@phdthesis{chubalaScalingFunctionLearning2017,
  title = {Scaling {{Function Learning}} from {{Individuals}} to {{Groups}}},
  author = {Chubala, Chrissy M},
  year = {2017},
  abstract = {Scale	invariance,	the	notion	that	scientific	principles	ought	to	hold	over	different	scales	of	 analysis,	is	a	regularity	in	the	physical	and biological	sciences but	is	underappreciated	in	 psychology.	Whereas	the	standard	approach	in	psychology	is	to	explain behaviours	at	 different	scales	of	analysis	with	different	mechanisms, I	argue	that sophisticated	behaviours	 at	any	scale	are	an	emergent	consequence	of	simple	processes	interacting	with	a	structured	 environment.	Changing	the	scale	of	analysis,	whether	temporal,	physical,	or	otherwise,	may	 alter the	structure	of	the	environment	but	need	not	imply	changes	to	the mechanisms that interact with	that	environment.	To	illustrate	the	centrality	of scale	invariance and	 emergence	to	human	cognition,	I	replicate	signature	findings	from	a	function	learning	task	 after	scaling	up	the	unit	of	analysis, from	individuals	to	groups. In	a	standard	function	 learning	task,	individuals	learn	the	relationship	between	two	variables	by	trial	and	error, matching	one	variable	(i.e.,	Y)	to	a	target	value	of	the	other	variable	(i.e.,	X) and	adjusting	 their	responses	according	to	feedback.	In	an	analogous	group	function	learning	task,	groups	 of	non-communicating	individuals	learn	the	relationship	between	two	variables	by	making individual-level	decisions	in	response	to	group-level	feedback.	My	experiments	with	this	 task	demonstrate	that	groups,	like	individuals, can	learn	both	simple	and	complex	functions by	trial	and	error,	and	can	generalize	their	knowledge	of	a	trained	function	to	untrained	 target	values in	a	transfer	test.	Groups are,	moreover, resilient	to	disruption	of	their	 knowledge,	a	central	feature of	distributed	representations	in biological and	artificial	 neural	networks.	The	results	recommend	a	principled	approach	to	cognition,	in	which	 simple	processes	interact	with	the	structure	of	the	environment	to	produce	sophisticated behaviours,	and	in	which	the	patterns	of	behaviour	produced	at	one	scale	of	analysis	are	 iii reproduced at	other	scales. Finally,	the	data	show	that,	when	constrained	by	a	collective	 environment	and	common	goals,	individuals	self-organize	into	unique	decision	roles that	 support	group-level	learning.	An exploratory	analysis	of	self-reported	strategies,	individual	 behaviours,	and	personality	profiles demonstrates how complex	social	variables can	help	or	 hinder	the	emergence	of	learning	at	the	level	of	the	group. Chapter	1:	A	Principled	Approach	to	Cognition Scale	Invariance Self-Similarity	and	Hierarchies Group	Cognition Function	Learning Structure	of	the	Thesis Chapter 2:	Function	Learning	in	Groups Experiment	1 Discussion Chapter	3:	Transfer	of	Learned	Functions	in	Groups Experiment	2 Discussion ii iv vi x xi 1 3 5 7 11 14 16 16 24 28 29 44 viii Chapter	4:	Function	Learning	Groups	as	Networks Artificial	Neural	Networks Distributed	Representation	in	Networks Experiment	3 Discussion Summary	of	Chapters	2-4 Chapter	5:	Understanding	How	Groups	Learn Groups	as Artificial	Neural	Networks Alternate	Approaches A	Preemptive	Summary Self-reported	Strategies Individual	Response	Patterns Personality	Variables Summary	of	Individual	Behaviour Sabotaged	Groups Chapter	6:	General	Discussion Function	Learning Considerations Differences	in	behaviour Differences	in	methodology Limitations	of	analogy 51 52 54 57 70 72 76 76 79 80 81 89 100 107 109 113 114 116 117 119 ix Statistical	uncertainties Future	Work Variations	on	group	function	learning An alternate	approach Modeling	group	cognition Implications Scale	invariance and	self-similarity Hierarchical	systems Self-organization	and	emergence Summary},
  langid = {english},
  file = {/Users/thomasgorman/Documents/Zotero_Markdown/chubalaScalingFunctionLearning2017-zotero.md;/Users/thomasgorman/Downloads/chubala_scaling_2017-zotero.md;/Users/thomasgorman/Downloads/chubala_scaling_2017.md;/Users/thomasgorman/OneDrive - Indiana University/resources/Zotero/Chubala_Scaling Function Learning from Individuals to Groups.pdf}
}

@article{chuTwoDifferentMotor2014,
  title = {Two Different Motor Learning Mechanisms Contribute to Learning Reaching Movements in a Rotated Visual Environment},
  author = {Chu, Virginia Way Tong and Sanger, Terence David},
  year = {2014},
  month = dec,
  journal = {F1000Research},
  volume = {3},
  pages = {72},
  issn = {2046-1402},
  doi = {10.12688/f1000research.3676.2},
  urldate = {2022-06-03},
  abstract = {Practice of movement in virtual-reality and other artificially altered environments has been proposed as a method for rehabilitation following neurological injury and for training new skills in healthy humans.~ For such training to be useful, there must be transfer of learning from the artificial environment to the performance of desired skills in the natural environment.~ Therefore an important assumption of such methods is that practice in the altered environment engages the same learning and plasticity mechanisms that are required for skill performance in the natural environment.~ We test the hypothesis that transfer of learning may fail because the learning and plasticity mechanism that adapts to the altered environment is different from the learning mechanism required for improvement of motor skill.~ In this paper, we propose that a model that separates skill learning and environmental adaptation is necessary to explain the learning and aftereffects that are observed in virtual reality experiments.~ In particular, we studied the condition where practice in the altered environment should lead to correct skill performance in the original environment. Our 2-mechanism model predicts that aftereffects will still be observed when returning to the original environment, indicating a lack of skill transfer from the artificial environment to the original environment. To illustrate the model prediction, we tested 10 healthy participants on the interaction between a simple overlearned motor skill (straight hand movements to targets in different directions) and an artificially altered visuomotor environment (rotation of visual feedback of the results of movement).~ As predicted by the models, participants show adaptation to the altered environment and after-effects on return to the baseline environment even when practice in the altered environment should have led to correct skill performance. ~The presence of aftereffect under all conditions that involved changes in environment demonstrates separation of environmental adaptation and skill learning. Our results support the existence of two distinct learning modules with different adaptation properties.~ Therefore we suggest that adaptation to an altered environment may not be useful for training new skills.},
  pmcid = {PMC4670007},
  pmid = {26673417},
  file = {/Users/thomasgorman/OneDrive - Indiana University/resources/Zotero/Chu_Sanger_2014_Two different motor learning mechanisms contribute to learning reaching.pdf}
}

@article{ciccioneAnalyzingMisperceptionExponential2022,
  title = {Analyzing the Misperception of Exponential Growth in Graphs},
  author = {Ciccione, Lorenzo and {Sabl{\'e}-Meyer}, Mathias and Dehaene, Stanislas},
  year = {2022},
  month = aug,
  journal = {Cognition},
  volume = {225},
  pages = {105112},
  issn = {00100277},
  doi = {10.1016/j.cognition.2022.105112},
  urldate = {2022-05-13},
  abstract = {Exponential growth is frequently underestimated, an error that can have a heavy social cost in the context of epidemics. To clarify its origins, we measured the human capacity (N = 521) to extrapolate linear and expo\- nential trends in scatterplots. Four factors were manipulated: the function underlying the data (linear or expo\- nential), the response modality (pointing or venturing a number), the scale on the y axis (linear or logarithmic), and the amount of noise in the data. While linear extrapolation was precise and largely unbiased, we observed a consistent underestimation of noisy exponential growth, present for both pointing and numerical responses. A biased ideal-observer model could explain these data as an occasional misperception of noisy exponential graphs as quadratic curves. Importantly, this underestimation bias was mitigated by participants' math knowledge, by using a logarithmic scale, and by presenting a noiseless exponential curve rather than a noisy data plot, thus suggesting concrete avenues for interventions.},
  langid = {english},
  file = {/Users/thomasgorman/Documents/Zotero_Markdown/ciccione_analyzing_2022-zotero.md;/Users/thomasgorman/OneDrive - Indiana University/resources/Zotero/Ciccione et al_2022_Analyzing the misperception of exponential growth in graphs.pdf}
}

@techreport{ciccioneCanHumansPerform2021,
  type = {Preprint},
  title = {Can Humans Perform Mental Regression on a Graph? {{Accuracy}} and Bias in the Perception of Scatterplots.},
  shorttitle = {Can Humans Perform Mental Regression on a Graph?},
  author = {Ciccione, Lorenzo and Dehaene, Stanislas},
  year = {2021},
  month = jan,
  institution = {{PsyArXiv}},
  doi = {10.31234/osf.io/2dxcn},
  urldate = {2021-05-22},
  abstract = {Despite the widespread use of graphs, little is known about how fast and how accurately we can extract information from them. Through a series of four behavioral experiments, we characterized human performance in ``mental regression'', i.e. the perception of statistical trends from scatterplots. When presented with a noisy scatterplot, even as briefly as 100 ms, human adults could accurately judge if it was increasing or decreasing, fit a regression line, and extrapolate outside the original data range, for both linear and non-linear functions. Performance was highly consistent across those three tasks of trend judgment, line fitting and extrapolation. Participants' linear trend judgments took into account the slope, the noise, and the number of data points, and were tightly correlated with the t-test classically used to evaluate the significance of a linear regression. However, they overestimated the absolute value of the regression slope. This bias was inconsistent with ordinary least squares (OLS) regression, which minimizes the sum of square deviations, but consistent with the use of Deming regression, which treats the x and y axes symmetrically and minimizes the Euclidean distance to the fitting line. We speculate that this fast but biased perception of scatterplots may be based on a ``neuronal recycling'' of the human visual capacity to identify the medial axis of a shape.},
  langid = {english},
  file = {/Users/thomasgorman/Documents/Zotero_Markdown/ciccione_can_2021-1-zotero.md;/Users/thomasgorman/OneDrive - Indiana University/resources/Zotero/Ciccione_Dehaene_2021_Can humans perform mental regression on a graph.pdf}
}

@article{ciccioneCanHumansPerform2021a,
  title = {Can Humans Perform Mental Regression on a Graph? {{Accuracy}} and Bias in the Perception of Scatterplots},
  shorttitle = {Can Humans Perform Mental Regression on a Graph?},
  author = {Ciccione, Lorenzo and Dehaene, Stanislas},
  year = {2021},
  month = aug,
  journal = {Cognitive Psychology},
  volume = {128},
  pages = {101406},
  issn = {0010-0285},
  doi = {10.1016/j.cogpsych.2021.101406},
  urldate = {2022-05-13},
  abstract = {Despite the widespread use of graphs, little is known about how fast and how accurately we can extract information from them. Through a series of four behavioral experiments, we characterized human performance in ``mental regression'', i.e. the perception of statistical trends from scatterplots. When presented with a noisy scatterplot, even as briefly as 100~ms, human adults could accurately judge if it was increasing or decreasing, fit a regression line, and extrapolate outside the original data range, for both linear and non-linear functions. Performance was highly consistent across those three tasks of trend judgment, line fitting and extrapolation. Participants' linear trend judgments took into account the slope, the noise, and the number of data points, and were tightly correlated with the t-test classically used to evaluate the significance of a linear regression. However, they overestimated the absolute value of the regression slope. This bias was inconsistent with ordinary least squares (OLS) regression, which minimizes the sum of square deviations, but consistent with the use of Deming regression, which treats the x and y axes symmetrically and minimizes the Euclidean distance to the fitting line. We speculate that this fast but biased perception of scatterplots may be based on a ``neuronal recycling'' of the human visual capacity to identify the medial axis of a shape.},
  langid = {english},
  keywords = {Cognitive bias,Extrapolation,Graph perception,Graphicacy,Regression,Scatterplot,Trend judgment},
  file = {/Users/thomasgorman/Documents/Zotero_Markdown/ciccione_can_2021-zotero.md;/Users/thomasgorman/OneDrive - Indiana University/resources/Zotero/Ciccione_Dehaene_2021_Can humans perform mental regression on a graph3.pdf;/Users/thomasgorman/Zotero/storage/73CD45IL/S001002852100030X.html}
}

@article{ciccioneTrendJudgmentPerceptual2023,
  title = {Trend Judgment as a Perceptual Building Block of Graphicacy and Mathematics, across Age, Education, and Culture},
  author = {Ciccione, Lorenzo and {Sabl{\'e}-Meyer}, Mathias and Boissin, Esther and Josserand, Mathilde and {Potier-Watkins}, Cassandra and Caparos, Serge and Dehaene, Stanislas},
  year = {2023},
  month = jun,
  journal = {Scientific Reports},
  volume = {13},
  number = {1},
  pages = {10266},
  publisher = {{Nature Publishing Group}},
  issn = {2045-2322},
  doi = {10.1038/s41598-023-37172-3},
  urldate = {2023-07-03},
  abstract = {Data plots are widely used in science, journalism and politics, since they efficiently allow to depict a large amount of information. Graphicacy, the ability to understand graphs, has thus become a fundamental cultural skill comparable to literacy or numeracy. Here, we introduce a measure of intuitive graphicacy that assesses the perceptual ability to detect a trend in noisy scatterplots (``does this graph go up or down?''). In 3943 educated participants, responses vary as a sigmoid function of the t-value that a statistician would compute to detect a significant trend. We find a minimum level of core intuitive graphicacy even in unschooled participants living in remote Namibian villages (N\,=\,87) and 6-year-old 1st-graders who never read a graph (N\,=\,27). The sigmoid slope that we propose as a proxy of intuitive graphicacy increases with education and tightly correlates with statistical and mathematical knowledge, showing that experience contributes to refining graphical intuitions. Our tool, publicly available online, allows to quickly evaluate and formally quantify a perceptual building block of graphicacy.},
  copyright = {2023 The Author(s)},
  langid = {english},
  keywords = {Human behaviour,Psychology},
  file = {/Users/thomasgorman/Library/CloudStorage/OneDrive-IndianaUniversity/Resources/Zotero/Ciccione et al_2023_Trend judgment as a perceptual building block of graphicacy and mathematics,.pdf}
}

@article{cohenCategoryVariabilityExemplar2001,
  title = {Category Variability, Exemplar Similarity, and Perceptual Classification},
  author = {Cohen, Andrew L. and Nosofsky, Robert M. and Zaki, Safa R.},
  year = {2001},
  month = dec,
  journal = {Memory \& Cognition},
  volume = {29},
  number = {8},
  pages = {1165--1175},
  issn = {0090-502X, 1532-5946},
  doi = {10.3758/BF03206386},
  urldate = {2019-11-04},
  langid = {english},
  keywords = {Artifical Stimuli,Coverage Manipulation,Empirical,Exemplar model,Generalization,Model,Similarity,Similarity Computation,Variability},
  file = {/Users/thomasgorman/Zotero/storage/2FWZX6P9/Cohen et al. - 2001 - Category variability, exemplar similarity, and per.pdf}
}

@misc{conawayModelsHumanCategory2012,
  title = {Models of {{Human Category Learning}}: {{Do They Generalize}}?: (502412013-997)},
  shorttitle = {Models of {{Human Category Learning}}},
  author = {Conaway, Nolan and Kurtz, Kenneth},
  year = {2012},
  publisher = {{American Psychological Association}},
  doi = {10.1037/e502412013-997},
  urldate = {2020-09-06},
  abstract = {Generalization to new examples is an essential aspect of categorization. However, recent category learning research has not focused on how people generalize their category knowledge. Taking generalization to be a critical basis for evaluating formal models of category learning, we employed a `minimal case' approach to begin a systematic investigation of generalization. Human participants received supervised training on a two-way artificial classification task based on two dimensions that were each perfect predictors. Learners were then asked to classify new examples sampled from the stimulus space. Most participants based their judgments on one or the other dimension. Varying the relative levels of dimension salience influenced generalization outcomes, but varying category size (2, 4, or 8 items) did not. We fit two theoretically distinct similarity-based models (ALCOVE and DIVA) to aggregate learning data and tested on the generalization set. Both models could explain important aspects of human performance, but DIVA produced a superior overall account.},
  langid = {english},
  file = {/Users/thomasgorman/Zotero/storage/D5MMZBV5/Conaway and Kurtz - 2012 - Models of Human Category Learning Do They General.pdf}
}

@article{conawayPACKERExemplarModel,
  title = {{{PACKER}}: {{An Exemplar Model}} of {{Category Generation}}},
  author = {Conaway, Nolan and Austerweil, Joseph L},
  pages = {6},
  abstract = {Generating new concepts is an intriguing yet understudied topic in cognitive science. In this paper, we present a novel exemplar model of category generation: PACKER (Producing Alike and Contrasting Knowledge using Exemplar Representations). PACKER's core design assumptions are (1) categories are represented as exemplars in a multidimensional psychological space, (2) generated items should be similar to exemplars of the same category, and (3) generated categories should be dissimilar to existing categories. A behavioral study reveals strong effects of contrast- and target-class similarity. These effects are novel empirical phenomena, which are directly predicted by the PACKER model but are not explained by existing formal approaches.},
  langid = {english},
  file = {/Users/thomasgorman/OneDrive - Indiana University/resources/Zotero/Conaway_Austerweil_PACKER.pdf}
}

@article{constantJudgmentsAgencyAre2022,
  title = {Judgments of Agency Are Affected by Sensory Noise without Recruiting Metacognitive Processing},
  author = {Constant, Marika and Salomon, Roy and Filevich, Elisa},
  editor = {Wyart, Valentin and {de Lange}, Floris P and Chambon, Valerian},
  year = {2022},
  month = jan,
  journal = {eLife},
  volume = {11},
  pages = {e72356},
  publisher = {{eLife Sciences Publications, Ltd}},
  issn = {2050-084X},
  doi = {10.7554/eLife.72356},
  urldate = {2022-04-08},
  abstract = {Acting in the world is accompanied by a sense of agency, or experience of control over our actions and their outcomes. As humans, we can report on this experience through judgments of agency. These judgments often occur under noisy conditions. We examined the computations underlying judgments of agency, in particular under the influence of sensory noise. Building on previous literature, we studied whether judgments of agency incorporate uncertainty in the same way that confidence judgments do, which would imply that the former share computational mechanisms with metacognitive judgments. In two tasks, participants rated agency, or confidence in a decision about their agency, over a virtual hand that tracked their movements, either synchronously or with a delay and either under high or low noise. We compared the predictions of two computational models to participants' ratings and found that agency ratings, unlike confidence, were best explained by a model involving no estimates of sensory noise. We propose that agency judgments reflect first-order measures of the internal signal, without involving metacognitive computations, challenging the assumed link between the two cognitive processes.},
  keywords = {agency,computational model,confidence,metacognition,Ordinal data,uncertainty},
  file = {/Users/thomasgorman/OneDrive - Indiana University/resources/Zotero/Constant et al_2022_Judgments of agency are affected by sensory noise without recruiting.pdf}
}

@article{cornwallEffectsCategoricalNumerical2022,
  title = {Effects of Categorical and Numerical Feedback on Category Learning},
  author = {Cornwall, Astin C. and Davis, Tyler and Byrne, Kaileigh A. and Worthy, Darrell A.},
  year = {2022},
  month = aug,
  journal = {Cognition},
  volume = {225},
  pages = {105163},
  issn = {0010-0277},
  doi = {10.1016/j.cognition.2022.105163},
  urldate = {2022-05-17},
  abstract = {Real-world learning signals often come in the form of a continuous range of rewards or punishments, such as receiving more or less money or other reward. However, in laboratory studies, feedback used to examine how humans learn new categories has almost invariably been categorical in nature (i.e. Correct/Incorrect, or A/Not-A). Whether numerical or categorical feedback leads to better learning is an open question. One possibility is that numerical feedback could give more fine-grained information about a category. Alternatively, categorical feedback is more dichotomous, potentially leading to larger error signals. Here we test how feedback impacts category learning by having participants learn to categorize novel line stimuli from either numerical, categorical, or a combination of both types of feedback. Performance was better for categorical relative to the more variable numerical feedback. However, participants were able to learn to effectively categorize from numerical feedback, and providing larger numerical rewards for easier, more representative stimuli was more successful in promoting learning than providing larger rewards for harder to classify stimuli. Simulations and fits of a connectionist model to participants' performance data suggest that categorical feedback promotes better learning by eliciting larger prediction errors than numerical feedback.},
  langid = {english},
  keywords = {ALCOVE,Category learning,{Reward learning, feedback}},
  file = {/Users/thomasgorman/OneDrive - Indiana University/resources/Zotero/Cornwall et al_2022_Effects of categorical and numerical feedback on category learning.pdf;/Users/thomasgorman/Zotero/storage/3FPMULL2/S0010027722001512.html}
}

@article{courrieuQuickApproximationBivariate2012,
  title = {Quick Approximation of Bivariate Functions},
  author = {Courrieu, Pierre},
  year = {2012},
  journal = {British Journal of Mathematical and Statistical Psychology},
  volume = {65},
  number = {1},
  pages = {89--121},
  issn = {2044-8317},
  doi = {10.1111/j.2044-8317.2011.02016.x},
  urldate = {2022-05-13},
  abstract = {This paper presents two experiments where participants had to approximate function values at various generalization points of a square, using given function values at a small set of data points. A representative set of standard function approximation models was trained to exactly fit the function values at data points, and models' responses at generalization points were compared to those of humans. Then one defined a large class of possible models (including the best two identified predictors) and the class maximal possible prediction accuracy was evaluated. A new model of quick multivariate function approximation belonging to this class was proposed. Its prediction accuracy was close to the maximum possible, and significantly better than that of all other models tested. The new model also provided a significant account of human response variability. Finally, it was shown that this model is more particularly suitable for problems in which the visual system can perform some specific structuring of the data space. This model is therefore considered as a suitable starting point for further investigations into quick multivariate function approximation, which is to date an inadequately explored question in cognitive psychology.},
  langid = {english},
  keywords = {matlab code},
  file = {/Users/thomasgorman/Documents/Zotero_Markdown/courrieuQuickApproximationBivariate2012-zotero.md;/Users/thomasgorman/Downloads/courrieu_quick_2012-zotero.md;/Users/thomasgorman/Downloads/courrieu_quick_2012.md;/Users/thomasgorman/Downloads/courrieuQuickApproximationBivariate2012.md;/Users/thomasgorman/OneDrive - Indiana University/resources/Zotero/Courrieu_2012_Quick approximation of bivariate functions.pdf;/Users/thomasgorman/Zotero/storage/KNRANX5G/j.2044-8317.2011.02016.html}
}

@article{cousineauLearningCurvesStrong2013,
  title = {Learning Curves as Strong Evidence for Testing Models: {{The}} Case of {{EBRW}}},
  shorttitle = {Learning Curves as Strong Evidence for Testing Models},
  author = {Cousineau, Denis and Lacroix, Guy L. and Gigu{\`e}re, Gyslain and H{\'e}lie, S{\'e}bastien},
  year = {2013},
  month = jun,
  journal = {Journal of Mathematical Psychology},
  volume = {57},
  number = {3},
  pages = {107--116},
  issn = {0022-2496},
  doi = {10.1016/j.jmp.2013.05.003},
  urldate = {2021-01-07},
  abstract = {This manuscript describes how learning curves can be used to provide a strong test for computational models of cognitive processes. As an example, we show how this method can be used to evaluate the Exemplar-Based Random-Walk model of categorization (EBRW; Nosofsky \& Palmeri, 1997a). EBRW is an extension of the Generalized Context Model (GCM; Nosofsky, 1984, Nosofsky, 1986). It predicts that the mean response times (RTs) follow a power function. It can be shown analytically, however, that the learning rate (i.e., the curvature) predicted by the model can only be equal to 1, a value rarely observed in empirical data analyses. We also explored an extended version of EBRW including background noise elements (Nosofsky \& Alfonso-Reese, 1999) and identified conditions under which this model can predict curvatures different from 1. The limitation of these models to predict a wide variety of curvatures as observed in human data can be resolved by a simple extension to EBRW in which the original exponential distribution of retrieval times is replaced by a Weibull distribution. Additional predictions regarding learning curves are discussed.},
  langid = {english},
  keywords = {Categorization models,Exemplar-based random-walk model,Learning curves,Power curve},
  file = {/Users/thomasgorman/OneDrive - Indiana University/resources/Zotero/Cousineau et al_2013_Learning curves as strong evidence for testing models.pdf;/Users/thomasgorman/Zotero/storage/F8CSS8KT/S0022249613000485.html}
}

@article{crumpEpisodicContributionsSequential2010,
  title = {Episodic Contributions to Sequential Control: {{Learning}} from a Typist's Touch.},
  shorttitle = {Episodic Contributions to Sequential Control},
  author = {Crump, Matthew J. C. and Logan, Gordon D.},
  year = {2010},
  journal = {Journal of Experimental Psychology: Human Perception and Performance},
  volume = {36},
  number = {3},
  pages = {662--672},
  issn = {1939-1277, 0096-1523},
  doi = {10.1037/a0018390},
  urldate = {2019-03-13},
  abstract = {Sequential control over routine action is widely assumed to be controlled by stable, highly practiced representations. Our findings demonstrate that the processes controlling routine actions in the domain of skilled typing can be flexibly manipulated by memory processes coding recent experience with typing particular words and letters. In two experiments, we extended Masson's (1986) procedure for measuring item-specific learning in the context of acquiring an unfamiliar skill to the highly skilled domain of typing. Skilled typists' performance improved during practice with typing words composed from a specific set of letters. In a transfer phase, performance was fastest for trained words, followed by new words composed of trained letters, and slowest for new words composed of untrained letters. The finding that recent episodic experience with typing particular words and letters influences skilled typing performance holds widespread implications for theories of typing, sequence learning, and motor control.},
  langid = {english},
  file = {/Users/thomasgorman/Zotero/storage/GG96BQGS/Crump and Logan - 2010 - Episodic contributions to sequential control Lear.pdf}
}

@article{daleGradedMotorResponses2007,
  title = {Graded Motor Responses in the Time Course of Categorizing Atypical Exemplars},
  author = {Dale, Rick and Kehoe, Caitlin and Spivey, Michael J.},
  year = {2007},
  month = jan,
  journal = {Memory \& Cognition},
  volume = {35},
  number = {1},
  pages = {15--28},
  issn = {0090-502X, 1532-5946},
  doi = {10.3758/BF03195938},
  urldate = {2020-09-04},
  abstract = {The time course of categorization was investigated in four experiments, which revealed graded competitive effects in a categorization task. Participants clicked one of two categories (e.g., mammal or fish) in response to atypical or typical exemplars (e.g., whale or cat) in the form of words (Experiments 1 and 2) or pictures (Experi- ments 3 and 4). Streaming x, y coordinates of mouse movement trajectories were recorded. Normalized mean tra- jectories revealed a graded competitive process: Atypical exemplars produced trajectories with greater curvature toward the competing category than did typical exemplars. The experiments contribute to recent examination of the time course of categorization and carry implications for theories of representation in cognitive science.},
  langid = {english},
  file = {/Users/thomasgorman/OneDrive - Indiana University/resources/Zotero/Dale et al_2007_Graded motor responses in the time course of categorizing atypical exemplars.pdf}
}

@article{dasguptaDistinguishingRuleExemplarbased2021,
  title = {Distinguishing Rule- and Exemplar-Based Generalization in Learning Systems},
  author = {Dasgupta, Ishita and Grant, Erin and Griffiths, Thomas L.},
  year = {2021},
  month = oct,
  journal = {arXiv:2110.04328 [cs]},
  eprint = {2110.04328},
  primaryclass = {cs},
  urldate = {2021-10-19},
  abstract = {Despite the increasing scale of datasets in machine learning, generalization to unseen regions of the data distribution remains crucial. Such extrapolation is by definition underdetermined and is dictated by a learner's inductive biases. Machine learning systems often do not share the same inductive biases as humans and, as a result, extrapolate in ways that are inconsistent with our expectations. We investigate two distinct such inductive biases: feature-level bias (differences in which features are more readily learned) and exemplar-vs-rule bias (differences in how these learned features are used for generalization). Exemplar- vs. rule-based generalization has been studied extensively in cognitive psychology, and, in this work, we present a protocol inspired by these experimental approaches for directly probing this trade-off in learning systems. The measures we propose characterize changes in extrapolation behavior when feature coverage is manipulated in a combinatorial setting. We present empirical results across a range of models and across both expository and real-world image and language domains. We demonstrate that measuring the exemplar-rule trade-off while controlling for feature-level bias provides a more complete picture of extrapolation behavior than existing formalisms. We find that most standard neural network models have a propensity towards exemplar-based extrapolation and discuss the implications of these findings for research on data augmentation, fairness, and systematic generalization.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Machine Learning},
  file = {/Users/thomasgorman/OneDrive - Indiana University/resources/Zotero/Dasgupta et al_2021_Distinguishing rule- and exemplar-based generalization in learning systems.pdf;/Users/thomasgorman/Zotero/storage/53ECUUQ4/2110.html}
}

@techreport{dasguptaLearningActIntegrating2018,
  type = {Preprint},
  title = {Learning to Act by Integrating Mental Simulations and Physical Experiments},
  author = {Dasgupta, Ishita and Smith, Kevin A. and Schulz, Eric and Tenenbaum, Joshua B. and Gershman, Samuel J.},
  year = {2018},
  month = may,
  institution = {{Animal Behavior and Cognition}},
  doi = {10.1101/321497},
  urldate = {2020-09-01},
  abstract = {People can learn about the effects of their actions either by performing physical experiments or by running mental simulations. Physical experiments are reliable but risky; mental simulations are unreliable but safe. We investigate how people negotiate the balance between these strategies. Participants attempted to shoot a ball at a target, and could pay to take practice shots (physical experiments). They could also simply think (run mental simulations), but were incentivized to act quickly by paying for time. We demonstrate that the amount of thinking time and physical experiments is sensitive to trial characteristics in a way that is consistent with a model that integrates information across simulation and experimentation and decides online when to perform each.},
  langid = {english},
  keywords = {projectile throwing},
  file = {/Users/thomasgorman/Zotero/storage/NQ4VK9HT/Dasgupta et al. - 2018 - Learning to act by integrating mental simulations .pdf}
}

@article{dekkerCurriculumLearningHuman2022,
  title = {Curriculum Learning for Human Compositional Generalization},
  author = {Dekker, Ronald B. and Otto, Fabian and Summerfield, Christopher},
  year = {2022},
  month = oct,
  journal = {Proceedings of the National Academy of Sciences},
  volume = {119},
  number = {41},
  pages = {e2205582119},
  publisher = {{Proceedings of the National Academy of Sciences}},
  doi = {10.1073/pnas.2205582119},
  urldate = {2022-10-10},
  file = {/Users/thomasgorman/Documents/Zotero_Markdown/dekkerCurriculumLearningHuman2022-zotero.md;/Users/thomasgorman/OneDrive - Indiana University/resources/Zotero/Dekker et al_2022_Curriculum learning for human compositional generalization.pdf}
}

@techreport{dekkerDeterminantsHumanCompositional2022,
  type = {Preprint},
  title = {Determinants of Human Compositional Generalization},
  author = {Dekker, Ronald and Otto, Fabian and Summerfield, Christopher},
  year = {2022},
  month = mar,
  institution = {{PsyArXiv}},
  doi = {10.31234/osf.io/qnpw6},
  urldate = {2022-04-05},
  abstract = {Generalisation (or transfer) is the ability to repurpose knowledge in novel settings. It is often asserted that generalisation is an important ingredient of human intelligence, but its extent, nature and determinants have proved controversial. Here, we re-examine this question with a new paradigm that formalises the transfer learning problem as one of recomposing existing functions to solve unseen problems. We find that people can generalise compositionally in ways that are elusive for standard neural networks, and that human generalisation benefits from training regimes in which items are axis-aligned and temporally correlated. We describe a neural network model based around a Hebbian gating process which can capture how human generalisation benefits from different training curricula. We additionally find that adult humans tend to learn composable functions asynchronously, exhibiting discontinuities in learning that resemble those seen in child development.},
  langid = {english},
  file = {/Users/thomasgorman/Documents/Zotero_Markdown/dekkerDeterminantsHumanCompositional2022-zotero.md;/Users/thomasgorman/OneDrive - Indiana University/resources/Zotero/Dekker et al_2022_Determinants of human compositional generalization.pdf}
}

@article{deloshExtrapolationSineQua1997,
  title = {Extrapolation: {{The Sine Qua Non}} for {{Abstraction}} in {{Function Learning}}},
  author = {DeLosh, Edward L and McDaniel, Mark A and Busemeyer, Jerome R},
  year = {1997},
  journal = {Journal of Experimental Psychology: Learning, Memory, and Cognition},
  pages = {19},
  langid = {english},
  file = {/Users/thomasgorman/Documents/Zotero_Markdown/deloshExtrapolationSineQua1997-zotero.md;/Users/thomasgorman/Downloads/delosh_extrapolation_1997-zotero.md;/Users/thomasgorman/Downloads/delosh_extrapolation_1997.md;/Users/thomasgorman/Zotero/storage/W6QH7JZK/DeLosh et al. - Extrapolation The Sine Qua Non for Abstraction in.pdf}
}

@article{denbyContextualVariabilityExemplar2018,
  title = {Contextual Variability and Exemplar Strength in Phonotactic Learning.},
  author = {Denby, Thomas and Schecter, Jeffrey and Arn, Sean and Dimov, Svetlin and Goldrick, Matthew},
  year = {2018},
  month = feb,
  journal = {Journal of Experimental Psychology: Learning, Memory, and Cognition},
  volume = {44},
  number = {2},
  pages = {280--294},
  issn = {1939-1285, 0278-7393},
  doi = {10.1037/xlm0000465},
  urldate = {2020-09-11},
  abstract = {Phonotactics\textemdash{} constraints on the position and combination of speech sounds within syllables\textemdash are subject to statistical differences that gradiently affect speaker and listener behavior (e.g., Vitevitch \& Luce, 1999). What statistical properties drive the acquisition of such constraints? Because they are naturally highly correlated, previous work has been unable to dissociate the contribution of 2 properties: contextual variability (the number of unique phonological contexts in which a phonotactic pattern appears) and exemplar strength (the overall number of times the pattern appears). Using an artificial language learning paradigm, 3 experiments disentangled the effects of variability and strength, indexed by type and token frequency, respectively, on the learning of gradient phonotactics. When the 2 factors were decorrelated (Experiment 2), participants showed greater generalization of patterns advantaged for contextual variability, but not those advantaged for exemplar strength. When the 2 factors were anticorrelated (Experiment 3), participants preferred patterns advantaged in contextual variability, even though they were disadvantaged for exemplar strength. These results suggest that contextual variability is the key force driving phonotactic learning, as it allows learners to home in on the invariant features of the input.},
  langid = {english},
  file = {/Users/thomasgorman/OneDrive - Indiana University/resources/Zotero/Denby et al_2018_Contextual variability and exemplar strength in phonotactic learning.pdf}
}

@article{dentonRulebasedExtrapolationContinuing2008,
  title = {Rule-Based Extrapolation: {{A}} Continuing Challenge for Exemplar Models},
  shorttitle = {Rule-Based Extrapolation},
  author = {Denton, Stephen E. and Kruschke, John K. and Erickson, Michael A.},
  year = {2008},
  month = aug,
  journal = {Psychonomic Bulletin \& Review},
  volume = {15},
  number = {4},
  pages = {780--786},
  issn = {1069-9384, 1531-5320},
  doi = {10.3758/PBR.15.4.780},
  urldate = {2020-09-07},
  abstract = {Erickson and Kruschke (1998, 2002) demonstrated that in rule-plus-exception categorization, people gen- eralize category knowledge by extrapolating in a rule-like fashion, even when they are presented with a novel stimulus that is most similar to a known exception. Although exemplar models have been found to be deficient in explaining rule-based extrapolation, Rodrigues and Murre (2007) offered a variation of an exemplar model that was better able to account for such performance. Here, we present the results of a new rule-plus-exception experiment that yields rule-like extrapolation similar to that of previous experiments, and yet the data are not accounted for by Rodrigues and Murre's augmented exemplar model. Further, a hybrid rule-and-exemplar model is shown to better describe the data. Thus, we maintain that rule-plus-exception categorization continues to be a challenge for exemplar-only models.},
  langid = {english},
  file = {/Users/thomasgorman/Documents/Zotero_Markdown/dentonRulebasedExtrapolationContinuing2008-zotero.md;/Users/thomasgorman/Zotero/storage/LBSSBBCE/Denton et al. - 2008 - Rule-based extrapolation A continuing challenge f.pdf}
}

@misc{DescriptionALCOVECatLearn,
  title = {Description of {{ALCOVE}} - {{CatLearn}}},
  urldate = {2021-05-21},
  file = {/Users/thomasgorman/OneDrive - Indiana University/resources/Zotero/Description of ALCOVE - CatLearn.pdf}
}

@incollection{dettermanCaseProsecutionTransfer1993,
  title = {The Case for the Prosecution: {{Transfer}} as an Epiphenomenon},
  shorttitle = {The Case for the Prosecution},
  booktitle = {Transfer on Trial:  {{Intelligence}}, Cognition, and Instruction},
  author = {Detterman, Douglas K.},
  year = {1993},
  pages = {1--24},
  publisher = {{Ablex Publishing}},
  address = {{Norwood, NJ.}},
  abstract = {a formal definition of transfer is presented, followed by a brief review of what is already known about transfer / [considers] examples of reviews, studies that find transfer, and studies that fail to find transfer  there are two issues that need to be addressed with respect to the relationship between intelligence and transfer / the first . . . is the degree to which far (or general) transfer explains intelligence / the second issue is the degree to which any kind of transfer, either near or far, is central to an understanding of individual differences in mental ability  transfer and education / [examines the role of transfer within two general theories of education, the doctrine of formal discipline and the theory that people learn specific examples] (PsycINFO Database Record (c) 2016 APA, all rights reserved)},
  isbn = {978-0-89391-825-5 978-0-89391-826-2},
  file = {/Users/thomasgorman/Zotero/storage/4FXHUJXA/Detterman - 1993 - The case for the prosecution Transfer as an epiph.pdf;/Users/thomasgorman/Zotero/storage/RI5XJFP4/1993-98301-001.html}
}

@article{deutschBiasedPerceptionDistributions2023,
  title = {Biased Perception of Distributions: {{Anchoring}}, Interpolation and Smoothing as Potential Causes},
  shorttitle = {Biased Perception of Distributions},
  author = {Deutsch, Roland and Ebert, Jonas and Barth, Markus and Roth, Jenny},
  year = {2023},
  month = aug,
  journal = {Cognition},
  volume = {237},
  pages = {105448},
  issn = {0010-0277},
  doi = {10.1016/j.cognition.2023.105448},
  urldate = {2023-06-01},
  abstract = {Perceiving the degree of variation in the social and non-social environment is a cognitive task that is important for many judgments and decisions. In the present research, we investigated cognitive underpinnings of how people estimate the average value of segments of a statistical distribution (e.g., what is the average income of the richest 25\% of a population?). In three experiments (total N~=~222), participants learned about the values of experimentally created distributions of income values and city sizes and later estimated the mean value of the four quarters of values. We expected participants to draw on heuristic shortcuts to generate such judgments. More specifically, we hypothesized that participants use the endpoints of the distributions as anchors and determine the mean values by linear interpolation. In addition, we tested the contribution of three further processes (Range-Frequency adjustments, Normal Smoothing, Linear Smoothing). Quantitative model tests suggest that anchoring and Linear Smoothing both affected mean interquartile judgments. This conclusion is corroborated by tests of qualitative predictions of the models under consideration.},
  langid = {english},
  keywords = {Anchoring,Distribution perception,Heuristics,Inequality,Regression,Statistical judgments},
  file = {/Users/thomasgorman/OneDrive - Indiana University/resources/Zotero/Deutsch et al_2023_Biased perception of distributions.pdf;/Users/thomasgorman/Zotero/storage/5NNKTGFR/S0010027723000823.html}
}

@article{dimperioUsingInterpolationRegions2007,
  title = {Using {{Interpolation Regions}} to {{Discriminate Models}} of {{Function Learning}}},
  author = {Dimperio, Eric},
  year = {2007},
  pages = {7},
  abstract = {This paper serves to compare existing models of function learning (EXAM \& POLE) on a complex interpolation task. Previous comparisons of the models have focused primarily on extrapolation behaviors. Participants' mean responses suggested a simple linear interpolation from nearby points of reference. Both models were able to predict a similar response. Although POLE served as a better predictor of responses made during training, the EXAM model was a better predictor of interpolation responses.},
  langid = {english},
  file = {/Users/thomasgorman/Documents/Zotero_Markdown/dimperioUsingInterpolationRegions2007-zotero.md;/Users/thomasgorman/Downloads/dimperioUsingInterpolationRegions2007-zotero.md;/Users/thomasgorman/Downloads/dimperioUsingInterpolationRegions2007.md;/Users/thomasgorman/OneDrive - Indiana University/resources/Zotero/Dimperio_Using Interpolation Regions to Discriminate Models of Function Learning.pdf}
}

@article{donkinIdentifyingStrategyUse2015,
  title = {Identifying Strategy Use in Category Learning Tasks: {{A}} Case for More Diagnostic Data and Models.},
  shorttitle = {Identifying Strategy Use in Category Learning Tasks},
  author = {Donkin, Chris and Newell, Ben R. and Kalish, Mike and Dunn, John C. and Nosofsky, Robert M.},
  year = {2015},
  journal = {Journal of Experimental Psychology: Learning, Memory, and Cognition},
  volume = {41},
  number = {4},
  pages = {933--948},
  issn = {1939-1285, 0278-7393},
  doi = {10.1037/xlm0000083},
  urldate = {2019-06-04},
  abstract = {The strength of conclusions about the adoption of different categorization strategies\textemdash and their implications for theories about the cognitive and neural bases of category learning\textemdash{} depend heavily on the techniques for identifying strategy use. We examine performance in an often-used ``informationintegration'' category structure and demonstrate that strategy identification is affected markedly by the range of models under consideration, the type of data collected, and model-selection techniques. We use a set of 27 potential models that represent alternative rule-based and information-integration categorization strategies. Our experimental paradigm includes the presentation of nonreinforced transfer stimuli that improve one's ability to discriminate among the predictions of alternative models. Our modelselection techniques incorporate uncertainty in the identification of individuals as either rule-based or information-integration strategy users. Based on this analysis we identify 48\% of participants as unequivocally using an information-integration strategy. However, adopting the standard practice of using a restricted set of models, restricted data, and ignoring the degree of support for a particular strategy, we would typically conclude that 89\% of participants used an information-integration strategy. We discuss the implications of potentially erroneous strategy identification for the security of conclusions about the categorization capabilities of various participant and patient groups.},
  langid = {english},
  file = {/Users/thomasgorman/Zotero/storage/V4D3T5GN/Donkin et al. - 2015 - Identifying strategy use in category learning task.pdf}
}

@article{donkinPowerLawModelPsychological2012,
  title = {A {{Power-Law Model}} of {{Psychological Memory Strength}} in {{Short-}} and {{Long-Term Recognition}}},
  author = {Donkin, Chris and Nosofsky, Robert M.},
  year = {2012},
  month = jun,
  journal = {Psychological Science},
  volume = {23},
  number = {6},
  pages = {625--634},
  publisher = {{SAGE Publications Inc}},
  issn = {0956-7976},
  doi = {10.1177/0956797611430961},
  urldate = {2020-07-21},
  abstract = {A classic law of cognition is that forgetting curves are closely approximated by power functions. This law describes relations between different empirical dependent variables and the retention interval, and the precise form of the functional relation depends on the scale used to measure each variable. In the research reported here, we conducted a recognition task involving both short- and long-term probes. We discovered that formal memory-strength parameters from an exemplar-recognition model closely followed a power function of the lag between studied items and a test probe. The model accounted for rich sets of response time (RT) data at both individual-subject and individual-lag levels. Because memory strengths were derived from model fits to choices and RTs from individual trials, the psychological power law was independent of the scale used to summarize the forgetting functions. Alternative models that assumed different functional relations or posited a separate fixed-strength working memory store fared considerably worse than the power-law model did in predicting the data.},
  file = {/Users/thomasgorman/OneDrive - Indiana University/resources/Zotero/Donkin_Nosofsky_2012_A Power-Law Model of Psychological Memory Strength in Short- and Long-Term.pdf}
}

@article{doozandehQuantificationHumanConfidence2016,
  title = {Quantification of Human Confidence in Functional Relations},
  author = {Doozandeh, Pooyan},
  year = {2016},
  month = dec,
  journal = {Cognitive Systems Research},
  volume = {40},
  pages = {18--34},
  issn = {1389-0417},
  doi = {10.1016/j.cogsys.2016.02.001},
  urldate = {2022-05-27},
  abstract = {What makes people infer that two continuous-valued entities are functionally related? Involving factors influencing human confidence in the existence of a functional link between two supposed variables has not so far been discussed in function learning literature. By examining this problem and based on relevant results from cognitive psychology, I propose a hypothesis according to which human confidence in a link between cue and criterion is affected by three factors: The difficulty of functions, the level of noise in observed data, and the sample size. Here, the formalization of this hypothesis forms a novel mathematical model of function learning which can also be used for predictions; so the resulting model receives cue-criterion pairs of a supposed relation and produces two outputs: Confidence and predicting function. In an experiment, the performance of a computational implementation of the model is compared with human data. The results show that the model is successful in tracking changes in human confidence. A close correspondence between the predictions of the model and humans was also achieved.},
  langid = {english},
  keywords = {Confidence measurement,Function learning,Function recognition,Mathematical model},
  file = {/Users/thomasgorman/Documents/Zotero_Markdown/doozandeh_quantification_2016-zotero.md;/Users/thomasgorman/OneDrive - Indiana University/resources/Zotero/Doozandeh_2016_Quantification of human confidence in functional relations.pdf;/Users/thomasgorman/Zotero/storage/H3FVHVB7/S138904171530019X.html}
}

@phdthesis{douglassExaminingTransferFunction2017,
  title = {Examining the {{Transfer}} of {{Function Representations}}},
  author = {Douglass, Ashley Nicole},
  year = {2017},
  abstract = {Scale	invariance,	the	notion	that	scientific	principles	ought	to	hold	over	different	scales	of	 analysis,	is	a	regularity	in	the	physical	and biological	sciences but	is	underappreciated	in	 psychology.	Whereas	the	standard	approach	in	psychology	is	to	explain behaviours	at	 different	scales	of	analysis	with	different	mechanisms, I	argue	that sophisticated	behaviours	 at	any	scale	are	an	emergent	consequence	of	simple	processes	interacting	with	a	structured	 environment.	Changing	the	scale	of	analysis,	whether	temporal,	physical,	or	otherwise,	may	 alter the	structure	of	the	environment	but	need	not	imply	changes	to	the mechanisms that interact with	that	environment.	To	illustrate	the	centrality	of scale	invariance and	 emergence	to	human	cognition,	I	replicate	signature	findings	from	a	function	learning	task	 after	scaling	up	the	unit	of	analysis, from	individuals	to	groups. In	a	standard	function	 learning	task,	individuals	learn	the	relationship	between	two	variables	by	trial	and	error, matching	one	variable	(i.e.,	Y)	to	a	target	value	of	the	other	variable	(i.e.,	X) and	adjusting	 their	responses	according	to	feedback.	In	an	analogous	group	function	learning	task,	groups	 of	non-communicating	individuals	learn	the	relationship	between	two	variables	by	making individual-level	decisions	in	response	to	group-level	feedback.	My	experiments	with	this	 task	demonstrate	that	groups,	like	individuals, can	learn	both	simple	and	complex	functions by	trial	and	error,	and	can	generalize	their	knowledge	of	a	trained	function	to	untrained	 target	values in	a	transfer	test.	Groups are,	moreover, resilient	to	disruption	of	their	 knowledge,	a	central	feature of	distributed	representations	in biological and	artificial	 neural	networks.	The	results	recommend	a	principled	approach	to	cognition,	in	which	 simple	processes	interact	with	the	structure	of	the	environment	to	produce	sophisticated behaviours,	and	in	which	the	patterns	of	behaviour	produced	at	one	scale	of	analysis	are	 iii reproduced at	other	scales. Finally,	the	data	show	that,	when	constrained	by	a	collective	 environment	and	common	goals,	individuals	self-organize	into	unique	decision	roles that	 support	group-level	learning.	An exploratory	analysis	of	self-reported	strategies,	individual	 behaviours,	and	personality	profiles demonstrates how complex	social	variables can	help	or	 hinder	the	emergence	of	learning	at	the	level	of	the	group.},
  langid = {english},
  file = {/Users/thomasgorman/Documents/Zotero_Markdown/douglass_examining_2017-zotero.md;/Users/thomasgorman/OneDrive - Indiana University/resources/Zotero/Douglass_Examining the Transfer of Function Representations.pdf}
}

@inproceedings{ebertInterpolationExtrapolationComparison2014,
  title = {Interpolation and Extrapolation: {{Comparison}} of Definitions and Survey of Algorithms for Convex and Concave Hulls},
  shorttitle = {Interpolation and Extrapolation},
  booktitle = {2014 {{IEEE Symposium}} on {{Computational Intelligence}} and {{Data Mining}} ({{CIDM}})},
  author = {Ebert, Tobias and Belz, Julian and Nelles, Oliver},
  year = {2014},
  month = dec,
  pages = {310--314},
  doi = {10.1109/CIDM.2014.7008683},
  abstract = {Any data based method is vulnerable to the problem of extrapolation, nonetheless there exists no unified theory on handling it. The main topic of this publication is to point out the differences in definitions of extrapolation and related methods. There are many different interpretations of extrapolation and a multitude of methods and algorithms, which address the problem of extrapolation detection in different fields of study. We examine popular definitions of extrapolation, compare them to each other and list related literature and methods. It becomes apparent, that the opinions what extrapolation is and how to handle it, differ greatly from each other. We categorize existing literature and give guidelines to choose an appropriate definition of extrapolation for a present problem. We also present hull algorithms, from classic approaches to recent advances. The presented guidelines and categorized literature enables the reader to categorize a present problem, inspect relevant literature and apply suitable methods and algorithms to solve a problem, which is affected by extrapolation.},
  keywords = {Algorithm design and analysis,Computational geometry,Extrapolation,Interpolation,Shape,Signal processing algorithms,Support vector machines},
  file = {/Users/thomasgorman/Documents/Zotero_Markdown/ebert_interpolation_2014-zotero.md;/Users/thomasgorman/OneDrive - Indiana University/resources/Zotero/Ebert et al_2014_Interpolation and extrapolation.pdf;/Users/thomasgorman/Zotero/storage/PSNAR6JM/7008683.html}
}

@inproceedings{edelmanLearningFormationLowdimensional1997,
  title = {Learning as Formation of Low-Dimensional Representation Spaces},
  booktitle = {Proceedings of the {{Nineteenth Annual Conference}} of the {{Cognitive Science Society}}},
  author = {Edelman, Shimon and Intrator, Nathan},
  year = {1997},
  urldate = {2021-08-26},
  abstract = {Psychophysical findings accumulated over the past several decades indicate that perceptual  tasks such as similarity judg-ment tend to be performed on a low-dimensional representation  of the sensory data. Low dimensionality is especially important for learning, as the number of},
  file = {/Users/thomasgorman/OneDrive - Indiana University/resources/Zotero/Edelman_Intrator_1997_Learning as formation of low-dimensional representation spaces.pdf}
}

@article{ennisConfusableDiscriminableStimuli,
  title = {Confusable and {{Discriminable Stimuli}}: {{Comment}} on {{Nosofsky}} (1986) and {{Shepard}} (1986)},
  author = {Ennis, Daniel M},
  pages = {4},
  langid = {english},
  file = {/Users/thomasgorman/Zotero/storage/6X59D4MX/Ennis - Confusable and Discriminable Stimuli Comment on N.pdf}
}

@article{ericksonRulesExemplarsCategory1998,
  title = {Rules and {{Exemplars}} in {{Category Learning}}},
  author = {Erickson, Michael A and Kruschke, John K},
  year = {1998},
  journal = {Journal of Experimental Psychology. General},
  volume = {127},
  number = {2},
  pages = {107--140},
  abstract = {Psychological theories of categorization generally focus on either rule- or exemplar-based explanations. We present 2 experiments that show evidence of both rule induction and exemplar encoding as well as a connectionist model, ATRIUM, that specifies a mechanism for combining rule- and exemplar-based representation. In 2 experiments participants learned to classify items, most of which followed a simple rule, although there were a few frequently occurring exceptions. Experiment 1 examined how people extrapolate beyond the range of training. Experiment 2 examined the effect of instance frequency on generalization. Categorization behavior was well described by the model, in which exemplar representation is used for both rule and exception processing. A key element in correctly modeling these results was capturing the interaction between the rule- and exemplar-based representations by using shifts of attention between rules and exemplars.},
  langid = {english},
  file = {/Users/thomasgorman/Documents/Zotero_Markdown/ericksonRulesExemplarsCategory1998-zotero.md;/Users/thomasgorman/Zotero/storage/JNCXBZJS/Erickson and Kruschke - Rules and Exemplars in Category Learning.pdf}
}

@article{ernstLearningIntegrateArbitrary2007,
  title = {Learning to Integrate Arbitrary Signals from Vision and Touch},
  author = {Ernst, Marc O.},
  year = {2007},
  month = jun,
  journal = {Journal of Vision},
  volume = {7},
  number = {5},
  pages = {7.1-14},
  issn = {1534-7362},
  doi = {10.1167/7.5.7},
  abstract = {When different perceptual signals of the same physical property are integrated, for example, an objects' size, which can be seen and felt, they form a more reliable sensory estimate (e.g., M. O. Ernst \& M. S. Banks, 2002). This, however, implies that the sensory system already knows which signals belong together and how they relate. In other words, the system has to know the mapping between the signals. In a Bayesian model of cue integration, this prior knowledge can be made explicit. Here, we ask whether such a mapping between two arbitrary sensory signals from vision and touch can be learned from their statistical co-occurrence such that they become integrated. In the Bayesian framework, this means changing the belief about the distribution of the stimuli. To this end, we trained subjects with stimuli that are usually unrelated in the world--the luminance of an object (visual signal) and its stiffness (haptic signal). In the training phase, we then presented subjects with combinations of these two signals, which were artificially correlated, and thus, we introduced a new mapping between them. For example, the stiffer the object, the brighter it was. We measured the influence of learning by comparing discrimination performance before and after training. The prediction is that integration makes discrimination worse for stimuli, which are incongruent with the newly learned mapping, because integration would cause this incongruency to disappear perceptually. The more certain subjects are about the new mapping, the stronger should the influence be on discrimination performance. Thus, learning in this context is about acquiring beliefs. We found a significant change in discrimination performance before and after training when comparing trials with congruent and incongruent stimuli. After training, discrimination thresholds for the incongruent stimuli are increased relative to thresholds for congruent stimuli, suggesting that subjects learned effectively to integrate the two formerly unrelated signals.},
  langid = {english},
  pmid = {18217847},
  keywords = {Adult,Bayes Theorem,Cues,Differential Threshold,{Discrimination, Psychological},Female,Form Perception,Humans,Learning,Male,{Models, Psychological},Touch,{Vision, Ocular}},
  file = {/Users/thomasgorman/Documents/Zotero_Markdown/ernst_learning_2007-zotero.md;/Users/thomasgorman/OneDrive - Indiana University/resources/Zotero/Ernst_2007_Learning to integrate arbitrary signals from vision and touch.pdf}
}

@article{estesBaseRateEffectsCategory,
  title = {Base-{{Rate Effects}} in {{Category Learning}}: {{A Comparison}} of {{Parallel Network}} and {{Memory Storage-Retrieval Models}}},
  author = {Estes, William K and Campbell, Jane A and Hatsopoulos, Nicholas and Hurwitz, Joshua B},
  pages = {16},
  langid = {english},
  file = {/Users/thomasgorman/Zotero/storage/DHDYRW5N/Estes et al. - Base-Rate Effects in Category Learning A Comparis.pdf}
}

@book{estesClassificationCognition1994,
  title = {Classification and {{Cognition}}},
  author = {Estes, William K.},
  year = {1994},
  month = jan,
  publisher = {{Oxford University Press}},
  abstract = {Based on Estes' important Fitts Lectures, this volume details a set of psychological concepts and principles that offers a unified interpretation of a wide variety of memory, categorization, and decision-making phenomena. These phenomena are explained via two families of models established by the author: a storage-retrieval model and an adaptive network model. Estes considers whether the models are competing or complementary, offering cogent and instructive arguments for both perspectives. Estes' theory is then applied to two large-scale series of studies on category learning and recognition, providing an integrated understanding of seemingly disparate phenomena. This book is the culmination of the author's more than ten years of research in the field, and stands as a great achievement by one of this century's eminent psychologists. It will be indispensable to a wide variety of behavioral scientists, including mathematical and cognitive psychologists.},
  googlebooks = {xsP2CPEvzBEC},
  isbn = {978-0-19-536088-2},
  langid = {english},
  file = {/Users/thomasgorman/Zotero/storage/F423PW5J/Estes - 1994 - Classification and Cognition.pdf}
}

@article{estesTheoryStimulusVariability1953,
  title = {A Theory of Stimulus Variability in Learning.},
  author = {Estes, W. K. and Burke, C. J.},
  year = {1953},
  journal = {Psychological Review},
  volume = {60},
  number = {4},
  pages = {276--286},
  issn = {1939-1471, 0033-295X},
  doi = {10.1037/h0055775},
  urldate = {2020-09-07},
  langid = {english},
  file = {/Users/thomasgorman/Zotero/storage/2M8U4JYM/Estes and Burke - 1953 - A theory of stimulus variability in learning..pdf}
}

@phdthesis{fadlerIndividualDifferencesFunction2012,
  title = {Individual {{Differences}} in {{Function Learning}} as {{They Relate}} to the {{Learning}} of {{Conceptual Information}}},
  author = {Fadler, Cynthia},
  year = {2012},
  abstract = {Individual differences have not often been considered within the problemsolving or concept-learning literatures despite the indication that some individuals are better able to transfer to novel problems and that manipulations in strategy can effectively increase the ability to transfer (Gick \& Holyoak, 1983). Research in the function-learning domain indicates that there may be two qualitatively different types of learners: those who remember distinct example associations (exemplar learners) and others who abstract rules that govern each association (rule learners; DeLosh, Busemeyer, \& McDaniel, 1997). Data from two unpublished studies (McDaniel, Cahill, Robbins, \& Trumpower, 2012; Fadler, Lee, Scullin, Shelton, \& McDaniel, 2012) have demonstrated the stability of these two types of learning across a variety of different higher order problem-solving, concept-learning, and cognitive tasks. However, it remains to be seen whether these differences between learners have implications for the type of conceptual material often used in classrooms.  In the current project, this issue was addressed through two experiments. During Experiment 1, participants were first identified as exemplar or rule-based learners on the basis of function learning transfer performance. Each group then read several passages and answered questions about the passages that ranged in their degree of transfer. Rule learners performed better than exemplar learners on each question type and the two types of learners also demonstrated qualitatively different processing during function learning training  iii and on a test of analogical transfer. The data from Experiment 2 showed that rule learners behaved qualitatively differently from exemplar learners during function learning training but failed to replicate the passage data from Experiment 1. However, a benefit was found on recognition memory for exemplar learners on a concept-learning task.  The current study is the first to show differential benefits for exemplar and rule-based processing. It also provides evidence that function-learning tendency can be used to predict differences on concept-learning tasks and that only rule learning is associated with abstraction ability. The findings suggest that individual differences should be considered both in current hybrid models of categorization, but also potentially in classrooms that might rely heavily on problem solving, where the differences in types of learners may have an impact on student performance and understanding},
  langid = {english},
  file = {/Users/thomasgorman/Documents/Zotero_Markdown/fadler_individual_2012-zotero.md;/Users/thomasgorman/OneDrive - Indiana University/resources/Zotero/Fadler_Individual Differences in Function Learning as They Relate to the Learning of.pdf}
}

@article{falandaysDecisionMakingHumanMachineInterface2021,
  title = {Decision-{{Making}} in the {{Human-Machine Interface}}},
  author = {Falandays, J. Benjamin and Spevack, Samuel and P{\"a}rnamets, Philip and Spivey, Michael},
  year = {2021},
  journal = {Frontiers in Psychology},
  volume = {12},
  issn = {1664-1078},
  urldate = {2022-07-08},
  abstract = {If our choices make us who we are, then what does that mean when these choices are made in the human-machine interface? Developing a clear understanding of how human decision making is influenced by automated systems in the environment is critical because, as human-machine interfaces and assistive robotics become even more ubiquitous in everyday life, many daily decisions will be an emergent result of the interactions between the human and the machine \textendash{} not stemming solely from the human. For example, choices can be influenced by the relative locations and motor costs of the response options, as well as by the timing of the response prompts. In drift diffusion model simulations of response-prompt timing manipulations, we find that it is only relatively equibiased choices that will be successfully influenced by this kind of perturbation. However, with drift diffusion model simulations of motor cost manipulations, we find that even relatively biased choices can still show some influence of the perturbation. We report the results of a two-alternative forced-choice experiment with a computer mouse modified to have a subtle velocity bias in a pre-determined direction for each trial, inducing an increased motor cost to move the cursor away from the pre-designated target direction. With queries that have each been normed in advance to be equibiased in people's preferences, the participant will often begin their mouse movement before their cognitive choice has been finalized, and the directional bias in the mouse velocity exerts a small but significant influence on their final choice. With queries that are not equibiased, a similar influence is observed. By exploring the synergies that are developed between humans and machines and tracking their temporal dynamics, this work aims to provide insight into our evolving decisions.},
  file = {/Users/thomasgorman/OneDrive - Indiana University/resources/Zotero/Falandays et al_2021_Decision-Making in the Human-Machine Interface.pdf}
}

@article{fansherGraphsNotLead2022,
  title = {Graphs Do Not Lead People to Infer Causation from Correlation},
  author = {Fansher, Madison and Adkins, Tyler J. and Shah, Priti},
  year = {2022},
  journal = {Journal of Experimental Psychology: Applied},
  volume = {28},
  number = {2},
  pages = {314--328},
  issn = {1939-2192},
  doi = {10.1037/xap0000393},
  abstract = {Media articles often communicate the latest scientific findings, and readers must evaluate the evidence and consider its potential implications. Prior work has found that the inclusion of graphs makes messages about scientific data more persuasive (Tal \& Wansink, 2016). One explanation for this finding is that such visualizations evoke the notion of ``science''; however, results are mixed. In the current investigation we extend this work by examining whether graphs lead people to erroneously infer causation from correlational data. In two experiments we gave participants realistic online news articles in which they were asked to evaluate the research and apply the work's findings to a real-life hypothetical scenario. Participants were assigned to read the text of the article alone or with an accompanying line or bar graph. We found no evidence that the presence of graphs affected participants' evaluations of correlational data as causal. Given that these findings were unexpected, we attempted to directly replicate a well-cited article making the claim that graphs are persuasive (Tal \& Wansink, 2016), but we were unsuccessful. Overall, our results suggest that the mere presence of graphs does not necessarily increase the likelihood that one infers incorrect causal claims. (PsycInfo Database Record (c) 2022 APA, all rights reserved)},
  keywords = {Causality,Graphical Displays,Imagery,Inclusion,Messages,Persuasion,Reasoning},
  annotation = {https://osf.io/7zc4a/?view\_only=520ccf9c06024291857dc481af05df3c},
  file = {/Users/thomasgorman/Library/CloudStorage/OneDrive-IndianaUniversity/Resources/Zotero/Fansher et al_2022_Graphs do not lead people to infer causation from correlation.pdf;/Users/thomasgorman/Zotero/storage/VBML3V94/2022-36700-001.html}
}

@article{fansherHowWellOrdinary2022,
  title = {How Well Do Ordinary {{Americans}} Forecast the Growth of {{COVID-19}}?},
  author = {Fansher, Madison and Adkins, Tyler J. and Lewis, Richard L. and Boduroglu, Aysecan and Lalwani, Poortata and Quirk, Madelyn and Shah, Priti and Jonides, John},
  year = {2022},
  month = mar,
  journal = {Memory \& Cognition},
  issn = {1532-5946},
  doi = {10.3758/s13421-022-01288-0},
  urldate = {2022-05-20},
  abstract = {Across three experiments (N = 1565), we investigated how forecasts about the spread of COVID 19 are impacted by data trends, and whether patterns of misestimation predict adherence to social-distancing guidelines. We also investigated how mode of data presentation influences forecasting of future cases by showing participants data on the number of COVID-19 cases from a 5-week period in either graphical, tabular, or text-only form. We consistently found that people shown tables produced more accurate forecasts compared to people shown line-graphs of the same data; yet people shown line-graphs were more confident in their estimates. These findings suggest that graphs engender false-confidence in the accuracy of forecasts, that people's forecasts of future cases have important implications for their attitudes concerning social distancing, and that tables may be better than graphs for informing the public about the trajectory of COVID-19.},
  langid = {english},
  keywords = {COVID-19,Data visualization,Forecasting},
  file = {/Users/thomasgorman/Documents/Zotero_Markdown/fansher_how_2022-zotero.md;/Users/thomasgorman/OneDrive - Indiana University/resources/Zotero/Fansher et al_2022_How well do ordinary Americans forecast the growth of COVID-19.pdf}
}

@article{fificLogicalRuleModelsClassification2010,
  title = {Logical-{{Rule Models}} of {{Classification Response Times}}: {{A Synthesis}} of {{Mental-Architecture}}, {{Random-Walk}}, and {{Decision-Bound Approaches}}},
  shorttitle = {Logical-{{Rule Models}} of {{Classification Response Times}}},
  author = {Fific, Mario and Little, Daniel R. and Nosofsky, Robert M.},
  year = {2010},
  month = apr,
  journal = {Psychological review},
  volume = {117},
  number = {2},
  pages = {309--348},
  issn = {0033-295X},
  doi = {10.1037/a0018526},
  urldate = {2021-01-07},
  abstract = {We formalize and provide tests of a set of logical-rule models for predicting perceptual classification response times (RTs) and choice probabilities. The models are developed by synthesizing mental-architecture, random-walk, and decision-bound approaches. According to the models, people make independent decisions about the locations of stimuli along a set of component dimensions. Those independent decisions are then combined via logical rules to determine the overall categorization response. The time course of the independent decisions is modeled via random-walk processes operating along individual dimensions. Alternative mental architectures are used as mechanisms for combining the independent decisions to implement the logical rules. We derive fundamental qualitative contrasts for distinguishing among the predictions of the rule models and major alternative models of classification RT. We also use the models to predict detailed RT distribution data associated with individual stimuli in tasks of speeded perceptual classification.},
  pmcid = {PMC2869285},
  pmid = {20438229},
  file = {/Users/thomasgorman/OneDrive - Indiana University/resources/Zotero/Fific et al_2010_Logical-Rule Models of Classification Response Times2.pdf}
}

@techreport{forsgrenFurtherPerceptionsProbability2020,
  type = {Preprint},
  title = {Further Perceptions of Probability: In Defence of Trial-by-Trial Estimation Models},
  shorttitle = {Further Perceptions of Probability},
  author = {Forsgren, Mattias and Juslin, Peter and {van den Berg}, Ronald},
  year = {2020},
  month = jan,
  institution = {{Animal Behavior and Cognition}},
  doi = {10.1101/2020.01.30.927558},
  urldate = {2022-05-27},
  abstract = {Many events we experience are binary and probabilistic, such as the weather (rain or no rain) and the outcome of medical tests (negative or positive). Extensive research in the behavioural sciences has addressed people's ability to learn stationary probabilities (i.e., probabilities that stay constant over time) of such events, but only recently have there been attempts to model the cognitive processes whereby people learn \textendash{} and track \textendash{}             non-stationary             probabilities. The old debate on whether learning occurs trial-by-trial or by occasional shifts between discrete hypotheses has been revived in this context. Trial-by-trial estimation models \textendash{} such as the delta-rule model \textendash{} have been successful in describing human learning in various contexts. It has been argued, however, that behaviour on non-stationary probability learning tasks is incompatible with trial-by-trial learning and can only be explained by models in which learning proceeds through hypothesis testing. Here, we show that this conclusion was premature. By combining two well-supported concepts from cognitive modelling \textendash{} delta-rule learning and drift diffusion evidence accumulation \textendash{} we reproduce all behavioural phenomena that were previously used to reject trial-by-trial learning models. Moreover, a quantitative model comparison shows that this model accounts for the data better than a model based on hypothesis testing. In the spirit of cumulative science, our results demonstrate that a combination of two well-established theories of trial-by-trial learning and evidence accumulation is sufficient to explain human learning of non-stationary probabilities.},
  langid = {english},
  file = {/Users/thomasgorman/Documents/Zotero_Markdown/forsgren_further_2020-zotero.md;/Users/thomasgorman/OneDrive - Indiana University/resources/Zotero/Forsgren et al_2020_Further perceptions of probability.pdf}
}

@article{freundNeuralCodingCognitive2021,
  title = {Neural {{Coding}} of {{Cognitive Control}}: {{The Representational Similarity Analysis Approach}}},
  shorttitle = {Neural {{Coding}} of {{Cognitive Control}}},
  author = {Freund, Michael C. and Etzel, Joset A. and Braver, Todd S.},
  year = {2021},
  month = jul,
  journal = {Trends in Cognitive Sciences},
  volume = {25},
  number = {7},
  pages = {622--638},
  issn = {13646613},
  doi = {10.1016/j.tics.2021.03.011},
  urldate = {2021-10-02},
  langid = {english},
  file = {/Users/thomasgorman/OneDrive - Indiana University/resources/Zotero/Freund et al_2021_Neural Coding of Cognitive Control.pdf}
}

@article{friedmanComparisonLearningModels1995,
  title = {A {{Comparison}} of {{Learning Models}}},
  author = {Friedman, Daniel and Massaro, Dominic W. and Kitzis, Stephen N. and Cohen, Michael M.},
  year = {1995},
  month = jun,
  journal = {Journal of Mathematical Psychology},
  volume = {39},
  number = {2},
  pages = {164--178},
  issn = {0022-2496},
  doi = {10.1006/jmps.1995.1018},
  urldate = {2019-04-13},
  abstract = {We investigate learning in a probabilistic task, called "medical diagnosis." On each trial, a subject is presented with a stimulus configuration indicating the value of four medical symptoms. The subject responds by guessing which of two diseases is present and is then given feedback about which disease was actually present. The feedback is determined according to fixed conditional probabilities unknown to the subject. We test a normative Bayesian model as well as simple variants of well-known psychological models including the Fuzzy Logical Model of Perception, an Exemplar model, a two-layer Connectionist model and an ALCOVE model. Both the asymptotic predictions of these models (i.e., predictions regarding behavior after it has stabilized and learning is complete) and predictions of trial-by-trial changes in behavior are tested. The models are tested against existing data from Estes et al. (1989, Journal of Experimental Psychology: Learning, Memory, \& Cognition,15, 556-571) and new data from medical diagnosis tasks that include not only asymmetric but also symmetric base rates. Learning was observed in all cases in that subjects tended to match the objective probabilities of the symptom configurations more closely in later trials. All of the descriptive models give a more accurate account of performance than the normative Bayesian model. Relative to a benchmark measure, however, none of these models does an especially good job of characterizing asymptotic performance or the learning process. We suggest that future experiments should address individual performance, rather than group learning curves.},
  file = {/Users/thomasgorman/Zotero/storage/EXRYXY4B/Friedman et al. - 1995 - A Comparison of Learning Models.pdf;/Users/thomasgorman/Zotero/storage/5JERJRQD/S0022249685710188.html}
}

@article{fulvioTaskSpecificResponseStrategy2014,
  title = {Task-{{Specific Response Strategy Selection}} on the {{Basis}} of {{Recent Training Experience}}},
  author = {Fulvio, Jacqueline M. and Green, C. Shawn and Schrater, Paul R.},
  year = {2014},
  month = jan,
  journal = {PLOS Computational Biology},
  volume = {10},
  number = {1},
  pages = {e1003425},
  publisher = {{Public Library of Science}},
  issn = {1553-7358},
  doi = {10.1371/journal.pcbi.1003425},
  urldate = {2020-07-17},
  abstract = {The goal of training is to produce learning for a range of activities that are typically more general than the training task itself. Despite a century of research, predicting the scope of learning from the content of training has proven extremely difficult, with the same task producing narrowly focused learning strategies in some cases and broadly scoped learning strategies in others. Here we test the hypothesis that human subjects will prefer a decision strategy that maximizes performance and reduces uncertainty given the demands of the training task and that the strategy chosen will then predict the extent to which learning is transferable. To test this hypothesis, we trained subjects on a moving dot extrapolation task that makes distinct predictions for two types of learning strategy: a narrow model-free strategy that learns an input-output mapping for training stimuli, and a general model-based strategy that utilizes humans' default predictive model for a class of trajectories. When the number of distinct training trajectories is low, we predict better performance for the mapping strategy, but as the number increases, a predictive model is increasingly favored. Consonant with predictions, subject extrapolations for test trajectories were consistent with using a mapping strategy when trained on a small number of training trajectories and a predictive model when trained on a larger number. The general framework developed here can thus be useful both in interpreting previous patterns of task-specific versus task-general learning, as well as in building future training paradigms with certain desired outcomes.},
  langid = {english},
  file = {/Users/thomasgorman/Documents/Zotero_Markdown/fulvio_task-specific_2014-zotero.md;/Users/thomasgorman/OneDrive - Indiana University/resources/Zotero/Fulvio et al_2014_Task-Specific Response Strategy Selection on the Basis of Recent Training.pdf;/Users/thomasgorman/OneDrive - Indiana University/resources/Zotero/Fulvio et al_2014_Task-Specific Response Strategy Selection on the Basis of Recent Training2.docx;/Users/thomasgorman/Zotero/storage/S25TU5I4/article.html}
}

@article{gelpiSamplingHeuristicsActive2021,
  title = {Sampling {{Heuristics}} for {{Active Function Learning}}},
  author = {Gelpi, Rebekah A and Lifchits, George and Lucas, Christopher G},
  year = {2021},
  pages = {7},
  abstract = {People are capable of learning diverse functional relationships from data; nevertheless, they are most accurate when learning linear relationships, and deviate further from estimating the true relationship when presented with non-linear functions. We investigate whether, when given the opportunity to learn actively, people choose samples in an efficient fashion, and whether better sampling policies improve their ability to learn linear and non-linear functions. We find that, across multiple different function families, people make informative sampling choices consistent with a simple, low-effort policy that minimizes uncertainty at extreme values without requiring adaptation to evidence. While participants were most accurate at learning linear functions, those who more closely adhered to the simple sampling strategy also made better predictions across all non-linear functions. We discuss how the use of this heuristic might reflect rational allocation of limited cognitive resources.},
  langid = {english},
  file = {/Users/thomasgorman/Documents/Zotero_Markdown/gelpi_sampling_2021-zotero.md;/Users/thomasgorman/Documents/Zotero_Markdown/gelpiSamplingHeuristicsActive2021-zotero.md;/Users/thomasgorman/OneDrive - Indiana University/resources/Zotero/Gelpi et al_Sampling Heuristics for Active Function Learning.pdf}
}

@article{geneweinStructureLearningBayesian2015,
  title = {Structure {{Learning}} in {{Bayesian Sensorimotor Integration}}},
  author = {Genewein, Tim and Hez, Eduard and Razzaghpanah, Zeynab and Braun, Daniel A.},
  year = {2015},
  month = aug,
  journal = {PLOS Computational Biology},
  volume = {11},
  number = {8},
  pages = {e1004369},
  publisher = {{Public Library of Science}},
  issn = {1553-7358},
  doi = {10.1371/journal.pcbi.1004369},
  urldate = {2020-11-03},
  abstract = {Previous studies have shown that sensorimotor processing can often be described by Bayesian learning, in particular the integration of prior and feedback information depending on its degree of reliability. Here we test the hypothesis that the integration process itself can be tuned to the statistical structure of the environment. We exposed human participants to a reaching task in a three-dimensional virtual reality environment where we could displace the visual feedback of their hand position in a two dimensional plane. When introducing statistical structure between the two dimensions of the displacement, we found that over the course of several days participants adapted their feedback integration process in order to exploit this structure for performance improvement. In control experiments we found that this adaptation process critically depended on performance feedback and could not be induced by verbal instructions. Our results suggest that structural learning is an important meta-learning component of Bayesian sensorimotor integration.},
  langid = {english},
  keywords = {Covariance,Experimental design,Human learning,Learning,Radii,Sensory perception,Virtual reality,Vision},
  file = {/Users/thomasgorman/Documents/Zotero_Markdown/geneweinStructureLearningBayesian2015-zotero.md;/Users/thomasgorman/OneDrive - Indiana University/resources/Zotero/Genewein et al_2015_Structure Learning in Bayesian Sensorimotor Integration.pdf;/Users/thomasgorman/Zotero/storage/I8QTXZ4X/article.html}
}

@article{georgeContextualModulationAttention2012,
  title = {Contextual Modulation of Attention in Human Category Learning},
  author = {George, David N. and Kruschke, John K.},
  year = {2012},
  month = dec,
  journal = {Learning \& Behavior},
  volume = {40},
  number = {4},
  pages = {530--541},
  issn = {1543-4494, 1543-4508},
  doi = {10.3758/s13420-012-0072-8},
  urldate = {2021-12-11},
  abstract = {In a category-learning experiment, we assessed whether participants were able to selectively attend to different components of a compound stimulus in two distinct contexts. The participants were presented with stimulus compounds for which they had to learn categorical labels. Each compound comprised one feature from each of two dimensions, and on different trials the compound was presented in two contexts, X and Y. In Context X, Dimension A was relevant to the solution of the categorization task and Dimension B was irrelevant, whereas in Context Y, Dimension A was irrelevant and Dimension B was relevant. The results of transfer tests to novel stimuli suggested that people learned to attend selectively to Dimension A in Context X and Dimension B in Context Y. These findings contribute to the growing body of evidence that people can learn to selectively attend to particular dimensions of stimuli dependent on the context in which the stimuli are presented. Furthermore, the findings demonstrate that context-dependent changes in attention transfer to other categorization tasks involving novel stimuli.},
  langid = {english},
  file = {/Users/thomasgorman/OneDrive - Indiana University/resources/Zotero/George_Kruschke_2012_Contextual modulation of attention in human category learning.pdf}
}

@phdthesis{ghadieHowWorkingMemory2020,
  type = {Master of {{Arts}}},
  title = {How {{Working Memory Moderates Function Learning Behaviour}}: {{A Dual-Task Paradigm}}},
  shorttitle = {How {{Working Memory Moderates Function Learning Behaviour}}},
  author = {Ghadie, Billal},
  year = {2020},
  address = {{Ottawa, Ontario}},
  doi = {10.22215/etd/2020-14207},
  urldate = {2022-04-20},
  abstract = {A breadth of research has demonstrated that many cognitive phenomena can be explained by a dual-processing account. However, little research has attempted to apply a dual-task paradigm to function learning. The present thesis aims to fill this gap in the literature by exploring the relationship between working memory and function learning behaviour. Eighty Carleton University students were randomly assigned to learn either a linear or bilinear function. Moreover, participants were randomly assigned to complete training and transfer under either single- or dual-task conditions. It was hypothesized that the secondary task would hinder performance resulting in a dependency on exemplar-based learning. Using a novel classification approach, the results showed that the secondary task reduced the stability of learning approach. However, the results remain inconclusive due to low power. Therefore, additional research is required to determine whether dual-task paradigms can be used to distinguish between rule- and exemplar-based processing in function learning.},
  langid = {english},
  school = {Carleton University},
  file = {/Users/thomasgorman/Documents/Zotero_Markdown/ghadie_how_2020-zotero.md;/Users/thomasgorman/OneDrive - Indiana University/resources/Zotero/Ghadie_2020_How Working Memory Moderates Function Learning Behaviour.pdf}
}

@article{ghahramaniModularDecompositionVisuomotor1997,
  title = {Modular Decomposition in Visuomotor Learning},
  author = {Ghahramani, Z. and Wolpert, D. M.},
  year = {1997},
  month = mar,
  journal = {Nature},
  volume = {386},
  number = {6623},
  pages = {392--395},
  issn = {0028-0836},
  doi = {10.1038/386392a0},
  abstract = {The principle of 'divide-and-conquer' the decomposition of a complex task into simpler subtasks each learned by a separate module, has been proposed as a computational strategy during learning. We explore the possibility that the human motor system uses such a modular decomposition strategy to learn the visuomotor map, the relationship between visual inputs and motor outputs. Using a virtual reality system, subjects were exposed to opposite prism-like visuomotor remappings-discrepancies between actual and visually perceived hand locations- for movements starting from two distinct locations. Despite this conflicting pairing between visual and motor space, subjects learned the two starting-point-dependent visuomotor mappings and the generalization of this learning to intermediate starting locations demonstrated an interpolation of the two learned maps. This interpolation was a weighted average of the two learned visuomotor mappings, with the weighting sigmoidally dependent on starting location, a prediction made by a computational model of modular learning known as the "mixture of experts". These results provide evidence that the brain may employ a modular decomposition strategy during learning.},
  langid = {english},
  pmid = {9121554},
  keywords = {Feedback,Hand,Humans,Learning,{Models, Neurological},Motor Activity,Psychomotor Performance,Visual Perception},
  file = {/Users/thomasgorman/Documents/Zotero_Markdown/ghahramani_modular_1997-zotero.md;/Users/thomasgorman/OneDrive - Indiana University/resources/Zotero/Ghahramani_Wolpert_1997_Modular decomposition in visuomotor learning.pdf}
}

@article{gibsonHumanSemiSupervisedLearning2013,
  title = {Human {{Semi-Supervised Learning}}},
  author = {Gibson, Bryan R. and Rogers, Timothy T. and Zhu, Xiaojin},
  year = {2013},
  journal = {Topics in Cognitive Science},
  volume = {5},
  number = {1},
  pages = {132--172},
  issn = {1756-8765},
  doi = {10.1111/tops.12010},
  urldate = {2020-09-02},
  abstract = {Most empirical work in human categorization has studied learning in either fully supervised or fully unsupervised scenarios. Most real-world learning scenarios, however, are semi-supervised: Learners receive a great deal of unlabeled information from the world, coupled with occasional experiences in which items are directly labeled by a knowledgeable source. A large body of work in machine learning has investigated how learning can exploit both labeled and unlabeled data provided to a learner. Using equivalences between models found in human categorization and machine learning research, we explain how these semi-supervised techniques can be applied to human learning. A series of experiments are described which show that semi-supervised learning models prove useful for explaining human behavior when exposed to both labeled and unlabeled data. We then discuss some machine learning models that do not have familiar human categorization counterparts. Finally, we discuss some challenges yet to be addressed in the use of semi-supervised models for modeling human categorization.},
  langid = {english},
  keywords = {Category learning,Machine learning,Semi-supervised learning},
  file = {/Users/thomasgorman/Zotero/storage/UI5PV797/Gibson et al. - 2013 - Human Semi-Supervised Learning.pdf;/Users/thomasgorman/Zotero/storage/4NDNSACR/tops.html}
}

@article{goldstoneUsingRelationsConceptual2002,
  title = {Using Relations within Conceptual Systems to Translate across Conceptual Systems},
  author = {Goldstone, Robert L. and Rogosky, Brian J.},
  year = {2002},
  month = jul,
  journal = {Cognition},
  volume = {84},
  number = {3},
  pages = {295--320},
  issn = {00100277},
  doi = {10.1016/S0010-0277(02)00053-7},
  urldate = {2020-12-22},
  abstract = {According to an ``external grounding'' theory of meaning, a concept's meaning depends on its connection to the external world. By a ``conceptual web'' account, a concept's meaning depends on its relations to other concepts within the same system. We explore one aspect of meaning, the identification of matching concepts across systems (e.g. people, theories, or cultures). We present a computational algorithm called ABSURDIST (Aligning Between Systems Using Relations Derived Inside Systems for Translation) that uses only within-system similarity relations to find between-system translations. While illustrating the sufficiency of a conceptual web account for translating between systems, simulations of ABSURDIST also indicate powerful synergistic interactions between intrinsic, within-system information and extrinsic information. q 2002 Elsevier Science B.V. All rights reserved.},
  langid = {english},
  file = {/Users/thomasgorman/Zotero/storage/CSH3JRE9/Goldstone - 2002 - Using relations within conceptual systems to trans.pdf}
}

@article{gongIntuitionsPerceptualConstraints,
  title = {Intuitions and Perceptual Constraints on Causal Learning from Dynamics},
  author = {Gong, Tianwei and Bramley, Neil R},
  pages = {8},
  langid = {english},
  file = {/Users/thomasgorman/Documents/Zotero_Markdown/gong_intuitions_nodate-zotero.md;/Users/thomasgorman/OneDrive - Indiana University/resources/Zotero/Gong_Bramley_Intuitions and perceptual constraints on causal learning from dynamics.pdf}
}

@article{goodeSuperiorityVariableRepeated2008,
  title = {Superiority of Variable to Repeated Practice in Transfer on Anagram Solution},
  author = {Goode, M. K. and Geraci, L. and Roediger, H. L.},
  year = {2008},
  month = jun,
  journal = {Psychonomic Bulletin \& Review},
  volume = {15},
  number = {3},
  pages = {662--666},
  issn = {1069-9384, 1531-5320},
  doi = {10.3758/PBR.15.3.662},
  urldate = {2019-03-14},
  langid = {english},
  keywords = {Benefit of Variability,Variability},
  file = {/Users/thomasgorman/Zotero/storage/LSEQDXNB/Goode et al. - 2008 - Superiority of variable to repeated practice in tr.pdf}
}

@article{gouravajhalaIndividualAgeDifferences2020,
  title = {Individual and Age Differences in Block-by-Block Dynamics of Category Learning Strategies},
  author = {Gouravajhala, Reshma and Wahlheim, Christopher N and McDaniel, Mark A},
  year = {2020},
  month = apr,
  journal = {Quarterly Journal of Experimental Psychology},
  volume = {73},
  number = {4},
  pages = {578--593},
  issn = {1747-0218, 1747-0226},
  doi = {10.1177/1747021819892584},
  urldate = {2020-09-08},
  abstract = {The present experiment examined individual and age differences in the dynamics of category learning strategies. Participants learned categories determined by a disjunctive rule with relational features through a feedback training procedure. During training, participants responded to strategy probes following each block to provide online assessment of the extent to which rule- and exemplar-based strategies were used throughout the training period. We introduced this measure as an alternative to model-based approaches to assessing individual differences in strategy use during training. Following training, participants classified ambiguous transfer objects that were assumed to distinguish between earlier use of rule- and exemplar-based learning strategies. We included this measure to obtain a relatively objective index of strategy use during training. Next, participants provided global ratings of their use of rule- and exemplar-based strategies during training. Results showed that strategy preferences expressed on the final training block predicted categorisation of ambiguous transfer objects better than global strategy reports. In addition, we utilised the block-by-block strategy reports to investigate the dynamics of learners' strategy preferences over the course of training. The findings revealed greater fluidity in strategy preferences for both younger and older adults than has been previously documented in the category learning literature. The novel block-by-block strategy reports in conjunction with the transfer-based approach allowed for a more nuanced examination of individual and age differences in strategy use and categorisation performance.},
  langid = {english},
  file = {/Users/thomasgorman/OneDrive - Indiana University/resources/Zotero/Gouravajhala et al_2020_Individual and age differences in block-by-block dynamics of category learning.pdf}
}

@article{grangeMixturPackageDesigning,
  title = {Mixtur: {{An R}} Package for Designing, Analysing, and Modelling Continuous Report Visual Short-Term Memory Studies},
  author = {Grange, James A and Moore, Stuart B},
  pages = {48},
  abstract = {Visual short-term memory (vSTM) is often measured via continuous-report tasks whereby participants are presented with stimuli that vary along a continuous dimension (e.g., colour) with the goal of memorising the stimulus features. At test, participants are probed to recall the feature value of one of the memoranda in a continuous manner (e.g., by clicking on a colour wheel). The angular deviation between the participant response and the true feature value provides an estimate of recall precision. Two prominent models of performance on such tasks are the two- and three-component mixture models (Bays et al., 2009; Zhang \& Luck, 2008). Both models decompose participant responses into probabilistic mixtures of: (1) responses to the true target value based on a noisy memory representation; (2) random guessing when memory fails. In addition, the three-component model proposes (3) responses to a non-target feature value (i.e., binding errors). Here we report the development of mixtur, an open-source package written for the statistical programming language R that facilitates the fitting of the 2- and 3-component mixture models to continuous report data. We also conduct simulations to develop recommendations for researchers on trial numbers, set-sizes and memoranda similarity, as well as parameter recovery and model recovery. In the Discussion, we discuss how mixtur can be used to fit the slots and the slots-plus-averaging models, as well as how mixtur can be extended to fit explanatory models of visual short-term memory. It is our hope that mixtur will lower the barrier of entry for utilising mixture modelling.},
  langid = {english},
  file = {/Users/thomasgorman/OneDrive - Indiana University/resources/Zotero/Grange_Moore_mixtur.pdf}
}

@article{grangeMixturPackageDesigning2022,
  title = {Mixtur: {{An R}} Package for Designing, Analysing, and Modelling Continuous Report Visual Short-Term Memory Studies},
  shorttitle = {Mixtur},
  author = {Grange, James A. and Moore, Stuart B.},
  year = {2022},
  month = jan,
  journal = {Behavior Research Methods},
  issn = {1554-3528},
  doi = {10.3758/s13428-021-01688-1},
  urldate = {2022-04-27},
  abstract = {Visual short-term memory (vSTM) is often measured via continuous-report tasks whereby participants are presented with stimuli that vary along a continuous dimension (e.g., colour) with the goal of memorising the stimulus features. At test, participants are probed to recall the feature value of one of the memoranda in a continuous manner (e.g., by clicking on a colour wheel). The angular deviation between the participant response and the true feature value provides an estimate of recall precision. Two prominent models of performance on such tasks are the two- and three-component mixture models (Bays et al., Journal of Vision, 9(10), Article 7, 2009; Zhang and Luck, Nature, 453(7192), 233\textendash 235, 2008). Both models decompose participant responses into probabilistic mixtures of: (1) responses to the true target value based on a noisy memory representation; (2) random guessing when memory fails. In addition, the three-component model proposes (3) responses to a non-target feature value (i.e., binding errors). Here we report the development of mixtur, an open-source package written for the statistical programming language R that facilitates the fitting of the two- and three-component mixture models to continuous report data. We also conduct simulations to develop recommendations for researchers on trial numbers, set sizes, and memoranda similarity, as well as parameter recovery and model recovery. In the Discussion, we discuss how mixtur can be used to fit the slots and the slots-plus-averaging models, as well as how mixtur can be extended to fit explanatory models of visual short-term memory. It is our hope that mixtur will lower the barrier of entry for utilising mixture modelling.},
  langid = {english},
  keywords = {Mixture modelling,R,Simulation,Visual short-term memory},
  annotation = {https://osf.io/yn9sf/},
  file = {/Users/thomasgorman/OneDrive - Indiana University/resources/Zotero/Grange_Moore_2022_mixtur.pdf}
}

@article{greenPracticeVariabilityTransfer1995a,
  title = {Practice {{Variability}} and {{Transfer}} of a {{Racket Skill}}},
  author = {Green, D. Penelope and Whitehead, Jean and Sugden, David A.},
  year = {1995},
  month = dec,
  journal = {Perceptual and Motor Skills},
  volume = {81},
  number = {3\_suppl},
  pages = {1275--1281},
  issn = {0031-5125, 1558-688X},
  doi = {10.2466/pms.1995.81.3f.1275},
  urldate = {2019-03-13},
  abstract = {This study used a forehand hitting task to explore the effect of racket variability on 'out of range' transfer. 48 11-yr.-old girls were randomly assigned to four treatment groups of Random Variability, Blocked Variabhty, Specific, and Control. The experimental groups had 32 trials for 4 successive days after which all groups were tested on 4 transfer conditions. Retention tests were given after 1, 4, and 8 days and the data were examined for treatment, range, and occasion effects. Analysis showed the superiority of practice over no practice, variable over specific practice, and random over blocked variability for transfer with two 'out of range' dimensions. Accuracy decayed between the transfer tests. These results are consistent with schema theory, and it is recommended that physical education teachers should focus variable practice on task dimensions that are new to their classes.},
  langid = {english},
  keywords = {{$>$}2 conditions,Benefit of Variability,constant control,Delayed Test,Development,Empirical,Motor,Natural Stimuli,NT-Control,Sequence,skill control,Varied Manipulation},
  file = {/Users/thomasgorman/Zotero/storage/2RE9NQE6/Green et al. - 1995 - Practice Variability and Transfer of a Racket Skil.pdf}
}

@article{griegoAdultAgeDifferences2007,
  title = {Adult {{Age Differences}} in {{Function Concept Learning}}},
  author = {Griego, Jacqueline A. and Kliegel, Matthias},
  year = {2007},
  month = dec,
  journal = {Aging, Neuropsychology, and Cognition},
  volume = {15},
  number = {1},
  pages = {1--30},
  issn = {1382-5585, 1744-4128},
  doi = {10.1080/13825580701442805},
  urldate = {2022-05-27},
  abstract = {Function concept learning and knowledge use was explored across adulthood. During training older and younger adults predicted an amount of physiological arousal produced as a negative and positive function of a chemical substance. Knowledge use was evaluated with two transfer conditions requiring a switch between contextual contingencies: a relationship inversion, predicting the chemical amount given the physiological arousal, and a change from graphic based to text based stimuli. Older adults were impaired in applying the negative slope concept. However, there was no relative deficit in switching between the negative and positive function slopes or inverting the learned relationship. Our results suggest that age-related differences in relational reasoning tasks vary not only with processing efficiency, but also task related conceptual knowledge.},
  langid = {english},
  file = {/Users/thomasgorman/Documents/Zotero_Markdown/griego_adult_2007-zotero.md;/Users/thomasgorman/OneDrive - Indiana University/resources/Zotero/Griego_Kliegel_2007_Adult Age Differences in Function Concept Learning.pdf}
}

@phdthesis{griegoEffectsTransferContext2001,
  title = {The Effects of Transfer Context on the Stability of Two Types of Conceptual Structure in a Function Concept},
  author = {Griego, Jacqueline Ann},
  year = {2001},
  address = {{United States -- New Mexico}},
  urldate = {2021-10-09},
  abstract = {The stability of rule- or exemplar-type conceptual structures was evaluated through the effects of experience, across multiple contexts, on the extrapolation of a functional relationship. The stability of extrapolation performance was assessed in Experiment 1 across three transfer tasks using experience with novel stimuli, in Experiment 2 where similarity to training stimuli was reduced for a subset of novel stimuli, and in Experiment 3 where a subset of novel stimuli were relatively more abstract than training stimuli. Individuals were first classified to type (i.e., rule or exemplar) based on one test of extrapolation using a performance criterion. Then the stability of extrapolation behavior was appraised along the dimensions of performance characteristics and empirical stability, both between and within the two types. Performance characteristics of each type were defined as extrapolation of the function relationship for rule use and limited extrapolation for exemplar use. Empirical stability was defined statistically by comparisons of performance within types and differences between types, after classification. Across the three experiments, the rule type, with limited exceptions, extrapolated the function. The exemplar type exhibited a mixture of extrapolation performance. These results were evaluated in terms of the possible performance outcomes of: type stability across experience, instability across experience, or adaptability across contexts. INTRODUCTION........................................................................................................................ 1 Introduction to Function Learning Paradigm.............................................................. 3 Relationship of Current Experiments to Past Results...................................................7 Preface to Current Experiments......................................................................................13 EXPERIMENT 1: General Stability with Experience in Extrapolation .......................... 15 Introduction...................................................................................................................... 15 Hypotheses......................................................................................................................... 16 Method................................................................................................................................. 20 Participants ..................................................................................................................... 20 Task ............................................................................................................................... 20 Criterion .......................................................................................................................... 22 Procedure...................................................................................................................... 24 Results.....................................................................................................................................25 Absolute Deviation Scores ...............................................................................25 Criterion Assessments..................................................................................... 30 Comparisons of Extrapolation Characteristics ............................................. 31 Discussion .......................................................................................................................... 34 EXPERIMENT 2: Stability With Reduction in Similarity ...................................................38 Introduction..................................................................................................................... 38 Hypotheses........................................................................................................................ 42 ix Reproduced with permission of the copyright owner. Further reproduction prohibited without permission. Method 44 Participants ...................................................................................................................... 44 Task and Procedure.........................................................................................................44 R esults......................................................................................................................................45 Absolute Deviation Scores ........................................................................................... 45 Criterion Assessments ...................................................................................................49 Comparisons o f Extrapolation Characteristics ..........................................................50 Discussion.................................................................................................................................53 EXPERIMENT 3: Stability With a Relative Abstraction o f Stimuli ............................... 55 Introduction...................................................................................................................... 55 Hypotheses........................................................................................................................ 56 Method....................................................................................................................................... 57 Participants ..................................................................................................................... 57 Task and Procedure ...................................................................................................... 57 Results........................................................................................................................................ 58 Absolute Deviation Scores ........................................................................................... 68 Criterion Assessments ................................................................................................... 61 Comparisons o f Extrapolation Characteristics ..........................................................62 Discussion...................................................................................................................................66 SUM M ARY.................................................................................................................................... 68 GENERAL DISCUSSION........................................................................................................... 72 Theoretical Conclusions ................................................................................................ 76 Lim itations......................................................................................................................... 80 REFERENCES..........................},
  copyright = {Database copyright ProQuest LLC; ProQuest does not claim copyright in the individual underlying works.},
  isbn = {9780493461489},
  langid = {english},
  school = {The University of New Mexico},
  keywords = {Causal relationships,Conceptual structure,Function concept,Psychology,Stability,Transfer context},
  file = {/Users/thomasgorman/Documents/Zotero_Markdown/griego_effects_2001-zotero.md;/Users/thomasgorman/OneDrive - Indiana University/resources/Zotero/Griego_The effects of transfer context on the stability of two types of conceptual.pdf}
}

@inproceedings{griffithsModelingHumanFunction2008,
  title = {Modeling Human Function Learning with {{Gaussian}} Processes},
  booktitle = {Advances in {{Neural Information Processing Systems}}},
  author = {Griffiths, Thomas and Lucas, Chris and Williams, Joseph and Kalish, Michael},
  year = {2008},
  volume = {21},
  publisher = {{Curran Associates, Inc.}},
  urldate = {2021-10-13},
  abstract = {Accounts of how people learn functional relationships between continuous variables have tended to focus on two possibilities: that people are estimating explicit functions, or that they are performing associative learning supported by similarity. We provide a rational analysis of function learning, drawing on work on regression in machine learning and statistics. Using the equivalence of Bayesian linear regression and Gaussian processes, we show that learning explicit rules and using similarity can be seen as two views of one solution to this problem. We use this insight to define a Gaussian process model of human function learning that combines the strengths of both approaches.},
  file = {/Users/thomasgorman/Documents/Zotero_Markdown/griffiths_modeling_2008-zotero.md;/Users/thomasgorman/OneDrive - Indiana University/resources/Zotero/Griffiths et al_2009_Modeling human function learning with Gaussian processes.pdf}
}

@article{guastelloForecastingChaoticEvents2021,
  title = {Forecasting Chaotic Events and the Prediction of a Rare Cognitive Ability},
  author = {Guastello, Stephen J. and Futch, William and Mirabito, Lucas and Green, Dominique and Marsicek, Laura and Witty, Brittany},
  year = {2021},
  month = feb,
  journal = {Personality and Individual Differences},
  volume = {170},
  pages = {110430},
  issn = {0191-8869},
  doi = {10.1016/j.paid.2020.110430},
  urldate = {2021-05-16},
  abstract = {People often live and work in chaotic environments, and thus need to forecast and control what will happen next. The management of chaos is an apparently rare skill, and it would be valuable to identify and develop this skill in the workforce. Untrained undergraduates (N~=~147) forecasted number series from four chaotic attractors of varying levels of complexity. They contributed measurements of 16PF personality traits, general intelligence, field independence, and divergent thinking. The results indicated that field independence and personality traits associated with the creative personality profile were the most frequent correlates of performance on forecasting one to four steps into the future. It should be possible to adapt the experimental results to personnel selection and placement decisions that require the search for talent for forecasting.},
  langid = {english},
  keywords = {16PF traits,Chaos,Complex systems,Creativity,Divergent,Forecasting},
  file = {/Users/thomasgorman/Documents/Zotero_Markdown/guastello_forecasting_2021-zotero.md;/Users/thomasgorman/OneDrive - Indiana University/resources/Zotero/Guastello et al_2021_Forecasting chaotic events and the prediction of a rare cognitive ability.pdf;/Users/thomasgorman/Zotero/storage/B5VTTI3F/S0191886920306218.html}
}

@phdthesis{guathFeedbackLearningMultiple2018,
  title = {Feedback Learning and Multiple Goal Pursuit in an Electricity Consumption Task},
  author = {Guath, Mona},
  year = {2018},
  urldate = {2021-10-09},
  abstract = {The overall aim with the thesis was to investigate how learning to pursue two conflicting goals (cost and utility) in an electricity consumption task is affected by different forms of feedback, goal phrasing, and task environment. Applied research investigating the efficiency of outcome feedback on electricity consumption via in-home displays points at modest reductions (2-4\%). Further, a wealth of cognitive psychological research shows that learning with outcome feedback is not unproblematic. A new experimental paradigm, the simulated household, that captures the cognitive task that confronts people when trying to regulate their electricity consumption, was developed. In three studies, different aspects of the problem of regulating one's consumption was investigated. Study I, investigated how different feedback in terms of frequency, detail, and presence of random noise or not affect performance. It also investigated if participants pursued the goals sequentially or simultaneously and if they were able to derive a model of the task. Results showed that frequent feedback was beneficial only in a deterministic system and, surprisingly, random noise improved performance by highlighting the most costly appliances. Modelling results indicated that participants pursued goals sequentially and did not have a mental model of the task. Study II, investigated if a short feedforward training could replace or complement outcome feedback. Results indicated that the performance with one of the feedforward training schemes lead to comparable performance to outcome feedback only. The best performance was obtained when this feedforward scheme was combined with outcome feedback. Study III, investigated if the sequential goal pursuit observed in Study I was related to interpretation of the task or cognitive limitations by specifying goals for cost and/ or utility. Further, it investigated the reason for the cost prioritisation. Results indicated that the sequential goal pursuit derives from cognitive constraints. Together, the results from the studies suggest that people pursue the goals sequentially and that instant outcome feedback may harm performance by distracting people from the most important and costly appliances to the appliances that allow large variability in use. Keywords: feedback, multiple goal pursuit, function learning, electricity consumption, optimisation},
  file = {/Users/thomasgorman/Documents/Zotero_Markdown/guath_feedback_2018-zotero.md;/Users/thomasgorman/OneDrive - Indiana University/resources/Zotero/Guath_Feedback learning and multiple goal pursuit in an electricity consumption task.pdf}
}

@article{guigonInterpolationExtrapolationHuman2004,
  title = {Interpolation and {{Extrapolation}} in {{Human Behavior}} and {{Neural Networks}}},
  author = {Guigon, Emmanuel},
  year = {2004},
  month = apr,
  journal = {Journal of Cognitive Neuroscience},
  volume = {16},
  number = {3},
  pages = {382--389},
  issn = {0898-929X, 1530-8898},
  doi = {10.1162/089892904322926728},
  urldate = {2021-05-16},
  abstract = {Unlike most artificial systems, the brain is able to face situations that it has not learned or even encountered before. This ability is not in general echoed by the properties of most neural networks. Here, we show that neural computation based on least-square error learning between populations of intensitycoded neurons can explain interpolation and extrapolation capacities of the nervous system in sensorimotor and cognitive tasks. We present simulations for function learning experiments, auditory-visual behavior, and visuomotor transformations. The results suggest that induction in human behavior, be it sensorimotor or cognitive, could arise from a common neural associative mechanism.},
  langid = {english},
  file = {/Users/thomasgorman/Documents/Zotero_Markdown/guigonInterpolationExtrapolationHuman2004-zotero.md;/Users/thomasgorman/Downloads/guigon_interpolation_2004-zotero.md;/Users/thomasgorman/Downloads/guigon_interpolation_2004.md;/Users/thomasgorman/OneDrive - Indiana University/resources/Zotero/Guigon_2004_Interpolation and Extrapolation in Human Behavior and Neural Networks.pdf}
}

@article{guigonNeuralModelPerceptualMotor2002,
  title = {A {{Neural Model}} of {{Perceptual-Motor Alignment}}},
  author = {Guigon, Emmanuel and Baraduc, Pierre},
  year = {2002},
  month = may,
  journal = {Journal of Cognitive Neuroscience},
  volume = {14},
  number = {4},
  pages = {538--549},
  issn = {0898-929X, 1530-8898},
  doi = {10.1162/08989290260045792},
  urldate = {2021-05-21},
  abstract = {Sensorimotor systems face complex and frequent discrepancies among spatial modalities, for example, growth, optical distortion, and telemanipulation. Adaptive mechanisms must act continuously to restore perceptual-motor alignments necessary for perception of a coherent world. Experimental manipulations that exposed participants to localized discrepancies showed that adaptation is revealed by the acquisition of a constrained relation between entire modalities rather than associations between individual exemplars within these modalities. The computational problem faced by the human nervous system can thus be conceived as having to induce constrained relations between continuous stimulus and response dimensions from ambiguous or incomplete training sets, that is, performing interpolation and extrapolation. How biological neuronal networks solve this problem is unknown. Here we show that neural processing based on linear collective computation and least-square (LS) error learning in populations of frequency-coded neurons (i.e., whose discharge varies in a monotonic fashion with a parameter) has built-in interpolation and extrapolation capacities. This model can account for the properties of perceptual-motor adaptations in sensorimotor systems.},
  langid = {english},
  file = {/Users/thomasgorman/Documents/Zotero_Markdown/guigon_neural_2002-zotero.md;/Users/thomasgorman/OneDrive - Indiana University/resources/Zotero/Guigon_Baraduc_2002_A Neural Model of Perceptual-Motor Alignment.pdf}
}

@article{haafDonAccountingVariability2019,
  title = {Some Do and Some Don't? {{Accounting}} for Variability of Individual Difference Structures},
  shorttitle = {Some Do and Some Don't?},
  author = {Haaf, Julia M. and Rouder, Jeffrey N.},
  year = {2019},
  month = jun,
  journal = {Psychonomic Bulletin \& Review},
  volume = {26},
  number = {3},
  pages = {772--789},
  issn = {1531-5320},
  doi = {10.3758/s13423-018-1522-x},
  urldate = {2021-10-23},
  abstract = {A prevailing notion in experimental psychology is that individuals' performance in a task varies gradually in a continuous fashion. In a Stroop task, for example, the true average effect may be 50 ms with a standard deviation of say 30 ms. In this case, some individuals will have greater effects than 50 ms, some will have smaller, and some are forecasted to have negative effects in sign\textemdash they respond faster to incongruent items than to congruent ones! But are there people who have a true negative effect in Stroop or any other task? We highlight three qualitatively different effects: negative effects, null effects, and positive effects. The main goal of this paper is to develop models that allow researchers to explore whether all three are present in a task: Do all individuals show a positive effect? Are there individuals with truly no effect? Are there any individuals with negative effects? We develop a family of Bayesian hierarchical models that capture a variety of these constraints. We apply this approach to Stroop interference experiments and a near-liminal priming experiment where the prime may be below and above threshold for different people. We show that most tasks people are quite alike\textemdash for example everyone has positive Stroop effects and nobody fails to Stroop or Stroops negatively. We also show a case that under very specific circumstances, we could entice some people to not Stroop at all.},
  langid = {english},
  file = {/Users/thomasgorman/OneDrive - Indiana University/resources/Zotero/Haaf_Rouder_2019_Some do and some don’t.pdf}
}

@article{harrisAttentionBasedModelLearning2005,
  title = {An {{Attention-Based Model}} of {{Learning}} a {{Function}} and a {{Category}} in {{Parallel}}},
  author = {Harris, H. D. and Minda, John Paul},
  year = {2005},
  abstract = {Minda and Ross (2004) described two experiments where subjects simultaneously learned both a category and a function. They showed that when both tasks were performed in parallel on the same stimuli, the inductive bias on the categorization task\textendash to focus on a single attribute\textendash spread to the function learning task. Here, we present a new computational model of this phenomenon, using the ALCOVE model of categorization, a new model of function learning, and a hypothesis for their interaction: shared selective attention. The model parsimoniously succeeds in learning the category and function, then in accounting for human generalization patterns on conflicting transfer stimuli. The novel function-learning component of the model, extending previous work in mixture-of-experts approaches (Kalish, Lewandowsky,  \& Kruschke, 2004; Harris \& Minda, 2005), is also introduced.},
  file = {/Users/thomasgorman/Documents/Zotero_Markdown/harrisAttentionBasedModelLearning2005-zotero.md;/Users/thomasgorman/OneDrive - Indiana University/resources/Zotero/An Attention-Based Model of Learning a Function and a.pdf;/Users/thomasgorman/Zotero/storage/6ENFDXYU/summary.html}
}

@article{harrisFunctionLearningEnsemble2005,
  title = {Function {{Learning}} with an {{Ensemble}} of {{Linear Experts}} and {{Off-The-Shelf Category-Learning Models}}},
  author = {Harris, Harlan D and Minda, John Paul},
  year = {2005},
  pages = {7},
  abstract = {The relationship between function learning and other types of concept acquisition is far from well understood. Some models of function learning have used approaches that are very different from current models of categorization, while more recent function learning models have used exemplar representations, following the categorization literature. This paper describes two new models of function learning that combine well-studied ``off-theshelf'' approaches to category learning (ALCOVE and SUSTAIN) with recent work in knowledge partitioning. These models are shown to perform basic function learning tasks, to partition knowledge of functions, and to be capable of addressing some individual differences in attention and generalization.},
  langid = {english},
  file = {/Users/thomasgorman/Documents/Zotero_Markdown/harrisFunctionLearningEnsemble2005-zotero.md;/Users/thomasgorman/Zotero/storage/WB9MD7DU/Harris and Minda - Function Learning with an Ensemble of Linear Exper.pdf}
}

@article{hautalaRetentionLinearTask1990,
  title = {Retention of a {{Linear Task}} at a {{Novel Distance}} after {{Practice}} at {{Varied Distances}}},
  author = {Hautala, Robert M. and Kidd, Thomas},
  year = {1990},
  month = dec,
  journal = {Perceptual and Motor Skills},
  volume = {71},
  number = {3\_suppl},
  pages = {1355--1358},
  publisher = {{SAGE Publications Inc}},
  issn = {0031-5125},
  doi = {10.2466/pms.1990.71.3f.1355},
  urldate = {2020-08-26},
  abstract = {The applicability of Schmidt's Schema Theory to a specific sport skill was investigated. 42 subjects in six intact groups practiced golf putting at different distances or combinations of distances. After 12 test putts at a novel distance, an analysis of variance of putts on test Trial 1 and the total of all test trials gave no significant differences among groups. The long-varied distance practice group (25, 30, 40, and 45 ft.) scored significantly better on test Trial 3 than the short- and long-nonvaried group (6 and 45 ft.). Analysis of test putts for varied and constant practice groups indicated a superiority of varied practice subjects in adjusting on a later test trial after initial attempts. The varied-practice groups showed a greater group consistency of score over the 12 test putts. Men performed significantly better than women, but age of subjects was not a significant factor.},
  keywords = {{$>$}2 conditions,projectile throwing,Proximity Confound},
  file = {/Users/thomasgorman/Zotero/storage/3UI7MEE9/Hautala and Kidd - 1990 - Retention of a Linear Task at a Novel Distance aft.pdf}
}

@article{hawkinsDynamicModelReasoning2016,
  title = {A Dynamic Model of Reasoning and Memory},
  author = {Hawkins, Guy E. and Hayes, Brett K. and Heit, Evan},
  year = {2016},
  month = feb,
  journal = {Journal of Experimental Psychology: General},
  volume = {145},
  number = {2},
  pages = {155--180},
  publisher = {{American Psychological Association}},
  issn = {0096-3445},
  doi = {10.1037/xge0000113},
  urldate = {2021-11-30},
  abstract = {Previous models of category-based induction have neglected how the process of induction unfolds over time. We conceive of induction as a dynamic process and provide the first fine-grained examination of the distribution of response times observed in inductive reasoning. We used these data to develop and empirically test the first major quantitative modeling scheme that simultaneously accounts for inductive decisions and their time course. The model assumes that knowledge of similarity relations among novel test probes and items stored in memory drive an accumulation-to-bound sequential sampling process: Test probes with high similarity to studied exemplars are more likely to trigger a generalization response, and more rapidly, than items with low exemplar similarity. We contrast data and model predictions for inductive decisions with a recognition memory task using a common stimulus set. Hierarchical Bayesian analyses across 2 experiments demonstrated that inductive reasoning and recognition memory primarily differ in the threshold to trigger a decision: Observers required less evidence to make a property generalization judgment (induction) than an identity statement about a previously studied item (recognition). Experiment 1 and a condition emphasizing decision speed in Experiment 2 also found evidence that inductive decisions use lower quality similarity-based information than recognition. The findings suggest that induction might represent a less cautious form of recognition. We conclude that sequential sampling models grounded in exemplar-based similarity, combined with hierarchical Bayesian analysis, provide a more fine-grained and informative analysis of the processes involved in inductive reasoning than is possible solely through examination of choice data. (PsycINFO Database Record (c) 2019 APA, all rights reserved)},
  keywords = {Adult,Bayes Theorem,Bayesian Analysis,Decision Making,Generalization (Psychology),hierarchical Bayesian analysis,Humans,Inductive Deductive Reasoning,inductive reasoning,mathematical model,Mathematical Modeling,Memory,{Models, Psychological},Reaction Time,Recognition (Learning),Recognition (Psychology),recognition memory,response time,Statistical Probability,Thinking,Young Adult},
  file = {/Users/thomasgorman/OneDrive - Indiana University/resources/Zotero/Hawkins et al_2016_A dynamic model of reasoning and memory.pdf}
}

@phdthesis{heAttentionalControlCategorisation2020,
  title = {Attentional {{Control}} in {{Categorisation}}: {{Towards}} a {{Computational Synthesis}}},
  author = {He, Liusha},
  year = {2020},
  abstract = {This thesis develops an integrated computational model of task switching in heterogeneous categorisation by combining theories of cognitive control and category learning. The thesis considers the strengths and shortcomings of a range of existing computational accounts of categorisation (ALCOVE, SUSTAIN, ATRIUM and COVIS) by reimplementing each and applying each to human data from the categorisation literature. It is argued that most of these models cannot account for heterogeneous categorisation, i.e., situations where the category structure includes subsets with incompatible boundaries. Moreover, the only one of the four computational models that can account for heterogeneous categorisation, ATRIUM, does not completely account for the influence of top-down control during categorisation tasks. The models are also limited because they are based purely on feedforward principles, and while they are able to learn to categorise stimuli adequately, they do not account for categorisation response times, or for task-switching effects observed in recent research on heterogeneous categorisation. In order to address these limitations, the thesis presents a model that combines an interactive activation account of task-switching with a modular architecture of categorisation. The model is shown to successfully simulate reaction time costs and effects of preparation time on task switching.},
  langid = {english},
  file = {/Users/thomasgorman/OneDrive - Indiana University/resources/Zotero/He_2020_Attentional Control in Categorisation.pdf}
}

@article{heckTreeBUGSPackageHierarchical2018,
  title = {{{TreeBUGS}}: {{An R}} Package for Hierarchical Multinomial-Processing-Tree Modeling},
  shorttitle = {{{TreeBUGS}}},
  author = {Heck, Daniel W. and Arnold, Nina R. and Arnold, Denis},
  year = {2018},
  month = feb,
  journal = {Behavior Research Methods},
  volume = {50},
  number = {1},
  pages = {264--284},
  issn = {1554-3528},
  doi = {10.3758/s13428-017-0869-7},
  urldate = {2021-06-06},
  abstract = {Multinomial processing tree (MPT) models are a class of measurement models that account for categorical data by assuming a finite number of underlying cognitive processes. Traditionally, data are aggregated across participants and analyzed under the assumption of independently and identically distributed observations. Hierarchical Bayesian extensions of MPT models explicitly account for participant heterogeneity by assuming that the individual parameters follow a continuous hierarchical distribution. We provide an accessible introduction to hierarchical MPT modeling and present the user-friendly and comprehensive R package TreeBUGS, which implements the two most important hierarchical MPT approaches for participant heterogeneity\textemdash the beta-MPT approach (Smith \& Batchelder, Journal of Mathematical Psychology 54:167-183, 2010) and the latent-trait MPT approach (Klauer, Psychometrika 75:70-98, 2010). TreeBUGS reads standard MPT model files and obtains Markov-chain Monte Carlo samples that approximate the posterior distribution. The functionality and output are tailored to the specific needs of MPT modelers and provide tests for the homogeneity of items and participants, individual and group parameter estimates, fit statistics, and within- and between-subjects comparisons, as well as goodness-of-fit and summary plots. We also propose and implement novel statistical extensions to include continuous and discrete predictors (as either fixed or random effects) in the latent-trait MPT model.},
  langid = {english},
  file = {/Users/thomasgorman/OneDrive - Indiana University/resources/Zotero/Heck et al_2018_TreeBUGS.pdf}
}

@article{helieUsingKnowledgePartitioning2007,
  title = {Using Knowledge Partitioning to Investigate the Psychological Plausibility of Mixtures of Experts},
  author = {H{\'e}lie, S{\'e}bastien and Gigu{\`e}re, Gyslain and Cousineau, Denis and Proulx, Robert},
  year = {2007},
  month = nov,
  journal = {Artificial Intelligence Review},
  volume = {25},
  number = {1-2},
  pages = {119--138},
  issn = {0269-2821, 1573-7462},
  doi = {10.1007/s10462-007-9024-7},
  urldate = {2022-05-27},
  abstract = {Over the years, the presence of knowledge partitioning (KP) in human function learning data has been used to argue that mixture-of-experts models (MOE) constitute a psychologically plausible explanation of human performance, and that the experts used by humans are always linear. These claims recently led to the proposition of the population of linear experts model (POLE). In this paper, variations of the firefighting paradigm developed by Lewandowsky and his colleagues, which initiated research about KP, were used to explore the psychological plausibility of MOE in general and POLE in particular. In a first experiment, these statements were tested by modifying the test display of the firefighting paradigm. The results showed that adding irrelevant information to the display resulted in a smaller proportion of partitioning participants. Also, some participants used non-linear experts to partition the stimulus space. This new type of KP was further explored in a second study, which included more training sessions. The results suggest that linear KP disappears with practice and that non-linear partitioning reflects the incapacity to correctly estimate the position of the function's vertex. It is concluded that MOE are adequate psychological models, but that the linearity and ubiquity claims of the POLE model need to be weakened.},
  langid = {english},
  file = {/Users/thomasgorman/Documents/Zotero_Markdown/helie_using_2007-zotero.md;/Users/thomasgorman/OneDrive - Indiana University/resources/Zotero/Hélie et al_2007_Using knowledge partitioning to investigate the psychological plausibility of.pdf}
}

@article{henrikssonCueAbstractionIdeal2019,
  title = {Cue Abstraction and Ideal Prototype Abstraction in Estimation Tasks},
  author = {Henriksson, Maria P.},
  year = {2019},
  month = jan,
  journal = {Journal of Cognitive Psychology},
  volume = {31},
  number = {1},
  pages = {76--91},
  issn = {2044-5911, 2044-592X},
  doi = {10.1080/20445911.2018.1564755},
  urldate = {2021-07-21},
  abstract = {This study investigates abstracted processes and introduces a new prototype abstraction model adapted to estimation tasks. This prototype abstraction model assumes that the processing of whole exemplar patterns supports the detection of the underlying statistics necessary for the abstraction of two extreme prototypes on the continuous criterion dimension of the task. The prototypes are stored in memory as valid reference points for future similarity-based judgments. This prototype model was compared with the cue abstraction model, which assumes that people abstract cue weights in learning and add the cue information from exemplars to infer their criterion values varying on the continuous dimension. This study hypothesises that the training mode and the number of exemplars in training interact and affect subsequent model performance at test. The results from an experiment confirmed this hypothesis and showed that observational training supports an efficient prototype abstraction and feedback training supports an efficient cue abstraction.},
  langid = {english},
  file = {/Users/thomasgorman/Documents/Zotero_Markdown/henrikssonCueAbstractionIdeal2019-zotero.md;/Users/thomasgorman/OneDrive - Indiana University/resources/Zotero/Henriksson_2019_Cue abstraction and ideal prototype abstraction in estimation tasks.pdf}
}

@phdthesis{henrikssonHumanRationalityObserving2015,
  title = {Human {{Rationality}}: {{Observing}} or {{Inferring Reality}}},
  author = {Henriksson, Maria P.},
  year = {2015},
  urldate = {2021-07-21},
  file = {/Users/thomasgorman/OneDrive - Indiana University/resources/Zotero/Henriksson_2015_Human Rationality.pdf}
}

@article{henrikssonLearningObservationFeedback2018,
  title = {Learning from Observation, Feedback, and Intervention in Linear and Non-Linear Task Environments},
  author = {Henriksson, Maria P. and Enkvist, Tommy},
  year = {2018},
  month = feb,
  journal = {Quarterly Journal of Experimental Psychology},
  volume = {71},
  number = {2},
  pages = {545--561},
  publisher = {{SAGE Publications}},
  issn = {1747-0218},
  doi = {10.1080/17470218.2016.1263998},
  urldate = {2021-07-21},
  abstract = {This multiple-cue judgment study investigates whether we can manipulate the judgment strategy and increase accuracy in linear and non-linear cue?criterion environments just by changing the training mode. Three experiments show that accuracy in simple linear additive task environments are improved with feedback training and intervention training, while accuracy in complex multiplicative tasks are improved with observational training. The observed interaction effect suggests that the training mode invites different strategies that are adjusted as a function of experience to the demands from the underlying cue?criterion structure. Thus, feedback and the intervention training modes invite cue abstraction, an effortful but successful strategy in combination with simple linear task structures, and observational training invites exemplar memory processes, a simple but successful strategy in combination with complex non-linear task structures. The study discusses adaptive cognition and the implication of the different training modes across a life span and for clinical populations.},
  file = {/Users/thomasgorman/Documents/Zotero_Markdown/henriksson_learning_2018-zotero.md;/Users/thomasgorman/OneDrive - Indiana University/resources/Zotero/Henriksson_Enkvist_2018_Learning from observation, feedback, and intervention in linear and non-linear.pdf}
}

@article{henrikssonMatterProcessAccuracy2012,
  title = {A {{Matter}} of {{Process Accuracy}}: {{Observing}} or {{Inferring}} the {{Criterion}} of {{Few}} or {{Many Exemplars}}},
  author = {Henriksson, Maria P},
  year = {2012},
  journal = {Proceedings of the Annual Meeting of the Cognitive Science Society},
  pages = {6},
  abstract = {Can we tailor fit the training to enhance judgment accuracy by changing to the learning format that invites the most effective cognitive process for the task environment at hand? The results from a study on multiple-cue judgments revealed that observing the cues and the criterion of exemplars simultaneously with no feedback involved in the training, a learning format predicted to invite exemplar memory processes, was the better learning option when there were few unique exemplars in training. Inferring the criteria of different exemplars and receiving outcome feedback during training, a learning format predicted to invite cue-abstraction, was the better learning option when there were many unique exemplars in training. Implications for the notion of an initial ``rule bias'' suggested by several previous studies are discussed.},
  langid = {english},
  file = {/Users/thomasgorman/Documents/Zotero_Markdown/henriksson_matter_2012-zotero.md;/Users/thomasgorman/Documents/Zotero_Markdown/henrikssonMatterProcessAccuracy2012-zotero.md;/Users/thomasgorman/OneDrive - Indiana University/resources/Zotero/Henriksson_A Matter of Process Accuracy.pdf}
}

@article{henrikssonWhatCodedMemory2010,
  title = {What Is {{Coded}} into {{Memory}} in the {{Absence}} of {{Outcome Feedback}}?},
  author = {Henriksson, Maria P. and Elwin, Ebba and Juslin, Peter},
  year = {2010},
  journal = {Journal of Experimental Psychology. Learning, Memory and Cognition},
  volume = {36},
  number = {1},
  pages = {1--16},
  urldate = {2020-08-30},
  abstract = {DiVA portal is a finding tool for research publications and student theses written at the following 49 universities and research institutions.},
  langid = {english},
  file = {/Users/thomasgorman/Zotero/storage/PLRTZEM8/Henriksson et al. - 2010 - What is Coded into Memory in the Absence of Outcom.pdf;/Users/thomasgorman/Zotero/storage/DB2V3FID/record.html}
}

@article{herzogBlendingChoosingOne2013,
  title = {Blending and Choosing within One Mind: {{Should}} Judgments Be Based on Exemplars, Rules or Both?},
  shorttitle = {Blending and Choosing within One Mind},
  author = {Herzog, Stefan M and Von Helversen, Bettina},
  year = {2013},
  publisher = {{Cognitive Science Society}},
  doi = {10.5167/UZH-135893},
  urldate = {2020-12-21},
  abstract = {Accurate judgments and decisions are crucial for success in many areas of human life. The accuracy of a judgment or decision depends largely on the cognitive process applied. In research on judgment, decision making, and categorization, two kinds of cognitive processes have often been contrasted: exemplar-based processes, which use similarity to previously encountered items to make judgments, decisions, and categorizations, and rule-based processes, which use abstracted cue knowledge. Although most cognitive models of judgment and decision processes assume that people rely on both processes, they differ in whether they assume that one process is selected or that both processes are blended into a single response. The present research takes a functional perspective and investigates what kind of interaction between the two processes leads to accurate responses. Based on crossvalidated simulations in real-world domains, it shows that blending rule- and exemplar-based processes generally leads to better judgments than does choosing between them, suggesting that the default strategy should be a blend of both processes, which is abandoned only when feedback justifies it.},
  langid = {english},
  file = {/Users/thomasgorman/Zotero/storage/AYZRXJAI/Herzog and Von Helversen - 2013 - Blending and choosing within one mind Should judg.pdf}
}

@article{hintzmanMINERVASimulationModel1984,
  title = {{{MINERVA}} 2: {{A}} Simulation Model of Human Memory},
  shorttitle = {{{MINERVA}} 2},
  author = {Hintzman, Douglas L.},
  year = {1984},
  month = mar,
  journal = {Behavior Research Methods, Instruments, \& Computers},
  volume = {16},
  number = {2},
  pages = {96--101},
  issn = {0743-3808, 1532-5970},
  doi = {10.3758/BF03202365},
  urldate = {2019-08-30},
  langid = {english},
  file = {/Users/thomasgorman/Zotero/storage/ESDBWLBY/Hintzman - 1984 - MINERVA 2 A simulation model of human memory.pdf}
}

@article{hoffmannSimilarTaskFeatures2016,
  title = {Similar Task Features Shape Judgment and Categorization Processes.},
  author = {Hoffmann, Janina A. and {von Helversen}, Bettina and Rieskamp, J{\"o}rg},
  year = {2016},
  month = aug,
  journal = {Journal of Experimental Psychology: Learning, Memory, and Cognition},
  volume = {42},
  number = {8},
  pages = {1193--1217},
  issn = {1939-1285, 0278-7393},
  doi = {10.1037/xlm0000241},
  urldate = {2020-12-21},
  abstract = {The distinction between similarity-based and rule-based strategies has instigated a large body of research in categorization and judgment. Within both domains, the task characteristics guiding strategy shifts are increasingly well documented. Across domains, past research has observed shifts from rule-based strategies in judgment to similarity-based strategies in categorization, but limited these comparisons to one prototypical environment, a linear task structure, and a restricted set of strategies. To systematically compare the two domains, we considered several instantiations of rule-based and similarity-based strategies and examined strategy choice across different types of judgment and categorization tasks. Between participants, we varied task characteristics from a one-dimensional linear to a multidimensional linear and to two multi-dimensional nonlinear tasks. Irrespective of domain, strategies considered, or model comparison technique used, we find that more participants relied on similarity-based strategies when the functional relationship between the cues and the criterion was nonlinear. Shifts from rule-based strategies in judgment to similarity-based strategies in categorization, however, were rare and most pronounced in one-dimensional environments. These results support the hypothesis that the cognitive strategies people select to solve a judgment or categorization task depend less on the domain but more on the complexity of the task.},
  langid = {english},
  file = {/Users/thomasgorman/Documents/Zotero_Markdown/hoffmann_similar_2016-zotero.md;/Users/thomasgorman/OneDrive - Indiana University/resources/Zotero/Hoffmann et al_2016_Similar task features shape judgment and categorization processes.pdf}
}

@article{hoffmannTestingLearningMechanisms2019,
  title = {Testing Learning Mechanisms of Rule-Based Judgment.},
  author = {Hoffmann, Janina A. and {von Helversen}, Bettina and Rieskamp, J{\"o}rg},
  year = {2019},
  month = oct,
  journal = {Decision},
  volume = {6},
  number = {4},
  pages = {305--334},
  issn = {2325-9973, 2325-9965},
  doi = {10.1037/dec0000109},
  urldate = {2020-12-21},
  abstract = {Weighing the importance of different pieces of information is a key determinant of making accurate judgments. In social judgment theory, these weighting processes have been successfully described with linear models. How people learn to make judgments has received less attention. Although the hitherto proposed delta learning rule can perfectly learn to solve linear problems, reanalyzing a previous experiment showed that it does not adequately describe human learning. To provide a more accurate description of learning processes we amended the delta learning rule with three learning mechanisms\textemdash a decay, an attentional learning mechanism, and a capacity limitation. An additional study tested the different learning mechanisms in predicting learning in linear judgment tasks. In this study, participants first learned to predict a continuous criterion based on four cues. To test the three learning mechanisms rigorously against each other, we changed the importance of the cues after 200 trials so that the mechanisms make different predictions with regard to how fast people adapt to the new environment. On average, judgment accuracy improved from Trial 1 to Trial 200, dropped when the task environment changed, but improved again until the end of the task. The capacity-restricted learning model, restricting how much people update the cue weights on a single trial, best described and predicted the learning curve of the majority of participants. Taken together, these results suggest that considering cognitive constraints within learning models may help to understand how humans learn when making inferences.},
  langid = {english},
  keywords = {matlab code},
  file = {/Users/thomasgorman/Documents/Zotero_Markdown/hoffmannTestingLearningMechanisms2019-zotero.md;/Users/thomasgorman/OneDrive - Indiana University/resources/Zotero/Hoffmann et al_2019_Testing learning mechanisms of rule-based judgment2.pdf}
}

@article{homaLimitationsExemplarbasedGeneralization1981,
  title = {Limitations of Exemplar-Based Generalization and the Abstraction of Categorical Information},
  author = {Homa, Donald and Sterling, Sharon and Trepel, Lawrence},
  year = {1981},
  month = nov,
  journal = {Journal of Experimental Psychology: Human Learning and Memory},
  volume = {7},
  number = {6},
  pages = {418--439},
  issn = {0096-1515},
  doi = {10.1037/0278-7393.7.6.418},
  urldate = {2019-05-27},
  abstract = {An evaluation of exemplar-based models of generalization was provided for ill-defined categories in a category abstraction paradigm. 72 undergraduates initially classified 35 high-level distortions into 3 categories, defined by 5, 10, and 20 different patterns, followed by a transfer test administered immediately and after 1 wk. The transfer patterns included old, new, prototype, and unrelated exemplars of which the new patterns were at 1 of 5 levels of similarity to a particular training (old) stimulus. In both experiments, increases in category size and old\textendash new similarity facilitated transfer performance. However, the effectiveness of old\textendash new similarity was strongly attenuated by increases in category size and delay of the transfer test. It is concluded that examplar-based generalization may be effective only under conditions of minimal category experience and immediacy of test; with continued category experience, performance on the prototype determines classification accuracy. (22 ref) (PsycINFO Database Record (c) 2016 APA, all rights reserved)},
  file = {/Users/thomasgorman/Zotero/storage/B6UGCDZR/Homa et al. - 1981 - Limitations of exemplar-based generalization and t.pdf}
}

@incollection{huangChapterFourAttentional2018,
  title = {Chapter {{Four}} - {{Attentional Processes}} in {{Social Perception}}},
  booktitle = {Advances in {{Experimental Social Psychology}}},
  author = {Huang, Lisa M. and Sherman, Jeffrey W.},
  editor = {Olson, James M.},
  year = {2018},
  month = jan,
  volume = {58},
  pages = {199--241},
  publisher = {{Academic Press}},
  doi = {10.1016/bs.aesp.2018.03.002},
  urldate = {2020-12-21},
  abstract = {In this chapter, we describe how a simple attentional mechanism can account for a wide variety of phenomena in social perception. According to Attention Theory (Kruschke, 1996, 2003), people preferentially attend to differentiating information in order to maximize category learning. When learning multiple social categories, people attend to all features that characterize the first-learned category but shift their attention to features that uniquely distinguish a later-learned category from the first. As a result, they form a stronger impression of the later-learned social category. First, we review research on attentional processes in stereotype formation and group categorization. We show how Attention Theory can account for both category accentuation and illusory correlation in the formation of majority and minority group stereotypes. We then explain how attention shifting influences face perception and racial categorization. Second, we describe attentional processes as they relate to context-based impression formation and the influence of individual- and group-based expectancies on context-based impressions. Last, we discuss implications for impression change.},
  langid = {english},
  keywords = {Attention,Context-based impressions,Group categorization,Group stereotypes,Impression formation},
  file = {/Users/thomasgorman/OneDrive - Indiana University/resources/Zotero/Huang_Sherman_2018_Chapter Four - Attentional Processes in Social Perception.pdf;/Users/thomasgorman/Zotero/storage/XIZ6NLN7/S0065260118300133.html}
}

@phdthesis{huangMysteryFunctions2020,
  title = {Mystery {{Functions}}},
  author = {Huang, Amy},
  year = {2020},
  abstract = {This thesis project investigates the process of theory formation through a study design we call Mystery Functions. Previous works have investigated how people collect and respond to data that they retrieve from a central ``oracle'' entity. Under this design paradigm, participants are given the means to query an all-knowing source of truth for data about some observed phenomenon with the goal of coming up with a theory that totally explains it. The oracle answers all queries immediately and perfectly, giving exactly the data asked for. To determine whether they have succeeded, participants present their theory to the oracle, and the oracle tells them whether or not it's correct. We designed an activity after this model in which participants guess what a computational function does. At first, the only pieces of information they know are the number of inputs and the input and output types of the function; then, they are given the means to ask for the corresponding output of any input and make a guess about the function. The activity is implemented as a web application. We conducted a study with 68 students from a psychology subject pool at Indiana University Bloomington, and 80 students from a software engineering class at Brown University. Our contributions are the dataset of inputs evaluated, quiz attempts made, and labeled guesses about the functions, and our analysis. Though the quality of guesses given by the two groups of students varies substantially, both groups exhibit similar patterns, such as doing most of their data collection before making their first guess. While collecting data, they made repetitive changes to past queries for data to generate future queries.},
  langid = {english},
  school = {Brown University},
  file = {/Users/thomasgorman/Documents/Zotero_Markdown/huang_mystery_2020-zotero.md;/Users/thomasgorman/Zotero/storage/HLWJR3NR/Huang - Mystery Functions.pdf}
}

@article{huExemplarmodelAccountCategorization2021,
  title = {Exemplar-Model Account of Categorization and Recognition When Training Instances Never Repeat},
  author = {Hu, Mingjia and Nosofsky, Robert M.},
  year = {2021},
  month = mar,
  journal = {Journal of Experimental Psychology: Learning, Memory, and Cognition},
  publisher = {{American Psychological Association}},
  issn = {0278-7393},
  doi = {10.1037/xlm0001008},
  urldate = {2021-03-31},
  abstract = {In a novel version of the classic dot-pattern prototype-distortion paradigm of category learning, Homa et al. (2019) tested a condition in which individual training instances never repeated, and observed results that they claimed severely challenged exemplar models of classification and recognition. Among the results was a dissociation in which participants classified transfer items with high accuracy in the no-repeat condition, yet in old-new recognition tests showed no ability to discriminate between old and new items of the same level of distortion from the prototype. In addition, speed of classification learning was no faster in a condition in which a small set of training instances was repeated continuously compared with the no-repeat condition. Here we show through computer-simulation modeling that exemplar models naturally capture the classification-recognition dissociation in the no-repeat condition, as well as a wide variety of other qualitative effects reported by Homa et al. (2019). We also conduct new conceptual-replication experiments to investigate their reported null effect of repeated versus nonrepeated training instances on speed of classification learning. In contrast to Homa et al. (2019) we find that speed of learning is substantially faster in the repeat condition than in the no-repeat condition, precisely as exemplar models predict. The exemplar model also captures a wide variety of transfer effects observed following the completion of category learning, including the classification-recognition dissociation observed across the repeat and no-repeat conditions. (PsycInfo Database Record (c) 2021 APA, all rights reserved)},
  keywords = {categorization,Classification (Cognitive Process),Cognitive Processing Speed,computational modeling,Computational Modeling,Dissociation,exemplars,Learning,Models,prototypes,recognition,Recognition (Learning),Training,Transfer (Learning)},
  file = {/Users/thomasgorman/OneDrive - Indiana University/resources/Zotero/Hu_Nosofsky_2021_Exemplar-model account of categorization and recognition when training.pdf}
}

@article{hurwitzRetrievalExemplarFeature1994,
  title = {Retrieval of Exemplar and Feature Information in Category Learning},
  author = {Hurwitz, Joshua B.},
  year = {1994},
  month = jul,
  journal = {Journal of Experimental Psychology: Learning, Memory, and Cognition},
  volume = {20},
  number = {4},
  pages = {887--903},
  publisher = {{American Psychological Association}},
  issn = {0278-7393},
  doi = {10.1037/0278-7393.20.4.887},
  urldate = {2021-11-17},
  abstract = {Two assumptions were tested regarding what information Ss use during category learning with independent features. One assumption is that Ss use only exemplar information and the other is that they use only feature information. Previous work has revealed no clear superiority of one over the other after training with independent features (W. K. Estes, see PA, Vol 74:334 and Vol 73:21175). The experiments presented here manipulate the opportunity for using whole exemplars when categorizing test patterns by providing either whole or fragmented training patterns. The results show that a feature-node network model was superior to feature-frequency and exemplar models at predicting asymptotic test performance after fragmented-pattern training. However, to achieve this result, all models were modified to account for possible attentional differences among the training conditions. (PsycINFO Database Record (c) 2016 APA, all rights reserved)},
  keywords = {Classification (Cognitive Process),college students,Human Information Storage,Stimulus Parameters,training using whole vs fragmented patterns,use \& retrieval of exemplar vs feature information in category learning},
  file = {/Users/thomasgorman/OneDrive - Indiana University/resources/Zotero/Hurwitz_1994_Retrieval of exemplar and feature information in category learning.pdf}
}

@article{hutzlerAnticipatingTrajectoriesExponential2021,
  title = {Anticipating Trajectories of Exponential Growth},
  author = {Hutzler, Florian and Richlan, Fabio and Leitner, Michael Christian and Schuster, Sarah and Braun, Mario and Hawelka, Stefan},
  year = {2021},
  journal = {Royal Society Open Science},
  volume = {8},
  number = {4},
  pages = {201574},
  publisher = {{Royal Society}},
  doi = {10.1098/rsos.201574},
  urldate = {2022-05-20},
  abstract = {Humans grossly underestimate exponential growth, but are at the same time overconfident in their (poor) judgement. The so-called `exponential growth bias' is of new relevance in the context of COVID-19, because it explains why humans have fundamental difficulties to grasp the magnitude of a spreading epidemic. Here, we addressed the question, whether logarithmic scaling and contextual framing of epidemiological data affect the anticipation of exponential growth. Our findings show that underestimations were most pronounced when growth curves were linearly scaled and framed in the context of a more advanced epidemic progression. For logarithmic scaling, estimates were much more accurate, on target for growth rates around 31\%, and not affected by contextual framing. We conclude that the logarithmic depiction is conducive for detecting exponential growth during an early phase as well as resurgences of exponential growth.},
  keywords = {contextual framing,COVID-19,exponential growth,linear scaling,logarithmic scaling,pandemic},
  file = {/Users/thomasgorman/Documents/Zotero_Markdown/hutzler_anticipating_2021-zotero.md;/Users/thomasgorman/OneDrive - Indiana University/resources/Zotero/Hutzler et al_Anticipating trajectories of exponential growth.pdf}
}

@phdthesis{inksterAttentionContextInverse,
  title = {Attention, {{Context}} and the {{Inverse Base Rate Effect}}},
  author = {Inkster, Angus B.},
  urldate = {2021-12-11},
  file = {/Users/thomasgorman/OneDrive - Indiana University/resources/Zotero/Inkster_Attention, Context and the Inverse Base Rate Effect.pdf}
}

@techreport{inksterEffectContextShift2019,
  type = {Preprint},
  title = {Effect of a Context Shift on the Inverse Base Rate Effect},
  author = {Inkster, Angus and Mitchell, Chris and Schlegelmilch, Ren{\'e} and Wills, Andy},
  year = {2019},
  month = sep,
  institution = {{PsyArXiv}},
  doi = {10.31234/osf.io/rpb7x},
  urldate = {2020-09-07},
  abstract = {The Inverse Base Rate Effect (IBRE; Medin and Edelson (1988)) is a non-rational behavioural phenomenon in predictive learning. In the IBRE, participants learn that a stimulus compound AB leads to one outcome and that another compound AC leads to a different outcome. Importantly, AB and its outcome are presented three times as often as AC (and its outcome). On test, when asked which outcome to expect on presentation of the novel compound BC, participants preferentially select the rarer outcome, previously associated with AC. This is irrational because, objectively, the common outcome is more likely. Usually, the IBRE is attributed to greater attention paid to cue C than to cue B, and so is an excellent test for attentional learning models. The current experiment tested a simple model of attentional learning proposed by Le Pelley, Mitchell, Beesley, George, and Wills (2016) where attention paid to a stimulus is determined by its associative strength. This model struggles to capture the IBRE, but a potential solution suggested by the authors appeals to the role of experimental context. In the present paper, we derive three predictions from their account concerning the effect of changing to a novel experimental context at test, and examine these predictions empirically. Only one of the predictions was supported, concerning the effect of a context shift on responding to a novel cue, was supported. In contrast, Kruschke (2001b)'s EXIT model, in which attention and associative strength can vary independently, captured the data with a high degree of quantitative accuracy.},
  langid = {english},
  file = {/Users/thomasgorman/OneDrive - Indiana University/resources/Zotero/Inkster et al_2019_Effect of a context shift on the inverse base rate effect.pdf}
}

@article{jagadishProbingCompositionalInference,
  title = {Probing {{Compositional Inference}} in {{Natural}} and {{Artificial Agents}}},
  author = {Jagadish, Akshay K and Saanum, Tankred and Wang, Jane X and Binz, Marcel and Schulz, Eric},
  pages = {5},
  abstract = {People can easily evoke previously encountered concepts, compose them, and apply the result to novel contexts in a zero-shot manner. What computational mechanisms underpin this ability? To study this question, we propose an extension to the structured multi-armed bandit paradigm, which has been used to probe human function learning in previous works. This new paradigm involves a learning curriculum where agents first perform two sub-tasks in which rewards were sampled from differently structured reward functions, followed by a third sub-task in which rewards were set to a composition of the previously encountered reward functions. This setup allows us to investigate how people reason compositionally over learned functions, while still being simple enough to be tractable. Human behavior in such tasks has been predominantly modeled by computational models with hard-coded structures such as Bayesian grammars. We indeed find that such a model performs well on our task. However, they do not explain how people learn to compose reward functions via trial and error but have, instead, been hand-designed to generalize compositionally by expert researchers. How could the ability to compose ever emerge through trial and error? We propose a model based on the principle of meta-learning to tackle this challenge and find that \textendash{} upon training on the previously described curriculum \textendash{} meta-learned agents exhibit characteristics comparable to those of a Bayesian agent with compositional priors. Model simulations suggest that both models can compose earlier learned functions to generalize in a zero-shot manner. We complemented these model simulations results with a behavioral study, in which we investigated how human participants approach our task. We find that they are indeed able to perform zero-shot compositional reasoning as predicted by our models. Taken together, our study paves a way for studying compositional reinforcement learning in humans, symbolic, and sub-symbolic agents.},
  langid = {english},
  file = {/Users/thomasgorman/Documents/Zotero_Markdown/jagadish_probing_nodate-zotero.md;/Users/thomasgorman/OneDrive - Indiana University/resources/Zotero/Jagadish et al_Probing Compositional Inference in Natural and Artificial Agents.pdf}
}

@article{jegminatBayesianRegressionExplains2020,
  title = {Bayesian Regression Explains How Human Participants Handle Parameter Uncertainty},
  author = {Jegminat, Jannes and Jastrz{\k{e}}bowska, Maya A. and Pachai, Matthew V. and Herzog, Michael H. and Pfister, Jean-Pascal},
  year = {2020},
  month = may,
  journal = {PLOS Computational Biology},
  volume = {16},
  number = {5},
  pages = {e1007886},
  publisher = {{Public Library of Science}},
  issn = {1553-7358},
  doi = {10.1371/journal.pcbi.1007886},
  urldate = {2022-05-27},
  abstract = {Accumulating evidence indicates that the human brain copes with sensory uncertainty in accordance with Bayes' rule. However, it is unknown how humans make predictions when the generative model of the task at hand is described by uncertain parameters. Here, we tested whether and how humans take parameter uncertainty into account in a regression task. Participants extrapolated a parabola from a limited number of noisy points, shown on a computer screen. The quadratic parameter was drawn from a bimodal prior distribution. We tested whether human observers take full advantage of the given information, including the likelihood of the quadratic parameter value given the observed points and the quadratic parameter's prior distribution. We compared human performance with Bayesian regression, which is the (Bayes) optimal solution to this problem, and three sub-optimal models, which are simpler to compute. Our results show that, under our specific experimental conditions, humans behave in a way that is consistent with Bayesian regression. Moreover, our results support the hypothesis that humans generate responses in a manner consistent with probability matching rather than Bayesian decision theory.},
  langid = {english},
  lccn = {https://github.com/Jegmi?tab=repositories},
  keywords = {Decision making,Decision theory,Learning,Machine learning,Parabolas,Probability distribution,Psychophysics,Sensory perception},
  file = {/Users/thomasgorman/Documents/Zotero_Markdown/jegminat_bayesian_2020-zotero.md;/Users/thomasgorman/OneDrive - Indiana University/resources/Zotero/Jegminat et al_2020_Bayesian regression explains how human participants handle parameter uncertainty.pdf;/Users/thomasgorman/Zotero/storage/VVQJW4RX/article.html}
}

@article{johnsonSimplicityGoodnessofFitExplanation,
  title = {Simplicity and {{Goodness-of-Fit}} in {{Explanation}}: {{The Case}} of {{Intuitive Curve-Fitting}}},
  author = {Johnson, Samuel G B and Jin, Andy and Keil, Frank C},
  pages = {7},
  abstract = {Other things being equal, people prefer simpler explanations to more complex ones. However, complex explanations often provide better fits to the observed data, and goodness-of-fit must therefore be traded off against simplicity to arrive at the most likely explanation. In three experiments, we examine how people negotiate this tradeoff. As a case study, we investigate laypeople's intuitions about curve-fitting in visually presented graphs, a domain with established quantitative criteria for trading off simplicity and goodness-of-fit. We examine whether people are well-calibrated to normative criteria, or whether they instead have an underfitting or overfitting bias (Experiment 1), we test people's intuitions in cases where simplicity and goodness-of-fit are no longer inversely correlated (Experiment 2), and we directly measure judgments concerning the complexity and goodness-of-fit in a set of curves (Experiment 3). To explain these findings, we posit a new heuristic: That the complexity of an explanation is used to estimate its goodness-of-fit to the data.},
  langid = {english},
  file = {/Users/thomasgorman/Documents/Zotero_Markdown/johnson_simplicity_nodate-zotero.md;/Users/thomasgorman/OneDrive - Indiana University/resources/Zotero/Johnson et al_Simplicity and Goodness-of-Fit in Explanation.pdf}
}

@techreport{jonesActiveFunctionLearning2018,
  type = {Preprint},
  title = {Active {{Function Learning}}},
  author = {Jones, Angela and Schulz, Eric and Meder, Bj{\"o}rn and Ruggeri, Azzurra},
  year = {2018},
  month = feb,
  institution = {{Animal Behavior and Cognition}},
  doi = {10.1101/262394},
  urldate = {2021-05-20},
  abstract = {How do people actively explore to learn about functional relationships, that is, how continuous inputs map onto continuous outputs? We introduce a novel paradigm to investigate information search in continuous, multi-feature function learning scenarios. Participants either actively selected or passively observed information to learn about an underlying linear function. We develop and compare different variants of rule-based (linear regression) and non-parametric (Gaussian process regression) active learning approaches to model participants' active learning behavior. Our results show that participants' performance is best described by a rule-based model that attempts to efficiently learn linear functions with a focus on high and uncertain outcomes. These results advance our understanding of how people actively search for information to learn about functional relations in the environment.},
  langid = {english},
  file = {/Users/thomasgorman/Documents/Zotero_Markdown/jones_active_2018-zotero.md;/Users/thomasgorman/OneDrive - Indiana University/resources/Zotero/Jones et al_2018_Active Function Learning.pdf}
}

@article{jonesLearningMyopiaAdaptive2003,
  title = {Learning Myopia: {{An}} Adaptive Recency Effect in Category Learning},
  shorttitle = {Learning Myopia},
  author = {Jones, Matt and Sieck, Winston R.},
  year = {2003},
  month = jul,
  journal = {Journal of Experimental Psychology: Learning, Memory, and Cognition},
  volume = {29},
  number = {4},
  pages = {626--640},
  publisher = {{American Psychological Association}},
  issn = {0278-7393},
  doi = {10.1037/0278-7393.29.4.626},
  urldate = {2021-12-11},
  abstract = {[Correction Notice: An erratum for this article was reported in Vol 29(6) of Journal of Experimental Psychology: Learning, Memory, and Cognition (see record [rid]2007-16866-001[/rid]). On page 633, Table 2, the values in columns (T, P) and (P, T) in the dual condition row incorrectly read .10 and .90, respectively. The correct values are .90 and .10, respectively.] Recency effects (REs) have been well established in memory and probability learning paradigms but have received little attention in category learning research. Extant categorization models predict REs to be unaffected by learning, whereas a functional interpretation of REs, suggested by results in other domains, predicts that people are able to learn sequential dependencies and incorporate this information into their responses. These contrasting predictions were tested in 2 experiments involving a classification task in which outcome sequences were autocorrelated. Experiment 1 showed that reliance on recent outcomes adapts to the structure of the task, in contrast to models' predictions. Experiment 2 provided constraints on how sequential information is learned and suggested possible extensions to current models to account for this learning. (PsycINFO Database Record (c) 2016 APA, all rights reserved)},
  keywords = {Attention,Bayes Theorem,categorization,category learning,classification,Classification (Cognitive Process),Cognition,cues,Cues,Humans,Learning,{Models, Psychological},Recency Effect,recency effects,sequential dependencies,Sequential Learning,simulation,Simulation,stimulus similarity,Stimulus Similarity},
  file = {/Users/thomasgorman/OneDrive - Indiana University/resources/Zotero/Jones_Sieck_2003_Learning myopia.pdf}
}

@article{jonesRecencyEffectsWindow2006,
  title = {Recency Effects as a Window to Generalization: {{Separating}} Decisional and Perceptual Sequential Effects in Category Learning.},
  shorttitle = {Recency Effects as a Window to Generalization},
  author = {Jones, Matt and Love, Bradley C. and Maddox, W. Todd},
  year = {2006},
  journal = {Journal of Experimental Psychology: Learning, Memory, and Cognition},
  volume = {32},
  number = {2},
  pages = {316--332},
  issn = {1939-1285, 0278-7393},
  doi = {10.1037/0278-7393.32.3.316},
  urldate = {2020-09-07},
  abstract = {Accounts of learning and generalization typically focus on factors related to lasting changes in representation (i.e., long-term memory). The authors present evidence that shorter term effects also play a critical role in determining performance and that these recency effects can be subdivided into perceptual and decisional components. Experimental results based on a probabilistic category structure show that the previous stimulus exerts a contrastive effect on the current percept (perceptual recency) and that responses are biased toward or away from the previous feedback, depending on the similarity between successive stimuli (decisional recency). A method for assessing these recency effects is presented that clarifies open questions regarding stimulus generalization and perceptual contrast effects in categorization and in other domains.},
  langid = {english},
  file = {/Users/thomasgorman/Zotero/storage/BDB4I44A/Jones et al. - 2006 - Recency effects as a window to generalization Sep.pdf}
}

@article{juslinExemplarEffectsCategorization2003,
  title = {Exemplar {{Effects}} in {{Categorization}} and {{Multiple-Cue Judgment}}},
  author = {Juslin, Peter and Olsson, Henrik and Olsson, Anna-Carin},
  year = {2003},
  month = apr,
  journal = {Journal of experimental psychology. General},
  volume = {132},
  pages = {133--56},
  doi = {10.1037/0096-3445.132.1.133},
  abstract = {Categorization and multiple-cue judgment are similar tasks, but the influential models in the two areas are different in terms of the computations, processes, and neural substrates that they imply. In categorization, exemplar memory is often emphasized, whereas multiple-cue judgment generally is interpreted in terms of integration of cues that have been abstracted in training. In 3 experiments the authors investigated whether these conclusions derive from genuine differences in the processes or are accidental to the different research methods. The results revealed large individual differences and a shift from exemplar memory to cue abstraction when the criterion is changed from a binary to a continuous variable, especially for a probabilistic criterion. People appear to switch between qualitatively distinct processes in the 2 tasks.},
  file = {/Users/thomasgorman/Documents/Zotero_Markdown/juslin_exemplar_2003-zotero.md;/Users/thomasgorman/OneDrive - Indiana University/resources/Zotero/Juslin et al_2003_Exemplar Effects in Categorization and Multiple-Cue Judgment.pdf}
}

@article{kalishIteratedLearningIntergenerational2007,
  title = {Iterated Learning: {{Intergenerational}} Knowledge Transmission Reveals Inductive Biases},
  shorttitle = {Iterated Learning},
  author = {Kalish, Michael L. and Griffiths, Thomas L. and Lewandowsky, Stephan},
  year = {2007},
  month = apr,
  journal = {Psychonomic Bulletin \& Review},
  volume = {14},
  number = {2},
  pages = {288--294},
  issn = {1069-9384, 1531-5320},
  doi = {10.3758/BF03194066},
  urldate = {2021-10-13},
  langid = {english},
  file = {/Users/thomasgorman/Documents/Zotero_Markdown/kalish_iterated_2007-zotero.md;/Users/thomasgorman/OneDrive - Indiana University/resources/Zotero/Kalish et al_2007_Iterated learning.pdf}
}

@article{kalishLearningExtrapolatingPeriodic2013,
  title = {Learning and Extrapolating a Periodic Function},
  author = {Kalish, Michael L.},
  year = {2013},
  month = aug,
  journal = {Memory \& Cognition},
  volume = {41},
  number = {6},
  pages = {886--896},
  issn = {1532-5946},
  doi = {10.3758/s13421-013-0306-9},
  urldate = {2021-05-16},
  abstract = {How people learn continuous functional relationships remains a poorly understood capacity. In this article, I argue that the mere presence of nonmonotonic extrapolation of periodic functions neither threatens existing theories of function learning nor distinguishes between them. However, I show that merely learning periodic functions is extremely difficult. It is only when stimuli are presented numerically, rather than as numberless quantities, that participants learn anything like a periodic function. In addition, I show that even then, people do not regularly extrapolate periodically. The lesson is that careful methodologies will be required to understand a psychological capacity that is as idiosyncratic as the learning of complex functions appears to be.},
  langid = {english},
  file = {/Users/thomasgorman/Documents/Zotero_Markdown/kalish_learning_2013-zotero.md;/Users/thomasgorman/OneDrive - Indiana University/resources/Zotero/Kalish_2013_Learning and extrapolating a periodic function.pdf}
}

@article{kalishPopulationLinearExperts2004,
  title = {Population of {{Linear Experts}}: {{Knowledge Partitioning}} and {{Function Learning}}.},
  shorttitle = {Population of {{Linear Experts}}},
  author = {Kalish, Michael L. and Lewandowsky, Stephan and Kruschke, John K.},
  year = {2004},
  journal = {Psychological Review},
  volume = {111},
  number = {4},
  pages = {1072--1099},
  issn = {1939-1471, 0033-295X},
  doi = {10.1037/0033-295X.111.4.1072},
  urldate = {2018-12-01},
  langid = {english},
  file = {/Users/thomasgorman/Documents/Zotero_Markdown/kalishPopulationLinearExperts2004-zotero.md;/Users/thomasgorman/Zotero/storage/9WIQ5G9D/Kalish et al. - 2004 - Population of Linear Experts Knowledge Partitioni.pdf}
}

@article{kaneApplicationsBiasVariance2020,
  title = {Applications of the Bias\textendash Variance Decomposition to Human Forecasting},
  author = {Kane, Patrick Bodilly and Broomell, Stephen B.},
  year = {2020},
  month = sep,
  journal = {Journal of Mathematical Psychology},
  volume = {98},
  pages = {102417},
  issn = {0022-2496},
  doi = {10.1016/j.jmp.2020.102417},
  urldate = {2021-05-22},
  abstract = {Forecasts are generated by both human experts and statistical models, and their forecast accuracy can be understood using error decompositions. However, the assumptions that underlie decompositions used in the analysis of human error differ substantially from those used in the analysis of models. The lens model, one of the most popular error decompositions for human errors, treats the beliefs of the human forecaster as fixed parameters to be estimated. Modern decompositions of model error treat the model as a random result from the process of fitting to noisy data. We highlight how these different approaches can be combined, expanding the application of the lens model to groups and opening up new perspectives on the study of human forecasting. We argue that treating human beliefs as the result of a process of learning from noisy data (even without specifying that process) can help to explain many documented phenomena in the world of forecasting such as: what kinds of environments human judgment will have difficulty with and what kinds they will be successful in; what conditions underlie the success of bootstrapping and aggregation of independent forecasts. Just as understanding statistical models as random variables has helped to improve the understanding of error in statistics and machines learning, we believe this framework will be able to help guide the literature on human judgment to a better understanding of error, its determinants and the mechanisms capable of improving forecasting accuracy.},
  langid = {english},
  keywords = {Bias\textendash variance decomposition,Forecasting,Judgment,Lens model,Statistical models},
  file = {/Users/thomasgorman/Documents/Zotero_Markdown/kaneApplicationsBiasVariance2020-zotero.md;/Users/thomasgorman/Downloads/kaneApplicationsBiasVariance2020-zotero.md;/Users/thomasgorman/Downloads/kaneApplicationsBiasVariance2020.md;/Users/thomasgorman/OneDrive - Indiana University/resources/Zotero/Kane_Broomell_2020_Applications of the bias–variance decomposition to human forecasting.pdf;/Users/thomasgorman/Zotero/storage/HCWRFERP/S0022249620300705.html}
}

@article{kangEffectsTestingLearning2011,
  title = {Effects of Testing on Learning of Functions},
  author = {Kang, Sean H. K. and McDaniel, Mark A. and Pashler, Harold},
  year = {2011},
  month = oct,
  journal = {Psychonomic Bulletin \& Review},
  volume = {18},
  number = {5},
  pages = {998--1005},
  issn = {1531-5320},
  doi = {10.3758/s13423-011-0113-x},
  urldate = {2020-07-16},
  abstract = {Is learning of a complex functional relationship enhanced by trying to predict what output will go with a given input, as compared to studying an input\textendash output pair? We examined learning of a bilinear function and transfer to new items outside the trained range. Subjects either saw the input\textendash output pairs (study-only condition) or attempted to guess the output and then saw the pair (test/study condition). The total study times were equated, and motivation was enhanced with a monetary bonus. Performance was markedly better for the test/study condition, both within the trained range and in the transfer test. This benefit of testing during training was observed on a criterial test administered shortly after training. Testing has long been shown to enhance the explicit learning and retention of verbal material; our present findings reveal a novel domain for which testing can also be advantageous\textemdash that is, function learning.},
  langid = {english},
  file = {/Users/thomasgorman/Documents/Zotero_Markdown/kang_effects_2011-zotero.md;/Users/thomasgorman/OneDrive - Indiana University/resources/Zotero/Kang et al_2011_Effects of testing on learning of functions.pdf}
}

@article{karelaiaDeterminantsLinearJudgment2008,
  title = {Determinants of Linear Judgment: A Meta-Analysis of Lens Model Studies},
  shorttitle = {Determinants of Linear Judgment},
  author = {Karelaia, Natalia and Hogarth, Robin M.},
  year = {2008},
  month = may,
  journal = {Psychological Bulletin},
  volume = {134},
  number = {3},
  pages = {404--426},
  issn = {0033-2909},
  doi = {10.1037/0033-2909.134.3.404},
  abstract = {The mathematical representation of E. Brunswik's (1952) lens model has been used extensively to study human judgment and provides a unique opportunity to conduct a meta-analysis of studies that covers roughly 5 decades. Specifically, the authors analyzed statistics of the "lens model equation" (L. R. Tucker, 1964) associated with 249 different task environments obtained from 86 articles. On average, fairly high levels of judgmental achievement were found, and people were seen to be capable of achieving similar levels of cognitive performance in noisy and predictable environments. Further, the effects of task characteristics that influence judgment (numbers and types of cues, inter-cue redundancy, function forms and cue weights in the ecology, laboratory versus field studies, and experience with the task) were identified and estimated. A detailed analysis of learning studies revealed that the most effective form of feedback was information about the task. The authors also analyzed empirically under what conditions the application of bootstrapping--or replacing judges by their linear models--is advantageous. Finally, the authors note shortcomings of the kinds of studies conducted to date, limitations in the lens model methodology, and possibilities for future research.},
  langid = {english},
  pmid = {18444703},
  keywords = {Humans,Judgment,Learning,Linear Models,{Models, Psychological},Psychology},
  file = {/Users/thomasgorman/Documents/Zotero_Markdown/karelaia_determinants_2008-zotero.md;/Users/thomasgorman/OneDrive - Indiana University/resources/Zotero/Karelaia_Hogarth_2008_Determinants of linear judgment2.pdf}
}

@article{karlssonAdaptiveChangesCue2007,
  title = {Adaptive Changes between Cue Abstraction and Exemplar Memory in a Multiple-Cue Judgment Task with Continuous Cues},
  author = {Karlsson, Linnea and Juslin, Peter and Olsson, Henrik},
  year = {2007},
  month = dec,
  journal = {Psychonomic Bulletin \& Review},
  volume = {14},
  number = {6},
  pages = {1140--1146},
  issn = {1069-9384, 1531-5320},
  doi = {10.3758/BF03193103},
  urldate = {2021-07-21},
  langid = {english},
  file = {/Users/thomasgorman/Documents/Zotero_Markdown/karlsson_adaptive_2007-zotero.md;/Users/thomasgorman/OneDrive - Indiana University/resources/Zotero/Karlsson et al_2007_Adaptive changes between cue abstraction and exemplar memory in a multiple-cue.pdf}
}

@article{kattnerPerceptualLearningGeneralization2017,
  title = {Perceptual Learning Generalization from Sequential Perceptual Training as a Change in Learning Rate},
  author = {Kattner, Florian and Cochrane, Aaron and Cox, Christopher R. and Gorman, Thomas E. and Green, C. Shawn},
  year = {2017},
  journal = {Current Biology},
  volume = {27},
  number = {6},
  pages = {840--846},
  urldate = {2017-09-18},
  copyright = {All rights reserved},
  file = {/Users/thomasgorman/Zotero/storage/GZRLJ4WA/Kattner et al. - 2017 - Perceptual learning generalization from sequential.pdf;/Users/thomasgorman/Zotero/storage/SNVAI3DH/CB_LTL_SI.docx}
}

@article{kelleyComparisonModelsLearning2008,
  title = {A Comparison of Models for Learning How to Dynamically Integrate Multiple Cues in Order to Forecast Continuous Criteria},
  author = {Kelley, Hugh and Busemeyer, Jerome},
  year = {2008},
  month = jun,
  journal = {Journal of Mathematical Psychology},
  volume = {52},
  number = {4},
  pages = {218--240},
  issn = {0022-2496},
  doi = {10.1016/j.jmp.2008.01.009},
  urldate = {2021-05-22},
  abstract = {Is human learning strongly adapted to the specific function learning task to which it is applied or is it a more general characteristic? This study addresses this question by empirically comparing the performance of five dynamic learning models across eleven different continuous criterion function learning tasks. We contrast three variants of rule-based and associative `neural network' models with two variants of a Bayesian regression forecasting model. The tasks involve: deterministic and stochastic functions, functions with equal and unequal stimuli weights, functions with large and small numbers of stimuli, and linear and nonlinear functions. Evidence of task specificity would be implied if the most descriptive model of learning does systematically vary by task and subject; the alternative independence hypothesis is implied if there are no performance differences. We find two primary results: first, there is evidence of the task independence of learning; and the most valid model is a neural network variant. However, if the criterion variance is large or there are a large number of cues relevant for making predictions, the results favor Bayesian forecasting methods for providing reliable and valid predictions of human responses.},
  langid = {english},
  keywords = {Experiment,Forecasting,Function learning,Least squares,Model comparison,Neural network},
  file = {/Users/thomasgorman/Documents/Zotero_Markdown/kelleyComparisonModelsLearning2008-zotero.md;/Users/thomasgorman/Downloads/kelleyComparisonModelsLearning2008-zotero.md;/Users/thomasgorman/Downloads/kelleyComparisonModelsLearning2008.md;/Users/thomasgorman/OneDrive - Indiana University/resources/Zotero/Kelley_Busemeyer_2008_A comparison of models for learning how to dynamically integrate multiple cues.pdf;/Users/thomasgorman/Zotero/storage/9EWGNZM9/S0022249608000217.html}
}

@article{kerrSpecificVariedPractice1978,
  title = {Specific and Varied Practice of Motor Skill},
  author = {Kerr, R and Booth, B},
  year = {1978},
  journal = {Perceptual and motor skills},
  volume = {46},
  number = {2},
  pages = {395--401},
  keywords = {Benefit of Variability,constant control,constant practice,Delayed Test,Development,Empirical,Motor,Varied Manipulation},
  file = {/Users/thomasgorman/Zotero/storage/X5JGUA7Z/Kerr & Booth 1978.pdf}
}

@article{kohFunctionLearningInduction1991,
  title = {Function Learning: {{Induction}} of Continuous Stimulus-Response Relations},
  author = {Koh and Meyer, D.E.},
  year = {1991},
  journal = {Journal of Experimental Psychology: Learning, Memory, and Cognition},
  volume = {17},
  number = {5},
  file = {/Users/thomasgorman/Documents/Zotero_Markdown/koh_function_1991-zotero.md;/Users/thomasgorman/Zotero/storage/22UKDI5W/Koh and Meyer - 1991 - Function learning Induction of continuous stimulu.pdf}
}

@article{kohInductionCombinationRules1993,
  title = {Induction of Combination Rules in Two-Dimensional Function Learning},
  author = {Koh, Kyunghee},
  year = {1993},
  month = sep,
  journal = {Memory \& Cognition},
  volume = {21},
  number = {5},
  pages = {573--590},
  issn = {0090-502X, 1532-5946},
  doi = {10.3758/BF03197190},
  urldate = {2021-05-22},
  langid = {english},
  file = {/Users/thomasgorman/Documents/Zotero_Markdown/koh_induction_1993-zotero.md;/Users/thomasgorman/OneDrive - Indiana University/resources/Zotero/Koh_1993_Induction of combination rules in two-dimensional function learning.pdf}
}

@phdthesis{koliHumanExplorationExtrapolation2022,
  title = {Human Exploration and Extrapolation in Conceptual and Spatial Tasks},
  author = {Koli, aakko},
  year = {2022},
  urldate = {2022-06-28},
  abstract = {Humans need to reason about the unknown constantly utilising similar existing knowledge as well as explore the unknown to gather more information for the future. I investigate this kind of human exploration and extrapolation in simple conceptual and spatial tasks in this thesis using Bayesian optimisation. My work extends Wu et al. paper Similarities and differences in spatial and nonspatial cognitive maps [Wu et al., 2020] where they model human exploration and extrapolation with Bayesian optimisation using an acquisition function and an activation function to represent human exploration and a Gaussian process to model the participant's belief of the environment based on the knowledge they acquire. Wu et al. use Bayesian optimisation to model human behaviour in these tasks as their main model of choice. Their model consists of a Gaussian process with a Radial Basis Function (RBF) kernel, Upper Confidence Bound (UCB) acquisition function and softmax activation function to transform the output of the acquisition function. Their model has three free parameters: the length scale of the RBF kernel {$\lambda$} describing the extent of generalisation, the exploration bonus of UCB sampling {$\beta$} and the temperature of softmax activation function {$\tau$} [Wu et al., 2020]. I attempt to extend their work by allowing the length scale parameter {$\lambda$} of the RBF kernel to change when participants explore the presented space and gather more information. This will model how the participants learn the extent of generalisation as they explore the space and gain more knowledge of the underlying environment. This model with a changing length scale parameter managed to improve the goodness of fit when compared to the model used by Wu et al. [Wu et al., 2020], but it failed to capture all of the behavioural differences between spatial and conceptual tasks. It is possible that the values estimated for the length scale parameter {$\lambda$} could have also absorbed information that would have otherwise allowed the other parameters {$\tau$} and {$\beta$} to capture the differences between the spatial and conceptual tasks. This thesis provides a basis for further research of human exploration and extrapolation utilising Bayesian optimisation with a changing degree of generalisation where the aforementioned shortcomings could be mitigated for example by designing the experiment in a way that provides more information about the participant's belief of the environment during each trial. ACM Computing Classification System (CCS): Applied computing \textrightarrow{} Law, social and behavioral sciences \textrightarrow{} Psychology Computing methodologies \textrightarrow{} Modeling and simulation \textrightarrow{} Model development and analysis \textrightarrow{} Modeling methodologies},
  school = {University of Helsinki},
  file = {/Users/thomasgorman/Documents/Zotero_Markdown/koli_human_2022-zotero.md;/Users/thomasgorman/OneDrive - Indiana University/resources/Zotero/Koli_2022_Human exploration and extrapolation in conceptual and spatial tasks.pdf}
}

@article{kruschkeALCOVEExemplarbasedConnectionist1992,
  title = {{{ALCOVE}}: {{An}} Exemplar-Based Connectionist Model of {{Category Learning}}},
  author = {Kruschke, John K.},
  year = {1992},
  journal = {Psychological Review},
  volume = {99},
  number = {1},
  abstract = {ALCOVE (attention learning covering map) is a connectionist model of category learning that incorporates an exemplar-based representation (D. L. Medin and M. M. Schaffer, 1978; R. M. Nosofsky, 1986) with error-driven learning (M. A. Gluck and G. H. Bower, 1988; D. E. Rumelhart et al, 1986). ALCOVE selectively attends to relevant stimulus dimensions, is sensitive to correlated dimensions, can account for a form of base-rate neglect, does not suffer catastrophic forgetting, and can exhibit 3-stage (U-shaped) learning of high-frequency exceptions to rules, whereas such effects are not easily accounted for by models using other combinations of representation and learning method.},
  file = {/Users/thomasgorman/Zotero/storage/372PLG2K/Kruschke - 1992 - ALCOVE An exemplar-based connectionist model of C.pdf}
}

@phdthesis{kruschkeConnectionistModelCategory,
  title = {A Connectionist Model of Category Learning},
  author = {Kruschke, John Kendall},
  address = {{United States -- California}},
  urldate = {2021-10-26},
  abstract = {ALCOVE is a new connectionist model of category learning that models the course of learning in humans and their asymptotic performance. The model is a variant of back propagation, using Gaussian (radial basis function) hidden nodes, and adaptive attential strengths on the input dimensions. Unlike standard back propagation networks, ALCOVE cannot develop completely new dimensions for representing the stimuli, but it does learn to differentially attend to the given input dimensions. ALCOVE is succesfully applied to several category learning phenomena: (1) It correctly orders the difficulty of the six category types from the classic work of Shepard, Hovland and Jenkins (1961). (2) It accurately fits trial-by-trial learning data and mimics the base-rate neglect observed by Gluck and Bower (1988b). In preliminary work, it is also shown that ALCOVE can: (3) exhibit three-stage learning of high-frequency exceptions to rules (cf. Rumelhart \& McClelland 1986), (4) show emergent graded internal structure in categories, i.e., typicality ratings, (5) produce asymmetries of similarities between typical and atypical exemplars, (6) show selective sensitivity to correlated dimensions, and (7) learn non-linearly separable categories faster than linearly separable categories, in those cases that humans do. It is also suggested that ALCOVE could serve as the input to a rule generating system, so that the dimensions most attended are the ones first used for rules. Moreover, it is shown that ALCOVE is falsifiable, in principle, and that there are some phenomena in category learning that ALCOVE cannot capture. Nevertheless, ALCOVE is attractive because of the broad range of phenomena it does model.},
  copyright = {Database copyright ProQuest LLC; ProQuest does not claim copyright in the individual underlying works.},
  langid = {english},
  school = {University of California, Berkeley},
  keywords = {back propagation,Psychology,selective attention},
  file = {/Users/thomasgorman/OneDrive - Indiana University/resources/Zotero/Kruschke_A connectionist model of category learning.pdf}
}

@unpublished{kruschkeCueCompetitionFunction2001,
  title = {Cue Competition in Function Learning: {{Blocking}} and Highlighting},
  shorttitle = {Comments Welcome. {{Cue}} Competition in Function Learning},
  author = {Kruschke, John K.},
  year = {2001},
  abstract = {In function learning, people learn to predict a continuous outcome from continuous cues. In category learning, people learn to predict a nominal outcome. The present research demonstrates that two complementary forms of cue competition, previously found in category learning, also occur in function learning. One form of cue competition is blocking of learning about a redundant cue (Kamin, 1968). A second form of cue competition is highlighting of a diagnostic cue (a.k.a. the inverse base rate effect; Medin \& Edelson, 1988). For tests with conflicting cues, the results show bimodality of responses, as opposed to averaging, which implies exclusive selectivity that cannot be discerned from category learning paradigms. It is argued that these effects are caused, in both category and function learning, by attentional shifts. No previously published model of function learning can account for these effects, but a model by Kalish, Lewandowsky, and Kruschke (2001) is promising. This article reports evidence of two types of strong cue competition in function learning. One effect is ``blocking '' of learning about a redundant relevant cue (Kamin, 1968). The other effect is what I call ``highlighting, '' previously referred},
  file = {/Users/thomasgorman/Documents/Zotero_Markdown/kruschke_cue_2001-zotero.md;/Users/thomasgorman/OneDrive - Indiana University/resources/Zotero/Kruschke_2001_Comments welcome.pdf;/Users/thomasgorman/Zotero/storage/Y9M6SJRV/summary.html}
}

@article{kruschkeDimensionalRelevanceShifts1996,
  title = {Dimensional {{Relevance Shifts}} in {{Category Learning}}},
  author = {Kruschke, John K},
  year = {1996},
  month = jun,
  journal = {Connection Science},
  volume = {8},
  number = {2},
  pages = {225--248},
  issn = {0954-0091, 1360-0494},
  doi = {10.1080/095400996116893},
  urldate = {2020-09-04},
  abstract = {A category learning experiment involving human participants compared the dif\textregistered{} culties of four types of shift learning. Initial learning was of an exclusive-or (XOR) structure on two of three stimulus dimensions. One shift type was a reversal, a second shift was to a single previously relevant dimension, a third shift was to a single previously irrelevant dimension, and a fourth shift was to an XOR on one previously relevant dimension and one previously irrelevant dimension. Results showed that reversal shift was easiest, follow ed, in order, by shift to a single previously relevant dimension, shift to a single previously irrelevant dimension, and a shift to a new XOR. An extended version of the ALCOVE model, called AM BRY, qualitatively \textregistered{} ts the data. The model incorporates two essential principles. First, internal category representations that can be quickly remapped to overt responses are important for accounting for the ease of reversal shift. Second, perseverating dimensional attention is important for accounting for the ease of shifting to a previously relevant dimension as opposed to a previously irrelevant dimension. It is suggested that any model of these effects will need to implement both of these principles.},
  langid = {english},
  file = {/Users/thomasgorman/Zotero/storage/WDRA4TCT/Kruschke - 1996 - Dimensional Relevance Shifts in Category Learning.pdf}
}

@article{kruschkeHumanCategoryLearning1993,
  title = {Human {{Category Learning}}: {{Implications}} for {{Backpropogation Models}}},
  author = {Kruschke, J.K.},
  year = {1993},
  journal = {Connection Science},
  volume = {5},
  urldate = {2021-11-17},
  abstract = {Backpropagation (Rumelhart et al., 1986) was proposed as a general learning algorithm for multi-layer perceptrons. This article demonstrates that a standard version of backprop fails to attend selectively to input dimensions in the same way as humans, suffers catastrophic forgetting of previously learned associations when novel exemplars are trained, and can be overly sensitive to linear category boundaries. Another connectionist model, ALCOVE (Kruschke 1990, 1992), does not suffer those failures. Previous researchers identified these problems; the present article reports quantitative fits of the models to new human learning data. ALCOVE can be functionally approximated by a network that uses linear-sigmoid hidden nodes, like standard backprop. It is argued that models of human category learning should incorporate quasi-local representations and dimensional attention learning, as well as error-driven learning, to address simultaneously all three phenomena.},
  file = {/Users/thomasgorman/OneDrive - Indiana University/resources/Zotero/Kruschke_1993_Human Category Learning.pdf}
}

@article{kruschkeLocallyBayesianLearning,
  title = {Locally {{Bayesian Learning}}},
  author = {Kruschke, John K},
  pages = {7},
  abstract = {This article is concerned with trial-by-trial, online learning of cue-outcome mappings. In models structured as successions of component functions, an external target can be backpropagated such that the lower layer's target is the input to the higher layer that maximizes the probability of the higher layer's target. Each layer then does locally Bayesian learning. The resulting parameter updating is not globally Bayesian, but can better capture human behavior. The approach is implemented for an associative learning model that first maps inputs to attentionally filtered inputs, and then maps attentionally filtered inputs to outputs. The model is applied to the humanlearning phenomenon called highlighting, which is challenging to other extant Bayesian models, including the rational model of Anderson, the Kalman filter model of Dayan and Kakade et al., the noisy-OR model of Tenenbaum and Griffiths et al., and the sigmoid-belief networks of Courville et al. Further details and applications are provided by Kruschke (in press); the present article reports new simulations of the Kalman filter and rational model.},
  langid = {english},
  file = {/Users/thomasgorman/OneDrive - Indiana University/resources/Zotero/Kruschke_Locally Bayesian Learning.pdf}
}

@article{kruschkeModelProbabilisticCategory1999,
  title = {A Model of Probabilistic Category Learning},
  author = {Kruschke, John K. and Johansen, Mark K.},
  year = {1999},
  journal = {Journal of Experimental Psychology: Learning, Memory, and Cognition},
  volume = {25},
  number = {5},
  pages = {1083--1119},
  publisher = {{American Psychological Association}},
  address = {{US}},
  issn = {1939-1285(Electronic),0278-7393(Print)},
  doi = {10.1037/0278-7393.25.5.1083},
  abstract = {A new connectionist model (named RASHNL) accounts for many "irrational" phenomena found in nonmetric multiple-cue probability learning, wherein people learn to utilize a number of discrete-valued cues that are partially valid indicators of categorical outcomes. Phenomena accounted for include cue competition, effects of cue salience, utilization of configural information, decreased learning when information is introduced after a delay, and effects of base rates. Exps 1 and 2 replicate previous experiments on cue competition and cue salience, and fits of the model provide parameter values for making qualitatively correct predictions for many other situations. The model also makes 2 new predictions, confirmed in Exps 3 and 4. The model formalizes 3 explanatory principles: rapidly shifting attention with learned shifts, decreasing learning rates, and graded similarity in exemplar representation. (PsycINFO Database Record (c) 2016 APA, all rights reserved)},
  keywords = {Attention,Cues,Models,Probability Learning},
  file = {/Users/thomasgorman/OneDrive - Indiana University/resources/Zotero/Kruschke_Johansen_1999_A model of probabilistic category learning.pdf;/Users/thomasgorman/Zotero/storage/EYFJL3PS/1999-03993-001.html}
}

@article{kruschkeModelsAttentionalLearning2011,
  title = {Models of Attentional Learning},
  author = {Kruschke, John K.},
  year = {2011},
  journal = {Formal approaches in categorization},
  volume = {120},
  file = {/Users/thomasgorman/Zotero/storage/BGFATPRS/Kruschke2011PWed.pdf}
}

@article{kruschkeUnifiedModelAttention2001,
  title = {Toward a {{Unified Model}} of {{Attention}} in {{Associative Learning}}},
  author = {Kruschke, John K.},
  year = {2001},
  month = dec,
  journal = {Journal of Mathematical Psychology},
  volume = {45},
  number = {6},
  pages = {812--863},
  issn = {00222496},
  doi = {10.1006/jmps.2000.1354},
  urldate = {2020-03-15},
  langid = {english},
  file = {/Users/thomasgorman/Zotero/storage/L5WG7XSM/Kruschke - 2001 - Toward a Unified Model of Attention in Associative.pdf}
}

@book{kumaranGeneralizationRecurrentInteraction,
  title = {Generalization {{Through}} the {{Recurrent Interaction}} of {{Episodic Memories}}: {{A Model}} of the {{Hippocampal System}}},
  shorttitle = {Generalization {{Through}} the {{Recurrent Interaction}} of {{Episodic Memories}}},
  author = {Kumaran, Dharshan and Mcclelland, James L. and Glick, Jeremy and Nosofsky, Robert M. and Saxe, Andrew and Sternberg, Daniel},
  abstract = {In this article, we present a perspective on the role of the hippocampal system in generalization, instantiated in a computational model called REMERGE (recurrency and episodic memory results in generalization). We expose a fundamental, but neglected, tension between prevailing computational theories that emphasize the function of the hippocampus in pattern separation (Marr, 1971; McClelland, McNaughton,  \& O'Reilly, 1995), and empirical support for its role in generalization and flexible relational memory (Cohen \& Eichenbaum, 1993; Eichenbaum, 1999). Our account provides a means by which to resolve this conflict, by demonstrating that the basic representational scheme envisioned by complementary learning systems theory (McClelland et al., 1995), which relies upon orthogonalized codes in the hippocampus, is compatible with efficient generalization\textemdash as long as there is recurrence rather than unidirectional flow within the hippocampal circuit or, more widely, between the hippocampus and neocortex. We propose that recurrent similarity computation, a process that facilitates the discovery of higher-order relationships between a set of related experiences, expands the scope of classical exemplar-based models of memory (e.g., Nosofsky, 1984) and allows the hippocampus to support},
  file = {/Users/thomasgorman/OneDrive - Indiana University/resources/Zotero/Kumaran et al_Generalization Through the Recurrent Interaction of Episodic Memories.pdf;/Users/thomasgorman/Zotero/storage/M6THSYSS/summary.html}
}

@article{kvamReconcilingSimilarityModels2021,
  title = {Reconciling Similarity across Models of Continuous Selections},
  author = {Kvam, Peter D. and Turner, Brandon},
  year = {2021},
  journal = {Psychological Review},
  volume = {128},
  number = {4},
  pages = {766--786},
  doi = {10.31234/osf.io/p3fty},
  urldate = {2020-08-14},
  abstract = {Recently developed models of decision-making have provided accounts of the cognitive processes underlying choice on tasks where responses can fall along a continuum, such as identifying the color or orientation of a stimulus. Even though nearly all of these models seek to extend diffusion decision processes to a continuum of response options, they vary in terms of complexity, tractability, and their ability to predict patterns of data such as multimodal distributions of responses. We suggest that these differences are almost entirely due to differences in how these models account for the similarity among response options. In this theoretical note, we reconcile these differences by characterizing the existing models under a common framework, where the assumptions about psychological representations of similarity, and their implications for behavioral data (e.g., multimodal responses), are made explicit. Furthermore, we imple- ment a simulation-based approach to computing model likelihoods that allows for greater freedom in constructing and implementing continuous response models. The resulting geometric similarity represen- tation (GSR) can supplement approaches like the circular/spherical diffusion models by allowing them to generate multimodal distributions of responses from a single drift, or simplify models like the spatially continuous diffusion model (SCDM) by condensing their representations of similarity and allowing them to generate simulations more efficiently. To illustrate its utility, we apply this approach to multimodal distributions responses, two-dimensional responses (such as locations on a computer screen), and continuous response options with nontrivial, nonlinear similarity relations between response options.},
  langid = {english},
  keywords = {matlab code},
  file = {/Users/thomasgorman/Documents/Zotero_Markdown/kvam_reconciling_2021-zotero.md;/Users/thomasgorman/OneDrive - Indiana University/resources/Zotero/Kvam_Turner_2021_Reconciling similarity across models of continuous selections.pdf}
}

@techreport{kvamUnifiedTheoryDiscrete2021,
  type = {Preprint},
  title = {A Unified Theory of Discrete and Continuous Responding},
  author = {Kvam, Peter D. and Marley, A. A. J. and Heathcote, Andrew},
  year = {2021},
  month = jul,
  institution = {{PsyArXiv}},
  doi = {10.31234/osf.io/dkybt},
  urldate = {2021-08-01},
  abstract = {Understanding the cognitive processes underlying choice requires theories that can disentangle the representation of stimuli from the processes that map these representations onto observed responses. We develop a dynamic theory of how stimuli are mapped onto discrete (choice) and continuous response scales. It proposes that the mapping from stimuli to the input to an evidence accumulation process is accomplished using multiple reference points or ``anchors''. Evidence is accumulated until a threshold amount for a particular response is obtained, with the relative balance of support for each anchor at that time determining the response. We tested this Multiple Anchored Accumulation Theory (MAAT) using the results of two experiments requiring discrete or continuous responses to line length and color stimuli. We manipulated the number of options for discrete responses, the number of different stimuli, and the similarity amongst them, and compared the outcomes to continuous response conditions. We show that MAAT accounts for several key phenomena: more accurate choices and more skewed response distributions near the ends of a response scale; a decrease in accuracy and response speed as the number of discrete choice options increases; and longer response times and lower accuracy when discrete responses were more similar to one another. Our empirical and modeling results suggest that discrete and continuous response tasks can share a common evidence representation, and that the decision process is sensitive to the perceived similarity among the response options.},
  langid = {english},
  file = {/Users/thomasgorman/Documents/Zotero_Markdown/kvam_unified_2021-zotero.md;/Users/thomasgorman/OneDrive - Indiana University/resources/Zotero/Kvam et al_2021_A unified theory of discrete and continuous responding.pdf}
}

@article{kvamUnifiedTheoryDiscrete2022,
  title = {A Unified Theory of Discrete and Continuous Responding},
  author = {Kvam, Peter D. and Marley, A. a. J. and Heathcote, Andrew},
  year = {2022},
  month = jul,
  journal = {Psychological Review},
  publisher = {{American Psychological Association}},
  issn = {0033-295X},
  doi = {10.1037/rev0000378},
  urldate = {2023-01-05},
  abstract = {Understanding the cognitive processes underlying choice requires theories that can disentangle the representation of stimuli from the processes that map these representations onto observed responses. We develop a dynamic theory of how stimuli are mapped onto discrete (choice) and onto continuous response scales. It proposes that the mapping from a stimulus to an internal representation and then to an evidence accumulation process is accomplished using multiple reference points or 'anchors.' Evidence is accumulated until a threshold amount for a particular response is obtained, with the relative balance of support for each anchor at that time determining the response. We tested this multiple anchored accumulation theory (MAAT) using the results of two experiments requiring discrete or continuous responses to line length and color stimuli. We manipulated the number of options for discrete responses, the number of different stimuli, and the similarity among them, and compared the outcomes to continuous response conditions. We show that MAAT accounts for several key phenomena: more accurate, faster, and more skewed distributions of responses near the ends of a response scale; lower accuracy and slower responses as the number of discrete choice options increases; and longer response times and lower accuracy when alternative responses are more similar to the target response. Our empirical and modeling results suggest that discrete and continuous response tasks can share a common evidence representation, and that the decision process is sensitive to the perceived similarity among the response options. (PsycInfo Database Record (c) 2022 APA, all rights reserved)},
  keywords = {absolute identification,Choice Behavior,cognitive modeling,Cognitive Processes,Color,continuous report,Decision Making,multi-alternative choice,perception,Responses,Simulation,Skewed Distribution,Theories,Threshold Determination},
  file = {/Users/thomasgorman/Documents/Zotero_Markdown/kvamUnifiedTheoryDiscrete2022-zotero.md;/Users/thomasgorman/OneDrive - Indiana University/resources/Zotero/Kvam et al_2022_A unified theory of discrete and continuous responding.pdf}
}

@article{kwantesFunctionLearningExemplar2003,
  title = {Function Learning {{An}} Exemplar Account of Extrapolation Performance},
  author = {Kwantes, Peter J.},
  year = {2003},
  pages = {27},
  abstract = {A function describes a one-to-one relationship between combinations of predictor and criterion variables. In this paper, we describe a new memory model that learns functional relationships. Two versions of the model are described. The first version learns the bivarite relationship between a single predictor and criterion. The second version expands on the first to multiple predictors. For both versions of the model, we present empirical data to test them and find that they do a good job of accounting for human performance.  Executive summary A function is a one-to-one relationship between a combination of predictor variables and criterion variables. There are few computational models that try to explain how people learn such relationships. There are generally two classes of model that could be used to explain the skill. Rule-abstraction models propose that trainees learn a representation of the training equation (akin to a regression equation) that maps the predictors onto the criterion. During learning, the system's job is to figure out the regression weights that do the best job. The other class of model, so-called exemplar models, propose that trainees make contact with and report the closest examples stored in memory from training. Both classes of model are wrong: Strict exemplar models cannot extrapolate to values it has not been trained on. Strict rule-abstraction models also fail because trainee's performance on extrapolation items tends to diverge from the values predicted by the training function. In this paper, we introduce an exemplar model that learns bivariate and multivariate functional relationships and has the ability to extrapolate to novel predictor values. The model is able to extrapolate because it learns the relative changes in the predictors and criterion as they occur from trial to trial, and uses that information to find the best value for extrapolation items. The model's performance is compared to human performance, and for both the bivariate and multivariate versions of the model, we show that it does a good job of accounting for trainees' performance. The model described in this report provides a simple, yet flexible, framework in which to characterize situations where an operator must learn a quantitative relationship between one or more predictors and a criterion variable. We are currently aiming to include the model in a virtual helicopter pilot to characterize knowledge of the relationship between the amount of movement in the controls (pedals, cyclic, collective) required in response to perturbations in the aircraft's position. Our intent is to build operator models for the CF that exhibit humanlike behaviours by virtue of the fact that they include psychological models of processes and knowledge representation. The model described in this report provides a basic architecture for representing knowledge of functional relationships in a virtual operator.},
  langid = {english},
  file = {/Users/thomasgorman/Documents/Zotero_Markdown/kwantes_function_2003-zotero.md;/Users/thomasgorman/OneDrive - Indiana University/resources/Zotero/Kwantes_2003_Function learning An exemplar account of extrapolation performance.pdf}
}

@article{kwantesItemOrderMatters2012,
  title = {Item Order Matters in a Function Learning Task.},
  author = {Kwantes, Peter J. and Neal, Andrew and Kalish, Michael},
  year = {2012},
  journal = {Canadian Journal of Experimental Psychology/Revue canadienne de psychologie exp\'erimentale},
  volume = {66},
  number = {2},
  pages = {90--97},
  issn = {1878-7290, 1196-1961},
  doi = {10.1037/a0026639},
  urldate = {2021-10-09},
  abstract = {In a function learning task, participants are taught the relationship between 2 variables, a predictor (e.g., the dosage of a drug) and a criterion (e.g., its effect on mood). Of particular interest in this article is the question of what information does a participant use to generate a response for test examples that fall outside the training region\textemdash so-called, extrapolation items. In this article, we test whether the presentation of training items has an impact on the pattern of responses for items requiring participants to extrapolate, and examine, whether the 2 dominant accounts of function learning (Population of Linear Experts [POLE]: Kalish, Lewandowsky, \& Kruschke, 2004; and Extrapolation Association Model [EXAM]: DeLosh, Busemeyer, \& McDaniel, 1997) can account for this effect. The results show that a manipulation of trial-to-trial changes in the relative magnitudes of the predictor and criterion does influence subsequent extrapolation, and neither POLE, nor EXAM, was able to account for this effect in their current forms. We demonstrate that a model that encodes information about the trial-to-trial changes in the predictor and criterion, and which subsequently uses this information to adjust the retrieved value of the criterion, can account for the effect.},
  langid = {english},
  file = {/Users/thomasgorman/Documents/Zotero_Markdown/kwantesItemOrderMatters2012-zotero.md;/Users/thomasgorman/OneDrive - Indiana University/resources/Zotero/Kwantes et al_2012_Item order matters in a function learning task.pdf}
}

@article{kwantesWhyPeopleUnderestimate2006,
  title = {Why People Underestimate y When Extrapolating in Linear Functions},
  author = {Kwantes, Peter J. and Neal, Andrew},
  year = {2006},
  month = sep,
  journal = {Journal of Experimental Psychology: Learning, Memory, and Cognition},
  volume = {32},
  number = {5},
  pages = {1019--1030},
  publisher = {{American Psychological Association}},
  issn = {0278-7393},
  doi = {10.1037/0278-7393.32.5.1019},
  urldate = {2022-04-19},
  abstract = {E. L. DeLosh, J. R. Busemeyer, and M. A. McDaniel (1997) found that when learning a positive, linear relationship between a continuous predictor (x) and a continuous criterion (y), trainees tend to underestimate y on items that ask the trainee to extrapolate. In 3 experiments, the authors examined the phenomenon and found that the tendency to underestimate y is reliable only in the so-called lower extrapolation region--that is, new values of x that lie between zero and the edge of the training region. Existing models of function learning, such as the extrapolation-association model (DeLosh et al., 1997) and the population of linear experts model (M. L. Kalish, S. Lewandowsky, \& J. Kruschke, 2004), cannot account for these results. The authors show that with minor changes, both models can predict the correct pattern of results. (PsycINFO Database Record (c) 2016 APA, all rights reserved)},
  keywords = {Concept Formation,continuous predictor \& criterion,extrapolation,function learning,Humans,interpolation,Judgment,Learning,linear functions,Linear Models,models,Models,{Models, Psychological},Problem Solving,Statistical Variables},
  file = {/Users/thomasgorman/Documents/Zotero_Markdown/kwantesWhyPeopleUnderestimate2006-zotero.md;/Users/thomasgorman/OneDrive - Indiana University/resources/Zotero/Kwantes_Neal_2006_Why people underestimate y when extrapolating in linear functions.pdf}
}

@article{lagnadoInsightStrategyMultiplecue2006,
  title = {Insight and Strategy in Multiple-Cue Learning.},
  author = {Lagnado, David A. and Newell, Ben R. and Kahan, Steven and Shanks, David R.},
  year = {2006},
  journal = {Journal of Experimental Psychology: General},
  volume = {135},
  number = {2},
  pages = {162--183},
  issn = {1939-2222, 0096-3445},
  doi = {10.1037/0096-3445.135.2.162},
  urldate = {2021-06-27},
  langid = {english},
  file = {/Users/thomasgorman/Documents/Zotero_Markdown/lagnado_insight_2006-zotero.md;/Users/thomasgorman/OneDrive - Indiana University/resources/Zotero/Lagnado et al_2006_Insight and strategy in multiple-cue learning.pdf}
}

@article{lambertsFlexibleTuningSimilarity1994,
  title = {Flexible {{Tuning}} of {{Similarity}} in {{Exemplar-Based Categorization}}},
  author = {Lamberts, Koen},
  year = {1994},
  journal = {Journal of Experimental Psychology: Learning, Memory, and Cognition},
  volume = {20},
  number = {5},
  pages = {1003--1021},
  abstract = {Flexibility in exemplar-based categorization was investigated in 3 experiments. Ss categorized schematic drawings of individuals' faces while they received information about the kinship relation between these individuals and previously observed exemplars. In Experiments 1 and 2, initial training was incidental, whereas an intentional learning task was used in Experiment 3. In all experiments, the kinship manipulation systematically affected categorizations. Model-based analyses showed that the effect of the kinship manipulation could be described by similarity-based exemplar models if it was assumed that Ss applied different levels of generalization as a function of the kinship instructions. These results demonstrate that categorization is a highlyflexibleprocess, and their methodological and theoretical implications are discussed.},
  file = {/Users/thomasgorman/Zotero/storage/XAV3LHSU/Lamberts - 1994 - Flexible Tuning of Similarity in Exemplar-Based Ca.pdf}
}

@article{lampinenTransformingTaskRepresentations2020,
  title = {Transforming Task Representations to Perform Novel Tasks},
  author = {Lampinen, Andrew K. and McClelland, James L.},
  year = {2020},
  month = dec,
  journal = {Proceedings of the National Academy of Sciences},
  volume = {117},
  number = {52},
  pages = {32970--32981},
  publisher = {{National Academy of Sciences}},
  issn = {0027-8424, 1091-6490},
  doi = {10.1073/pnas.2008852117},
  urldate = {2021-05-15},
  abstract = {An important aspect of intelligence is the ability to adapt to a novel task without any direct experience (zero shot), based on its relationship to previous tasks. Humans can exhibit this cognitive flexibility. By contrast, models that achieve superhuman performance in specific tasks often fail to adapt to even slight task alterations. To address this, we propose a general computational framework for adapting to novel tasks based on their relationship to prior tasks. We begin by learning vector representations of tasks. To adapt to new tasks, we propose metamappings, higher-order tasks that transform basic task representations. We demonstrate the effectiveness of this framework across a wide variety of tasks and computational paradigms, ranging from regression to image classification and reinforcement learning. We compare to both human adaptability and language-based approaches to zero-shot learning. Across these domains, metamapping is successful, often achieving 80 to 90\% performance, without any data, on a novel task, even when the new task directly contradicts prior experience. We further show that metamapping can not only generalize to new tasks via learned relationships, but can also generalize using novel relationships unseen during training. Finally, using metamapping as a starting point can dramatically accelerate later learning on a new task and reduce learning time and cumulative error substantially. Our results provide insight into a possible computational basis of intelligent adaptability and offer a possible framework for modeling cognitive flexibility and building more flexible artificial intelligence systems.},
  chapter = {Physical Sciences},
  copyright = {\textcopyright{} 2020 . https://www.pnas.org/site/aboutpnas/licenses.xhtmlPublished under the PNAS license.},
  langid = {english},
  pmid = {33303652},
  keywords = {artificial intelligence,cognitive science,transfer,zero-shot},
  file = {/Users/thomasgorman/Documents/Zotero_Markdown/lampinen_transforming_2020-zotero.md;/Users/thomasgorman/OneDrive - Indiana University/resources/Zotero/Lampinen_McClelland_2020_Transforming task representations to perform novel tasks.pdf;/Users/thomasgorman/Zotero/storage/UWMTVWWU/pnas.2008852117.pdf;/Users/thomasgorman/Zotero/storage/RIPSUU7U/32970.html}
}

@article{lawsonSampleSelectionInductive2009,
  title = {Sample Selection and Inductive Generalization},
  author = {Lawson, Chris A. and Kalish, Charles W.},
  year = {2009},
  month = jul,
  journal = {Memory \& Cognition},
  volume = {37},
  number = {5},
  pages = {596--607},
  issn = {0090-502X, 1532-5946},
  doi = {10.3758/MC.37.5.596},
  urldate = {2020-08-19},
  langid = {english},
  file = {/Users/thomasgorman/Zotero/storage/MSBLGZV4/Lawson and Kalish - 2009 - Sample selection and inductive generalization.pdf}
}

@article{leeConnectionistConstructionPsychological1997,
  title = {The {{Connectionist Construction}} of {{Psychological Spaces}}},
  author = {Lee, Michael D},
  year = {1997},
  month = dec,
  journal = {Connection Science},
  volume = {9},
  number = {4},
  pages = {323--352},
  issn = {0954-0091, 1360-0494},
  doi = {10.1080/095400997116586},
  urldate = {2021-10-26},
  langid = {english},
  file = {/Users/thomasgorman/OneDrive - Indiana University/resources/Zotero/Lee_1997_The Connectionist Construction of Psychological Spaces.pdf}
}

@article{leeNotTakingEasy2015,
  title = {Not Taking the Easy Road: {{When}} Similarity Hurts Learning},
  shorttitle = {Not Taking the Easy Road},
  author = {Lee, Hee Seung and Betts, Shawn and Anderson, John R.},
  year = {2015},
  month = aug,
  journal = {Memory \& Cognition},
  volume = {43},
  number = {6},
  pages = {939--952},
  issn = {0090-502X, 1532-5946},
  doi = {10.3758/s13421-015-0509-3},
  urldate = {2017-09-25},
  langid = {english},
  file = {/Users/thomasgorman/Zotero/storage/Q5JWE9QH/Lee et al. - 2015 - Not taking the easy road When similarity hurts le.pdf}
}

@article{leon-villagraExploringRepresentationLinear2019,
  title = {Exploring the {{Representation}} of {{Linear Functions}}},
  author = {{Leon-Villagra}, Pablo and Klar, Verena S and Sanborn, Adam N and Lucas, Christopher G},
  year = {2019},
  pages = {7},
  abstract = {Function learning research has highlighted the importance of human inductive biases that facilitate long-range extrapolations. However, most previous research is focused on aggregate errors or single-criterion extrapolations. Thus, little is known about the underlying psychological space in which continuous relationships are represented. We ask whether people can learn the distributional properties of new classes of relationships, using Markov Chain Monte Carlo with People, and find that (1) people are able to track not just the expected parameters of a linear function, but information about the variability of functions in a specific context and (2) in many cases these spaces over parameters exhibit multiple modes.},
  langid = {english},
  file = {/Users/thomasgorman/Documents/Zotero_Markdown/leon-villagraExploringRepresentationLinear2019-zotero.md;/Users/thomasgorman/OneDrive - Indiana University/resources/Zotero/Leon-Villagra et al_Exploring the Representation of Linear Functions.pdf}
}

@techreport{leon-villagraGeneralizingFunctionsSparse2019,
  type = {Preprint},
  title = {Generalizing {{Functions}} in {{Sparse Domains}}},
  author = {{Leon-Villagra}, Pablo and Lucas, Christopher G.},
  year = {2019},
  month = jun,
  institution = {{PsyArXiv}},
  doi = {10.31234/osf.io/zfrbu},
  urldate = {2021-05-16},
  abstract = {We propose that when humans learn sets of relationships they are able to learn the abstract structure or type of a family of relationships, and exploit that knowledge to improve their ability to learn and generalize in the future, especially in the face of sparse or ambiguous data. In two experiments we found that participants choose patterns and extrapolate in ways consistent with sets of previously learned relations, as measured by extrapolation judgments and forced-choice tasks. We take these results to suggest that humans can detect shared abstract relations and apply this learned regularity to perform rapid and flexible generalization.},
  langid = {english},
  file = {/Users/thomasgorman/Documents/Zotero_Markdown/leon-villagra_generalizing_2019-zotero.md;/Users/thomasgorman/OneDrive - Indiana University/resources/Zotero/Leon-Villagra_Lucas_2019_Generalizing Functions in Sparse Domains.pdf}
}

@phdthesis{leon-villagraRepresentationalPrinciplesFunction2020,
  title = {Representational {{Principles}} of {{Function Generalization}}},
  author = {{Le{\'o}n-Villagr{\'a}}, Pablo},
  year = {2020},
  abstract = {Generalization is at the core of human intelligence. When the relationship between continuous-valued data is generalized, generalization amounts to function learning. Function learning is important for understanding human cognition, as many everyday tasks and problems involve learning how quantities relate and subsequently using this knowledge to predict novel relationships. While function learning has been studied in psychology since the early 1960s, this thesis argues that questions regarding representational characteristics have not been adequately addressed in previous research. Previous accounts of function learning have often proposed one-size-fits-all models that excel at capturing how participants learn and extrapolate. In these models, learning amounts to learning the details of the presented patterns. Instead, this thesis presents computational and empirical results arguing that participants often learn abstract features of the data, such as the type of function or the variability of features of the function, instead of the details of the function. While previous work has emphasized domain-general inductive biases and learning rates, I propose that these biases are more flexible and adaptive than previously suggested. Given contextual information that sequential tasks share the same structure, participants can transfer knowledge from previous training to inform their generalizations. Furthermore, this thesis argues that function representations can be composed to form more complex hypotheses, and humans are perceptive to, and sometimes generalize according to these compositional features. Previous accounts of function learning had to postulate a fixed set of candidate functions that form a participants' hypothesis space, which ultimately struggled to account for the variety of extrapolations people can produce. In contrast, this thesis's results suggest that a small set of broadly applicable functions, in combination with compositional principles, can produce flexible and productive generalization. Introduction 5 2.1 The Basis for Generalization . . . . . . . . . . . . . . . . . . . . . 6 2.2 Representation and the Target of Generalization . . . . . . . . . . 10 2.3 Generalization and Transfer in Function Learning . . . . . . . . . 13 2.3.1 Experimental Paradigms . . . . . . . . . . . . . . . . . . . 19 2.3.2 Models of Function Learning and Generalization . . . . . . 20 2.3.3 Open Questions in Function Learning and Outline of the Thesis . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 21 3 Function Representation and Generalization 25 3.1 Experiment . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 26 3.1.1 Participants . . . . . . . . . . . . . . . . . . . . . . . . . . 27 3.1.2 Materials . . . . . . . . . . . . . . . . . . . . . . . . . . . 27 3.1.3 Procedure . . . . . . . . . . . . . . . . . . . . . . . . . . . 28 3.2 Results . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 30 3.2.1 Functions and Presentation Form . . . . . . . . . . . . . . 30 3.2.2 Data Availability and Presentation . . . . . . . . . . . . . 31 3.3 Modeling Function Extrapolations . . . . . . . . . . . . . . . . . . 34 3.3.1 Human Function Priors . . . . . . . . . . . . . . . . . . . . 34 3.3.2 Modeling Data Availability . . . . . . . . . . . . . . . . . . 36 vii 3.3.3 Posterior Mass for Functions . . . . . . . . . . . . . . . . . 37 3.3.4 Posterior Model Extrapolations . . . . . . . . . . . . . . . 39 3.3.5 Recovering Experimental Conditions from Likelihoods . . . 40 3.4 Discussion . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 42 4 A Distributional Space of Functions 45 4.1 Markov chain Monte Carlo with people . . . . . . . . . . . . . . . 46 4.2 Experiment . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 49 4.2.1 Participants . . . . . . . . . . . . . . . . . . . . . . . . . . 50 4.2.2 Materials . . . . . . . . . . . . . . . . . . . . . . . . . . . 50 4.2.3 MCMCP . . . . . . . . . . . . . . . . . . . . . . . . . . . . 51 4.2.4 Procedure . . . . . . . . . . . . . . . . . . . . . . . . . . . 52 4.3 Results . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 53 4.3.1 Determining Burn-in . . . . . . . . . . . . . . . . . . . . . 55 4.3.2 Acceptance Probabilities . . . . . . . . . . . . . . . . . . . 55 4.3.3 Posterior Distributions . . . . . . . . . . . . . . . . . . . . 56 4.4 Discussion . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 62 5 Transferring Functions and Parametrizations 65 5.1 Experiments . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 67 5.1.1 Procedure . . . . . . . . . . . . . . . . . . . . . . . . . . . 68 5.1.2 Materials . . . . . . . . . . . . . . . . . . . . . . . . . . . 69 5.1.3 Participants . . . . . . . . . . . . . . . . . . . . . . . . . . 73 5.2 Results . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 73 5.2.1 Training Errors . . . . . . . . . . . . . . . . . . . . . . . . 73 5.2.2 Choices . . . . . . . . . . . . . . . . . . . . . . . . . . . . 77 5.2.3 Extrapolations . . . . . . . . . . . . . . . . . . . . . . . . 84 5.3 Discussion . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 92 viii 6 Generalizing Function Compositions 95 6.1 Overview of the Experiments . . . . . . . . . . . . . . . . . . . . 99 6.1.1 Generating Functions . . . . . . . . . . . . . . . . . . . . . 100 6.2 Experiment 1: Distinguishing Compositions . . . . . . . . . . . . 102 6.2.1 Participants . . . . . . . . . . . . . . . . . . . . . . . . . . 103 6.2.2 Materials . . . . . . . . . . . . . . . . . . . . . . . . . . . 103 6.2.3 Procedure . . . . . . . . . . . . . . . . . . . . . . . . . . . 103 6.2.4 Results . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 104 6.3 Experiment 2: Generalizing a Composition . . . . . . . . . . . . . 108 6.3.1 Participants . . . . . . . . . . . . . . . . . . . . . . . . . . 109 6.3.2 Design and Procedure . . . . . . . . . . . . . . . . . . . . 109 6.3.3 Results . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 109 6.4 Experiment 3: Generalizing Distinguishable Compositions . . . . 112 6.4.1 Participants . . . . . . . . . . . . . . . . . . . . . . . . . . 112 6.4.2 Design and Procedure . . . . . . . . . . . . . . . . . . . . 113 6.4.3 Results . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 113 6.5 Experiment 4: Alternative Explanations . . . . . . . . . . . . . . 119 6.5.1 Participants . . . . . . . . . . . . . . . . . . . . . . . . . . 119 6.5.2 Design and Procedure . . . . . . . . . . . . . . . . . . . . 119 6.5.3 Results . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 120 6.6 Discussion and Conclusion . . . . . . . . . . . . . . . . . . . . . . 122 7 Transferring Function Compositions 127 7.1 Experiments . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 129 7.1.1 Participants . . . . . . . . . . . . . . . . . . . . . . . . . . 131 7.1.2 Procedure . . . . . . . . . . . . . . . . . . . . . . . . . . . 132 7.1.3 Materials . . . . . . . . . . . . . . . . . . . . . . . . . . . 133 7.2 Results . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 135 7.2.1 Training Errors . . . . . . . . . . . . . . . . . . . . . . . . 135 ix 7.2.2 Extrapolations . . . . . . . . . . . . . . . . . . . . . . . . 141 7.2.3 Choices . . . . . . . . . . . . . . . . . . . . . . . . . . . . 148 7.3 Discussion . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 154 8 Conclusion 157 8.1 Contributions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 157 8.2 Open Questions and Implications . . . . . . . . . . . . . . . . . . 159 A Gaussian Processes 165 A.1 What are Gaussian Processes? . . . . . . . . . . . . . . . . . . . . 165 A.2 Sampling from the Prior and Conditioning on Data . . . . . . . . 168 A.3 Composing Gaussian Processes . . . . . . . . . . . . . . . . . . . 168 B Function Representation and Generalization 173 C A Distributional Space of Functions 177 D Transferring Functions and Parametrizations 181 D.1 Experiment . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 181 D.2 Error Models . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 185 D.2.1 Log-normal Error Models . . . . . . . . . . . . . . . . . . 185 D.2.2 Exponential Decay Model . . . . . . . . . . . . . . . . . . 186 D.2.3 Model Comparisons . . . . . . . . . . . . . . . . . . . . . . 189 D.3 Choice Model . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 191 E Generalizing Function Compositions 195 F Transferring Function Compositions 199 F.1 Experiment . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 199 F.2 Error Models . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 204 F.2.1 Model Comparisons . . . . . . . . . . . . . . . . . . . . . . 204 F.3 Choice Model . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 208},
  langid = {english},
  school = {University of Edinburgh},
  file = {/Users/thomasgorman/Documents/Zotero_Markdown/leon-villagra_representational_2020-zotero.md;/Users/thomasgorman/OneDrive - Indiana University/resources/Zotero/León-Villagrá_Representational Principles of Function Generalization.pdf}
}

@article{lewandowskyBaserateNeglectALCOVE1995,
  title = {Base-Rate Neglect in {{ALCOVE}}: {{A}} Critical Reevaluation},
  shorttitle = {Base-Rate Neglect in {{ALCOVE}}},
  author = {Lewandowsky, Stephan},
  year = {1995},
  month = jan,
  journal = {Psychological Review},
  volume = {102},
  number = {1},
  pages = {185--191},
  publisher = {{American Psychological Association}},
  issn = {0033-295X},
  doi = {10.1037/0033-295X.102.1.185},
  urldate = {2021-12-11},
  abstract = {A recent hybrid model of categorization (Attention Learning Covering Map [ALCOVE]; J. K. Kruschke, 1992) has combined the most desirable properties of exemplar models with a connectionist architecture and learning rule. A critically important property of ALCOVE is its apparent ability to account for base-rate neglect, a phenomenon beyond the purview of previous exemplar models. This article reexamines ALCOVE's base-rate neglect predictions and shows that they are confined to a very limited set of circumstances. In most cases, ALCOVE is unable to produce base-rate neglect. (PsycINFO Database Record (c) 2016 APA, all rights reserved)},
  keywords = {Attention Learning Covering Map model of categorization,Classification (Cognitive Process),Models,prediction of base rate neglect},
  file = {/Users/thomasgorman/OneDrive - Indiana University/resources/Zotero/Lewandowsky_1995_Base-rate neglect in ALCOVE.pdf}
}

@article{lewandowskySimplifiedLearningComplex2002,
  title = {Simplified Learning in Complex Situations: {{Knowledge}} Partitioning in Function Learning},
  shorttitle = {Simplified Learning in Complex Situations},
  author = {Lewandowsky, Stephan and Kalish, Michael and Ngang, S},
  year = {2002},
  month = jul,
  journal = {Journal of experimental psychology. General},
  volume = {131},
  pages = {163--93},
  doi = {10.1037/0096-3445.131.2.163},
  abstract = {The authors explored the phenomenon that knowledge is not always integrated and consistent but may be partitioned into independent parcels that may contain mutually contradictory information. In 4 experiments, using a function learning paradigm, a binary context variable was paired with the continuous stimulus variable of a to-be-learned function. In the first 2 experiments, when context predicted the slope of a quadratic function, generalization was context specific. Because context did not predict function values, it is suggested that people use context to gate separate learning of simpler partial functions. The 3rd experiment showed that partitioning also occurs with a decreasing linear function, whereas the 4th study showed that partitioning is absent for a linearly increasing function. The results support the notion that people simplify complex learning tasks by acquiring independent parcels of knowledge.},
  file = {/Users/thomasgorman/Documents/Zotero_Markdown/lewandowsky_simplified_2002-zotero.md;/Users/thomasgorman/OneDrive - Indiana University/resources/Zotero/Lewandowsky et al_2002_Simplified learning in complex situations.pdf}
}

@unpublished{liCharacterizingNetworkComplexity1999,
  title = {Characterizing {{Network Complexity}} and {{Classification Efficiency}} by the {{Ratio}} of {{Weight Interdependence}} to {{Sensitivity}}},
  author = {Li, Shu-Chen and DeBrunner, Victor E. and Lewandowsky, Stephan},
  year = {1999},
  abstract = {We extend previous research on digital filter structures and parameter sensitivity to the relationship between the nature of hidden-unit activation function, weight sensitivity and interdependence, and classification learning in neural networks. Weight sensitivity indicates the extent of variations in a network's output when reacting to small perturbations in its weights; whereas weight interdependence indicates the degree of co-linearity between weights. A combined measure (t ), defined as the ratio of weight interdependence to sensitivity, was examined in three feedforward networks employing different hidden-unit activation functions in the context of a non-linearly separable two-choice classification task. Simulation results show that t reflects the complexity of hidden-unit activation function and determines the rate of learning quadratic classification boundary. Networks with more complex hidden-unit activation function evince a smaller t and more rapid classification learning.},
  file = {/Users/thomasgorman/OneDrive - Indiana University/resources/Zotero/Li et al_1999_Characterizing Network Complexity and Classification Efficiency by the Ratio of.pdf;/Users/thomasgorman/Zotero/storage/94432PS6/download.html}
}

@article{liddellAnalyzingOrdinalData2018,
  title = {Analyzing Ordinal Data with Metric Models: {{What}} Could Possibly Go Wrong?},
  shorttitle = {Analyzing Ordinal Data with Metric Models},
  author = {Liddell, Torrin M. and Kruschke, John K.},
  year = {2018},
  month = nov,
  journal = {Journal of Experimental Social Psychology},
  volume = {79},
  pages = {328--348},
  issn = {0022-1031},
  doi = {10.1016/j.jesp.2018.08.009},
  urldate = {2021-11-17},
  abstract = {We surveyed all articles in the Journal of Personality and Social Psychology (JPSP), Psychological Science (PS), and the Journal of Experimental Psychology: General (JEP:G) that mentioned the term ``Likert,'' and found that 100\% of the articles that analyzed ordinal data did so using a metric model. We present novel evidence that analyzing ordinal data as if they were metric can systematically lead to errors. We demonstrate false alarms (i.e., detecting an effect where none exists, Type I errors) and failures to detect effects (i.e., loss of power, Type II errors). We demonstrate systematic inversions of effects, for which treating ordinal data as metric indicates the opposite ordering of means than the true ordering of means. We show the same problems \textemdash{} false alarms, misses, and inversions \textemdash{} for interactions in factorial designs and for trend analyses in regression. We demonstrate that averaging across multiple ordinal measurements does not solve or even ameliorate these problems. A central contribution is a graphical explanation of how and when the misrepresentations occur. Moreover, we point out that there is no sure-fire way to detect these problems by treating the ordinal values as metric, and instead we advocate use of ordered-probit models (or similar) because they will better describe the data. Finally, although frequentist approaches to some ordered-probit models are available, we use Bayesian methods because of their flexibility in specifying models and their richness and accuracy in providing parameter estimates. An R script is provided for running an analysis that compares ordered-probit and metric models.},
  langid = {english},
  keywords = {Bayesian analysis,Likert,Ordered-probit,Ordinal data},
  annotation = {https://github.com/mt-digital/gp-statmod http://doingbayesiandataanalysis.blogspot.com/2014/11/ordinal-probit-regression-transforming.html},
  file = {/Users/thomasgorman/OneDrive - Indiana University/resources/Zotero/Liddell_Kruschke_2018_Analyzing ordinal data with metric models2.pdf}
}

@article{liLearningLearnFunctions2023,
  title = {Learning to {{Learn Functions}}},
  author = {Li, Michael Y. and Callaway, Fred and Thompson, William D. and Adams, Ryan P. and Griffiths, Thomas L.},
  year = {2023},
  journal = {Cognitive Science},
  volume = {47},
  number = {4},
  pages = {e13262},
  issn = {1551-6709},
  doi = {10.1111/cogs.13262},
  urldate = {2023-04-18},
  abstract = {Humans can learn complex functional relationships between variables from small amounts of data. In doing so, they draw on prior expectations about the form of these relationships. In three experiments, we show that people learn to adjust these expectations through experience, learning about the likely forms of the functions they will encounter. Previous work has used Gaussian processes\textemdash a statistical framework that extends Bayesian nonparametric approaches to regression\textemdash to model human function learning. We build on this work, modeling the process of learning to learn functions as a form of hierarchical Bayesian inference about the Gaussian process hyperparameters.},
  langid = {english},
  keywords = {Bayesian nonparametrics,Function learning,Gaussian process,Hierarchical Bayesian models,Learning-to-learn},
  file = {/Users/thomasgorman/Documents/Zotero_Markdown/liLearningLearnFunctions2023-zotero.md;/Users/thomasgorman/Library/CloudStorage/OneDrive-IndianaUniversity/Resources/Zotero/Li et al_2023_Learning to Learn Functions.pdf;/Users/thomasgorman/Zotero/storage/YSJ2H2US/cogs.html}
}

@article{liMetalearningInductiveBiases,
  title = {Meta-Learning Inductive Biases of Learning Systems with {{Gaussian}} Processes},
  author = {Li, Michael Y and Grant, Erin and Griffiths, Thomas L},
  pages = {8},
  abstract = {Many advances in machine learning can be attributed to designing systems with inductive biases well-suited for particular tasks. However, it can be challenging to ascertain the inductive biases of a learning system, much less control them in the design process. We propose a framework to capture the inductive biases in a learning system by meta-learning Gaussian process kernel hyperparameters from its predictions. We illustrate the potential of this framework across several case studies, including investigating the inductive biases of both untrained and trained neural networks, and assessing whether a given neural network family is wellsuited for a task family.},
  langid = {english},
  file = {/Users/thomasgorman/Documents/Zotero_Markdown/li_meta-learning_nodate-zotero.md;/Users/thomasgorman/OneDrive - Indiana University/resources/Zotero/Li et al_Meta-learning inductive biases of learning systems with Gaussian processes.pdf}
}

@article{littleBetterLearningMore2009,
  title = {Better Learning with More Error: {{Probabilistic}} Feedback Increases Sensitivity to Correlated Cues in Categorization.},
  shorttitle = {Better Learning with More Error},
  author = {Little, Daniel R. and Lewandowsky, Stephan},
  year = {2009},
  journal = {Journal of Experimental Psychology: Learning, Memory, and Cognition},
  volume = {35},
  number = {4},
  pages = {1041--1061},
  issn = {1939-1285, 0278-7393},
  doi = {10.1037/a0015902},
  urldate = {2020-09-06},
  abstract = {Despite the fact that categories are often composed of correlated features, the evidence that people detect and use these correlations during intentional category learning has been overwhelmingly negative to date. Nonetheless, on other categorization tasks, such as feature prediction, people show evidence of correlational sensitivity. A conventional explanation holds that category learning tasks promote rule use, which discards the correlated-feature information, whereas other types of category learning tasks promote exemplar storage, which preserves correlated-feature information. Contrary to that common belief, the authors report 2 experiments that demonstrate that using probabilistic feedback in an intentional categorization task leads to sensitivity to correlations among nondiagnostic cues. Deterministic feedback eliminates correlational sensitivity by focusing attention on relevant cues. Computational modeling reveals that exemplar storage coupled with selective attention is necessary to explain this effect.},
  langid = {english},
  file = {/Users/thomasgorman/Zotero/storage/EACYYPTR/Little and Lewandowsky - 2009 - Better learning with more error Probabilistic fee.pdf}
}

@article{littleIndividualDifferencesCategory2015,
  title = {Individual Differences in Category Learning: {{Memorization}} versus Rule Abstraction},
  shorttitle = {Individual Differences in Category Learning},
  author = {Little, Jeri L. and McDaniel, Mark A.},
  year = {2015},
  month = feb,
  journal = {Memory \& Cognition},
  volume = {43},
  number = {2},
  pages = {283--297},
  issn = {1532-5946},
  doi = {10.3758/s13421-014-0475-1},
  urldate = {2021-10-09},
  abstract = {Although individual differences in category-learning tasks have been explored, the observed differences have tended to represent different instantiations of general processes (e.g., learners rely upon different cues to develop a rule) and their consequent representations. Additionally, studies have focused largely on participants' categorizations of transfer items to determine the representations that they formed. In the present studies, we used a convergent-measures approach to examine participants' categorizations of transfer items in addition to their self-reported learning orientations and response times on transfer items, and in doing so, we garnered evidence that qualitatively distinct approaches in explicit strategies for category learning (i.e., memorization vs. abstracting an articulable rule) and consequent representations might emerge in a single task. Participants categorized instances that followed a categorization rule (in Study~1, we used a relational rule; in Study~2, an additional task with a single-feature rule). Critically, for both tasks,~some transfer items differed from trained instances on only one attribute (but otherwise were perceptually similar), rendering the item a member of the opposing category on the basis of the rule (i.e., termed ambiguous items). Some learners categorized ambiguous items on the basis of perceptual similarity, whereas others categorized them on the basis of an abstracted rule. Self-reported learning orientation (i.e., memorization vs. rule abstraction) predicted categorizations and response times on transfer items. Differences in learning orientations were not associated with performance on other cognitive measures (i.e., working memory capacity and Raven's Advanced Progressive Matrices). This work suggests that individuals may have different predispositions toward memorization versus rule abstraction in a single categorization task.},
  langid = {english},
  file = {/Users/thomasgorman/Documents/Zotero_Markdown/littleIndividualDifferencesCategory2015-zotero.md;/Users/thomasgorman/OneDrive - Indiana University/resources/Zotero/Little_McDaniel_2015_Individual differences in category learning.pdf}
}

@article{littleSimplicityBiasEstimation2009,
  title = {Simplicity {{Bias}} in the {{Estimation}} of {{Causal Functions}}},
  author = {Little, Daniel R and Shiffrin, Richard M},
  year = {2009},
  journal = {Proceedings of the annual meeting of the cognitive science society},
  pages = {7},
  abstract = {We ask observers to make judgments of the best causal functions underlying noisy test data. This method allows us to examine how people combine existing biases about causal relations with new information (the noisy data). Participants are shown n data points representing a sample of noisy data from a supposed experiment. They generate points on what they believe to be the true causal function. The presented functions vary in noise, gaps, and functional form. The method is similar to function learning studies, but minimizes the roles of learning and memory. To what degree do the participants exhibit a bias for simple linear functions? We describe a hierarchical Bayesian polynomial regression model to quantify complexity. The results show the expected bias for simplicity, but with some interesting individual differences.},
  file = {/Users/thomasgorman/Documents/Zotero_Markdown/little_simplicity_2009-zotero.md;/Users/thomasgorman/Documents/Zotero_Markdown/littleSimplicityBiasEstimation2009-zotero.md;/Users/thomasgorman/OneDrive - Indiana University/resources/Zotero/Little_Shiffrin_Simplicity Bias in the Estimation of Causal Functions.pdf}
}

@article{loganInstanceTheoryAttention2002a,
  title = {An Instance Theory of Attention and Memory},
  author = {Logan, Gordon D.},
  year = {2002},
  journal = {Psychological Review},
  pages = {376--400},
  abstract = {An instance theory of attention and memory (ITAM) is presented that integrates formal theories of attention and memory phenomena by exploiting commonalities in their formal structure. The core idea in each theory is that performance depends on a choice process that can be modeled as a race between competing alternatives. Attention and categorization are viewed as different perspectives on the same race. Attention selects objects by categorizing them; objects are categorized by attending to them. ITAM incorporates each of its ancestors as a special case, so it inherits their successes. Imagine yourself on your way home from work. You walk into the parking lot and look for your car. It takes you a second, perhaps. Now imagine your colleagues analyzing the simple act of cognition underlying that look. A student of attention would be interested in how your gaze went to the cars rather than other structural features. A student of categorization would be interested in how you knew those were cars in the parking lot. And a student of memory would be interested in how you did (or did not) pick your own car out of the group. These differences in perspective},
  file = {/Users/thomasgorman/Zotero/storage/68F4M3RD/Logan - 2002 - An instance theory of attention and memory.pdf;/Users/thomasgorman/Zotero/storage/XXKJ2BU2/summary.html}
}

@article{loganInstanceTheoryAutomatization1988,
  title = {Toward an Instance Theory of Automatization},
  author = {Logan, Gordon D.},
  year = {1988},
  journal = {Psychological Review},
  volume = {95},
  number = {4},
  pages = {492--527},
  file = {/Users/thomasgorman/Zotero/storage/TKMXAE9K/Logan - 1988 - Toward an instance theory of automatization.pdf}
}

@article{lorchHebbianModelAccount2023,
  title = {A {{Hebbian Model}} to {{Account}} for {{Musical Expertise Differences}} in a {{Working Memory Task}}},
  author = {L{\"o}rch, Lucas and Lemaire, Beno{\^i}t and Portrat, Sophie},
  year = {2023},
  month = may,
  journal = {Cognitive Computation},
  issn = {1866-9964},
  doi = {10.1007/s12559-023-10138-3},
  urldate = {2023-08-10},
  abstract = {The TBRS*C computational model provides a mathematical implementation of the cognitive processes involved in complex span tasks. The logic of the core processes, i.e., encoding, refreshing/time-based decay, and chunking, is based on Hebbian learning, synaptic facilitation, and long-term neural plasticity, respectively. The modeling, however, takes place on a cognitive rather than a~physiological level. Chunking is implemented as a process of searching for~sequences of memoranda in long-term memory and recoding them as a single unit which increases the efficacy of memory maintenance. Using TBRS*C simulations, the present study investigated how chunking and central working memory processes change with expertise. Hobby musicians and music students completed a complex span task in which sequences of twelve note symbols were presented for serial recall of pitch. After the presentation of each memorandum, participants performed an unknown, notated melody on an electric piano. To manipulate the potential for chunking, we varied whether sequences of memoranda formed meaningful tonal structures (major triads) or arbitrary trichords. Hobby musicians and music students were each split up in a higher-expertise and a lower-expertise group and TBRS*C simulations were performed for each group individually. In the simulations, higher-expertise hobby musicians encoded memoranda more rapidly, invested less time in chunk search, and recognized chunks with a higher chance than lower-expertise hobby musicians. Parameter estimates for music students showed only marginal expertise differences. We conclude that expertise in the TBRS model can be conceptualized by a rapid access to long-term memory and by chunking, which leads to an increase in the opportunity and efficacy of refreshing.},
  langid = {english},
  keywords = {Chunking,Complex span task,Computational simulations,Expert memory,TBRS*C},
  file = {/Users/thomasgorman/Library/CloudStorage/OneDrive-IndianaUniversity/Resources/Zotero/Lörch et al_2023_A Hebbian Model to Account for Musical Expertise Differences in a Working.pdf}
}

@article{loveSUSTAINNetworkModel2004,
  title = {{{SUSTAIN}}: {{A Network Model}} of {{Category Learning}}.},
  shorttitle = {{{SUSTAIN}}},
  author = {Love, Bradley C. and Medin, Douglas L. and Gureckis, Todd M.},
  year = {2004},
  journal = {Psychological Review},
  volume = {111},
  number = {2},
  pages = {309--332},
  issn = {1939-1471, 0033-295X},
  doi = {10.1037/0033-295X.111.2.309},
  urldate = {2017-09-04},
  abstract = {SUSTAIN (Supervised and Unsupervised STratified Adaptive Incremental Network) is a model of how humans learn categories from examples. SUSTAIN initially assumes a simple category structure. If simple solutions prove inadequate and SUSTAIN is confronted with a surprising event (e.g., it is told that a bat is a mammal instead of a bird), SUSTAIN recruits an additional cluster to represent the surprising event. Newly recruited clusters are available to explain future events and can themselves evolve into prototypes\textendash attractors\textendash rules. SUSTAIN's discovery of category substructure is affected not only by the structure of the world but by the nature of the learning task and the learner's goals. SUSTAIN successfully extends category learning models to studies of inference learning, unsupervised learning, category construction, and contexts in which identification learning is faster than classification learning.},
  langid = {english},
  file = {/Users/thomasgorman/Zotero/storage/AW3BVUEW/Love et al. - 2004 - SUSTAIN A Network Model of Category Learning..pdf}
}

@article{lucasRationalModelFunction2015,
  title = {A Rational Model of Function Learning},
  author = {Lucas, Christopher G. and Griffiths, Thomas L. and Williams, Joseph J. and Kalish, Michael L.},
  year = {2015},
  month = oct,
  journal = {Psychonomic Bulletin \& Review},
  volume = {22},
  number = {5},
  pages = {1193--1215},
  issn = {1069-9384, 1531-5320},
  doi = {10.3758/s13423-015-0808-5},
  urldate = {2017-09-25},
  langid = {english},
  file = {/Users/thomasgorman/Documents/Zotero_Markdown/lucas_rational_2015-zotero.md;/Users/thomasgorman/Zotero/storage/QP4N3VTA/Lucas et al. - 2015 - A rational model of function learning.pdf}
}

@article{lucasSuperspaceExtrapolationReveals2012,
  title = {Superspace Extrapolation Reveals Inductive Biases in Function Learning},
  author = {Lucas, Christopher G and Sterling, Douglas and Kemp, Charles},
  year = {2012},
  journal = {Proceedings of the Annual Meeting of the Cognitive Science Society},
  pages = {7},
  abstract = {We introduce a new approach for exploring how humans learn and represent functional relationships based on limited observations. We focus on a problem called superspace extrapolation, where learners observe training examples drawn from an n-dimensional space and must extrapolate to an n + 1dimensional superspace of the training examples. Many existing psychological models predict that superspace extrapolation should be fundamentally underdetermined, but we show that humans are able to extrapolate both linear and non-linear functions under these conditions. We also show that a Bayesian model can account for our results given a hypothesis space that includes families of simple functional relationships.},
  langid = {english},
  file = {/Users/thomasgorman/Documents/Zotero_Markdown/lucas_superspace_2012-zotero.md;/Users/thomasgorman/OneDrive - Indiana University/resources/Zotero/Lucas et al_Superspace extrapolation reveals inductive biases in function learning.pdf}
}

@article{mahdiReviewNeuralNetwork,
  title = {A {{Review}} of {{R Neural Network Packages}} (with {{NNbenchmark}}): {{Accuracy}} and {{Ease}} of {{Use}}},
  author = {Mahdi, Salsabila and Verma, Akshaj and Dutang, Christophe and Kiener, Patrice and Nash, John C},
  pages = {23},
  abstract = {In the last three decades, neural-networks have evolved from an academic topic to a common scientific computing tool. CRAN currently hosts around 80 packages (May 2020) that involve neural-network modeling; some offering more than one algorithm. However, to our knowledge, there is no comprehensive study which tests the accuracy, the reliability, and the ease-of-use of those NN packages.},
  langid = {english},
  annotation = {https://theairbend3r.github.io/NNbenchmarkWeb/notebooks/Rmd\_2020/NNbenchmark-2020-RSNNS.html},
  file = {/Users/thomasgorman/Documents/Zotero_Markdown/mahdi_review_nodate-zotero.md;/Users/thomasgorman/OneDrive - Indiana University/resources/Zotero/Mahdi et al_A Review of R Neural Network Packages (with NNbenchmark).pdf}
}

@article{makowskiBayestestRDescribingEffects2019a,
  title = {{{bayestestR}}: {{Describing Effects}} and Their {{Uncertainty}}, {{Existence}} and {{Significance}} within the {{Bayesian Framework}}},
  shorttitle = {{{bayestestR}}},
  author = {Makowski, Dominique and {Ben-Shachar}, Mattan S. and L{\"u}decke, Daniel},
  year = {2019},
  month = aug,
  journal = {Journal of Open Source Software},
  volume = {4},
  number = {40},
  pages = {1541},
  issn = {2475-9066},
  doi = {10.21105/joss.01541},
  urldate = {2023-08-15},
  abstract = {Makowski et al., (2019). bayestestR: Describing Effects and their Uncertainty, Existence and Significance within the Bayesian Framework. Journal of Open Source Software, 4(40), 1541, https://doi.org/10.21105/joss.01541},
  langid = {english},
  file = {/Users/thomasgorman/Library/CloudStorage/OneDrive-IndianaUniversity/Resources/Zotero/Makowski et al_2019_bayestestR2.pdf}
}

@article{marongelliAdvantageFlexibleNeuronal2013,
  title = {The Advantage of Flexible Neuronal Tunings in Neural Network Models for Motor Learning},
  author = {Marongelli, Ellisha and Thoroughman, K},
  year = {2013},
  journal = {Frontiers in Computational Neuroscience},
  volume = {7},
  pages = {100},
  issn = {1662-5188},
  doi = {10.3389/fncom.2013.00100},
  urldate = {2021-12-10},
  abstract = {Human motor adaptation to novel environments is often modeled by a basis function network that transforms desired movement properties into estimated forces. This network employs a layer of nodes that have fixed broad tunings that generalize across the input domain. Learning is achieved by updating the weights of these nodes in response to training experience. This conventional model is unable to account for rapid flexibility observed in human spatial generalization during motor adaptation. However, added plasticity in the widths of the basis function tunings can achieve this flexibility, and several neurophysiological experiments have revealed flexibility in tunings of sensorimotor neurons. We found a model, Locally Weighted Projection Regression (LWPR), which uniquely possesses the structure of a basis function network in which both the weights and tuning widths of the nodes are updated incrementally during adaptation. We presented this LWPR model with training functions of different spatial complexities and monitored incremental updates to receptive field widths. An inverse pattern of dependence of receptive field adaptation on experienced error became evident, underlying both a relationship between generalization and complexity, and a unique behavior in which generalization always narrows after a sudden switch in environmental complexity. These results implicate a model that is flexible in both basis function widths and weights, like LWPR, as a viable alternative model for human motor adaptation that can account for previously observed plasticity in spatial generalization. This theory can be tested by using the behaviors observed in our experiments as novel hypotheses in human studies.},
  file = {/Users/thomasgorman/Documents/Zotero_Markdown/marongelli_advantage_2013-zotero.md;/Users/thomasgorman/OneDrive - Indiana University/resources/Zotero/Marongelli_Thoroughman_2013_The advantage of flexible neuronal tunings in neural network models for motor.pdf}
}

@article{matsukaDescriptiveCognitiveModel2008,
  title = {Toward a Descriptive Cognitive Model of Human Learning},
  author = {Matsuka, Toshihiko and Sakamoto, Yasuaki and Chouchourelou, Arieta and Nickerson, Jeffrey V.},
  year = {2008},
  month = aug,
  journal = {Neurocomputing},
  series = {Artificial {{Neural Networks}} ({{ICANN}} 2006) / {{Engineering}} of {{Intelligent Systems}} ({{ICEIS}} 2006)},
  volume = {71},
  number = {13},
  pages = {2446--2455},
  issn = {0925-2312},
  doi = {10.1016/j.neucom.2007.12.039},
  urldate = {2020-12-21},
  abstract = {The majority of previous computational models of high-order human cognition incorporate gradient descent algorithms for their learning mechanisms and strict error minimization as the sole objective of learning. Recently, however, the validity of gradient descent as a descriptive model of real human cognitive processes has been criticized. In the present paper, we introduce a new framework for descriptive models of human learning that offers qualitatively plausible interpretations of cognitive behaviors. Specifically, we apply a simple multi-objective evolutionary algorithm as a learning method for modeling human category learning, where the definition of the learning objective is not based solely on the accuracy of knowledge, but also on the subjectively and contextually determined utility of knowledge being acquired. In addition, unlike gradient descent, our model assumes that humans entertain multiple hypotheses and learn not only by modifying a single existing hypothesis but also by combining a set of hypotheses. This learning-by-combination has been empirically supported, but largely overlooked in computational modeling research. Simulation studies show that our new modeling framework successfully replicated important observed psychological phenomena.},
  langid = {english},
  keywords = {Cognitive modeling,Evolutionary computation,Human learning},
  file = {/Users/thomasgorman/OneDrive - Indiana University/resources/Zotero/Matsuka et al_2008_Toward a descriptive cognitive model of human learning.pdf;/Users/thomasgorman/Zotero/storage/RJ4X5U4W/S0925231208002075.html}
}

@article{matsukaObservedAttentionAllocation2008,
  title = {Observed Attention Allocation Processes in Category Learning},
  author = {Matsuka, Toshihiko and Corter, James E.},
  year = {2008},
  month = jul,
  journal = {Quarterly Journal of Experimental Psychology},
  volume = {61},
  number = {7},
  pages = {1067--1097},
  issn = {1747-0218, 1747-0226},
  doi = {10.1080/17470210701438194},
  urldate = {2020-09-07},
  langid = {english},
  file = {/Users/thomasgorman/Zotero/storage/VAGI7TM8/Matsuka and Corter - 2008 - Observed attention allocation processes in categor.pdf}
}

@article{matsukaSimpleIndividuallyUnique2005,
  title = {Simple, Individually Unique, and Context-Dependent Learning Methods for Models of Human Category Learning},
  author = {Matsuka, Toshihiko},
  year = {2005},
  month = may,
  journal = {Behavior Research Methods},
  volume = {37},
  number = {2},
  pages = {240--255},
  issn = {1554-351X, 1554-3528},
  doi = {10.3758/BF03192692},
  urldate = {2021-10-23},
  langid = {english},
  file = {/Users/thomasgorman/OneDrive - Indiana University/resources/Zotero/Matsuka_2005_Simple, individually unique, and context-dependent learning methods for models.pdf}
}

@article{matsukaStochasticLearningAlgorithms,
  title = {Stochastic {{Learning Algorithms}} for {{Modeling Human Category Learning}}},
  author = {Matsuka, Toshihiko and Corter, James E},
  volume = {1},
  number = {1},
  pages = {9},
  abstract = {Most neural network (NN) models of human category learning use a gradient-based learning method, which assumes that locally-optimal changes are made to model parameters on each learning trial. This method tends to underpredict variability in individual-level cognitive processes. In addition many recent models of human category learning have been criticized for not being able to replicate rapid changes in categorization accuracy and attention processes observed in empirical studies. In this paper we introduce stochastic learning algorithms for NN models of human category learning and show that use of the algorithms can result in (a) rapid changes in accuracy and attention allocation, and (b) different learning trajectories and more realistic variability at the individual-level.},
  langid = {english},
  file = {/Users/thomasgorman/OneDrive - Indiana University/resources/Zotero/Matsuka_Corter_Stochastic Learning Algorithms for Modeling Human Category Learning.pdf}
}

@article{matsukaStochasticLearningNeural,
  title = {Stochastic Learning in Neural Network Models of Categorization},
  author = {Matsuka, Toshihiko and Corter, James E},
  pages = {2},
  langid = {english},
  file = {/Users/thomasgorman/OneDrive - Indiana University/resources/Zotero/Matsuka_Corter_Stochastic learning in neural network models of categorization.pdf}
}

@article{mazorInternalModelsVisual,
  title = {Internal Models of Visual Search Are Rich, Person-Specific, and Mostly Accurate},
  author = {Mazor, Matan},
  pages = {34},
  abstract = {Having an internal model of one's attention can be useful for effectively managing limited perceptual and cognitive resources. While previous work has hinted to the existence of an internal model of attention, it is still unknown how rich and flexible this model is, whether it corresponds to one's own attention or alternatively to a generic person-invariant schema, and whether it is specified as a list of facts and rules, or alternatively as a probabilistic simulation model. To this end, we designed a task to test participants' ability to estimate their own behavior in a visual search task with novel displays. In four online experiments (two exploratory and two preregistered), prospective search time estimates reflected accurate metacognitive knowledge of key findings in the visual search literature, including the set-size effect, higher efficiency of featureover conjunction- searches, and visual search asymmetry for familiar and unfamiliar stimuli. We further find that participants' estimates fit better with their own search times compared to the search times of other participants. Together, we interpret our findings as suggesting that people hold an internal model of visual search that is rich, person specific, and mostly accurate.},
  langid = {english},
  annotation = {https://matanmazor.github.io/metaVisualSearch/experiments/demos/Experiment4/},
  file = {/Users/thomasgorman/OneDrive - Indiana University/resources/Zotero/Mazor_Internal models of visual search are rich, person-specific, and mostly accurate.pdf}
}

@article{mcdanielConceptualBasisFunction2005,
  title = {The Conceptual Basis of Function Learning and Extrapolation: {{Comparison}} of Rule-Based and Associative-Based Models},
  shorttitle = {The Conceptual Basis of Function Learning and Extrapolation},
  author = {Mcdaniel, Mark A. and Busemeyer, Jerome R.},
  year = {2005},
  month = feb,
  journal = {Psychonomic Bulletin \& Review},
  volume = {12},
  number = {1},
  pages = {24--42},
  issn = {1069-9384, 1531-5320},
  doi = {10.3758/BF03196347},
  urldate = {2019-02-13},
  langid = {english},
  file = {/Users/thomasgorman/Documents/Zotero_Markdown/mcdanielConceptualBasisFunction2005-zotero.md;/Users/thomasgorman/Downloads/mcdaniel_conceptual_2005-zotero.md;/Users/thomasgorman/Downloads/mcdaniel_conceptual_2005.md;/Users/thomasgorman/Downloads/mcdanielConceptualBasisFunction2005.md;/Users/thomasgorman/Zotero/storage/KQ9XSQ4H/Mcdaniel and Busemeyer - 2005 - The conceptual basis of function learning and extr.pdf}
}

@article{mcdanielEffectsSpacedMassed2013,
  title = {Effects of Spaced versus Massed Training in Function Learning.},
  author = {McDaniel, Mark A. and Fadler, Cynthia L. and Pashler, Harold},
  year = {2013},
  journal = {Journal of Experimental Psychology: Learning, Memory, and Cognition},
  volume = {39},
  number = {5},
  pages = {1417--1432},
  issn = {1939-1285, 0278-7393},
  doi = {10.1037/a0032184},
  urldate = {2021-05-21},
  abstract = {A robust finding in the literature is that spacing material leads to better retention than massing; however, the benefit of spacing for concept learning is less clear. When items are massed, it may help the learner to discover the relationship between instances, leading to better abstraction of the underlying concept. Two experiments addressed this question through a typical function learning task in which subjects were trained via presentations of input points (cue values) for which output responses (criterion values) were required. Subjects were trained either using spaced points, strategically massed points (points were paired in training such that they occurred on the same side of the underlying V-shaped function), or randomly massed points (points were randomly paired during training). All subjects were then tested on repeated training points, new (interpolation) points within the training range, and extrapolation points that fell outside the training range. Spacing led to superior interpolation and extrapolation performance, with random massing leading to the worst performance on all test trial types. These results suggest that, at least for function concepts, massed training is not superior to spaced training for concept learning.},
  langid = {english},
  file = {/Users/thomasgorman/Documents/Zotero_Markdown/mcdaniel_effects_2013-zotero.md;/Users/thomasgorman/OneDrive - Indiana University/resources/Zotero/McDaniel et al_2013_Effects of spaced versus massed training in function learning.pdf}
}

@article{mcdanielIndividualDifferencesLearning2014,
  title = {Individual Differences in Learning and Transfer: {{Stable}} Tendencies for Learning Exemplars versus Abstracting Rules.},
  shorttitle = {Individual Differences in Learning and Transfer},
  author = {McDaniel, Mark A. and Cahill, Michael J. and Robbins, Mathew and Wiener, Chelsea},
  year = {2014},
  journal = {Journal of Experimental Psychology: General},
  volume = {143},
  number = {2},
  pages = {668--693},
  issn = {1939-2222, 0096-3445},
  doi = {10.1037/a0032963},
  urldate = {2017-10-22},
  langid = {english},
  file = {/Users/thomasgorman/Documents/Zotero_Markdown/mcdanielIndividualDifferencesLearning2014-zotero.md;/Users/thomasgorman/Zotero/storage/IMPV4CRV/McDaniel et al. - 2014 - Individual differences in learning and transfer S.pdf}
}

@article{mcdanielLearningIntroductoryBiology2022,
  title = {Learning {{Introductory Biology}}: {{Students}}' {{Concept-Building Approaches Predict Transfer}} on {{Biology Exams}}},
  shorttitle = {Learning {{Introductory Biology}}},
  author = {McDaniel, Mark A. and Cahill, Michael J. and Frey, Regina F. and Limeri, Lisa B. and Lemons, Paula P.},
  editor = {Nehm, Ross},
  year = {2022},
  month = dec,
  journal = {CBE\textemdash Life Sciences Education},
  volume = {21},
  number = {4},
  pages = {ar65},
  issn = {1931-7913},
  doi = {10.1187/cbe.21-12-0335},
  urldate = {2022-10-04},
  abstract = {Previous studies have found that students' concept-building approaches, identified a priori with a cognitive psychology laboratory task, are associated with student exam performances in chemistry classes. Abstraction learners (those who extract the principles underlying related examples) performed better than exemplar learners (those who focus on memorizing the training exemplars and responses) on transfer exam questions but not retention questions, after accounting for general ability. We extended these findings to introductory biology courses in which active-learning techniques were used to try to foster deep conceptual learning. Exams were constructed to contain both transfer and retention questions. Abstraction learners demonstrated better performance than exemplar learners on the transfer questions but not on the retention questions. These results were not moderated by indices of crystallized or fluid intelligence. Our central interpretation is that students identified as abstraction learners appear to construct a deep understanding of the concepts (presumably based on abstract underpinnings), thereby enabling them to apply and generalize the concepts to scenarios and instantiations not seen during instruction (transfer questions). By contrast, other students appear to base their representations on memorized instructed examples, leading to good performance on retention questions but not transfer questions.},
  langid = {english},
  file = {/Users/thomasgorman/Documents/Zotero_Markdown/mcdanielLearningIntroductoryBiology2022-zotero.md;/Users/thomasgorman/OneDrive - Indiana University/resources/Zotero/McDaniel et al_2022_Learning Introductory Biology.pdf}
}

@article{mcdanielPredictingTransferPerformance2009,
  title = {Predicting Transfer Performance: {{A}} Comparison of Competing Function Learning Models.},
  shorttitle = {Predicting Transfer Performance},
  author = {Mcdaniel, Mark and Dimperio, Eric and Griego, Jacqueline and Busemeyer, Jerome},
  year = {2009},
  month = jan,
  journal = {Journal of experimental psychology. Learning, memory, and cognition},
  volume = {35},
  pages = {173--95},
  doi = {10.1037/a0013982},
  abstract = {The population of linear experts (POLE) model suggests that function learning and transfer are mediated by activation of a set of prestored linear functions that together approximate the given function (Kalish, Lewandowsky, \& Kruschke, 2004). In the extrapolation-association (EXAM) model, an exemplar-based architecture associates trained input values with their paired output values. Transfer incorporates a linear rule-based response mechanism (McDaniel \& Busemeyer, 2005). Learners were trained on a functional relationship defined by 2 linear-function segments with mirror slopes. In Experiment 1, 1 segment was densely trained and 1 was sparsely trained; in Experiment 2, both segments were trained equally, but the 2 segments were widely separated. Transfer to new input values was tested. For each model, training performance for each individual participant was fit, and transfer predictions were generated. POLE generally better fit the training data than did EXAM, but EXAM was more accurate at predicting (and fitting) transfer behaviors. It was especially telling that in Experiment 2 the transfer pattern was more consistent with EXAM's but not POLE's predictions, even though the presentation of salient linear segments during training dovetailed with POLE's approach.},
  file = {/Users/thomasgorman/Documents/Zotero_Markdown/mcdanielPredictingTransferPerformance2009-zotero.md;/Users/thomasgorman/Downloads/mcdanielPredictingTransferPerformance2009-zotero.md;/Users/thomasgorman/Downloads/mcdanielPredictingTransferPerformance2009.md;/Users/thomasgorman/OneDrive - Indiana University/resources/Zotero/Mcdaniel et al_2009_Predicting transfer performance2.pdf}
}

@article{medinContextTheoryClassification1978,
  title = {Context {{Theory}} of {{Classification Learning}}},
  author = {Medin, Douglas L and Schaffer, Marguerite M},
  year = {1978},
  journal = {Psychological review},
  volume = {85},
  number = {3},
  pages = {207},
  langid = {english},
  file = {/Users/thomasgorman/Zotero/storage/XRPSUMDV/Medin et al. - Context Theory of Classification Learning.pdf}
}

@article{meighNovelInvestigationGeneralized2017a,
  title = {A {{Novel Investigation}} of {{Generalized Motor Program Theory}}: {{Syllable Stress}} as a {{Motor-Class Variable}}},
  shorttitle = {A {{Novel Investigation}} of {{Generalized Motor Program Theory}}},
  author = {Meigh, Kimberly M.},
  year = {2017},
  month = jun,
  journal = {Journal of Speech, Language, and Hearing Research},
  volume = {60},
  number = {6S},
  pages = {1685--1694},
  issn = {1092-4388, 1558-9102},
  doi = {10.1044/2017_JSLHR-S-16-0247},
  urldate = {2019-03-13},
  langid = {english},
  file = {/Users/thomasgorman/Zotero/storage/6MIYDQR9/Meigh - 2017 - A Novel Investigation of Generalized Motor Program.pdf}
}

@article{meighWhatMemoryRepresentation2018,
  title = {What Memory Representation Is Acquired during Nonword Speech Production Learning? {{The}} Influence of Stimulus Features and Training Modality on Nonword Encoding},
  shorttitle = {What Memory Representation Is Acquired during Nonword Speech Production Learning?},
  author = {Meigh, Kimberly M. and Shaiman, Susan and Tompkins, Connie A. and Abbott, Katherine Verdolini and {Nokes-Malach}, Timothy},
  editor = {Walla, Peter},
  year = {2018},
  month = jan,
  journal = {Cogent Psychology},
  volume = {5},
  number = {1},
  pages = {1493714},
  issn = {null},
  doi = {10.1080/23311908.2018.1493714},
  urldate = {2019-03-13},
  abstract = {The purpose of this research was to investigate memory representations related to speech processing. Psycholinguistic and speech motor control theorists have hypothesized a variety of fundamental memory representations, such as syllables or phonemes, which may be learned during speech acquisition tasks. Yet, it remains unclear which fundamental representations are encoded and retrieved during learning and generalization tasks. Two experiments were conducted using a motor learning paradigm to investigate if representations for syllables and phonemes were acquired during a nonword repetition task. Additionally, different training modalities were implemented across studies to examine if training modality influenced memory encoding for nonword stimuli. Results suggest multiple representations may be acquired during training regardless of training modality; however, the underlying memory representations learned during training may be less abstract than current models hypothesize.},
  file = {/Users/thomasgorman/Zotero/storage/FL6GG4K6/Meigh et al. - 2018 - What memory representation is acquired during nonw.pdf;/Users/thomasgorman/Zotero/storage/CXNZ89JE/23311908.2018.html}
}

@article{mileticNewModelDecision2021,
  title = {A New Model of Decision Processing in Instrumental Learning Tasks},
  author = {Mileti{\'c}, Steven and Boag, Russell J and Trutti, Anne C and Stevenson, Niek and Forstmann, Birte U and Heathcote, Andrew},
  year = {2021},
  month = jan,
  journal = {eLife},
  volume = {10},
  pages = {e63055},
  issn = {2050-084X},
  doi = {10.7554/eLife.63055},
  urldate = {2021-09-11},
  abstract = {Learning and decision-making are interactive processes, yet cognitive modeling of error-driven learning and decision-making have largely evolved separately. Recently, evidence accumulation models (EAMs) of decision-making and reinforcement learning (RL) models of errordriven learning have been combined into joint RL-EAMs that can in principle address these interactions. However, we show that the most commonly used combination, based on the diffusion decision model (DDM) for binary choice, consistently fails to capture crucial aspects of response times observed during reinforcement learning. We propose a new RL-EAM based on an advantage racing diffusion (ARD) framework for choices among two or more options that not only addresses this problem but captures stimulus difficulty, speed-accuracy trade-off, and stimulus-responsemapping reversal effects. The RL-ARD avoids fundamental limitations imposed by the DDM on addressing effects of absolute values of choices, as well as extensions beyond binary choice, and provides a computationally tractable basis for wider applications.},
  langid = {english},
  file = {/Users/thomasgorman/OneDrive - Indiana University/resources/Zotero/Miletić et al_2021_A new model of decision processing in instrumental learning tasks.pdf}
}

@article{miyatsuEffectsSpecificlevelBroadlevel2019,
  title = {Effects of Specific-Level versus Broad-Level Training for Broad-Level Category Learning in a Complex Natural Science Domain.},
  author = {Miyatsu, Toshiya and Nosofsky, Robert M. and McDaniel, Mark A.},
  year = {2019},
  month = sep,
  journal = {Journal of Experimental Psychology: Applied},
  issn = {1939-2192, 1076-898X},
  doi = {10.1037/xap0000240},
  urldate = {2019-10-03},
  abstract = {This study suggests that learning broad-level rock categories (igneous, sedimentary, and metamorphic rocks) can be supported through teaching the subtypes of these broad levels (e.g., diorite under igneous, breccia under sedimentary) and doing so can be as effective as directly teaching the broad-level categories. This subtype-teaching technique might be considered more often in science education because it results in students learning a more expert-like multiple-level structure of categories, even when broad-level training is the initial learning objective.},
  langid = {english},
  file = {/Users/thomasgorman/Zotero/storage/4F9GNB9J/Miyatsu et al. - 2019 - Effects of specific-level versus broad-level train.pdf}
}

@article{miyatsuFeatureHighlightingEnhances2019,
  title = {Feature Highlighting Enhances Learning of a Complex Natural-Science Category.},
  author = {Miyatsu, Toshiya and Gouravajhala, Reshma and Nosofsky, Robert M. and McDaniel, Mark A.},
  year = {2019},
  month = jan,
  journal = {Journal of Experimental Psychology: Learning, Memory, and Cognition},
  volume = {45},
  number = {1},
  pages = {1--16},
  issn = {1939-1285, 0278-7393},
  doi = {10.1037/xlm0000538},
  urldate = {2019-06-04},
  abstract = {Learning naturalistic categories, which tend to have fuzzy boundaries and vary on many dimensions, can often be harder than learning well defined categories. One method for facilitating the category learning of naturalistic stimuli may be to provide explicit feature descriptions that highlight the characteristic features of each category. Although this method is commonly used in textbooks and classrooms, theoretically it remains uncertain whether feature descriptions should advantage learning complex natural-science categories. In three experiments, participants were trained on 12 categories of rocks, either without or with a brief description highlighting key features of each category. After training, they were tested on their ability to categorize both old and new rocks from each of the categories. Providing feature descriptions as a caption under a rock image failed to improve category learning relative to providing only the rock image with its category label (Experiment 1). However, when these same feature descriptions were presented such that they were explicitly linked to the relevant parts of the rock image (feature highlighting), participants showed significantly higher performance on both immediate generalization to new rocks (Experiment 2) and generalization after a 2-day delay (Experiment 3). Theoretical and practical implications are discussed.},
  langid = {english},
  file = {/Users/thomasgorman/Zotero/storage/SVV75DQC/Miyatsu et al. - 2019 - Feature highlighting enhances learning of a comple.pdf}
}

@article{montambaultRewardFunctionComplexity2019,
  title = {Reward {{Function Complexity}} and {{Goals}} in {{Exploration-Exploitation Tasks}}},
  author = {Montambault, Brian and Lucas, Christopher},
  year = {2019},
  pages = {7},
  langid = {english},
  file = {/Users/thomasgorman/Documents/Zotero_Markdown/montambault_reward_2019-zotero.md;/Users/thomasgorman/OneDrive - Indiana University/resources/Zotero/Montambault_Lucas_Reward Function Complexity and Goals in Exploration-Exploitation Tasks.pdf}
}

@article{myungDoesResponseScaling,
  title = {Does Response Scaling Cause the Generalized Context Model to Mimic a Prototype Model?},
  author = {Myung, Jay I and Pitt, Mark A and Navarro, Daniel J},
  pages = {8},
  langid = {english},
  file = {/Users/thomasgorman/OneDrive - Indiana University/resources/Zotero/Myung et al_Does response scaling cause the generalized context model to mimic a prototype.pdf}
}

@article{nalborczykIntroductionBayesianMultilevel2019,
  title = {An {{Introduction}} to {{Bayesian Multilevel Models Using}} Brms: {{A Case Study}} of {{Gender Effects}} on {{Vowel Variability}} in {{Standard Indonesian}}},
  shorttitle = {An {{Introduction}} to {{Bayesian Multilevel Models Using}} Brms},
  author = {Nalborczyk, Ladislas and Batailler, C{\'e}dric and L{\oe}venbruck, H{\'e}l{\`e}ne and Vilain, Anne and B{\"u}rkner, Paul-Christian},
  year = {2019},
  month = may,
  journal = {Journal of Speech, Language, and Hearing Research},
  volume = {62},
  number = {5},
  pages = {1225--1242},
  publisher = {{American Speech-Language-Hearing Association}},
  doi = {10.1044/2018_JSLHR-S-18-0006},
  urldate = {2023-08-08},
  abstract = {Purpose  Bayesian multilevel models are increasingly used to overcome the limitations of frequentist approaches in the analysis of complex structured data. This tutorial introduces Bayesian multilevel modeling for the specific analysis of speech data, using the brms package developed in R. Method  In this tutorial, we provide a practical introduction to Bayesian multilevel modeling by reanalyzing a phonetic data set containing formant (F1 and F2) values for 5 vowels of standard Indonesian (ISO 639-3:ind), as spoken by 8 speakers (4 females and 4 males), with several repetitions of each vowel. Results  We first give an introductory overview of the Bayesian framework and multilevel modeling. We then show how Bayesian multilevel models can be fitted using the probabilistic programming language Stan and the R package brms, which provides an intuitive formula syntax. Conclusions  Through this tutorial, we demonstrate some of the advantages of the Bayesian framework for statistical modeling and provide a detailed case study, with complete source code for full reproducibility of the analyses (https://osf.io/dpzcb/). Supplemental Material  https://doi.org/10.23641/asha.7973822},
  file = {/Users/thomasgorman/Library/CloudStorage/OneDrive-IndianaUniversity/Resources/Zotero/Nalborczyk et al_2019_An Introduction to Bayesian Multilevel Models Using brms.pdf}
}

@article{narainStructureLearningOccam2014,
  title = {Structure Learning and the {{Occam}}'s Razor Principle: A New View of Human Function Acquisition},
  shorttitle = {Structure Learning and the {{Occam}}'s Razor Principle},
  author = {Narain, Devika and Smeets, Jeroen B. J. and Mamassian, Pascal and Brenner, Eli and {van Beers}, Robert J.},
  year = {2014},
  journal = {Frontiers in Computational Neuroscience},
  volume = {8},
  publisher = {{Frontiers}},
  issn = {1662-5188},
  doi = {10.3389/fncom.2014.00121},
  urldate = {2020-11-03},
  abstract = {We often encounter pairs of variables in the world whose mutual relationship can be described by a function. After training, human responses closely correspond to these functional relationships. Here we study how humans predict unobserved segments of a function that they have been trained on and we compare how human predictions differ to those made by various function-learning models in the literature. Participants' performance was best predicted by the polynomial functions that generated the observations. Further, participants were able to explicitly report the correct generating function in most cases upon a post-experiment survey. This suggests that humans can abstract functions. To understand how they do so, we modeled human learning using an hierarchical Bayesian framework organized at two levels of abstraction: function learning and parameter learning, and used it to understand the time course of participants' learning as we surreptitiously changed the generating function over time. This Bayesian model selection framework allowed us to analyze the time course of function learning and parameter learning in relative isolation. We found that participants acquired new functions as they changed and even when parameter learning was not completely accurate, the probability that the correct function was learned remained high. Most importantly, we found that humans selected the simplest-fitting function with the highest probability and that they acquired simpler functions faster than more complex ones. Both aspects of this behavior, extent and rate of selection, present evidence that human function learning obeys the Occam's razor principle.},
  langid = {english},
  keywords = {associative learning,bayesian model selection,Function learning,gaussian processes,occam's razor,sensorimotor learning,structure learning},
  file = {/Users/thomasgorman/Documents/Zotero_Markdown/narain_structure_2014-zotero.md;/Users/thomasgorman/OneDrive - Indiana University/resources/Zotero/Narain et al_2014_Structure learning and the Occam's razor principle.pdf}
}

@article{navarroAssessingDistinguishabilityModels2004,
  title = {Assessing the Distinguishability of Models and the Informativeness of Data},
  author = {Navarro, Daniel J. and Pitt, Mark A. and Myung, In Jae},
  year = {2004},
  month = aug,
  journal = {Cognitive Psychology},
  volume = {49},
  number = {1},
  pages = {47--84},
  issn = {00100285},
  doi = {10.1016/j.cogpsych.2003.11.001},
  urldate = {2020-09-02},
  abstract = {A difficulty in the development and testing of psychological models is that they are typically evaluated solely on their ability to fit experimental data, with little consideration given to their ability to fit other possible data patterns. By examining how well model A fits data generated by model B, and vice versa (a technique that we call landscaping), much safer inferences can be made about the meaning of a model\~Os fit to data. We demonstrate the landscaping technique using four models of retention and 77 historical data sets, and show how the method can be used to: (1) evaluate the distinguishability of models, (2) evaluate the informativeness of data in distinguishing between models, and (3) suggest new ways to distinguish between models. The generality of the method is demonstrated in two other research areas (information integration and categorization), and its relationship to the important notion of model complexity is discussed.},
  langid = {english},
  file = {/Users/thomasgorman/Zotero/storage/BY4CS5IN/Navarro et al. - 2004 - Assessing the distinguishability of models and the.pdf}
}

@article{navarroInteractionExemplarbasedConcepts2007,
  title = {On the Interaction between Exemplar-Based Concepts and a Response Scaling Process},
  author = {Navarro, Daniel J.},
  year = {2007},
  month = apr,
  journal = {Journal of Mathematical Psychology},
  volume = {51},
  number = {2},
  pages = {85--98},
  issn = {0022-2496},
  doi = {10.1016/j.jmp.2006.11.003},
  urldate = {2020-09-07},
  abstract = {An analysis of the ``response scaling'' parameter in the Generalized Context Model is presented. In light of the existing debate over the behavior of the model when this parameter is included, three different interpretations are discussed, in order to illustrate the effect of the parameter at the decision level, the category similarity level, and the representational structure level.},
  langid = {english},
  file = {/Users/thomasgorman/Zotero/storage/PXLDCME3/Navarro - 2007 - On the interaction between exemplar-based concepts.pdf;/Users/thomasgorman/Zotero/storage/LENM9B8H/S0022249606001404.html}
}

@article{navarroSimilarityDistanceCategorization2007,
  title = {Similarity, Distance, and Categorization: {{A}} Discussion of {{Smith}}'s (2006) Warning about ``Colliding Parameters''},
  shorttitle = {Similarity, Distance, and Categorization},
  author = {Navarro, Daniel J.},
  year = {2007},
  month = oct,
  journal = {Psychonomic Bulletin \& Review},
  volume = {14},
  number = {5},
  pages = {823--833},
  issn = {1069-9384, 1531-5320},
  doi = {10.3758/BF03194107},
  urldate = {2020-09-09},
  langid = {english},
  file = {/Users/thomasgorman/Zotero/storage/JG35YP8Y/Navarro - 2007 - Similarity, distance, and categorization A discus.pdf}
}

@article{newellSchemaTheory19752003,
  title = {Schema {{Theory}} (1975): {{Retrospectives}} and {{Prospectives}}},
  shorttitle = {Schema {{Theory}} (1975)},
  author = {Newell, Karl M.},
  year = {2003},
  month = dec,
  journal = {Research Quarterly for Exercise and Sport},
  volume = {74},
  number = {4},
  pages = {383--388},
  issn = {0270-1367, 2168-3824},
  doi = {10.1080/02701367.2003.10609108},
  urldate = {2019-01-19},
  abstract = {A briefcommentaryis providedon the theoretical assumptions, scholarly impact and continuing influenceoftheschematheory of motorlearning (Schmidt, 1975). The traditional contrasts ofschematheory to the coordinative structureor dynamical systems framework arereemphasized, and limitations ofthevariabilityofpractice experiments noted. A centralproblemfor theories of motorlearning is changeovertime, thebasison which learning is typically defined. Most theories including schemahave, however, undervalued the importanceofthe time-dependent nature ofchangein deference to the almostexclusivestudy ofthe amount ofsomeaveraged change in behavioraloutcome. Thepersistent and transitorychangers) in movementand outcome that areobserved in action arereflections ofmultiple timescales ofchangein a dynamical system.},
  langid = {english},
  file = {/Users/thomasgorman/Zotero/storage/SZKC9BQK/Newell - 2003 - Schema Theory (1975) Retrospectives and Prospecti.pdf}
}

@article{nosofskyActivationNeuralNetwork2012,
  title = {Activation in the Neural Network Responsible for Categorization and Recognition Reflects Parameter Changes},
  author = {Nosofsky, R. M. and Little, D. R. and James, T. W.},
  year = {2012},
  month = jan,
  journal = {Proceedings of the National Academy of Sciences},
  volume = {109},
  number = {1},
  pages = {333--338},
  issn = {0027-8424, 1091-6490},
  doi = {10.1073/pnas.1111304109},
  urldate = {2020-09-04},
  langid = {english},
  file = {/Users/thomasgorman/Zotero/storage/84HF53BZ/Nosofsky et al. - 2012 - Activation in the neural network responsible for c.pdf}
}

@article{nosofskyAttentionLearningProcesses1987,
  title = {Attention and Learning Processes in the Identification and Categorization of Integral Stimuli},
  author = {Nosofsky, Robert M.},
  year = {1987},
  journal = {Journal of Experimental Psychology: teaming, Memory, and Cognition},
  pages = {87--109},
  abstract = {The relationship between subjects ' identification and categorization learning of integral-dimension stimuli was studied within the framework of an exemplar-based generalization model. The model was used to predict subjects ' learning in six different categorization conditions on the basis of data obtained in a single identification learning condition. A crucial assumption in the model is that because of selective attention to component dimensions, similarity relations may change in systematic ways across different experimental contexts. The theoretical analysis provided evidence that, at least under unspeeded conditions, selective attention may play a critical role in determining the identification-categorization relationship for integral stimuli. Evidence was also provided that similarity among exemplars decreased as a function of identification learning. Various alternative classification models, including prototype, multiple-prototype, average distance, and "value-on-dimensions" models, were unable to account for the results. This article seeks to characterize performance relations between the two fundamental classification paradigms of identification and categorization. Whereas in an identification paradigm people identify stimuli as unique items (a one-to-one},
  file = {/Users/thomasgorman/Zotero/storage/HKLIYM6T/Nosofsky - 1987 - Attention and learning processes in the identifica.pdf;/Users/thomasgorman/Zotero/storage/52Q2Z4FK/summary.html}
}

@article{nosofskyAttentionSimilarityIdentificationcategorization1986,
  title = {Attention, Similarity, and the Identification-Categorization Relationship},
  author = {Nosofsky, Robert M.},
  year = {1986},
  journal = {Journal of Experimental Psychology: General},
  volume = {115},
  number = {1},
  pages = {39--57},
  keywords = {{categorization, exemplars}},
  file = {/Users/thomasgorman/Zotero/storage/NV5FNHIP/Nosofsky - 1986 - Attention, similarity, and the identification-cate.pdf}
}

@incollection{nosofskyChapterTwoExemplarRetrieval2016,
  title = {Chapter {{Two}} - {{An Exemplar-Retrieval Model}} of {{Short-term Memory Search}}: {{Linking Categorization}} and {{Probe Recognition}}},
  shorttitle = {Chapter {{Two}} - {{An Exemplar-Retrieval Model}} of {{Short-term Memory Search}}},
  booktitle = {Psychology of {{Learning}} and {{Motivation}}},
  author = {Nosofsky, Robert M.},
  editor = {Ross, Brian H.},
  year = {2016},
  month = jan,
  volume = {65},
  pages = {47--84},
  publisher = {{Academic Press}},
  doi = {10.1016/bs.plm.2016.03.002},
  urldate = {2019-06-04},
  abstract = {Exemplar-retrieval models such as the exemplar-based random walk (EBRW) model have provided good accounts of response time (RT) and choice-probability data in a wide variety of categorization paradigms. In this chapter, I review recent work showing that the model also accounts accurately for RT and choice-probability data in a wide variety of probe-recognition, short-term, memory-search paradigms. According to the model, observers store items from study lists as individual exemplars in memory. When a test probe is presented, it causes the exemplars to be retrieved. The exemplars that are most readily retrieved are those that are highly similar to the test probe and that have the greatest memory strengths. The retrieved exemplars drive a familiarity-based evidence-accumulation process that determines the speed and accuracy of old\textendash new recognition decisions. The model accounts for effects of memory-set size, old-new status of test probe, and study-test lag; effects of the detailed similarity structure of the memory set; and the role of the history of previously experienced memory sets on performance. Applications of the model reveal a quantitative law of how memory strength varies with the retention interval. In addition, the model provides a unified account of how probe recognition operates in cases involving short and long study lists. Furthermore~it provides an account of the classic distinction between controlled versus automatic processing depending on the types of memory-search practice in which observers engage. In short~the model brings together and extends prior research and theory on categorization, attention and automaticity, short- and long-term memory, and evidence-accumulation models of choice RT to move the field closer to a unified account of diverse forms of memory search.},
  file = {/Users/thomasgorman/Zotero/storage/IJWW6RUW/Nosofsky - 2016 - Chapter Two - An Exemplar-Retrieval Model of Short.pdf;/Users/thomasgorman/Zotero/storage/VZ2HALGE/S0079742116000153.html}
}

@article{nosofskyClassificationResponseTimes2010,
  title = {Classification Response Times in Probabilistic Rule-Based Category Structures: {{Contrasting}} Exemplar-Retrieval and Decision-Boundary Models},
  shorttitle = {Classification Response Times in Probabilistic Rule-Based Category Structures},
  author = {Nosofsky, Robert M. and Little, Daniel R.},
  year = {2010},
  month = oct,
  journal = {Memory \& Cognition},
  volume = {38},
  number = {7},
  pages = {916--927},
  issn = {0090-502X, 1532-5946},
  doi = {10.3758/MC.38.7.916},
  urldate = {2020-09-05},
  langid = {english},
  file = {/Users/thomasgorman/Zotero/storage/EMCX2R6Q/Nosofsky and Little - 2010 - Classification response times in probabilistic rul.pdf}
}

@article{nosofskyClassificationResponseTimes2010a,
  title = {Classification Response Times in Probabilistic Rule-Based Category Structures: {{Contrasting}} Exemplar-Retrieval and Decision-Boundary Models},
  shorttitle = {Classification Response Times in Probabilistic Rule-Based Category Structures},
  author = {Nosofsky, Robert M. and Little, Daniel R.},
  year = {2010},
  month = oct,
  journal = {Memory \& Cognition},
  volume = {38},
  number = {7},
  pages = {916--927},
  issn = {0090-502X, 1532-5946},
  doi = {10.3758/MC.38.7.916},
  urldate = {2020-07-15},
  langid = {english},
  file = {/Users/thomasgorman/Zotero/storage/IGQ27L2L/Nosofsky and Little - 2010 - Classification response times in probabilistic rul.pdf}
}

@article{nosofskyComparingModesRulebased1994,
  title = {Comparing Modes of Rule-Based Classification Learning: {{A}} Replication and Extension of {{Shepard}}, {{Hovland}}, and {{Jenkins}} (1961)},
  shorttitle = {Comparing Modes of Rule-Based Classification Learning},
  author = {Nosofsky, Robert M. and Gluck, Mark A. and Palmeri, Thomas J. and Mckinley, Stephen C. and Glauthier, Paul},
  year = {1994},
  month = may,
  journal = {Memory \& Cognition},
  volume = {22},
  number = {3},
  pages = {352--369},
  issn = {0090-502X, 1532-5946},
  doi = {10.3758/BF03200862},
  urldate = {2020-03-15},
  langid = {english},
  file = {/Users/thomasgorman/Zotero/storage/62ZIKPP2/Nosofsky et al. - 1994 - Comparing modes of rule-based classification learn.pdf}
}

@article{nosofskyDissociationsCategorizationRecognition1998,
  title = {Dissociations {{Between Categorization}} and {{Recognition}} in {{Amnesic}} and {{Normal Individuals}}: {{An Exemplar-Based Interpretation}}},
  shorttitle = {Dissociations {{Between Categorization}} and {{Recognition}} in {{Amnesic}} and {{Normal Individuals}}},
  author = {Nosofsky, Robert M. and Zaki, Safa R.},
  year = {1998},
  month = jul,
  journal = {Psychological Science},
  volume = {9},
  number = {4},
  pages = {247--255},
  issn = {0956-7976, 1467-9280},
  doi = {10.1111/1467-9280.00051},
  urldate = {2020-09-07},
  langid = {english},
  file = {/Users/thomasgorman/Zotero/storage/B78ZCRTR/Nosofsky and Zaki - 1998 - Dissociations Between Categorization and Recogniti.pdf}
}

@article{nosofskyExemplarbasedAccountsMultiplesystem2000,
  title = {Exemplar-Based Accounts of "Multiple-System" Phenomena in Perceptual Categorization},
  author = {Nosofsky, Robert M and Johansen, Mark K.},
  year = {2000},
  journal = {Psychonomic Bulletin \& Review},
  volume = {7},
  number = {3},
  pages = {375--402},
  abstract = {We demonstrate that a wide variety of recently reported "rule-described" and "prototype-described" phenomena in perceptual classification, which have led to the development of a number of multiple- system models, can be given an alternative interpretation in terms of a single-system exemplar-similarity model. The phenomena include various rule- and prototype-described patterns of generalization, dis- sociations between categorization and similarity judgments, and dissociations between categorization and old-new recognition. The alternative exemplar-based interpretation relies on the idea that simi- larity is not an invariant relation but a context-dependent one. Similarity relations among exemplars change systematically because of selective attention to dimensions and because of changes in the level of sensitivity relating judged similarity to distance in psychological space. Adaptive learning principles may help explain the systematic influence of the selective attention process and of modulation in sen- sitivity settings on judged similarity.},
  langid = {english},
  file = {/Users/thomasgorman/Zotero/storage/5IKW6YXY/Nosofsky - Exemplar-based accounts of multiple-system pheno.pdf}
}

@article{nosofskyExemplarBasedAccountsRelations1988,
  title = {Exemplar-{{Based Accounts}} of {{Relations Between Classification}}, {{Recognition}}, and {{Typicality}}},
  author = {Nosofsky, Robert M},
  year = {1988},
  journal = {Journal of Experimental Psychology. Learning, Memory and Cognition},
  volume = {14},
  number = {4},
  pages = {700--708},
  abstract = {Previously published sets of classification and old-new recognition memory data are reanalyzed within the framework of an exemplar-based generalization model. The key assumption in the model is that, whereas classification decisions are based on the similarity of a probe to exemplars of a target category relative to exemplars of contrast categories, recognition decisions are based on overall summed similarity of a probe to all exemplars. The summed-similarity decision rule is shown to be consistent with a wide variety of recognition memory data obtained in classification learning situations and may provide a unified approach to understanding relations between categorization and recognition.},
  langid = {english},
  file = {/Users/thomasgorman/Zotero/storage/DQE3SG8Q/Nosofsky - Exemplar-Based Accounts of Relations Between Class.pdf}
}

@article{nosofskyExemplarBasedExemplarRepresentations,
  title = {On {{Exemplar-Based Exemplar Representations}}: {{Reply}} to {{Ennis}} (1988)},
  author = {Nosofsky, Robert M},
  pages = {3},
  langid = {english},
  file = {/Users/thomasgorman/Zotero/storage/AK8PD9EG/Nosofsky - On Exemplar-Based Exemplar Representations Reply .pdf}
}

@article{nosofskyExemplarbasedRandomWalk1997,
  title = {An Exemplar-Based Random Walk Model of Speeded Classification},
  author = {Nosofsky, Robert M. and Palmeri, Thomas J.},
  year = {1997},
  journal = {Psychological Review},
  pages = {266--300},
  abstract = {The authors propose and test an exemplar-based random walk model for predicting response times in tasks of speeded, multidimensional perceptual classification. The model combines elements of R. M. Nosofsky's (1986) generalized context model of categorization and G. D. Logan's (1988) instance-based model of automaticity. In the model, exemplars race among one another to be retrieved from memory, with rates determined by their similarity to test items. The retrieved exemplars provide incremental information that enters into a random walk process for making classification decisions. The model predicts correctly effects of within- and between-categories similarity, individual-object familiarity, and extended practice on classification response times. It also builds bridges between the domains of categorization and automaticity. Models of multidimensional perceptual classification have grown increasingly powerful and sophisticated in recent years, providing detailed quantitative accounts of patterns of classification learning, transfer, and generalization (e.g., Anderson,},
  file = {/Users/thomasgorman/OneDrive - Indiana University/resources/Zotero/Nosofsky_Palmeri_1997_An exemplar-based random walk model of speeded classification.pdf;/Users/thomasgorman/Zotero/storage/77LF2NLL/summary.html}
}

@book{nosofskyExemplarBasedRandomWalkModel2015,
  title = {An {{Exemplar-Based Random-Walk Model}} of {{Categorization}} and {{Recognition}}},
  author = {Nosofsky, Robert M. and Palmeri, Thomas J.},
  editor = {Busemeyer, Jerome R. and Wang, Zheng and Townsend, James T. and Eidels, Ami},
  year = {2015},
  month = dec,
  volume = {1},
  publisher = {{Oxford University Press}},
  doi = {10.1093/oxfordhb/9780199957996.013.7},
  urldate = {2020-09-09},
  abstract = {In this chapter, we provide a review of a process-oriented mathematical model of categorization known as the exemplar-based random-walk (EBRW) model (Nosofsky \& Palmeri, 1997a). The EBRW model is a member of the class of exemplar models. According to such models, people represent categories by storing individual exemplars of the categories in memory, and classify objects on the basis of their similarity to the stored exemplars. The EBRW model combines ideas ranging from the fields of choice and similarity, to the development of automaticity, to response-time models of evidence accumulation and decision-making. This integrated model explains relations between categorization and other fundamental cognitive processes, including individual-object identification, the development of expertise in tasks of skilled performance, and old-new recognition memory. Furthermore, it provides an account of how categorization and recognition decision-making unfold through time. We also provide comparisons with some other process models of categorization.},
  langid = {english},
  file = {/Users/thomasgorman/Zotero/storage/MJ6ZKB9C/Nosofsky and Palmeri - 2015 - An Exemplar-Based Random-Walk Model of Categorizat.pdf}
}

@article{nosofskyExemplarfamiliarityModelPredicts2014,
  title = {An Exemplar-Familiarity Model Predicts Short-Term and Long-Term Probe Recognition across Diverse Forms of Memory Search.},
  author = {Nosofsky, Robert M. and Cox, Gregory E. and Cao, Rui and Shiffrin, Richard M.},
  year = {2014},
  journal = {Journal of Experimental Psychology: Learning, Memory, and Cognition},
  volume = {40},
  number = {6},
  pages = {1524--1539},
  issn = {1939-1285, 0278-7393},
  doi = {10.1037/xlm0000015},
  urldate = {2019-06-04},
  abstract = {Experiments were conducted to test a modern exemplar-familiarity model on its ability to account for both short-term and long-term probe recognition within the same memory-search paradigm. Also, making connections to the literature on attention and visual search, the model was used to interpret differences in probe-recognition performance across diverse conditions that manipulated relations between targets and foils across trials. Subjects saw lists of from 1 to 16 items followed by a single item recognition probe. In a varied-mapping condition, targets and foils could switch roles across trials; in a consistent-mapping condition, targets and foils never switched roles; and in an all-new condition, on each trial a completely new set of items formed the memory set. In the varied-mapping and all-new conditions, mean correct response times (RTs) and error proportions were curvilinear increasing functions of memory set size, with the RT results closely resembling ones from hybrid visual-memory search experiments reported by Wolfe (2012). In the consistent-mapping condition, new-probe RTs were invariant with set size, whereas old-probe RTs increased slightly with increasing study\textendash test lag. With appropriate choice of psychologically interpretable free parameters, the model accounted well for the complete set of results. The work provides support for the hypothesis that a common set of processes involving exemplar-based familiarity may govern long-term and short-term probe recognition across wide varieties of memory- search conditions.},
  langid = {english},
  file = {/Users/thomasgorman/Zotero/storage/CR2DWB52/Nosofsky et al. - 2014 - An exemplar-familiarity model predicts short-term .pdf}
}

@article{nosofskyExemplarmodelAccountFeature2015,
  title = {An Exemplar-Model Account of Feature Inference from Uncertain Categorizations.},
  author = {Nosofsky, Robert M.},
  year = {2015},
  month = nov,
  journal = {Journal of Experimental Psychology: Learning, Memory, and Cognition},
  volume = {41},
  number = {6},
  pages = {1929--1941},
  issn = {1939-1285, 0278-7393},
  doi = {10.1037/xlm0000120},
  urldate = {2020-08-16},
  langid = {english},
  file = {/Users/thomasgorman/Zotero/storage/ZSTL95LZ/Nosofsky - 2015 - An exemplar-model account of feature inference fro.pdf}
}

@article{nosofskyExemplarPrototypeModels2002,
  title = {Exemplar and Prototype Models Revisited: {{Response}} Strategies, Selective Attention, and Stimulus Generalization.},
  shorttitle = {Exemplar and Prototype Models Revisited},
  author = {Nosofsky, Robert M. and Zaki, Safa R.},
  year = {2002},
  journal = {Journal of Experimental Psychology: Learning, Memory, and Cognition},
  volume = {28},
  number = {5},
  pages = {924--940},
  issn = {0278-7393},
  doi = {10.1037//0278-7393.28.5.924},
  urldate = {2019-03-16},
  langid = {english},
  file = {/Users/thomasgorman/Zotero/storage/SRFG3YLQ/Nosofsky and Zaki - 2002 - Exemplar and prototype models revisited Response .pdf}
}

@article{nosofskyExemplarSimilarityStudy2006,
  title = {Exemplar Similarity, Study List Homogeneity, and Short-Term Perceptual Recognition},
  author = {Nosofsky, Robert M. and Kantner, Justin},
  year = {2006},
  month = jan,
  journal = {Memory \& Cognition},
  volume = {34},
  number = {1},
  pages = {112--124},
  issn = {0090-502X, 1532-5946},
  doi = {10.3758/BF03193391},
  urldate = {2020-05-31},
  langid = {english},
  file = {/Users/thomasgorman/Zotero/storage/SMPLNWHX/Nosofsky and Kantner - 2006 - Exemplar similarity, study list homogeneity, and s.pdf}
}

@article{nosofskyFamiliarityCategorizationProcesses2014,
  title = {Familiarity and Categorization Processes in Memory Search},
  author = {Nosofsky, Robert M. and Cao, Rui and Cox, Gregory E. and Shiffrin, Richard M.},
  year = {2014},
  month = dec,
  journal = {Cognitive Psychology},
  volume = {75},
  pages = {97--129},
  issn = {0010-0285},
  doi = {10.1016/j.cogpsych.2014.08.003},
  urldate = {2021-01-07},
  abstract = {A fundamental distinction in tasks of memory search is whether items receive varied mappings (targets and distractors switch roles across trials) or consistent mappings (targets and distractors never switch roles). The type of mapping often produces markedly different performance patterns, but formal memory-based models that account quantitatively for detailed aspects of the results have not yet been developed and evaluated. Experiments were conducted to test a modern exemplar-retrieval model on its ability to account for memory-search performance involving a wide range of memory-set sizes in both varied-mapping (VM) and consistent-mapping (CM) probe-recognition tasks. The model formalized the idea that both familiarity-based and categorization-based processes operate. The model was required to fit detailed response-time (RT) distributions of individual, highly practiced subjects. A key manipulation involved the repetition of negative probes across trials. This manipulation produced a dramatic dissociation: False-alarm rates increased and correct-rejection RTs got longer in VM, but not in CM. The qualitative pattern of results and modeling analyses provided evidence for a strong form of categorization-based processing in CM, in which observers made use of the membership of negative probes in the ``new'' category to make old\textendash new recognition decisions.},
  langid = {english},
  keywords = {Automatic processing,Categorization,Exemplar model,Familiarity,Memory search,Old\textendash new recognition,Response times},
  file = {/Users/thomasgorman/OneDrive - Indiana University/resources/Zotero/Nosofsky et al_2014_Familiarity and categorization processes in memory search.pdf;/Users/thomasgorman/Zotero/storage/RZIBDRKW/S0010028514000590.html}
}

@article{nosofskyGeneralizedContextModel2011,
  title = {The Generalized Context Model: {{An}} Exemplar Model of Classification},
  shorttitle = {The Generalized Context Model},
  author = {Nosofsky, Robert M.},
  year = {2011},
  journal = {Formal approaches in categorization},
  pages = {18--39},
  file = {/Users/thomasgorman/Zotero/storage/67FGVR2I/Nosofsky - 2011 - The generalized context model An exemplar model o.pdf}
}

@article{nosofskyHybridsimilarityExemplarModel2003,
  title = {A Hybrid-Similarity Exemplar Model for Predicting Distinctiveness Effects in Perceptual Old\textendash New Recognition},
  author = {Nosofsky, Robert M. and Zaki, Safa R.},
  year = {2003},
  journal = {Journal of Experimental Psychology: Learning, Memory, \& Cognition},
  pages = {1194--1209},
  abstract = {In 2 sets of experiments, the authors investigated the basis for old-item distinctiveness effects in perceptual recognition, whereby distinctive old items are recognized with higher probability than are typical old items. In Experiment 1, distinctive old items were defined as those lying in isolated regions of a continuous-dimension similarity space. In this case, any beneficial effects of distinctiveness were absent or small, regardless of the structure of the test list used to assess recognition memory. In Experiment 2, distinctive items were defined as those objects containing certain discrete, individuating features. In this case, large old-item distinctive effects were observed, with the nature of the effects being modulated by the structure of the test lists. A hybrid-similarity exemplar model, combining elements of continuous-dimension distance and discrete-feature matching, was used to account for these distinctiveness effects in the recognition data. According to global-activation models of old\textendash new recognition memory, observers make recognition judgments on the basis of the overall familiarity of test objects. Presentation of a test object is assumed to give rise to a global activation of information stored in memory. The greater this global activation, the greater is the sense of familiarity associated with the object, and so the greater is the probability with which an observer judges the object to be old},
  file = {/Users/thomasgorman/Zotero/storage/Y79DGLZE/Nosofsky and Zaki - 2003 - A hybrid-similarity exemplar model for predicting .pdf;/Users/thomasgorman/Zotero/storage/R6WSP4G7/summary.html}
}

@incollection{nosofskyInvestigationsExemplarBasedConnectionist1992,
  title = {Investigations of an {{Exemplar-Based Connectionist Model}} of {{Category Learning}}},
  booktitle = {Psychology of {{Learning}} and {{Motivation}}},
  author = {Nosofsky, Robert M. and Kruschke, John K.},
  editor = {Medin, Douglas L.},
  year = {1992},
  month = jan,
  volume = {28},
  pages = {207--250},
  publisher = {{Academic Press}},
  doi = {10.1016/S0079-7421(08)60491-0},
  urldate = {2021-12-11},
  abstract = {This chapter discusses that learning to categorize objects stands among the most fundamental cognitive processes. Categorizing brings order and organization to our mental lives and is a building block of more complex cognitive processes such as reasoning, problem solving, and thinking. Central issues in the study of categorization include how categories are represented in memory, and what decision processes are involved when people make categorization judgments. It provides an overview of ALEX and discusses its relation to the context model. It explains applications of the model in a variety of category learning situations. The context model and ALEX are also compared. It applies ALEX to several previously published data sets that have been fitted accurately by the context model. The main goal is to provide some quantitative tests of ALEX and demonstrate that it performs well in situations in which the context model has performed well. It also discusses the advantages that are yielded by elaborating the context model as an exemplar-based network. The chapter demonstrates a variety of phenomena that are characterized well by ALEX but not by the context model. There is also some discussion about the limitations of the exemplar-based network, considering how the model might be further extended, and evaluating the model's applications.},
  langid = {english},
  file = {/Users/thomasgorman/OneDrive - Indiana University/resources/Zotero/Nosofsky_Kruschke_1992_Investigations of an Exemplar-Based Connectionist Model of Category Learning.pdf;/Users/thomasgorman/Zotero/storage/GKD68J6B/S0079742108604910.html}
}

@article{nosofskyLearningClassifyIntegraldimension1996,
  title = {Learning to Classify Integral-Dimension Stimuli},
  author = {Nosofsky, Robert M. and Palmeri, Thomas J.},
  year = {1996},
  month = jun,
  journal = {Psychonomic Bulletin \& Review},
  volume = {3},
  number = {2},
  pages = {222--226},
  issn = {1069-9384, 1531-5320},
  doi = {10.3758/BF03212422},
  urldate = {2020-08-25},
  langid = {english},
  file = {/Users/thomasgorman/Zotero/storage/JQ3FTMR9/Nosofsky and Palmeri - 1996 - Learning to classify integral-dimension stimuli.pdf}
}

@article{nosofskyLearningHierarchicallyOrganized2019,
  title = {Learning Hierarchically Organized Science Categories: Simultaneous Instruction at the High and Subtype Levels},
  shorttitle = {Learning Hierarchically Organized Science Categories},
  author = {Nosofsky, Robert M. and Slaughter, Colin and McDaniel, Mark A.},
  year = {2019},
  month = dec,
  journal = {Cognitive Research: Principles and Implications},
  volume = {4},
  number = {1},
  pages = {48},
  issn = {2365-7464},
  doi = {10.1186/s41235-019-0200-5},
  urldate = {2020-07-14},
  abstract = {Most science categories are hierarchically organized, with various high-level divisions comprising numerous subtypes. If we suppose that one's goal is to teach students to classify at the high level, past research has provided mixed evidence about whether an effective strategy is to require simultaneous classification learning of the subtypes. This past research was limited, however, either because authentic science categories were not tested, or because the procedures did not allow participants to form strong associations between subtype-level and high-level category names. Here we investigate a two-stage response-training procedure in which participants provide both a high-level and subtype-level response on most trials, with feedback provided at both levels. The procedure is tested in experiments in which participants learn to classify large sets of rocks that are representative of those taught in geoscience classes.},
  file = {/Users/thomasgorman/Zotero/storage/MXN73B9I/Nosofsky et al. - 2019 - Learning hierarchically organized science categori.pdf;/Users/thomasgorman/Zotero/storage/HCRCQL8C/s41235-019-0200-5.html}
}

@book{nosofskyLimitationsExemplarModels,
  title = {Limitations of {{Exemplar Models}} of {{Multi-Attribute Probabilistic Inference}}},
  author = {Nosofsky, Robert M. and Bergert, F. Bryan},
  abstract = {Observers were presented with pairs of objects varying along binary-valued attributes and learned to predict which member of each pair had a greater value on a continuously varying criterion variable. The predictions from exemplar models of categorization were contrasted with classic alternative models, including generalized versions of a ``take-the-best '' model and a weighted-additive model, by testing structures in which interactions between attributes predicted the magnitude of the criterion variable. Under typical training conditions, observers showed little sensitivity to the attribute interactions, thereby challenging the predictions from the exemplar models. In a condition involving highly extended training, observers eventually learned the relations between the attribute interactions and the criterion variable. However, an analysis of the observers ' response times for making their paired-comparison decisions also challenged the exemplar model predictions. Instead, it appeared that most observers recoded the interacting attributes into emergent configural cues. They then applied a set of hierarchically organized rules based on the priority of the cues to make their decisions.},
  keywords = {Cue Task,Instance Search,take-the-best},
  file = {/Users/thomasgorman/Zotero/storage/ZLJYRS2J/Nosofsky and Bergert - Limitations of Exemplar Models of Multi-Attribute .pdf;/Users/thomasgorman/Zotero/storage/KT48QN6T/summary.html}
}

@article{nosofskyMemoryStrengthMemory2016,
  title = {Memory Strength versus Memory Variability in Visual Change Detection},
  author = {Nosofsky, Robert M. and Gold, Jason},
  year = {2016},
  month = jan,
  journal = {Attention, Perception, \& Psychophysics},
  volume = {78},
  number = {1},
  pages = {78--93},
  issn = {1943-393X},
  doi = {10.3758/s13414-015-0992-4},
  urldate = {2020-07-18},
  abstract = {Observers made change-detection judgments for colored squares in a paradigm that manipulated the retention interval, the magnitude of change, and objective change probability. The probability of change judgments increased across the retention interval for ``same'' and ``small-change'' test items but stayed the same or decreased for ``large-change'' and ``far'' test items. A variety of formal models were fitted to the individual-subject data. The modeling results provided evidence that, beyond changes in visual-memory precision, there were decreases in memory strength of individual study items across the retention interval. In addition, the modeling results provided evidence of a zero-information, absence-of-memory state that required guessing. The data were not sufficiently strong to sharply distinguish whether the losses in memory strength across the retention interval were continuous in nature or all-or-none. The authors argue that the construct of memory strength as distinct from memory variability is an important component of the nature of forgetting from visual working memory.},
  langid = {english},
  file = {/Users/thomasgorman/Zotero/storage/YFUSRPCK/Nosofsky and Gold - 2016 - Memory strength versus memory variability in visua.pdf}
}

@article{nosofskyModelguidedSearchOptimal2018,
  title = {Model-Guided Search for Optimal Natural-Science-Category Training Exemplars: {{A}} Work in Progress},
  shorttitle = {Model-Guided Search for Optimal Natural-Science-Category Training Exemplars},
  author = {Nosofsky, Robert M. and Sanders, Craig A. and Zhu, Xiaojin and McDaniel, Mark A.},
  year = {2018},
  month = jul,
  journal = {Psychonomic Bulletin \& Review},
  volume = {26},
  number = {1},
  pages = {48--76},
  issn = {1069-9384, 1531-5320},
  doi = {10.3758/s13423-018-1508-8},
  urldate = {2018-08-27},
  abstract = {Under the guidance of a formal exemplar model of categorization, we conduct comparisons of natural-science classification learning across four conditions in which the nature of the training examples is manipulated. The specific domain of inquiry is rock classification in the geologic sciences; the goal is to use the model to search for optimal training examples for teaching the rock categories. On the positive side, the model makes a number of successful predictions: Most notably, compared with conditions involving focused training on small sets of training examples, generalization to novel transfer items is significantly enhanced in a condition in which learners experience a broad swath of training examples from each category. Nevertheless, systematic departures from the model predictions are also observed. Further analyses lead us to the hypothesis that the high-dimensional featurespace representation derived for the rock stimuli (to which the exemplar model makes reference) systematically underestimates within-category similarities. We suggest that this limitation is likely to arise in numerous situations in which investigators attempt to build detailed feature-space representations for naturalistic categories. A low-parameter extended version of the model that adjusts for this limitation provides dramatically improved accounts of performance across the four conditions. We outline future steps for enhancing the current feature-space representation and continuing our goal of using formal psychological models to guide the search for effective methods of teaching science categories.},
  langid = {english},
  keywords = {Benefit of Variability,Coverage Manipulation,Exemplar model,Instance,Model,Natural Stimuli,Similarity,Similarity Computation,Varied Manipulation},
  file = {/Users/thomasgorman/Zotero/storage/32J3EFNN/Nosofsky et al. - 2018 - Model-guided search for optimal natural-science-ca.pdf}
}

@article{nosofskyRecommendationsCognitivePsychology2019,
  title = {Recommendations {{From Cognitive Psychology}} for {{Enhancing}} the {{Teaching}} of {{Natural-Science Categories}}},
  author = {Nosofsky, Robert M. and McDaniel, Mark A.},
  year = {2019},
  month = mar,
  journal = {Policy Insights from the Behavioral and Brain Sciences},
  volume = {6},
  number = {1},
  pages = {21--28},
  issn = {2372-7322, 2372-7330},
  doi = {10.1177/2372732218814861},
  urldate = {2019-06-04},
  abstract = {Because of their complex structures, many natural-science categories are difficult to learn. Yet achieving accuracy in classification is crucial to scientific inference and reasoning. Thus, an emerging theme in cognitive-psychology and cognitivescience research has been to investigate better ways to instruct about categories. This article briefly reviews major findings that will help inform policies for teaching categories in the science classroom. Many of the examples come from our specific project that examines teaching rock classifications in the geologic sciences. This project uses formal models of human category learning\textemdash developed in cognitive psychology\textemdash to search for optimal teaching procedures. The model-suggested category-teaching procedures often lead to better learning outcomes than do alternative procedures motivated by teachers' and students' intuitive judgments. In addition to reviewing these enhanced procedures for teaching natural-science categories, the article points to recent broader efforts for fostering collaborations between cognitive-science researchers and education researchers.},
  langid = {english},
  file = {/Users/thomasgorman/Zotero/storage/SHHLGG4F/Nosofsky and McDaniel - 2019 - Recommendations From Cognitive Psychology for Enha.pdf}
}

@article{nosofskyResponsetimeEvidenceMixed2016,
  title = {Response-Time Evidence for Mixed Memory States in a Sequential-Presentation Change-Detection Task},
  author = {Nosofsky, Robert M. and Donkin, Chris},
  year = {2016},
  month = feb,
  journal = {Cognitive Psychology},
  volume = {84},
  pages = {31--62},
  issn = {00100285},
  doi = {10.1016/j.cogpsych.2015.11.001},
  urldate = {2020-09-10},
  abstract = {Response-time (RT) and choice-probability data were obtained in a rapid visual sequential-presentation change-detection task in which memory set size, study-test lag, and objective change probabilities were manipulated. False ``change'' judgments increased dramatically with increasing lag, consistent with the idea that study items with long lags were ejected from a discrete-slots buffer. Error RTs were nearly invariant with set size and lag, consistent with the idea that the errors were produced by a stimulusindependent guessing process. The patterns of error and RT data could not be explained in terms of encoding limitations, but were consistent with the hypothesis that long retention lags produced a zero-stimulus-information state that required guessing. Formal modeling of the change-detection RT and error data pointed toward a hybrid model of visual working memory. The hybrid model assumed mixed states involving a combination of memory and guessing, but with higher memory resolution for items with shorter retention lags. The work raises new questions concerning the nature of the memory representations that are produced across the closely related tasks of change detection and visual memory search.},
  langid = {english},
  file = {/Users/thomasgorman/Zotero/storage/WIEXN7DR/Nosofsky and Donkin - 2016 - Response-time evidence for mixed memory states in .pdf}
}

@article{nosofskyRulePlusExceptionModelClassification,
  title = {Rule-{{Plus-Exception Model}} of {{Classification Learning}}},
  author = {Nosofsky, Robert M and Palmeri, ThomasJ},
  pages = {27},
  langid = {english},
  file = {/Users/thomasgorman/Zotero/storage/FE9QBJIR/Nosofsky and Palmeri - Rule-Plus-Exception Model of Classification Learni.pdf}
}

@article{nosofskyRulesExemplarsCategorization1989,
  title = {Rules and Exemplars in Categorization, Identification, and Recognition},
  author = {Nosofsky, R. M. and Clark, {\relax SE} and Shin, H.},
  year = {1989},
  journal = {Journal of Experimental Psychology. Learning, Memory and Cognition},
  volume = {15},
  number = {2},
  pages = {282},
  urldate = {2020-09-07},
  abstract = {Subjectslearnedto classifyperceptualstimuli varyingalongcontinuous,separabledimensions into rule-describedcategories.The categorieswere designedto contrast the predictions of a selective-attentionexemplarmodel and a simple rule-basedmodel formalizing an economy-of- description view. Converging evidenceabout categorizationstrategieswas obtained by also collectingidentification andrecognitiondataandby manipulatingstrategiesvia instructions.In free-strategyconditions,theexemplarmodelgenerallyprovidedan accuratequantitativeaccount ofidentification,categorization,andrecognitionperformance,andit allowedfortheinterrela- tionship of theseparadigmswithin a unified framework.Analysesof individual subjectdataalso providedsomeevidencefor the useof rules,but in general,the rulesseemedto havea greatdeal incommonwithexemplarstorageprocessesC.lassificationandrecognitionperformancefor subjectsgivenexplicit instructionsto usespecificrulescontrasteddramaticallywith performance in thefree-strategyconditionsandcouldnotbepredictedbytheexemplarmodel.},
  file = {/Users/thomasgorman/Zotero/storage/ALA3M38J/191150823.pdf}
}

@article{nosofskyShortTermMemoryScanning2011,
  title = {Short-{{Term Memory Scanning Viewed}} as {{Exemplar-Based Categorization}}},
  author = {Nosofsky, Robert M. and Little, Daniel R. and Donkin, Christopher and Fific, Mario},
  year = {2011},
  month = apr,
  journal = {Psychological review},
  volume = {118},
  number = {2},
  pages = {280--315},
  issn = {0033-295X},
  doi = {10.1037/a0022494},
  urldate = {2019-03-13},
  abstract = {Exemplar-similarity models such as the exemplar-based random-walk (EBRW) model () were designed to provide a formal account of multidimensional classification choice probabilities and response times (RTs). At the same time, a recurring theme has been to use exemplar models to account for old-new item recognition and to explain relations between classification and recognition. However, a major gap in research is that the models have not been tested on their ability to provide a theoretical account of RTs and other aspects of performance in the classic  short-term memory-scanning paradigm, perhaps the most venerable of all recognition-RT tasks. The present research fills that gap by demonstrating that the EBRW model accounts in natural fashion for a wide variety of phenomena involving diverse forms of short-term memory scanning. The upshot is that similar cognitive operating principles may underlie the domains of multidimensional classification and short-term, old-new recognition.},
  pmcid = {PMC3136045},
  pmid = {21355662},
  file = {/Users/thomasgorman/Zotero/storage/BQWH9ARE/Nosofsky et al. - 2011 - Short-Term Memory Scanning Viewed as Exemplar-Base.pdf}
}

@article{nosofskySimilarityFrequencyCategory1988,
  title = {Similarity, Frequency, and Category Representations},
  author = {Nosofsky, Robert M},
  year = {1988},
  journal = {Journal of Experimental Psychology: Learning , Memory, and Cognition},
  volume = {14},
  number = {1},
  pages = {54},
  abstract = {This article studiesthe joint roles of similarity and frequencyin determining graded category structure. Perceptual classification learning experiments were condiuncwtehdich presentation frequenciesof individual exemplars were manipulateTd.he exemplars had varying degreoefs similarity to membersof thetargetandcontrast categories. Classification accurancydtypicality ratings increasedfor exemplars presented with high frequenacnyd for membersof the target categorythat were similarto the high-frequency exemplars. Typicality decreafsoerdmembersof the contrast categorythat were similarto the high-frequency exemplars. A frequency-sensitive similarity-to-exemplars model providedgaoodquantitativeaccountof theclassification learning andtypicality data.Theinteractive relationsamongsimilarity, frequencya, ndcategorization are consideredin theGeneral Discussion.},
  file = {/Users/thomasgorman/Zotero/storage/A693VCIN/Nosofsky - 1988 - Similarity, frequency, and category representation.pdf}
}

@article{nosofskySimilarityScalingCognitive1992,
  title = {Similarity Scaling and Cognitive Process Models},
  author = {Nosofsky, Robert M.},
  year = {1992},
  journal = {Annual review of Psychology},
  volume = {43},
  number = {1},
  pages = {25--53},
  urldate = {2017-09-07},
  file = {/Users/thomasgorman/Zotero/storage/XTEGAH6Q/Nosofsky - 1992 - Similarity scaling and cognitive process models.pdf}
}

@article{nosofskySpeededClassificationProbabilistic2005,
  title = {Speeded Classification in a Probabilistic Category Structure: Contrasting Exemplar-Retrieval, Decision-Boundary, and Prototype Models},
  shorttitle = {Speeded Classification in a Probabilistic Category Structure},
  author = {Nosofsky, Robert M. and Stanton, Roger D.},
  year = {2005},
  month = jun,
  journal = {Journal of Experimental Psychology. Human Perception and Performance},
  volume = {31},
  number = {3},
  pages = {608--629},
  issn = {0096-1523},
  doi = {10.1037/0096-1523.31.3.608},
  abstract = {Speeded perceptual classification experiments were conducted to distinguish among the predictions of exemplar-retrieval, decision-boundary, and prototype models. The key manipulation was that across conditions, individual stimuli received either probabilistic or deterministic category feedback. Regardless of the probabilistic feedback, however, an ideal observer would always classify the stimuli by using an identical linear decision boundary. Subjects classified the probabilistic stimuli with lower accuracy and longer response times than they classified the deterministic stimuli. These results are in accord with the predictions of the exemplar model and challenge the predictions of the prototype and decision-boundary models.},
  langid = {english},
  pmid = {15982134},
  file = {/Users/thomasgorman/Zotero/storage/NW8MS8IH/Nosofsky and Stanton - 2005 - Speeded classification in a probabilistic category.pdf}
}

@article{nosofskyStimulusBiasAsymmetric1991,
  title = {Stimulus Bias, Asymmetric Similarity, and Classification},
  author = {Nosofsky, Robert M},
  year = {1991},
  month = jan,
  journal = {Cognitive Psychology},
  volume = {23},
  number = {1},
  pages = {94--140},
  issn = {00100285},
  doi = {10.1016/0010-0285(91)90004-8},
  urldate = {2020-09-03},
  abstract = {This article proposes that patterns of proximity data that have been character- ized in terms of ``asymmetric similarity'' may be alternatively characterized in terms of differential ``bias.'' Bias is a characteristic pertaining to an individual object, as opposed to similarity, which is a relation between two objects. It is proposed that biases can be stimulus based as well as response based, and nu- merous examples are provided. Part 1 of the article reviews an additive similarity and bias model proposed by Holman (1979,Journal of Mathematical Psychology, 20, l-15), which generalizes various extant models that have successfully char- acterized asymmetric proximities. Part 1 then discusses relations between asym- metric proximities and differences in self-proximities, and also discusses multidi- mensional scaling models that are supplemented with stimulus bias terms. Part 2 of the article reviews and integrates a variety of phenomena in the perceptual classification literature involving asymmetries that can be characterized in terms of symmetric similarity together with differential stimulus bias. Part 3 provides examples of limitations of the additive similarity and bias model. A main thesis of the article is that models of proximity and classification data that incorporate properties of the individual stimulus may not always require recourse to the positing of asymmetric similarities. 0 1991Academic PESS, Inc.},
  langid = {english},
  file = {/Users/thomasgorman/Zotero/storage/HGZQ26MI/Nosofsky - 1991 - Stimulus bias, asymmetric similarity, and classifi.pdf}
}

@article{nosofskyTestsExemplarMemoryModel2017,
  title = {Tests of an {{Exemplar-Memory Model}} of {{Classification Learning}} in a {{High-Dimensional Natural-Science Category Domain}}.},
  author = {Nosofsky, Robert M. and Sanders, Craig A. and McDaniel, Mark A.},
  year = {2017},
  month = oct,
  journal = {Journal of Experimental Psychology: General},
  issn = {1939-2222, 0096-3445},
  doi = {10.1037/xge0000369},
  urldate = {2017-12-20},
  langid = {english},
  file = {/Users/thomasgorman/Zotero/storage/8HQJ3IYV/Nosofsky et al. - 2017 - Tests of an Exemplar-Memory Model of Classificatio.pdf}
}

@article{nosofskyTestsExemplarmemoryModel2018,
  title = {Tests of an Exemplar-Memory Model of Classification Learning in a High-Dimensional Natural-Science Category Domain.},
  author = {Nosofsky, Robert M. and Sanders, Craig A. and McDaniel, Mark A.},
  year = {2018},
  month = mar,
  journal = {Journal of Experimental Psychology: General},
  volume = {147},
  number = {3},
  pages = {328--353},
  issn = {1939-2222, 0096-3445},
  doi = {10.1037/xge0000369},
  urldate = {2020-06-26},
  abstract = {Experiments were conducted in which novice participants learned to classify pictures of rocks into real-world, scientifically defined categories. The experiments manipulated the distribution of training instances during an initial study phase, and then tested for correct classification and generalization performance during a transfer phase. The similarity structure of the to-be-learned categories was also manipulated across the experiments. A low-parameter version of an exemplar-memory model, used in combination with a high-dimensional feature-space representation for the rock stimuli, provided good overall accounts of the categorization data. The successful accounts included (a) predicting how performance on individual item types within the categories varied with the distributions of training examples, (b) predicting the overall levels of classification accuracy across the different rock categories, and (c) predicting the patterns of between-category confusions that arose when classification errors were made. The work represents a promising initial step in scaling up the application of formal models of perceptual classification learning to complex natural-category domains. We discuss further steps for making use of the model and its associated feature-space representation to search for effective techniques of teaching categories in the science classroom.},
  langid = {english},
  file = {/Users/thomasgorman/Zotero/storage/U3V8ZJML/Nosofsky et al. - 2018 - Tests of an exemplar-memory model of classificatio.pdf}
}

@article{nosofskyTestsExemplarModel1991,
  title = {Tests of an {{Exemplar Model}} for {{Relating Perceptual Classification}} and {{Recognition Memory}}},
  author = {Nosofsky, Robert M},
  year = {1991},
  journal = {Journal of Experimental Psychology \textendash{} Human Perception and Performance},
  volume = {17},
  number = {1},
  pages = {25},
  abstract = {Experiments were conducted in which Ss made classification, recognition, and similarity judg- ments for 34 schematic faces. A multidimensional scaling (MDS) solution for the faces was derived on the basis of the similarityjudgments. This MDS solution was then used in conjunction with an exemplar-similarity model to accurately predict Ss' classification and recognition judgments. Evidence was provided that Ss allocated attention to the psychological dimensions differentially for classification and recognition. The distribution of attention came close to the ideal-observer distribution for classification, and some tendencies in that direction were observed for recognition. Evidence was also provided for interactive effects of individual exemplar frequencies and similarities on classification and recognition, in accord with the predictions of the exemplar model. Unexpectedly, however, the frequency effects appeared to be larger for classification than for recognition.},
  langid = {english},
  file = {/Users/thomasgorman/Zotero/storage/Y3DHEFQG/Nosofsky - Tests of an Exemplar Model for Relating Perceptual.pdf}
}

@article{nosofskyTypicalityLogicallyDefined1991,
  title = {Typicality in Logically Defined Categories: {{Exemplar-similarity}} versus Rule Instantiation},
  shorttitle = {Typicality in Logically Defined Categories},
  author = {Nosofsky, Robert M.},
  year = {1991},
  month = mar,
  journal = {Memory \& Cognition},
  volume = {19},
  number = {2},
  pages = {131--150},
  issn = {0090-502X, 1532-5946},
  doi = {10.3758/BF03197110},
  urldate = {2020-08-31},
  abstract = {A rule-instantiation model and a similarity-to-exemplars model were contrasted in terms of their predictions of typicality judgments and speeded eIassifications for members of logically de- fined categories. In Experiment 1, subjeets learned a unidimensional rule based on the size of objects. It was assumed that items that maximally instantiated the rule were those farthest from the category boundary that separated small and large stimuli. In Experiment 2, subjects learned a disjunctive rule ofthe form "x or y or both." It was assumed that items that maximally instan- tiated the rule were those with both positive values (x and y). In both experiments, the frequency with which different exemplars were presented during eIassification learning was manipulated across conditions. These frequency manipulations exerted a major impact on subjeets' postacqui- sition goodness-of-example judgments, and they also influenced reaction times in a speeded clas- sification task. The results could not be predicted solelyon the basis of the degree to which the rules were instantiated. The goodnessjudgments were predicted fairly weIl by a mixed exemplar model involving both relative-similarity and absolute-similarity components. It was coneIuded that even for logically defined concepts, stored exemplars may form a major component of the category representation.},
  langid = {english},
  file = {/Users/thomasgorman/Zotero/storage/GVR672FE/Nosofsky - 1991 - Typicality in logically defined categories Exempl.pdf}
}

@article{olschewskiReinforcementLearningAsset2021,
  title = {Reinforcement Learning about Asset Variability and Correlation in Repeated Portfolio Decisions},
  author = {Olschewski, Sebastian and Diao, Linan and Rieskamp, J{\"o}rg},
  year = {2021},
  month = sep,
  journal = {Journal of Behavioral and Experimental Finance},
  pages = {100559},
  issn = {22146350},
  doi = {10.1016/j.jbef.2021.100559},
  urldate = {2021-09-07},
  abstract = {Lay investors construct portfolios that are often not efficient and fail to take the correlation of assets into account. The present work examines whether providing people with a learning opportunity makes them sensitive to the correlation between assets. In two studies, where participants repeatedly allocated their endowment to three assets with feedback, participants changed their portfolio over time dependent on the asset correlation. To model learning about relevant characteristics of a portfolio, we developed reinforcement learning models that take learning about asset variability and correlation into account. We demonstrated via out-ofsample predictions that these models explain portfolio allocations better than basic reinforcement learning models, a static 1/N diversification strategy, and the mean-variance model using sample means, variances, and correlation. Hence, experiencing returns can help investors take asset correlations into account. The principles of reinforcement learning are a cognitively plausible and descriptively valid framework for understanding repeated portfolio allocations.},
  langid = {english},
  file = {/Users/thomasgorman/Documents/Zotero_Markdown/olschewski_reinforcement_2021-zotero.md;/Users/thomasgorman/OneDrive - Indiana University/resources/Zotero/Olschewski et al_2021_Reinforcement learning about asset variability and correlation in repeated2.pdf}
}

@article{onyperDeterminantsRetrievalSolutions,
  title = {Determinants of Retrieval Solutions during Cognitive Skill Training: {{Source}} Confusions},
  author = {Onyper, Serge V and Hoyer, William J and Cerella, John},
  pages = {12},
  langid = {english},
  file = {/Users/thomasgorman/OneDrive - Indiana University/resources/Zotero/Onyper et al_Determinants of retrieval solutions during cognitive skill training.pdf}
}

@article{opdebeeckRepresentationPerceivedShape2008,
  title = {The Representation of Perceived Shape Similarity and Its Role for Category Learning in Monkeys: {{A}} Modeling Study},
  shorttitle = {The Representation of Perceived Shape Similarity and Its Role for Category Learning in Monkeys},
  author = {{Op de Beeck}, Hans P. and Wagemans, Johan and Vogels, Rufin},
  year = {2008},
  month = feb,
  journal = {Vision Research},
  volume = {48},
  number = {4},
  pages = {598--610},
  issn = {0042-6989},
  doi = {10.1016/j.visres.2007.11.019},
  urldate = {2021-12-11},
  abstract = {Categorization models often assume an intermediate stimulus representation by units implementing ``distance functions'', that is, units that are activated according to the distance or similarity among stimuli. Here we show that a popular example of these models, ALCOVE, is able to account for the performance of monkeys during category learning when it takes the perceived similarity among stimuli into account. Similar results were obtained with a slightly different model (ITCOVE) that included experimentally measured tuning curves of neurons in inferior temporal (IT) cortex. These results show the intimate link between category learning and perceived similarity as represented in IT cortex.},
  langid = {english},
  keywords = {Extrastriate cortex,Monkey,Object recognition,Shape perception},
  file = {/Users/thomasgorman/OneDrive - Indiana University/resources/Zotero/Op de Beeck et al_2008_The representation of perceived shape similarity and its role for category.pdf}
}

@article{pacerRationalModelCausal2011,
  title = {A Rational Model of Causal Induction with Continuous Causes},
  author = {Pacer, Michael D and Griffiths, Thomas L},
  year = {2011},
  journal = {Advances in neural information processing systems,},
  pages = {9},
  abstract = {Rational models of causal induction have been successful in accounting for people's judgments about causal relationships. However, these models have focused on explaining inferences from discrete data of the kind that can be summarized in a 2\texttimes{} 2 contingency table. This severely limits the scope of these models, since the world often provides non-binary data. We develop a new rational model of causal induction using continuous dimensions, which aims to diminish the gap between empirical and theoretical approaches and real-world causal induction. This model successfully predicts human judgments from previous studies better than models of discrete causal inference, and outperforms several other plausible models of causal induction with continuous causes in accounting for people's inferences in a new experiment.},
  langid = {english},
  file = {/Users/thomasgorman/Documents/Zotero_Markdown/pacer_rational_2011-zotero.md;/Users/thomasgorman/OneDrive - Indiana University/resources/Zotero/Pacer_Grifﬁths_A rational model of causal induction with continuous causes.pdf}
}

@article{pachecoLearningSpecificIndividual2018,
  title = {Learning a Specific, Individual and Generalizable Coordination Function: Evaluating the Variability of Practice Hypothesis in Motor Learning},
  shorttitle = {Learning a Specific, Individual and Generalizable Coordination Function},
  author = {Pacheco, Matheus M. and Newell, Karl M.},
  year = {2018},
  month = sep,
  journal = {Experimental Brain Research},
  volume = {236},
  number = {12},
  pages = {3307--3318},
  issn = {1432-1106},
  doi = {10.1007/s00221-018-5383-3},
  urldate = {2018-09-30},
  abstract = {Constant and variable practice conditions have been hypothesized to lead to different learning outcomes between them but similar within. However, experiments have found that within a constant practice condition, participants can show highly individual outcomes (i.e., coordination functions). Considering the contradictory evidence on the effects of variable practice, we tested the idea that measures of the individual learned outcome would be required to provide a full explanation for results in transfer tests rather than or in addition to the group task-related conditions on which individuals practiced. Twenty-four participants were divided into three groups with different practice conditions (constant, varied distance of the target, and varied angle of the target) and for 5 days performed a task of throwing for precision to a target. Pre-, post-, and transfer tests were used to evaluate our hypothesis. The results showed that although the group measures could predict certain aspects of the transfer tests, the coordination function characteristics were required to show higher levels of explanatory power. This finding supports the view that learning involves a specific, individual and generalizable solution although there are aspects of learning that are specific to the condition of practice.},
  langid = {english},
  keywords = {projectile throwing},
  file = {/Users/thomasgorman/Zotero/storage/7HYXW4M9/Pacheco and Newell - 2018 - Learning a specific, individual and generalizable .pdf}
}

@article{pachecoTransferFunctionExploration2015,
  title = {Transfer as a Function of Exploration and Stabilization in Original Practice},
  author = {Pacheco, Matheus M. and Newell, K.M.},
  year = {2015},
  month = dec,
  journal = {Human Movement Science},
  volume = {44},
  pages = {258--269},
  issn = {0167-9457},
  doi = {10.1016/j.humov.2015.09.009},
  urldate = {2018-04-23},
  abstract = {The identification of practice conditions that provide flexibility to perform successfully in transfer is a long-standing issue in motor learning but \ldots},
  langid = {english},
  file = {/Users/thomasgorman/Zotero/storage/WFWUR9E5/2015 - 1a -Transfer as a function of exploration and stab.pdf;/Users/thomasgorman/Zotero/storage/QJ7D4XES/S0167945715300427.html}
}

@article{pachecoTransferLearnedCoordination2018,
  title = {Transfer of a Learned Coordination Function: {{Specific}}, Individual and Generalizable},
  shorttitle = {Transfer of a Learned Coordination Function},
  author = {Pacheco, Matheus M. and Newell, Karl M.},
  year = {2018},
  month = jun,
  journal = {Human Movement Science},
  volume = {59},
  pages = {66--80},
  issn = {01679457},
  doi = {10.1016/j.humov.2018.03.019},
  urldate = {2018-05-05},
  langid = {english},
  file = {/Users/thomasgorman/Zotero/storage/KAZN7WUP/2018 - Transfer of a learned coordination function Speci.pdf}
}

@article{palmeriCentralTendenciesExtreme2001,
  title = {Central {{Tendencies}}, {{Extreme Points}}, and {{Prototype Enhancement Effects}} in {{Ill-Defined Perceptual Categorization}}},
  author = {Palmeri, Thomas J. and Nosofsky, Robert M.},
  year = {2001},
  month = feb,
  journal = {The Quarterly Journal of Experimental Psychology Section A},
  volume = {54},
  number = {1},
  pages = {197--235},
  issn = {0272-4987, 1464-0740},
  doi = {10.1080/02724980042000084},
  urldate = {2020-07-18},
  abstract = {In three perceptual classi􏱤 cation experiments involving ill-de􏱤 ned category structures, extreme prototype enhancement effects were observed in which prototypes were classi􏱤ed more accurately than other category instances. Such empirical 􏱤ndings can prove theoretically challenging to exemplar-based models of categorization if prototypes are psychological central tendencies of category instances. We found instead that category prototypes were sometimes better characterized as psychological extreme points relative to contrast categories. Extending a classic and widely cited study (Posner \& Keele, 1968), participants learned categories created from distortions of dot patterns arranged in familiar shapes. Participants then made pairwise similarity judgements of the patterns. Multidimensional scaling (MDS) analyses of the similar- ity data revealed the prototypes to be psychological extreme points, not central tendencies. Evidence for extreme point representations was also found for novel prototype patterns dis- playing a symmetry structure and for prototypes of grid patterns used in recent studies by McLaren and colleagues (McLaren, Bennet, Guttman-Nahir, Kim, \& Mackintosh, 1995). When used in combination with the derived MDS solutions, an exemplar-based model of cate- gorization, the Generalized Context Model (Nosofsky, 1986), provided good 􏱤 ts to the observed categorization data in all three experiments.},
  langid = {english},
  file = {/Users/thomasgorman/Zotero/storage/E2DKCW8T/Palmeri and Nosofsky - 2001 - Central Tendencies, Extreme Points, and Prototype .pdf}
}

@article{palmeriExemplarSimilarityDevelopment1997,
  title = {Exemplar {{Similarity}} and the {{Development}} of {{Automaticity}}},
  author = {Palmeri, Thomas J},
  year = {1997},
  journal = {Journal of Experimental Psychology: Human Learning and Memory},
  volume = {23},
  number = {2},
  pages = {324--354},
  abstract = {Effects of exemplar similarity on the development of automaticity were investigated with a task in which participants judged the numerosity of random patterns of between 6 and 11 dots. After several days of training, response times were the same at all levels of numerosity, signaling the development of automaticity. In Experiment 1, response times to new patterns were a function of their similarity to old patterns. In Experiment 2, responses to patterns with high within-category similarity became automatized more quickly than responses to patterns with low within-category similarity. In Experiment 3, responses to patterns with high between-category similarity became automatized more slowly than responses to patterns with low between-category similarity. A new theory, the exemplar-based random walk (EBRW) model, was used to explain the results. Combining elements of G. D. Logan's (1988) instance theory of automaticity and R. M. Nosofsky's (1986) generalized context model of categoriza- tion, the theory embeds a dynamic similarity-based memory retrieval mechanism within a competitive random walk decision process.},
  langid = {english},
  file = {/Users/thomasgorman/Zotero/storage/QX5K62QJ/Palmed - Exemplar Similarityand the Development of Automati.pdf}
}

@article{palmeriLearningCategoriesDifferent1999,
  title = {Learning Categories at Different Hierarchical Levels: {{A}} Comparison of Category Learning Models},
  shorttitle = {Learning Categories at Different Hierarchical Levels},
  author = {Palmeri, Thomas J.},
  year = {1999},
  month = sep,
  journal = {Psychonomic Bulletin \& Review},
  volume = {6},
  number = {3},
  pages = {495--503},
  issn = {1069-9384, 1531-5320},
  doi = {10.3758/BF03210840},
  urldate = {2021-12-11},
  langid = {english},
  file = {/Users/thomasgorman/OneDrive - Indiana University/resources/Zotero/Palmeri_1999_Learning categories at different hierarchical levels.pdf}
}

@techreport{papenbergUsingAnticlusteringPartition2019,
  title = {Using Anticlustering to Partition Data Sets into Equivalent Parts},
  author = {Papenberg, Martin and Klau, Gunnar W.},
  year = {2019},
  month = oct,
  institution = {{PsyArXiv}},
  urldate = {2022-04-06},
  abstract = {Numerous applications in psychological research require that a pool of elements is partitioned into multiple parts. While many applications seek groups that are well-separated, i.e., dissimilar from each other, others require the different groups to be as similar as possible. Examples include the assignment of students to parallel courses, assembling stimulus sets in experimental psychology, splitting achievement tests into parts of equal difficulty, and dividing a data set for cross validation. We present anticlust, an easy-to-use and free software package for solving these problems fast and in an automated manner. The package anticlust is an open source extension to the R programming language and implements the methodology of anticlustering. Anticlustering divides elements into similar parts, ensuring similarity between groups by enforcing heterogeneity within groups. Thus, anticlustering is the direct reversal of cluster analysis that aims to maximize homogeneity within groups and dissimilarity between groups. Our package anticlust implements two anticlustering criteria, reversing the clustering methods k-means and cluster editing, respectively. In a simulation study, we show that anticlustering returns excellent results and outperforms alternative approaches like random assignment and matching. In three example applications, we illustrate how to apply anticlust on real data sets. We demonstrate how to assign experimental stimuli to equivalent sets based on norming data, how to divide a large data set for cross validation, and how to split a test into parts of equal item difficulty and discrimination.},
  langid = {american},
  keywords = {anticluster editing,anticlustering,cross validation,experimental design,k-means,maximum diverse grouping problem,Quantitative Methods,Quantitative Psychology,Social and Behavioral Sciences,stimulus selection},
  annotation = {https://m-py.github.io/anticlust/},
  file = {/Users/thomasgorman/OneDrive - Indiana University/resources/Zotero/Papenberg_Klau_2019_Using anticlustering to partition data sets into equivalent parts.pdf}
}

@article{parkCausalInvarianceTacit2022,
  title = {Causal Invariance as a Tacit Aspiration: {{Analytic}} Knowledge of Invariance Functions},
  shorttitle = {Causal Invariance as a Tacit Aspiration},
  author = {Park, Jooyong and McGillivray, Shannon and Bye, Jeffrey K. and Cheng, Patricia W.},
  year = {2022},
  month = feb,
  journal = {Cognitive Psychology},
  volume = {132},
  pages = {101432},
  issn = {0010-0285},
  doi = {10.1016/j.cogpsych.2021.101432},
  urldate = {2022-06-05},
  abstract = {For causal knowledge to be worth learning, it must remain valid when that knowledge is applied. Because unknown background causes are potentially present, and may vary across the learning and application contexts, extricating the strength of a candidate cause requires an assumption regarding the decomposition of the observed outcome into the unobservable influences from the candidate and from background causes. Acquiring stable, useable causal knowledge is challenging when the search space of candidate causes is large, such that the reasoner's current set of candidates may fail to include a cause that generalizes well to an application context. We have hypothesized that an indispensable navigation device that shapes our causal representations toward useable knowledge involves the concept of causal invariance \textendash{} the sameness of how a cause operates to produce an effect across contexts. Here, we tested our causal invariance hypothesis by making use of the distinct mathematical functions expressing causal invariance for two outcome-variable types: continuous and binary. Our hypothesis predicts that, given identical prior domain knowledge, intuitive causal judgments should vary in accord with the causal-invariance function for a reasoner's perceived outcome-variable type. The judgments are made as if the reasoner aspires to formulate causally invariant knowledge. Our experiments involved two cue-competition paradigms: blocking and overexpectation. Results show that adult humans tacitly use the appropriate causal-invariance functions for decomposition. Our analysis offers an explanation for the apparent elusiveness of the blocking effect and the adaptiveness of intuitive causal inference to the representation-dependent reality in the mind.},
  langid = {english},
  keywords = {Analytic knowledge,Causal induction,Causal invariance,Causal-knowledge generalization,Integration functions},
  file = {/Users/thomasgorman/Documents/Zotero_Markdown/park_causal_2022-zotero.md;/Users/thomasgorman/OneDrive - Indiana University/resources/Zotero/Park et al_2022_Causal invariance as a tacit aspiration.pdf;/Users/thomasgorman/Zotero/storage/MW376YY9/S0010028521000554.html}
}

@incollection{peeblesConnectionistModelCategorization1999,
  title = {A {{Connectionist Model}} of {{Categorization Response Times}}},
  booktitle = {Connectionist {{Models}} in {{Cognitive Neuroscience}}},
  author = {Peebles, David and Lamberts, Koen},
  editor = {Taylor, John G. and Heinke, Dietmar and Humphreys, Glynn W. and Olson, Andrew},
  year = {1999},
  pages = {228--239},
  publisher = {{Springer London}},
  address = {{London}},
  doi = {10.1007/978-1-4471-0813-9_20},
  urldate = {2021-08-10},
  abstract = {Although perceptual categorization has been studied extensively in psychology, response times in categorization tasks have only recently become an important research topic [1, 2, 3, 4, 5, 6, 7, 8, 9]. In this article, we propose a connectionist model of categorization RT, called CONCAT, which aims to provide a joint account of response times and choice proportions in binary classification tasks. First, we outline the basic principles of the model. Next, we present a perceptual categorization experiment and apply CONCAT to the results.},
  isbn = {978-1-85233-052-1 978-1-4471-0813-9},
  langid = {english},
  file = {/Users/thomasgorman/OneDrive - Indiana University/resources/Zotero/Peebles_Lamberts_1999_A Connectionist Model of Categorization Response Times.pdf}
}

@article{peeblesEffectStimulusFrequency,
  title = {The {{Effect}} of {{Stimulus Frequency}} on {{Classification Accuracy}} and {{Response Time}}},
  author = {Peebles, David John},
  pages = {143},
  langid = {english},
  file = {/Users/thomasgorman/Zotero/storage/NTAXXJRV/Peebles - The Eﬀect of Stimulus Frequency on Classiﬁcation A.pdf}
}

@article{posnerGenesisAbstractIdeas1968,
  title = {On the Genesis of Abstract Ideas.},
  author = {Posner, Michael I. and Keele, Steven W.},
  year = {1968},
  journal = {Journal of experimental psychology},
  volume = {77},
  number = {3},
  pages = {353--363},
  urldate = {2017-08-12},
  keywords = {Artifical Stimuli,Benefit of Variability,Delayed Test,Empirical,Prototype,Schema,Theoretical,Variability,Varied Manipulation},
  file = {/Users/thomasgorman/Zotero/storage/NJXQ6WGK/posner_keele_1968.pdf}
}

@article{puLearningAcquireInformation2017,
  title = {Learning to {{Acquire Information}}},
  author = {Pu, Yewen and Kaelbling, Leslie P. and {Solar-Lezama}, Armando},
  year = {2017},
  month = jul,
  journal = {arXiv:1704.06131 [cs, stat]},
  eprint = {1704.06131},
  primaryclass = {cs, stat},
  urldate = {2021-04-06},
  abstract = {We consider the problem of diagnosis where a set of simple observations are used to infer a potentially complex hidden hypothesis. Finding the optimal subset of observations is intractable in general, thus we focus on the problem of active diagnosis, where the agent selects the next most-informative observation based on the results of previous observations. We show that under the assumption of uniform observation entropy, one can build an implication model which directly predicts the outcome of the potential next observation conditioned on the results of past observations, and selects the observation with the maximum entropy. This approach enjoys reduced computation complexity by bypassing the complicated hypothesis space, and can be trained on observation data alone, learning how to query without knowledge of the hidden hypothesis.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {/Users/thomasgorman/Documents/Zotero_Markdown/pu_learning_2017-zotero.md;/Users/thomasgorman/OneDrive - Indiana University/resources/Zotero/Pu et al_2017_Learning to Acquire Information.pdf;/Users/thomasgorman/Zotero/storage/2LJVK53X/1704.html}
}

@misc{quirogaStructuredPriorsHuman2018,
  title = {Structured Priors in Human Forecasting},
  author = {Quiroga, Francisco and Schulz, Eric and Speekenbrink, Maarten and Harvey, Nigel},
  year = {2018},
  month = feb,
  institution = {{PsyArXiv}},
  doi = {10.31234/osf.io/zv9sx},
  urldate = {2022-04-19},
  abstract = {Forecasting is an increasingly important part of our daily lives. Many studies on how people produce forecasts frame their behavior as prone to systematic errors. Based on recent evidence on how people learn about functions, we propose that participants' forecasts are not irrational but rather driven by structured priors, i.e. situationally induced expectations of structure derived from experience with the real world. To test this, we extract participants' priors over various contexts using a free-form forecasting paradigm. Instead of exhibiting systematic biases, our results show that participants' priors match well with structure found in real-world data. Moreover, given the same data set, structured priors induce predictably different posterior forecasts depending on the evoked situational context.},
  langid = {american},
  keywords = {Decision Making,Function Learning,Gaussian Process,Intuitive Statistics,Judgments,jupyter\_notebook,Perception,Quantitative Methods,Social and Behavioral Sciences,Structured Learning,Time Series},
  file = {/Users/thomasgorman/Documents/Zotero_Markdown/quiroga_structured_2018-zotero.md;/Users/thomasgorman/OneDrive - Indiana University/resources/Zotero/Quiroga et al_2018_Structured priors in human forecasting.pdf}
}

@article{reidSpatialBiasesMotion2018,
  title = {Spatial Biases in Motion Extrapolation for Manual Interception},
  author = {Reid, Sinead A. and Dessing, Joost C.},
  year = {2018},
  month = jan,
  journal = {Journal of Experimental Psychology: Human Perception and Performance},
  volume = {44},
  number = {1},
  pages = {38},
  publisher = {{American Psychological Association, Inc.}},
  issn = {0096-1523},
  urldate = {2021-07-12},
  abstract = {The exact mechanisms by which humans control the manual interception of moving targets are currently unknown. Here, the authors explored the behaviors associated with the spatial control for manual interception. The examined task required controlling a cursor to intercept moving targets on a touch screen. They explored the effects of target motion direction, curvature and occlusion on manual interception. They observed occlusion-dependent spatial errors and arrival times for curved and diagonal trajectories (larger errors and earlier arrival of the finger at its final position with longer occlusion). These effects were particularly apparent for targets moving away from screen center at interception due to curve. In a follow-up experiment, the authors showed that the outward curve effects on spatial errors were absent because the associated trajectories appears to move toward positions that participants could expect the target to never reach. Their analyses also revealed occlusion-dependent spatial errors for diagonal trajectories, which is the well-known angle-of-approach effect. Follow-up experiments demonstrated that this effect was not due to the central initial cursor position acting as a visual reference point or the initial ocular pursuit. Most importantly, the angle-of-approach effect persisted in a judgment task. The authors thus concluded that this effect does not stem from online information-based modulations of movement speed, but from target information used to control aiming (i.e., movement direction). Moreover, processing for diagonal target motion appears to be biased toward straight downward.},
  keywords = {Motion perception (Vision) -- Analysis,Psychology and mental health,Spatial behavior -- Psychological aspects},
  file = {/Users/thomasgorman/OneDrive - Indiana University/resources/Zotero/Reid_Dessing_2018_Spatial biases in motion extrapolation for manual interception.pdf}
}

@article{reimannColorencodedLinksImprove2022,
  title = {Color-Encoded {{Links Improve Homophily Perception}} in {{Node-Link Diagrams}}},
  author = {Reimann, Daniel and Schulz, Andr{\'e} and Ram, Nilam and Gaschler, Robert},
  year = {2022},
  journal = {IEEE Transactions on Visualization and Computer Graphics},
  pages = {1--7},
  issn = {1941-0506},
  doi = {10.1109/TVCG.2022.3221014},
  abstract = {Node-link diagrams enable visual assessment of homophily when viewers can identify and evaluate the relative number of intra-cluster and inter-cluster links. Our online experiment shows that a new design with link type encoded edge color leads to more accurate perception of homophily than a design with same-color edges.},
  keywords = {Color,homophily,Image color analysis,Information visualization,Layout,node-link diagrams,perception,Psychology,Standards,Task analysis,Visualization},
  file = {/Users/thomasgorman/Documents/Zotero_Markdown/reimannColorencodedLinksImprove2022-zotero.md;/Users/thomasgorman/OneDrive - Indiana University/resources/Zotero/Reimann et al_2022_Color-encoded Links Improve Homophily Perception in Node-Link Diagrams.pdf;/Users/thomasgorman/Zotero/storage/HGVYDCLY/9944974.html}
}

@article{reimannLollipopsHelpAlign2022,
  title = {Lollipops {{Help Align Visual}} and {{Statistical Fit Estimates}} in {{Scatterplots}} with {{Nonlinear Models}}},
  author = {Reimann, Daniel and Ram, Nilam and Gaschler, Robert},
  year = {2022},
  journal = {IEEE Transactions on Visualization and Computer Graphics},
  pages = {1--1},
  issn = {1941-0506},
  doi = {10.1109/TVCG.2022.3158093},
  abstract = {Scatterplots overlayed with a nonlinear model enable visual estimation of model-data fit. Although statistical fit is calculated using vertical distances, viewers subjective fit is often based on shortest distances. Our results suggest that adding vertical lines (lollipops) supports more accurate fit estimation in the steep area of model curves (https://osf.io/fybx5/).},
  keywords = {Computational modeling,Data models,Data visualization,Estimation,Information visualization,perception and psychophysics,Psychology,Task analysis,theory and models,Visualization},
  file = {/Users/thomasgorman/Documents/Zotero_Markdown/reimannLollipopsHelpAlign2022-zotero.md;/Users/thomasgorman/OneDrive - Indiana University/resources/Zotero/Reimann et al_2022_Lollipops Help Align Visual and Statistical Fit Estimates in Scatterplots with.pdf;/Users/thomasgorman/Zotero/storage/97EGIUQ5/9732236.html}
}

@techreport{roarkNeuralNetworkModel2020,
  type = {Preprint},
  title = {A Neural Network Model of the Effect of Prior Experience with Regularities on Subsequent Category Learning},
  author = {Roark, Casey L and Plaut, David C. and Holt, Lori L.},
  year = {2020},
  month = oct,
  institution = {{PsyArXiv}},
  doi = {10.31234/osf.io/uvaew},
  urldate = {2021-09-18},
  abstract = {Categories are often structured by the similarities of instances within the category defined across dimensions or features. Researchers typically assume that there is a direct, linear relationship between the physical input dimensions across which category exemplars are defined and the psychological representation of these dimensions. However, this assumption is not always warranted. Through a set of simulations, we demonstrate that the psychological representations of input dimensions developed through long-term prior experience can place very strong constraints on category learning. We compare the model's behavior to auditory, visual, and cross-modal human category learning and make conclusions regarding the nature of the psychological representations of the dimensions in those studies. These simulations support the conclusion that the nature of psychological representations of input dimensions is a critical aspect to understanding the mechanisms underlying category learning.},
  langid = {english},
  file = {/Users/thomasgorman/OneDrive - Indiana University/resources/Zotero/Roark et al_2020_A neural network model of the effect of prior experience with regularities on.pdf}
}

@misc{roarkStatisticalLearningDoes2020,
  title = {Statistical Learning Does Not Overrule Perceptual Priors during Category Learning},
  author = {Roark, Casey L. and Holt, Lori L.},
  year = {2020},
  month = oct,
  institution = {{PsyArXiv}},
  doi = {10.31234/osf.io/sdf7y},
  urldate = {2021-12-03},
  abstract = {Cognitive systems face a constant tension of maintaining existing representations that have been fine-tuned to long-term input regularities and adapting representations to meet the needs of short-term input that may deviate from long-term norms. These systems must balance the stability of long-term representations with plasticity to accommodate novel contexts. We investigated the interaction between perceptual biases or priors acquired across the long-term and sensitivity to statistical regularities introduced in the short-term. Participants were first passively exposed to short-term acoustic regularities and then learned categories in a supervised training task that either conflicted or aligned with long-term perceptual priors. We found that the long-term priors had robust and pervasive impact on categorization behavior. In contrast, behavior was not influenced by the nature of the short-term passive exposure. These results demonstrate that perceptual priors place strong constraints on the course of learning and that short-term passive exposure to acoustic regularities has limited impact on directing subsequent category learning.},
  langid = {american},
  keywords = {audition,Audition,category learning,Cognitive Psychology,Concepts and Categories,Learning,Perception,perceptual priors,Social and Behavioral Sciences,statistical learning,statistical regularities},
  file = {/Users/thomasgorman/OneDrive - Indiana University/resources/Zotero/Roark_Holt_2020_Statistical learning does not overrule perceptual priors during category.pdf}
}

@article{robinsonYouDrawIt,
  title = {`{{You Draw It}}': {{Implementation}} of Visually Fitted Trends with R2d3},
  author = {Robinson, Emily A and Howard, Reka and VanderPlas, Susan},
  pages = {19},
  abstract = {How do statistical regression results compare to intuitive, visually fitted results? Fitting lines by eye through a set of points has been explored since the 20th century. Common methods of fitting trends by eye involve maneuvering a string, black thread, or ruler until the fit is suitable, then drawing the line through the set of points. In 2015, the New York Times introduced an interactive feature, called `You Draw It,' where readers are asked to input their own assumptions about various metrics and compare how these assumptions relate to reality. This research is intended to implement `You Draw It', adapted from the New York Times, as a way to measure the patterns we see in data. In this paper, we describe the adaptation of an old tool for graphical testing and evaluation, eye-fitting, for use in modern web-applications suitable for testing statistical graphics. We present an empirical evaluation of this testing method for linear regression, and briefly discuss an extension of this method to non-linear applications.},
  langid = {english},
  annotation = {https://emily-robinson.shinyapps.io/you-draw-it-validation-applet/},
  file = {/Users/thomasgorman/Documents/Zotero_Markdown/robinson_you_nodate-zotero.md;/Users/thomasgorman/OneDrive - Indiana University/resources/Zotero/Robinson et al_`You Draw It'.pdf}
}

@article{rosenbaumPosturebasedMotionPlanning2001,
  title = {Posture-Based Motion Planning: {{Applications}} to Grasping.},
  shorttitle = {Posture-Based Motion Planning},
  author = {Rosenbaum, David A. and Meulenbroek, Ruud J. and Vaughan, Jonathan and Jansen, Chris},
  year = {2001},
  journal = {Psychological Review},
  volume = {108},
  number = {4},
  pages = {709--734},
  issn = {0033-295X},
  doi = {10.1037//0033-295X.108.4.709},
  urldate = {2019-03-13},
  langid = {english},
  file = {/Users/thomasgorman/Zotero/storage/6B4DBD2H/Rosenbaum et al. - 2001 - Posture-based motion planning Applications to gra.pdf}
}

@article{ruderLearningSelectData2017,
  title = {Learning to Select Data for Transfer Learning with {{Bayesian Optimization}}},
  author = {Ruder, Sebastian and Plank, Barbara},
  year = {2017},
  month = jul,
  journal = {arXiv:1707.05246 [cs]},
  eprint = {1707.05246},
  primaryclass = {cs},
  urldate = {2021-12-04},
  abstract = {Domain similarity measures can be used to gauge adaptability and select suitable data for transfer learning, but existing approaches define ad hoc measures that are deemed suitable for respective tasks. Inspired by work on curriculum learning, we propose to \textbackslash emph\{learn\} data selection measures using Bayesian Optimization and evaluate them across models, domains and tasks. Our learned measures outperform existing domain similarity measures significantly on three tasks: sentiment analysis, part-of-speech tagging, and parsing. We show the importance of complementing similarity with diversity, and that learned measures are -- to some degree -- transferable across models, domains, and even tasks.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Computation and Language,Computer Science - Machine Learning},
  file = {/Users/thomasgorman/OneDrive - Indiana University/resources/Zotero/Ruder_Plank_2017_Learning to select data for transfer learning with Bayesian Optimization.pdf;/Users/thomasgorman/Zotero/storage/ZDCJ2MGK/1707.html}
}

@article{ryanGraphsLogarithmicAxes2020,
  title = {Graphs with Logarithmic Axes Distort Lay Judgments},
  author = {Ryan, William H and Evers, Ellen R K},
  year = {2020},
  journal = {behavioral science},
  pages = {19},
  abstract = {Graphs that depict numbers of COVID-19 cases often use a linear or logarithmic scale on the y-axis. To examine the effect of scale on how the general public interprets the curves and uses that understanding to infer the urgency of the need for protective actions, we conducted a series of experiments that presented laypeople with the same data plotted on one scale or the other. We found that graphs with a logarithmic, as opposed to a linear, scale resulted in laypeople making less accurate predictions of how fast cases would increase, viewing COVID-19 as less dangerous, and expressing both less support for policy interventions and less intention to take personal actions to combat the disease. Education about the differences between linear and logarithmic graphs reduces but does not eliminate these effects. These results suggest that communications to the general public should mostly use linear graphs. When logarithmic graphs must be used, they should be presented alongside linear graphs of the same data and with guidance on how to interpret the plots.},
  langid = {english},
  file = {/Users/thomasgorman/Documents/Zotero_Markdown/ryan_graphs_2020-zotero.md;/Users/thomasgorman/OneDrive - Indiana University/resources/Zotero/Ryan_Evers_2020_Graphs with logarithmic axes distort lay judgments.pdf}
}

@article{safstromShorttermPlasticityVisuomotor2005,
  title = {Short-Term Plasticity of the Visuomotor Map during Grasping Movements in Humans},
  author = {S{\"a}fstr{\"o}m, Daniel and Edin, Benoni B.},
  year = {2005},
  month = jan,
  journal = {Learning \& Memory},
  volume = {12},
  number = {1},
  pages = {67--74},
  issn = {1072-0502, 1549-5485},
  doi = {10.1101/lm.83005},
  urldate = {2022-05-27},
  abstract = {During visually guided grasping movements, visual information is transformed into motor commands. This transformation is known as the ``visuomotor map.'' To investigate limitations in the short-term plasticity of the visuomotor map in normal humans, we studied the maximum grip aperture (MGA) during the reaching phase while subjects grasped objects of various sizes. The objects seen and the objects grasped were physically never the same. When a discrepancy had been introduced between the size of the visual and the grasped objects, and the subjects were fully adapted to it, they all readily interpolated and extrapolated the MGA to objects not included in training trials. In contrast, when the subjects were exposed to discrepancies that required a slope change in the visuomotor map, they were unable to adapt adequately. They instead retained a subject-specific slope of the relationship between the visual size and MGA. We conclude from these results that during reaching for grasping, normal subjects are unable to abandon a straight linear function determining the relationship between visual object size and MGA. Moreover, the plasticity of the visuomotor map is, at least in short term, constrained to allow only offset changes, that is, only ``rigid shifts'' are possible between the visual and motor coordinate systems.},
  langid = {english},
  file = {/Users/thomasgorman/Documents/Zotero_Markdown/safstrom_short-term_2005-zotero.md;/Users/thomasgorman/OneDrive - Indiana University/resources/Zotero/Säfström_Edin_2005_Short-term plasticity of the visuomotor map during grasping movements in humans.pdf}
}

@article{saidExtrapolationAccuracyUnderestimates2021,
  title = {Extrapolation Accuracy Underestimates Rule Learning: {{Evidence}} from the Function-Learning Paradigm},
  shorttitle = {Extrapolation Accuracy Underestimates Rule Learning},
  author = {Said, Nadia and Fischer, Helen},
  year = {2021},
  month = jul,
  journal = {Acta Psychologica},
  volume = {218},
  pages = {103356},
  issn = {0001-6918},
  doi = {10.1016/j.actpsy.2021.103356},
  urldate = {2022-04-12},
  abstract = {Understanding the development of non-linear processes such as economic or population growth is an important prerequisite for informed decisions in those areas. In the function-learning paradigm, people's understanding of the function rule that underlies the to-be predicted process is typically measured by means of extrapolation accuracy. Here we argue, however, that even though accurate extrapolation necessitates rule-learning, the reverse does not necessarily hold: Inaccurate extrapolation does not exclude rule-learning. Experiment 1 shows that more than one third of participants who would be classified as ``exemplar-based learners'' based on their extrapolation accuracy were able to identify the correct function shape and slope in a rule-selection paradigm, demonstrating accurate understanding of the function rule. Experiment 2 shows that higher proportions of rule learning than ruleapplication in the function-learning paradigm is not due to (i) higher a priori probabilities to guess the correct rule in the rule-selection paradigm; nor is it due to (ii) a lack of simultaneous access to all function values in the function-learning paradigm. We conclude that rule application is not tantamount to rule-learning, and that assessing rule xlearning via extrapolation accuracy underestimates the proportion of rule learners in function-learning experiments.},
  langid = {english},
  keywords = {Function-learning,Non-linear processes,Rule-based vs exemplar-based learners,Understanding},
  annotation = {https://figshare.com/authors/\_/2828834},
  file = {/Users/thomasgorman/Documents/Zotero_Markdown/saidExtrapolationAccuracyUnderestimates2021-zotero.md;/Users/thomasgorman/OneDrive - Indiana University/resources/Zotero/Said_Fischer_2021_Extrapolation accuracy underestimates rule learning2.pdf;/Users/thomasgorman/Zotero/storage/5K5PL22Q/S0001691821001062.html}
}

@article{salaDoesFarTransfer2017,
  title = {Does {{Far Transfer Exist}}? {{Negative Evidence From Chess}}, {{Music}}, and {{Working Memory Training}}},
  shorttitle = {Does {{Far Transfer Exist}}?},
  author = {Sala, Giovanni and Gobet, Fernand},
  year = {2017},
  month = dec,
  journal = {Current Directions in Psychological Science},
  volume = {26},
  number = {6},
  pages = {515--520},
  issn = {0963-7214},
  doi = {10.1177/0963721417712760},
  urldate = {2018-06-23},
  abstract = {Chess masters and expert musicians appear to be, on average, more intelligent than the general population. Some researchers have thus claimed that playing chess or learning music enhances children's cognitive abilities and academic attainment. We here present two meta-analyses assessing the effect of chess and music instruction on children's cognitive and academic skills. A third meta-analysis evaluated the effects of working memory training\textemdash a cognitive skill correlated with music and chess expertise\textemdash on the same variables. The results show small to moderate effects. However, the effect sizes are inversely related to the quality of the experimental design (e.g., presence of active control groups). This pattern of results casts serious doubts on the effectiveness of chess, music, and working memory training. We discuss the theoretical and practical implications of these findings; extend the debate to other types of training such as spatial training, brain training, and video games; and conclude that far transfer of learning rarely occurs.},
  langid = {english},
  file = {/Users/thomasgorman/Zotero/storage/F7ZTCL94/Sala and Gobet - 2017 - Does Far Transfer Exist Negative Evidence From Ch.pdf}
}

@article{sandersUsingDeepLearningRepresentations,
  title = {Using {{Deep-Learning Representations}} of {{Complex Natural Stimuli}} as {{Input}} to {{Psychological Models}} of {{Classification}}},
  author = {Sanders, Craig A and Nosofsky, Robert M.},
  pages = {6},
  abstract = {Tests of formal models of human categorization have traditionally been restricted to artificial categories because deriving psychological representations for large numbers of natural stimuli has been an intractable task. We show that deep learning may be used to solve this problem. We train an ensemble of convolutional neural networks (CNNs) to produce the multidimensional scaling (MDS) coordinates of images of rocks. We then show that not only are the CNNs able to predict the MDS coordinates of a held-out test set of rocks, but that the CNN-derived representations can be used in combination with a formal psychological model to predict human categorization behavior on a completely new set of rocks.},
  langid = {english},
  file = {/Users/thomasgorman/Zotero/storage/BLY6W4WJ/Sanders and Nosofsky - Using Deep-Learning Representations of Complex Nat.pdf}
}

@article{schaalConstructiveIncrementalLearning1998,
  title = {Constructive {{Incremental Learning}} from {{Only Local Information}}},
  author = {Schaal, Stefan and Atkeson, Christopher G.},
  year = {1998},
  month = nov,
  journal = {Neural Computation},
  volume = {10},
  number = {8},
  pages = {2047--2084},
  issn = {0899-7667, 1530-888X},
  doi = {10.1162/089976698300016963},
  urldate = {2022-01-13},
  abstract = {We introduce a constructive, incremental learning system for regression problems that models data by means of spatially localized linear models. In contrast to other approaches, the size and shape of the receptive field of each locally linear model, as well as the parameters of the locally linear model itself, are learned independently, that is, without the need for competition or any other kind of communication. Independent learning is accomplished by incrementally minimizing a weighted local cross-validation error. As a result, we obtain a learning system that can allocate resources as needed while dealing with the bias-variance dilemma in a principled way. The spatial localization of the linear models increases robustness toward negative interference. Our learning system can be interpreted as a nonparametric adaptive bandwidth smoother, as a mixture of experts where the experts are trained in isolation, and as a learning system that profits from combining independent expert knowledge on the same problem. This article illustrates the potential learning capabilities of purely local learning and offers an interesting and powerful approach to learning with receptive fields.},
  langid = {english},
  keywords = {Bias\textendash variance decomposition},
  file = {/Users/thomasgorman/Documents/Zotero_Markdown/schaalConstructiveIncrementalLearning1998-zotero.md;/Users/thomasgorman/OneDrive - Indiana University/resources/Zotero/Schaal_Atkeson_1998_Constructive Incremental Learning from Only Local Information.pdf}
}

@article{scheibehenneTestingAdaptiveToolbox2013,
  title = {Testing Adaptive Toolbox Models: {{A Bayesian}} Hierarchical Approach.},
  shorttitle = {Testing Adaptive Toolbox Models},
  author = {Scheibehenne, Benjamin and Rieskamp, J{\"o}rg and Wagenmakers, Eric-Jan},
  year = {2013},
  month = jan,
  journal = {Psychological Review},
  volume = {120},
  number = {1},
  pages = {39--64},
  issn = {1939-1471, 0033-295X},
  doi = {10.1037/a0030777},
  urldate = {2020-04-17},
  abstract = {Many theories of human cognition postulate that people are equipped with a repertoire of strategies to solve the tasks they face. This theoretical framework of a cognitive toolbox provides a plausible account of intra- and interindividual differences in human behavior. Unfortunately, it is often unclear how to rigorously test the toolbox framework. How can a toolbox model be quantitatively specified? How can the number of toolbox strategies be limited to prevent uncontrolled strategy sprawl? How can a toolbox model be formally tested against alternative theories? The authors show how these challenges can be met by using Bayesian inference techniques. By means of parameter recovery simulations and the analysis of empirical data across a variety of domains (i.e., judgment and decision making, children's cognitive development, function learning, and perceptual categorization), the authors illustrate how Bayesian inference techniques allow toolbox models to be quantitatively specified, strategy sprawl to be contained, and toolbox models to be rigorously tested against competing theories. The authors demonstrate that their approach applies at the individual level but can also be generalized to the group level with hierarchical Bayesian procedures. The suggested Bayesian inference techniques represent a theoretical and methodological advancement for toolbox theories of cognition and behavior.},
  langid = {english},
  annotation = {Includes datasets from these 4 studies:

Jansen, B. R. J. \& van der Maas, H. L. J. (2002). The Development of Children's Rule Use on the Balance Scale Task.

Rieskamp, J., \& Otto, P. E. (2006). SSL: A theory of how people learn to select strategies

Lewandowsky, S., Kalish, M. \& Ngang, S. K. (2002). Simplified Learning in Complex Situations: Knowledge Partitioning in Function Learning

Yang, L. X. \& Lewandowsky, S. (2004).Knowledge Partitioning in Categorization: Constraints on Exemplar Models},
  file = {/Users/thomasgorman/Documents/Zotero_Markdown/scheibehenne_testing_2013-zotero.md;/Users/thomasgorman/Zotero/storage/E7PXA8JQ/Scheibehenne et al. - 2013 - Testing adaptive toolbox models A Bayesian hierar.pdf}
}

@techreport{schlegelmilchCognitiveCategoryLearningModel2020,
  type = {Preprint},
  title = {A {{Cognitive Category-Learning Model}} of {{Rule Abstraction}}, {{Attention Learning}}, and {{Contextual Modulation}}},
  author = {Schlegelmilch, Ren{\'e} and Wills, Andy and {von Helversen}, Bettina},
  year = {2020},
  month = jun,
  institution = {{PsyArXiv}},
  doi = {10.31234/osf.io/4jukw},
  urldate = {2020-06-17},
  abstract = {We introduce the CAL model (Category Abstraction Learning), a cognitive framework formally describing category learning built on similarity-based generalization, dissimilarity-based abstraction, two attention learning mechanisms, error-driven knowledge structuring and stimulus memorization. Our hypotheses draw on an array of empirical and theoretical insights connecting reinforcement and category learning, and working memory. The key novelty of the model is its explanation of how rules are learned from scratch based on three central assumptions. (1) Category rules emerge from two processes of stimulus generalization (similarity) and its direct inverse (category contrast) on independent dimensions. (2) Two attention mechanisms guide learning by focusing on rules, or on the contexts in which they produce errors. (3) Knowing about these contexts inhibits executing the rule, without correcting it, and consequently leads to applying partial rules in different situations. We show that the model decisively outperforms the established category-learning models ALCOVE (Kruschke, 1992), SUSTAIN (Love, Medin \& Gureckis, 2004) and ATRIUM (Erickson \& Kruschke, 1998) on data sets from benchmark studies, including cross-validations based on trial-wise eye-movements. Additionally, CAL's three free parameters, which measure abstraction, memorization and attention control, are related to abilities measured in working memory tasks in a theoretically meaningful way. We illustrate the model's explanatory scope by simulating several phenomena (peak shift, sample size, instruction effects, extrapolation), which were so far unexplained (or unexplained within a single model). We discuss CAL's relation to existing accounts, and its promise in understanding the role of attention control and working memory in category learning and related domains.},
  langid = {english},
  file = {/Users/thomasgorman/OneDrive - Indiana University/resources/Zotero/Schlegelmilch et al_2020_A Cognitive Category-Learning Model of Rule Abstraction, Attention Learning,.pdf}
}

@article{schmidtSchemaTheoryDiscrete1975,
  title = {A Schema Theory of Discrete Motor Skill Learning.},
  author = {Schmidt, Richard A.},
  year = {1975},
  journal = {Psychological Review},
  volume = {82},
  number = {4},
  pages = {225--260},
  issn = {0033-295X},
  doi = {10.1037/h0076770},
  urldate = {2019-01-16},
  langid = {english},
  file = {/Users/thomasgorman/Zotero/storage/GUU87G94/Schmidt - 1975 - A schema theory of discrete motor skill learning..pdf}
}

@article{schulzCommunicatingCompositionalPatterns2020,
  title = {Communicating {{Compositional Patterns}}},
  author = {Schulz, Eric and Quiroga, Francisco and Gershman, Samuel J.},
  year = {2020},
  month = aug,
  journal = {Open Mind},
  volume = {4},
  pages = {25--39},
  issn = {2470-2986},
  doi = {10.1162/opmi_a_00032},
  urldate = {2021-12-01},
  abstract = {How do people perceive and communicate structure? We investigate this question by letting participants play a communication game, where one player describes a pattern, and another player redraws it based on the description alone. We use this paradigm to compare two models of pattern description, one compositional (complex structures built out of simpler ones) and one noncompositional. We find that compositional patterns are communicated more effectively than noncompositional patterns, that a compositional model of pattern description predicts which patterns are harder to describe, and that this model can be used to evaluate participants' drawings, producing humanlike quality ratings. Our results suggest that natural language can tap into a compositionally structured pattern description language.},
  file = {/Users/thomasgorman/Documents/Zotero_Markdown/schulz_communicating_2020-zotero.md;/Users/thomasgorman/OneDrive - Indiana University/resources/Zotero/Schulz et al_2020_Communicating Compositional Patterns.pdf;/Users/thomasgorman/Zotero/storage/WDCVLW9Q/95939.html}
}

@article{schulzCompositionalInductiveBiases2017,
  title = {Compositional Inductive Biases in Function Learning},
  author = {Schulz, Eric and Tenenbaum, Joshua B. and Duvenaud, David and Speekenbrink, Maarten and Gershman, Samuel J.},
  year = {2017},
  month = dec,
  journal = {Cognitive Psychology},
  volume = {99},
  pages = {44--79},
  issn = {0010-0285},
  doi = {10.1016/j.cogpsych.2017.11.002},
  urldate = {2019-11-17},
  abstract = {How do people recognize and learn about complex functional structure? Taking inspiration from other areas of cognitive science, we propose that this is achieved by harnessing compositionality: complex structure is decomposed into simpler building blocks. We formalize this idea within the framework of Bayesian regression using a grammar over Gaussian process kernels, and compare this approach with other structure learning approaches. Participants consistently chose compositional (over non-compositional) extrapolations and interpolations of functions. Experiments designed to elicit priors over functional patterns revealed an inductive bias for compositional structure. Compositional functions were perceived as subjectively more predictable than non-compositional functions, and exhibited other signatures of predictability, such as enhanced memorability and reduced numerosity. Taken together, these results support the view that the human intuitive theory of functions is inherently compositional.},
  langid = {english},
  annotation = {not sure if correct github},
  file = {/Users/thomasgorman/Documents/Zotero_Markdown/schulz_compositional_2017-zotero.md;/Users/thomasgorman/OneDrive - Indiana University/resources/Zotero/Schulz et al_2017_Compositional inductive biases in function learning.pdf;/Users/thomasgorman/Zotero/storage/3NYYYT34/S0010028517301743.html}
}

@techreport{schulzLearningFunctionsActively2019,
  type = {Preprint},
  title = {Learning Functions Actively},
  author = {Schulz, Eric and Angela, Jones and Azzurra, Ruggeri and Bjorn, Meder},
  year = {2019},
  month = dec,
  institution = {{PsyArXiv}},
  doi = {10.31234/osf.io/wqf4u},
  urldate = {2022-05-13},
  abstract = {How do people actively learn functional rules, i.e. a mapping of continuous inputs onto a continuous output? We investigate information search behavior in a multiple-feature function learning task in which participants either actively select or passively receive observations. We find that participants benefit from actively selecting information, in particular in their function extrapolation performance. By introducing and comparing different models of active function learning, we find that participants are best described by a non-parametric function learning model that learns about both the underlying function and inputs that are likely to produce high outputs. These results enrich our understanding of active function learning in complex domains. Keywords: active learning; function learning; self-directed learning; search},
  langid = {english},
  file = {/Users/thomasgorman/Documents/Zotero_Markdown/schulz_learning_2019-zotero.md;/Users/thomasgorman/OneDrive - Indiana University/resources/Zotero/Schulz_2019_Learning functions actively.pdf}
}

@inproceedings{schulzProbingCompositionalityIntuitive2016,
  title = {Probing the {{Compositionality}} of {{Intuitive Functions}}},
  booktitle = {Advances in {{Neural Information Processing Systems}}},
  author = {Schulz, Eric and Tenenbaum, Josh and Duvenaud, David K and Speekenbrink, Maarten and Gershman, Samuel J},
  year = {2016},
  volume = {29},
  publisher = {{Curran Associates, Inc.}},
  urldate = {2022-06-30},
  abstract = {How do people learn about complex functional structure? Taking inspiration from other areas of cognitive science, we propose that this is accomplished by harnessing compositionality: complex structure is decomposed into simpler building blocks. We formalize this idea within the framework of Bayesian regression using a grammar over Gaussian process kernels. We show that participants prefer compositional over non-compositional function extrapolations, that samples from the human prior over functions are best described by a compositional model, and that people perceive compositional functions as more predictable than their non-compositional but otherwise similar counterparts. We argue that the compositional nature of intuitive functions is consistent with broad principles of human cognition.},
  file = {/Users/thomasgorman/Documents/Zotero_Markdown/schulz_probing_2016-zotero.md;/Users/thomasgorman/Zotero/storage/3QBZQWY4/Schulz et al. - 2016 - Probing the Compositionality of Intuitive Function.pdf}
}

@techreport{schulzPuttingBanditsContext2016,
  type = {Preprint},
  title = {Putting Bandits into Context: {{How}} Function Learning Supports Decision Making},
  shorttitle = {Putting Bandits into Context},
  author = {Schulz, Eric and Konstantinidis, Emmanouil and Speekenbrink, Maarten},
  year = {2016},
  month = oct,
  institution = {{Animal Behavior and Cognition}},
  doi = {10.1101/081091},
  urldate = {2020-05-07},
  abstract = {We introduce the contextual multi-armed bandit task as a framework to investigate learning and decision making in uncertain environments. In this novel paradigm, participants repeatedly choose between multiple options in order to maximise their rewards. The options are described by a number of contextual features which are predictive of the rewards through initially unknown functions. From their experience with choosing options and observing the consequences of their decisions, participants can learn about the functional relation between contexts and rewards and improve their decision strategy over time. In three experiments, we explore participants' behaviour in such learning environments. We predict participants' behaviour by context-blind (mean-tracking, Kalman filter) and contextual (Gaussian process and linear regression) learning approaches combined with different choice strategies. Participants are mostly able to learn about the context-reward functions and their behaviour is best described by a Gaussian process learning strategy which generalizes previous experience to similar instances. In a relatively simple task with binary features, they seem to combine this learning with a ``probability of improvement'' decision strategy which focuses on alternatives that are expected to lead to an improvement upon a current favourite option. In a task with continuous features that are linearly related to the rewards, participants seem to more explicitly balance exploration and exploitation. Finally, in a difficult learning environment where the relation between features and rewards is non-linear, some participants are again well-described by a Gaussian process learning strategy, whereas others revert to context-blind strategies.},
  langid = {english},
  keywords = {Bandit,Bayesian Search,Complex Bandit,Function Learning,Gaussian process,Search Learning,Search model,Similarity in Search},
  file = {/Users/thomasgorman/Documents/Zotero_Markdown/schulz_putting_2016-zotero.md;/Users/thomasgorman/Zotero/storage/P2Y3ZZV4/Schulz et al. - 2016 - Putting bandits into context How function learnin.pdf}
}

@article{schulzTutorialGaussianProcess2018,
  title = {A Tutorial on {{Gaussian}} Process Regression: {{Modelling}}, Exploring, and Exploiting Functions},
  shorttitle = {A Tutorial on {{Gaussian}} Process Regression},
  author = {Schulz, Eric and Speekenbrink, Maarten and Krause, Andreas},
  year = {2018},
  month = aug,
  journal = {Journal of Mathematical Psychology},
  volume = {85},
  pages = {1--16},
  issn = {00222496},
  doi = {10.1016/j.jmp.2018.03.001},
  urldate = {2023-07-02},
  abstract = {This tutorial introduces the reader to Gaussian process regression as an expressive tool to model, actively explore and exploit unknown functions. Gaussian process regression is a powerful, non-parametric Bayesian approach towards regression problems that can be utilized in exploration and exploitation scenarios. This tutorial aims to provide an accessible introduction to these techniques. We will introduce Gaussian processes which generate distributions over functions used for Bayesian non-parametric regression, and demonstrate their use in applications and didactic examples including simple regression problems, a demonstration of kernel-encoded prior assumptions and compositions, a pure exploration scenario within an optimal design framework, and a bandit-like exploration\textendash exploitation scenario where the goal is to recommend movies. Beyond that, we describe a situation modelling risk-averse exploration in which an additional constraint (not to sample below a certain threshold) needs to be accounted for. Lastly, we summarize recent psychological experiments utilizing Gaussian processes. Software and literature pointers are also provided.},
  langid = {english},
  file = {/Users/thomasgorman/Library/CloudStorage/OneDrive-IndianaUniversity/Resources/Zotero/Schulz et al_2018_A tutorial on Gaussian process regression.pdf}
}

@phdthesis{schulzUnifyingTheoryGeneralization2017,
  title = {Towards a Unifying Theory of Generalization},
  author = {Schulz, Eric},
  year = {2017},
  urldate = {2019-12-11},
  abstract = {How do humans generalize from observed to unobserved data? How does generalization support inference, prediction, and decision making? I propose that a big part of human generalization can be explained by a powerful mechanism of function learning. I put forward and assess Gaussian Process regression as a model of human function learning that can unify several psychological theories of generalization. Across 14 experiments and using extensive computational modeling, I show that this model generates testable predictions about human preferences over different levels of complexity, provides a window into compositional inductive biases, and \textendash combined with an optimistic yet efficient sampling strategy\textendash{} guides human decision making through complex spaces. Chapters 1 and 2 propose that, from a psychological and mathematical perspective, function learning and generalization are close kin. Chapter 3 derives and tests theoretical predictionsof participants' preferences over differently complex functions. Chapter 4 develops a compositional theory of generalization and extensively probes this theory using 8 experimental paradigms.During the second half of the thesis, I investigate how function learning guides decision making in complex decision making tasks. In particular, Chapter 5 will look at how people search for rewards in various grid worlds where a spatial correlation of rewards provides a context supporting generalization and decision making. Chapter 6 gauges human behavior in contextual multi-armed bandit problems where a function maps features onto expectedrewards. In both Chapter 5 and Chapter 6, I find that the vast majority of subjects are best predicted by a Gaussian Process function learning model combined with an upper confidence bound sampling strategy. Chapter 7 will formally assess the adaptiveness of human generalization in complex decision making tasks using mismatched Bayesian optimization simulations and finds that the empirically observed phenomenon of undergeneralization might rather be a feature than a bug of human behavior. Finally, I summarize the empirical and theoretical lessons learned and lay out a road-map for future research on generalization in Chapter 8. 1 Introduction 1 1.1 The quest for a universal law . . . . . . . . . . . . . . . . . . . . . . . . . 2 1.2 Generalization as function learning . . . . . . . . . . . . . . . . . . . . . . 3 1.3 Overview . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 5 2 From generalization to function learning 7 2.1 Shepard's rule of generalization . . . . . . . . . . . . . . . . . . . . . . . . 8 2.2 Carroll's idea to study function learning . . . . . . . . . . . . . . . . . . . . 9 2.3 Rule-based accounts of function learning and generalization . . . . . . . . . 13 2.4 Similarity-based accounts of function learning . . . . . . . . . . . . . . . . 15 2.5 Hybrid accounts of function learning . . . . . . . . . . . . . . . . . . . . . 18 2.6 Function learning everywhere? . . . . . . . . . . . . . . . . . . . . . . . . 19 2.7 Discussion . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 22 3 From function learning to generalization 24 3.1 Motivation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 25 3.2 Linear regression: the weight space view . . . . . . . . . . . . . . . . . . . 27 3.3 The function space view . . . . . . . . . . . . . . . . . . . . . . . . . . . 32 3.4 Encoding smoothness . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 40 3.5 Composing kernels . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 42 3.6 Exploration-Exploitation . . . . . . . . . . . . . . . . . . . . . . . . . . . 46 i 3.7 Past and present research utilizing Gaussian Process regression . . . . . . . . 49 3.8 The current proposal . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 51 4 From theory to behavior 53 4.1 Better noisy than complex? . . . . . . . . . . . . . . . . . . . . . . . . . . 54 4.2 Gaussian Process learning curves . . . . . . . . . . . . . . . . . . . . . . . 55 4.3 Experiment 1: Perceived predictability of functions . . . . . . . . . . . . . . 59 4.4 Discussion . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 65 5 A compositional theory of generalization 68 5.1 Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 69 5.2 Compositionality as a core principle of generalization . . . . . . . . . . . . . 70 5.3 Generalization and structure learning with Gaussian processes . . . . . . . . 72 5.4 Experiment 2a: Pattern completions of compositional functions . . . . . . . 78 5.5 Experiment 2b: Pattern completions of non-compositional functions . . . . 81 5.6 Markov chain Monte Carlo with people . . . . . . . . . . . . . . . . . . . 84 5.7 Experiment 3a: Compositional ground truth . . . . . . . . . . . . . . . . . 85 5.8 Experiment 3b: Real-world functions . . . . . . . . . . . . . . . . . . . . . 87 5.9 Experiment 4: Manual pattern completion . . . . . . . . . . . . . . . . . . 90 5.10 Generating comparison functions . . . . . . . . . . . . . . . . . . . . . . . 94 5.11 Experiment 5: Compositional predictability . . . . . . . . . . . . . . . . . . 96 5.12 Experiment 6: Traditional function learning paradigm . . . . . . . . . . . . 102 5.13 Experiment 7: Assessing numerosity . . . . . . . . . . . . . . . . . . . . . 106 5.14 Experiment 8: Change detection with functions . . . . . . . . . . . . . . . 111 5.15 Experiment 9: Compositional chunking in short-term memory . . . . . . . . 117 5.16 Discussion . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 123 6 Exploration and generalization in vast spaces 127 6.1 Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 128 6.2 Spatially correlated multi-armed bandits . . . . . . . . . . . . . . . . . . . 131 6.3 Models of learning in complex spaces . . . . . . . . . . . . . . . . . . . . . 132 6.4 Adaptive sampling strategies . . . . . . . . . . . . . . . . . . . . . . . . . 135 6.5 Experiment 10: Univariate function exploration-exploitation . . . . . . . . . 139 6.6 Experiment 11: Bivariate function exploration-exploitation . . . . . . . . . . 149 6.7 Discussion . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 156 7 Contextual Multi-Armed Bandits 159 7.1 Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 160 7.2 Contextual multi-armed bandits . . . . . . . . . . . . . . . . . . . . . . . 161 7.3 General CMAB task . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 164 7.4 Models of learning and decision making in CMAB-tasks . . . . . . . . . . . 165 7.5 Experiment 12: Binary features . . . . . . . . . . . . . . . . . . . . . . . . 170 7.6 Experiment 13: Continuous-linear features . . . . . . . . . . . . . . . . . . 177 7.7 Experiment 14: Continuous-non-linear features . . . . . . . . . . . . . . . . 182 7.8 Inter-experimental model comparison . . . . . . . . . . . . . . . . . . . . 187 7.9 Discussion . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 189 8 From behavior to theory 193 8.1 Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 194 8.2 Mismatched Bayesian optimization . . . . . . . . . . . . . . . . . . . . . . 195 8.3 Simulation 1: Simple mismatch . . . . . . . . . . . . . . . . . . . . . . . . 202 8.4 Simulation 2: Regret in higher dimensions . . . . . . . . . . . . . . . . . . 204 8.5 Simulation 3: Optimizing hyper-parameters . . . . . . . . . . . . . . . . . 206 8.6 Simulation 4: The effect of {$\lambda$} on regret . . . . . . . . . . . . . . . . . . . . 208 8.7 Discussion . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 210 9 Conclusion 213 9.1 Lessons learned . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 214 9.2 Open questions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 219 9.3 Generalizing generalization? . . . . . . . . . . . . . . . . . . . . . . . . . 222 9.4 Conclusion . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 224 Appendix A Appendix 226 A.1 Forecastibility . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 226 A.2 Wavelet transform similarity measure . . . . . . . . . . . . . . . . . . . . . 227 A.3 Model details for spatially correlated mulit-armed bandit experiments . . . . 228 A.4 Model recovery . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 229 A.5 Parameter Recovery . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 231 A.6 Model details for contextual mulit-armed bandit experiments . . . . . . . . 234 A.7 Sublinear regret of GP-UCB . . . . . . . . . . . . . . . . . . . . . . . . . 236 A.8 Regret of a mixture kernel . . . . . . . . . . . . . . . . . . . . . . . . . . . 237},
  langid = {english},
  file = {/Users/thomasgorman/Documents/Zotero_Markdown/schulz_towards_2017-zotero.md;/Users/thomasgorman/Zotero/storage/IZNZ2CV5/Schulz - Towards a unifying theory of generalization.pdf}
}

@article{schweenPlanbasedGeneralizationShapes2018,
  title = {Plan-Based Generalization Shapes Local Implicit Adaptation to Opposing Visuomotor Transformations},
  author = {Schween, Raphael and Taylor, Jordan A. and Hegele, Mathias},
  year = {2018},
  month = dec,
  journal = {Journal of Neurophysiology},
  volume = {120},
  number = {6},
  pages = {2775--2787},
  issn = {0022-3077, 1522-1598},
  doi = {10.1152/jn.00451.2018},
  urldate = {2021-07-06},
  abstract = {The human ability to use different tools demonstrates our capability of forming and maintaining multiple, context-specific motor memories. Experimentally, this has been investigated in dual adaptation, where participants adjust their reaching movements to opposing visuomotor transformations. Adaptation in these paradigms occurs by distinct processes, such as strategies for each transformation or the implicit acquisition of distinct visuomotor mappings. Although distinct, transformation-dependent aftereffects have been interpreted as support for the latter, they could reflect adaptation of a single visuomotor map, which is locally adjusted in different regions of the workspace. Indeed, recent studies suggest that explicit aiming strategies direct where in the workspace implicit adaptation occurs, thus potentially serving as a cue to enable dual adaptation. Disentangling these possibilities is critical to understanding how humans acquire and maintain motor memories for different skills and tools. We therefore investigated generalization of explicit and implicit adaptation to untrained movement directions after participants practiced two opposing cursor rotations, which were associated with the visual display being presented in the left or right half of the screen. Whereas participants learned to compensate for opposing rotations by explicit strategies specific to this visual workspace cue, aftereffects were not cue sensitive. Instead, aftereffects displayed bimodal generalization patterns that appeared to reflect locally limited learning of both transformations. By varying target arrangements and instructions, we show that these patterns are consistent with implicit adaptation that generalizes locally around movement plans associated with opposing visuomotor transformations. Our findings show that strategies can shape implicit adaptation in a complex manner.             NEW \& NOTEWORTHY Visuomotor dual adaptation experiments have identified contextual cues that enable learning of separate visuomotor mappings, but the underlying representations of learning are unclear. We report that visual workspace separation as a contextual cue enables the compensation of opposing cursor rotations by a combination of explicit and implicit processes: Learners developed context-dependent explicit aiming strategies, whereas an implicit visuomotor map represented dual adaptation independent from arbitrary context cues by local adaptation around the explicit movement plan.},
  langid = {english},
  file = {/Users/thomasgorman/OneDrive - Indiana University/resources/Zotero/Schween et al_2018_Plan-based generalization shapes local implicit adaptation to opposing.pdf}
}

@article{segertMaximumEntropyFunction,
  title = {Maximum {{Entropy Function Learning}}},
  author = {Segert, Simon and Cohen, Jonathan},
  pages = {8},
  langid = {english},
  file = {/Users/thomasgorman/Documents/Zotero_Markdown/segert_maximum_nodate-zotero.md;/Users/thomasgorman/OneDrive - Indiana University/resources/Zotero/Segert_Cohen_Maximum Entropy Function Learning.pdf}
}

@article{segertSelfSupervisedFrameworkFunction2021,
  title = {A {{Self-Supervised Framework}} for {{Function Learning}} and {{Extrapolation}}},
  author = {Segert, Simon N. and Cohen, Jonathan D.},
  year = {2021},
  month = jun,
  journal = {arXiv:2106.07369 [cs, q-bio]},
  eprint = {2106.07369},
  primaryclass = {cs, q-bio},
  urldate = {2021-10-09},
  abstract = {Understanding how agents learn to generalize -- and, in particular, to extrapolate -- in high-dimensional, naturalistic environments remains a challenge for both machine learning and the study of biological agents. One approach to this has been the use of function learning paradigms, which allow peoples' empirical patterns of generalization for smooth scalar functions to be described precisely. However, to date, such work has not succeeded in identifying mechanisms that acquire the kinds of general purpose representations over which function learning can operate to exhibit the patterns of generalization observed in human empirical studies. Here, we present a framework for how a learner may acquire such representations, that then support generalization -- and extrapolation in particular -- in a few-shot fashion. Taking inspiration from a classic theory of visual processing, we construct a self-supervised encoder that implements the basic inductive bias of invariance under topological distortions. We show the resulting representations outperform those from other models for unsupervised time series learning in several downstream function learning tasks, including extrapolation.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Machine Learning,python\_code,Quantitative Biology - Neurons and Cognition},
  file = {/Users/thomasgorman/Documents/Zotero_Markdown/segertSelfSupervisedFrameworkFunction2021-zotero.md;/Users/thomasgorman/OneDrive - Indiana University/resources/Zotero/Segert_Cohen_2021_A Self-Supervised Framework for Function Learning and Extrapolation.pdf;/Users/thomasgorman/Zotero/storage/2N33EXC9/2106.html}
}

@article{seowDecaybasedAccountLearning2021,
  title = {A Decay-Based Account of Learning and Adaptation in Complex Skills},
  author = {Seow, Roderick Yang Terng and Betts, Shawn A. and Anderson, John R.},
  year = {2021},
  month = nov,
  journal = {Journal of Experimental Psychology: Learning, Memory, and Cognition},
  publisher = {{American Psychological Association}},
  issn = {0278-7393},
  doi = {10.1037/xlm0001071},
  urldate = {2021-12-02},
  abstract = {How do humans adapt to parametric changes in a task without having to learn a new skill from scratch? Many studies of memory and sensorimotor adaptation have proposed theories that incorporate a decay on prior events, which leads the agent to eventually forget old experiences. This study investigates if a similar decay mechanism can account for human adaptation in complex skills that require the simultaneous integration of cognitive, motor, and perceptual processes. In 2 experiments, subjects learned to play a novel racing video game while adapting to parametric changes in the physics of the game's controls. Human learning and performance were modeled using the ACT\textendash R cognitive architecture, which has been used successfully to model learning and fluency across a wide range of skills in prior research. Anderson et al. (2019) introduced the Controller module, a new component of the architecture that learns the setting of control parameters for actions and allows the agent to execute the rapid and precise actions that are necessary for good performance on complex tasks. Model simulations support including a moderate time\textendash based decay on the weight of the experiences that the Controller uses. This is implemented in the Controller module by discounting the influence of older observations which helps the agent to focus on recent experiences that better reflect the current relationship between different settings of a control parameter and the rate of payoff from using that setting. (PsycInfo Database Record (c) 2021 APA, all rights reserved)},
  keywords = {ACT-R,adaptation,Adaptation,Cognitive Complexity,decay,Forgetting,Learning Ability,modeling,Psychometrics,Simulation,skill acquisition,Skill Learning},
  file = {/Users/thomasgorman/Documents/Zotero_Markdown/seowDecaybasedAccountLearning2021-zotero.md;/Users/thomasgorman/OneDrive - Indiana University/resources/Zotero/Seow et al_2021_A decay-based account of learning and adaptation in complex skills.pdf}
}

@article{sewellCombiningErrordrivenModels2019,
  title = {Combining Error-Driven Models of Associative Learning with Evidence Accumulation Models of Decision-Making},
  author = {Sewell, David K. and Jach, Hayley K. and Boag, Russell J. and Van Heer, Christina A.},
  year = {2019},
  month = jun,
  journal = {Psychonomic Bulletin \& Review},
  volume = {26},
  number = {3},
  pages = {868--893},
  issn = {1069-9384, 1531-5320},
  doi = {10.3758/s13423-019-01570-4},
  urldate = {2020-09-10},
  abstract = {As people learn a new skill, performance changes along two fundamental dimensions: Responses become progressively faster and more accurate. In cognitive psychology, these facets of improvement have typically been addressed by separate classes of theories. Reductions in response time (RT) have usually been addressed by theories of skill acquisition, whereas increases in accuracy have been explained by associative learning theories. To date, relatively little work has examined how changes in RT relate to changes in response accuracy, and whether these changes can be accounted for quantitatively within a single theoretical framework. The current work examines joint changes in accuracy and RT in a probabilistic category learning task. We report a model-based analysis of changes in the shapes of RT distributions for different category responses at the level of individual stimuli over the course of learning. We show that changes in performance are determined solely by changes in the quality of information entering the decision process. We then develop a new model that combines an associative learning front end with a sequential sampling model of the decision process, showing that the model provides a good account of all aspects of the learning data. We conclude by discussing potential extensions of the model and future directions for theoretical development that are opened up by our findings.},
  langid = {english},
  file = {/Users/thomasgorman/Zotero/storage/WFKVRS88/Sewell et al. - 2019 - Combining error-driven models of associative learn.pdf}
}

@article{sewellRestructuringPartitionedKnowledge2011,
  title = {Restructuring Partitioned Knowledge: {{The}} Role of Recoordination in Category Learning},
  shorttitle = {Restructuring Partitioned Knowledge},
  author = {Sewell, David K. and Lewandowsky, Stephan},
  year = {2011},
  month = mar,
  journal = {Cognitive Psychology},
  volume = {62},
  number = {2},
  pages = {81--122},
  issn = {00100285},
  doi = {10.1016/j.cogpsych.2010.09.003},
  urldate = {2021-12-11},
  abstract = {Knowledge restructuring refers to changes in the strategy with which people solve a given problem. Two types of knowledge restructuring are supported by existing category learning models. The first is a relearning process, which involves incremental updating of knowledge as learning progresses. The second is a recoordination process, which involves novel changes in the way existing knowledge is applied to the task. Whereas relearning is supported by both single- and multiple-module models of category learning, only multiple-module models support recoordination. To date, only relearning has been directly supported empirically. We report two category learning experiments that provide direct evidence of recoordination. People can fluidly alternate between different categorization strategies, and moreover, can reinstate an old strategy even after prolonged use of an alternative. The knowledge restructuring data are not well fit by a single-module model (ALCOVE). By contrast, a multiple-module model (ATRIUM) quantitatively accounts for recoordination. Low-level changes in the distribution of dimensional attention are shown to subsequently affect how ATRIUM coordinates its modular knowledge. We argue that learning about complex tasks occurs at the level of the partial knowledge elements used to generate a response strategy.},
  langid = {english},
  file = {/Users/thomasgorman/OneDrive - Indiana University/resources/Zotero/Sewell_Lewandowsky_2011_Restructuring partitioned knowledge.pdf}
}

@inproceedings{shepardConnectionistImplementationTheory1991,
  title = {Connectionist {{Implementation}} of a {{Theory}} of {{Generalization}}},
  booktitle = {Advances in {{Neural Information Processing Systems}}},
  author = {Shepard, Roger and Kannappan, Sheila},
  year = {1991},
  volume = {3},
  publisher = {{Morgan-Kaufmann}},
  urldate = {2021-09-01},
  file = {/Users/thomasgorman/OneDrive - Indiana University/resources/Zotero/Shepard_Kannappan_1991_Connectionist Implementation of a Theory of Generalization.pdf}
}

@article{shepardUniversalLawGeneralization1987,
  title = {Toward a Universal Law of Generalization for Psychological Science},
  author = {Shepard, R.N.},
  year = {1987},
  journal = {Science},
  volume = {237},
  number = {4820},
  pages = {1317--1323},
  file = {/Users/thomasgorman/Zotero/storage/Y3QMSP9B/Shepard - 1987 - Toward a universal law of generalization for psych.pdf}
}

@article{shiffrinSevenMinusTwo1994,
  title = {Seven plus or Minus Two: {{A}} Commentary on Capacity Limitations},
  author = {Shiffrin, R.M. and Nosofsky, Robert M.},
  year = {1994},
  journal = {Psychological Review},
  volume = {101},
  number = {2Journal Article Indiana U, Dept of Psychology, Bloomington, USA. Apr English},
  pages = {357--361}
}

@article{shinSimilarityscalingStudiesDotpattern1992,
  title = {Similarity-Scaling Studies of Dot-Pattern Classification and Recognition},
  author = {Shin, H. and Nosofsky, Robert M},
  year = {1992},
  journal = {Journal of Experimental Psychology. General},
  volume = {121},
  number = {3},
  pages = {278},
  urldate = {2020-07-18},
  file = {/Users/thomasgorman/Zotero/storage/KIQKPZVM/Nosofsky and Shin - 1992 - Similarity-scaling studies of dot-pattern classifi.pdf}
}

@article{shinyaPitchingFormDetermines2017,
  title = {Pitching Form Determines Probabilistic Structure of Errors in Pitch Location},
  author = {Shinya, Masahiro and Tsuchiya, Shinji and Yamada, Yousuke and Nakazawa, Kimitaka and Kudo, Kazutoshi and Oda, Shingo},
  year = {2017},
  month = nov,
  journal = {Journal of Sports Sciences},
  volume = {35},
  number = {21},
  pages = {2142--2147},
  issn = {0264-0414, 1466-447X},
  doi = {10.1080/02640414.2016.1258484},
  urldate = {2021-08-12},
  abstract = {According to recent motor control studies, it is important to know probabilistic structure of his/her own motor errors to choose an optimal motor plan (i.e., where you aim at) to maximise the expected gain. In this study, we questioned if pitching form determines the probabilistic structure of pitching errors in baseball pitchers. Eighteen collegiate baseball pitchers with various pitching forms including right- and left-handed overarm, sidearm and underarm throwers threw 100 pitches aiming at a target located 90 cm above the ground. Two dimensional distribution of pitch location was fitted by using bivariate normal distribution and 95\% confidence ellipse was calculated. In order to quantify the pitching form, the direction of the throwing arm trajectory in frontal plane was calculated. The direction of the long axis was dependent on each participant's pitching form (e.g., right overarm pitchers pitched along a right-up\textendash left-down ellipse and left overarm pitchers pitched along a left-up\textendash right-down ellipse). This was confirmed by circular correlation analysis (P = 0.98). These results suggest that different mechanisms, potentially errors in pitching mechanics and errors in ball release timing, might contribute to errors along the long axis and those along the short axis.},
  langid = {english},
  file = {/Users/thomasgorman/OneDrive - Indiana University/resources/Zotero/Shinya et al_2017_Pitching form determines probabilistic structure of errors in pitch location.pdf}
}

@inproceedings{slomanSocialInterpolationModel2021a,
  title = {A {{Social Interpolation}} Model of Group Problem-Solving},
  author = {Sloman, Sabina J. and Goldstone, Robert L. and Gonzalez, Cleotilde},
  year = {2021},
  urldate = {2021-11-08},
  abstract = {How do people use information from others to solve complex problems? Prior work has addressed this question by placing people in social learning situations where the problems they were asked to solve required varying degrees of exploration. This past work uncovered important interactions between groups' connectivity and the problem's complexity: the advantage of less connected networks over more connected networks increased as exploration was increasingly required for optimally solving the problem at hand. We propose the Social Interpolation Model (SIM), an agent-based model to explore the cognitive mechanisms that can underlie exploratory behavior in groups. Through results from simulation experiments, we conclude that ``exploration'' may not be a single cognitive property, but rather the emergent result of three distinct behavioral and cognitive mechanisms, namely 1) breadth of generalization, 2) quality of prior expectation and 3) relative valuation of self-obtained information. We formalize these mechanisms in the SIM, and explore their effects on group dynamics and success at solving different kinds of problems. Our main finding is that broad generalization and high quality of prior expectation facilitate successful search in environments where exploration is important, and hinder successful search in environments where exploitation alone is sufficient.},
  file = {/Users/thomasgorman/Documents/Zotero_Markdown/sloman_social_2021-1-zotero.md;/Users/thomasgorman/OneDrive - Indiana University/resources/Zotero/Sloman et al_A Social Interpolation model of group problem-solving.pdf}
}

@article{smithAssessingIndividualDifferences2008,
  title = {Assessing Individual Differences in Categorical Data},
  author = {Smith, Jared B. and Batchelder, William H.},
  year = {2008},
  month = aug,
  journal = {Psychonomic Bulletin \& Review},
  volume = {15},
  number = {4},
  pages = {713--731},
  issn = {1069-9384, 1531-5320},
  doi = {10.3758/PBR.15.4.713},
  urldate = {2020-04-17},
  abstract = {In cognitive modeling, data are often categorical observations taken over participants and items. Usually subsets of these observations are pooled and analyzed by a cognitive model assuming the category counts come from a multinomial distribution with the same model parameters underlying all observations. It is well known that if there are individual differences in participants and/or items, a model analysis of the pooled data may be quite misleading, and in such cases it may be appropriate to augment the cognitive model with parametric ran- dom effects assumptions. On the other hand, if random effects are incorporated into a cognitive model that is not needed, the resulting model may be more flexible than the multinomial model that assumes no heterogeneity, and this may lead to overfitting. This article presents Monte Carlo statistical tests for directly detecting individual participant and/or item heterogeneity that depend only on the data structure itself. These tests are based on the fact that heterogeneity in participants and/or items results in overdispersion of certain category count statistics. It is argued that the methods developed in the article should be applied to any set of participant},
  langid = {english},
  file = {/Users/thomasgorman/OneDrive - Indiana University/resources/Zotero/Smith_Batchelder_2008_Assessing individual differences in categorical data.pdf}
}

@article{smithComputationalAccountContingency,
  title = {A Computational Account of Contingency Learning},
  author = {Smith, Bradley C},
  pages = {161},
  langid = {english},
  file = {/Users/thomasgorman/OneDrive - Indiana University/resources/Zotero/Smith_A computational account of contingency learning.pdf}
}

@article{soderstromLearningPerformanceIntegrative2015,
  title = {Learning versus Performance: {{An}} Integrative Review},
  shorttitle = {Learning versus Performance},
  author = {Soderstrom, Nicholas C. and Bjork, Robert A.},
  year = {2015},
  journal = {Perspectives on Psychological Science},
  volume = {10},
  number = {2},
  pages = {176--199},
  urldate = {2017-09-07},
  keywords = {Benefit of Variability,Category Learning,Motor,Review paper,Theoretical,Variability},
  file = {/Users/thomasgorman/Zotero/storage/4VY9F39T/Soderstrom and Bjork - 2015 - Learning versus performance An integrative review.pdf}
}

@article{souzaCategoricalDistinctivenessConstrains2021,
  title = {Categorical Distinctiveness Constrains the Labeling Benefit in Visual Working Memory},
  author = {Souza, Alessandra S. and Overkott, Clara and Matyja, Marta},
  year = {2021},
  month = aug,
  journal = {Journal of Memory and Language},
  volume = {119},
  pages = {104242},
  issn = {0749-596X},
  doi = {10.1016/j.jml.2021.104242},
  urldate = {2021-08-18},
  abstract = {Describing our visual experiences improves their retention in visual working memory, yielding a labeling benefit. Labels vary, however, in categorical distinctiveness: they can be applied broadly or narrowly to categorize stimuli. Does categorical distinctiveness constrain the labeling benefit? Here, we varied the number of terms used to label continuously varying colors (Experiment 1) and shapes (Experiment 2). Participants memorized four items, and later recalled them using a continuous color or shape wheel. During study, participants articulated ``bababa'' or labeled the items with two, four, or their preferred term. Recall error decreased with increases in the number of labels. Mixture modeling showed that labeling increased the probability of recall. Memory precision, however, varied with categorical distinctiveness: broad labels reduced precision, whereas categorically distinct labels increased precision compared to no-labels. In sum, in-the-moment labeling activates categorical knowledge that facilitates the storage of visual details. Data and analysis scripts are available at: https://osf.io/mqg4k/},
  langid = {english},
  keywords = {Categorization,Color,Distinctiveness,Labeling,Shapes,Visual working memory},
  file = {/Users/thomasgorman/OneDrive - Indiana University/resources/Zotero/Souza et al_2021_Categorical distinctiveness constrains the labeling benefit in visual working.pdf;/Users/thomasgorman/Zotero/storage/ACRWF7WD/S0749596X21000255.html}
}

@article{speekenbrinkLearningChangingEnvironment2010,
  title = {Learning in a {{Changing Environment}}},
  author = {Speekenbrink, Maarten and Shanks, David R.},
  year = {2010},
  month = may,
  journal = {Journal of Experimental Psychology: General},
  volume = {139},
  number = {2},
  pages = {266--298},
  publisher = {{Journal of Experimental Psychology: General}},
  issn = {0096-3445},
  urldate = {2022-03-08},
  abstract = {Multiple cue probability learning studies have typically focused on stationary environments. We present 3 experiments investigating learning in changing environments. A fine-grained analysis of the learning dynamics shows that participants were responsive to both abrupt and gradual changes in cue-outcome relations. We found no evidence that participants adapted to these types of change in qualitatively different ways. Also, in contrast to earlier claims that these tasks are learned implicitly, participants showed good insight into what they learned. By fitting formal learning models, we investigated whether participants learned global functional relationships or made localized predictions from similar experienced exemplars. Both a local (the associative learning model) and a global learning model (the Bayesian linear filter) fitted the data of the first 2 experiments. However, the results of Experiment 3, which was specifically designed to discriminate between local and global learning models, provided more support for global learning models. Finally, we present a novel model to account for the cue competition effects found in previous research and displayed by some of our participants. (Contains 10 figures, 5 tables and, 7 footnotes.)},
  keywords = {Adjustment (to Environment),Associative Learning,Cues,Difficulty Level,Learning Processes,Models,Prediction,Probability,Rewards,Stimuli},
  file = {/Users/thomasgorman/Documents/Zotero_Markdown/speekenbrinkLearningChangingEnvironment2010a-zotero.md;/Users/thomasgorman/Downloads/speekenbrinkLearningChangingEnvironment2010a-zotero.md;/Users/thomasgorman/Downloads/speekenbrinkLearningChangingEnvironment2010a.md;/Users/thomasgorman/OneDrive - Indiana University/resources/Zotero/Speekenbrink_Shanks_2010_Learning in a Changing Environment.pdf}
}

@article{speekenbrinkLearningChangingEnvironment2010a,
  title = {Learning in a Changing Environment.},
  author = {Speekenbrink, Maarten and Shanks, David R.},
  year = {2010},
  journal = {Journal of Experimental Psychology: General},
  volume = {139},
  number = {2},
  pages = {266--298},
  issn = {1939-2222, 0096-3445},
  doi = {10.1037/a0018620},
  urldate = {2020-05-07},
  abstract = {Multiple cue probability learning studies have typically focused on stationary environments. We present three experiments investigating learning in changing environments. A fine-grained analysis of the learning dynamics shows that participants were responsive to both abrupt and gradual changes in cue-outcome relations. We found no evidence that participants adapted to these types of change in qualitatively different ways. Also, in contrast to earlier claims that these tasks are learned implicitly, participants showed good insight into what they learned. By fitting formal learning models, we investigated whether participants learned global functional relationships or made localized predictions from similar experienced exemplars. Both a local (the Associative Learning Model) and a global learning model (the novel Bayesian Linear Filter) fitted the data of the first two experiments. However, the results of Experiment 3, which was specifically designed to discriminate between local and global learning models, provided more support for global learning models. Finally, we present a novel model to account for the cue competition effects found in previous research and displayed by some of our participants.},
  langid = {english},
  keywords = {Cue Task,Global vs. Local Search},
  file = {/Users/thomasgorman/Documents/Zotero_Markdown/speekenbrinkLearningChangingEnvironment2010-zotero.md;/Users/thomasgorman/Zotero/storage/485X99II/Speekenbrink and Shanks - 2010 - Learning in a changing environment..pdf}
}

@article{speekenbrinkTutorialParticleFilters2016,
  title = {Tutorial on Particle Filters},
  author = {Speekenbrink, Maarten},
  year = {2016},
  month = may,
  publisher = {{OSF}},
  urldate = {2022-03-08},
  abstract = {This tutorial aims to provide an accessible introduction to particle  lters,and sequential Monte Carlo (SMC) more generally.  These techniques allowfor  Bayesian  inference  in  complex  dynamic  state-space  models  and  havebecome increasingly popular over the last decades. The basic building blocksof SMC \{ sequential importance sampling and resampling \{ are discussedin  detail  with  illustrative  examples.   A   nal  example  presents  a  particle lter for estimating time-varying learning rates in a probabilistic categorylearning task.Keywords:Particle  lter, Sequential Monte Carlo, State-space model,Sequential Bayesian inference\vphantom{\}\}}},
  langid = {english},
  file = {/Users/thomasgorman/Documents/Zotero_Markdown/speekenbrink_tutorial_2016-zotero.md;/Users/thomasgorman/OneDrive - Indiana University/resources/Zotero/Speekenbrink_2016_Tutorial on particle filters.pdf}
}

@techreport{spicerHowPeoplePredict2022,
  type = {Preprint},
  title = {How Do People Predict a Random Walk? {{Lessons}} for Models of Human Cognition},
  shorttitle = {How Do People Predict a Random Walk?},
  author = {Spicer, Jake and Zhu, Jian-Qiao and Chater, Nick and Sanborn, Adam N},
  year = {2022},
  month = jul,
  institution = {{PsyArXiv}},
  doi = {10.31234/osf.io/fjtha},
  urldate = {2022-07-12},
  abstract = {Repeated forecasts of changing targets are a key aspect of many everyday tasks, from predicting the weather to financial markets. Random walks provide a particularly simple and informative case study, as new values represent random deviations from the preceding value only, with further previous points being irrelevant. Moreover, random walks often hold simple rational solutions in which predictions should repeat the most recent state, and hence replicate the properties of the target. In previous experiments, however, we have found that human forecasters do not adhere to this standard, showing systematic deviations from the properties of a random walk such as excessive volatility and extreme movements between subsequent predictions. We suggest that such deviations reflect general statistical signatures of human cognition displayed across multiple tasks, offering a window into underlying cognitive mechanisms. Using these deviations as new criteria, we here explore several cognitive models for predicting random walks drawn from various approaches developed in the existing literature, including Bayesian, error-based learning, autoregressive and sampling mechanisms. These models are contrasted to determine which best accounts for the particular statistical features displayed by experimental participants. We find support for sampling models in both aggregate and individual fits, suggesting that these variations are attributable to the use of inherently stochastic prediction systems. We thus argue that variability in predictions is driven by computational noise in the decision making process, rather than ``late'' noise at the output stage.},
  langid = {english},
  keywords = {matlab code},
  file = {/Users/thomasgorman/OneDrive - Indiana University/resources/Zotero/Spicer et al_2022_How do people predict a random walk.pdf}
}

@article{spicerUsingOccamRazor2020,
  title = {Using {{Occam}}'s Razor and {{Bayesian}} Modelling to Compare Discrete and Continuous Representations in Numerosity Judgements},
  author = {Spicer, Jake and Sanborn, Adam N. and Beierholm, Ulrik R.},
  year = {2020},
  month = nov,
  journal = {Cognitive Psychology},
  volume = {122},
  pages = {101309},
  issn = {0010-0285},
  doi = {10.1016/j.cogpsych.2020.101309},
  urldate = {2022-07-12},
  abstract = {Previous research has established that numeric estimates are based not just on perceptual data but also past experience, and so may be influenced by the form of this stored information. It remains unclear, however, how such experience is represented: numerical data can be processed by either a continuous analogue number system or a discrete symbolic number system, with each predicting different generalisation effects. The present paper therefore contrasts discrete and continuous prior formats within the domain of numerical estimation using both direct comparisons of computational models of this process using these representations, as well as empirical contrasts exploiting different predicted reactions of these formats to uncertainty via Occam's razor. Both computational and empirical results indicate that numeric estimates commonly rely on a continuous prior format, mirroring the analogue approximate number system, or `number sense'. This implies a general preference for the use of continuous numerical representations even where both stimuli and responses are discrete, with learners seemingly relying on innate number systems rather than the symbolic forms acquired in later life. There is however remaining uncertainty in these results regarding individual differences in the use of these systems, which we address in recommendations for future work.},
  langid = {english},
  keywords = {Estimation,matlab code,Numerosity,Rational modelling},
  file = {/Users/thomasgorman/OneDrive - Indiana University/resources/Zotero/Spicer et al_2020_Using Occam’s razor and Bayesian modelling to compare discrete and continuous.pdf;/Users/thomasgorman/Zotero/storage/4AUQ8VM3/S0010028520300384.html}
}

@article{stantonCategoryNumberImpacts2013,
  title = {Category Number Impacts Rule-Based and Information-Integration Category Learning: {{A}} Reassessment of Evidence for Dissociable Category-Learning Systems.},
  shorttitle = {Category Number Impacts Rule-Based and Information-Integration Category Learning},
  author = {Stanton, Roger D. and Nosofsky, Robert M.},
  year = {2013},
  journal = {Journal of Experimental Psychology: Learning, Memory, and Cognition},
  volume = {39},
  number = {4},
  pages = {1174--1191},
  issn = {1939-1285, 0278-7393},
  doi = {10.1037/a0031670},
  urldate = {2020-09-03},
  abstract = {Researchers have proposed that an explicit reasoning system is responsible for learning rule-based category structures and that a separate implicit, procedural-learning system is responsible for learning information-integration category structures. As evidence for this multiple-system hypothesis, researchers report a dissociation based on category-number manipulations in which rule-based category learning is worse when the category is composed of 4, rather than 2, response categories; however, informationintegration category learning is unaffected by category-number manipulations. We argue that within the reported category-number manipulations, there exists a critical confound: Perceptual clusters used to construct the categories are spread apart in the 4-category condition relative to the 2-category one. The present research shows that when this confound is eliminated, performance on information-integration category learning is worse for 4 categories than for 2 categories, and this finding is demonstrated across 2 different information-integration category structures. Furthermore, model-based analyses indicate that a single-system learning model accounts well for both the original findings and the updated experimental findings reported here.},
  langid = {english},
  file = {/Users/thomasgorman/Zotero/storage/7TQSMV57/Stanton and Nosofsky - 2013 - Category number impacts rule-based and information.pdf}
}

@article{stantonComparisonsExemplarSimilarity2002,
  title = {Comparisons between Exemplar Similarity and Mixed Prototype Models Using a Linearly Separable Category Structure},
  author = {Stanton, Roger D. and Nosofsky, Robert M. and Zaki, Safa R.},
  year = {2002},
  month = sep,
  journal = {Memory \& Cognition},
  volume = {30},
  number = {6},
  pages = {934--944},
  issn = {0090-502X, 1532-5946},
  doi = {10.3758/BF03195778},
  urldate = {2020-09-06},
  langid = {english},
  file = {/Users/thomasgorman/Zotero/storage/X4B7W4G6/Stanton et al. - 2002 - Comparisons between exemplar similarity and mixed .pdf}
}

@article{stewartAbsoluteIdentificationRelative2005,
  title = {Absolute {{Identification}} by {{Relative Judgment}}.},
  author = {Stewart, Neil and Brown, Gordon D. A. and Chater, Nick},
  year = {2005},
  journal = {Psychological Review},
  volume = {112},
  number = {4},
  pages = {881--911},
  issn = {1939-1471, 0033-295X},
  doi = {10.1037/0033-295X.112.4.881},
  urldate = {2021-05-18},
  abstract = {In unidimensional absolute identification tasks, participants identify stimuli that vary along a single dimension. Performance is surprisingly poor compared with discrimination of the same stimuli. Existing models assume that identification is achieved using long-term representations of absolute magnitudes. The authors propose an alternative relative judgment model (RJM) in which the elemental perceptual units are representations of the differences between current and previous stimuli. These differences are used, together with the previous feedback, to respond. Without using long-term representations of absolute magnitudes, the RJM accounts for (a) information transmission limits, (b) bowed serial position effects, and (c) sequential effects, where responses are biased toward immediately preceding stimuli but away from more distant stimuli (assimilation and contrast).},
  langid = {english},
  file = {/Users/thomasgorman/OneDrive - Indiana University/resources/Zotero/Stewart et al_2005_Absolute Identification by Relative Judgment.pdf}
}

@misc{stojicExplainingInterindividualVariability2020,
  title = {Explaining Inter-Individual Variability in Strategy Selection: {{A}} Cue Weight Learning Approach},
  shorttitle = {Explaining Inter-Individual Variability in Strategy Selection},
  author = {Stojic, Hrvoje and Olsson, Henrik and Analytis, Pantelis P.},
  year = {2020},
  journal = {Journal of Experimental Psychology: Learning, Memory, and Cognition},
  eprint = {https://figshare.com/articles/dataset/Heuristic\_and\_Linear\_Models\_of\_Judgment\_A\_Cue\_Weight\_Learning\_Perspective\_-\_Experimental\_data/1609680},
  pages = {4712361 Bytes},
  doi = {10.6084/M9.FIGSHARE.1609680},
  urldate = {2020-05-07},
  abstract = {This is raw data from the experiment reported in Stojic, H., Olsson, H., and Analytis, P.P. (2016) "Explaining inter-individual variability in strategy selection: A cue weight learning approach". In: Proceedings of the 14th International Conference on Cognitive Modeling. University Park, PA: Penn State, 2016, pp. 144\textendash 150.See Readme file for more detailed descriptions of the datasets.},
  archiveprefix = {https://osf.io/7yxrz/},
  copyright = {CC0},
  langid = {english},
  keywords = {Cue Task,different learning,in-task learning,individual search differences,Learning Differences,non-search comparison,Search Learning},
  file = {/Users/thomasgorman/Documents/Zotero_Markdown/stojic_explaining_2020-zotero.md;/Users/thomasgorman/OneDrive - Indiana University/resources/Zotero/Stojic et al_2020_Explaining inter-individual variability in strategy selection.pdf}
}

@article{stojicItNewIt2020,
  title = {It's New, but Is It Good? {{How}} Generalization and Uncertainty Guide the Exploration of Novel Options},
  author = {Stojic, Hrvoje and Analytis, Pantelis P and Schulz, Eric and Speekenbrink, Maarten},
  year = {2020},
  journal = {Journal of Experimental Psychology: General},
  pages = {35},
  langid = {english},
  keywords = {Bandit,Bayesian Search,Complex Bandit,Function Learning,generalization in search,individual search differences,Novelty in Search,Reinforcement learning,Search,Search model,Search Strategy,Similarity in Search,Uncertainty},
  file = {/Users/thomasgorman/Documents/Zotero_Markdown/stojic_its_2020-zotero.md;/Users/thomasgorman/Zotero/storage/2NP37DQY/Stojic et al. - 2020 - It’s new, but is it good How generalization and u.pdf}
}

@phdthesis{stojicStojicTheisStrategySelectionFunction2017,
  title = {Stojic-{{Theis-Strategy Selection}} and {{Function Learning}} in {{Decision Making}}},
  author = {Stojic, Hrvoje},
  year = {2017},
  abstract = {This thesis consists of three studies investigating the strategy selection problem and the role of function learning in human decision making. Chapter 1 examines how people learn which decision strategy to use when facing multiple environments. It provides evidence that people associate different decision strategies to different types of environments through a trial-anderror type of process and learn to flexibly switch between the strategies as needed. Chapter 2 aims to identify the source of inter-individual differences in strategy adoption. It suggests that such differences can be traced back to how fast people learn the relationships between cues and the criterion they are trying to infer. Finally, Chapter 3 focuses on how people simultaneously learn functional relationships between cues and alternative rewards and make decisions. It provides evidence for interactions between function learning and decision processes and proposes a Bayesian optimization framework for understanding these interactions. Contents List of Figures xvi List of Tables xvii 1 Not everything looks like a nail: Learning to select appropriate decision strategies in multiple environments 3 1.1 Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . 4 1.1.1 Strategy selection in multiple environments . . . . . 6 1.1.2 Overview . . . . . . . . . . . . . . . . . . . . . . . . 9 1.2 Method . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 10 1.2.1 Participants . . . . . . . . . . . . . . . . . . . . . . . 10 1.2.2 Materials . . . . . . . . . . . . . . . . . . . . . . . . 10 1.2.3 Procedure . . . . . . . . . . . . . . . . . . . . . . . . 13 1.3 Results . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 13 1.3.1 Behavioral analysis . . . . . . . . . . . . . . . . . . . 13 1.3.2 Identifying the strategies adopted by the participants 16 1.3.3 Contextual strategy selection learning . . . . . . . . 23 1.4 Discussion . . . . . . . . . . . . . . . . . . . . . . . . . . . . 28 1.A Parameter Estimation and Model Selection . . . . . . . . . . 33 1.A.1 Identifying the strategies adopted by the participants 33 1.A.2 Contextual strategy selection learning . . . . . . . . 34 1.B Additional results . . . . . . . . . . . . . . . . . . . . . . . . 37 2 Explaining inter-individual variability in strategy selection: A cue weight learning approach 41 2.1 Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . 42 2.2 Method . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 44 2.2.1 Participants . . . . . . . . . . . . . . . . . . . . . . . 44 2.2.2 Stimuli and procedure . . . . . . . . . . . . . . . . . 44 2.3 Behavioral results . . . . . . . . . . . . . . . . . . . . . . . . 46 2.3.1 Choices in the decision task . . . . . . . . . . . . . . 46 xii ``thesis'' \textemdash{} 2016/11/22 \textemdash{} 14:10 \textemdash{} page xiv \textemdash{} \#14 2.3.2 Predictions in the estimation task . . . . . . . . . . . 47 2.3.3 Relation between decisions and predictions . . . . . 49 2.4 Modeling . . . . . . . . . . . . . . . . . . . . . . . . . . . . 49 2.4.1 Modeling the cue weight learning . . . . . . . . . . . 49 2.4.2 Modeling the choices . . . . . . . . . . . . . . . . . . 52 2.5 Modeling results . . . . . . . . . . . . . . . . . . . . . . . . 53 2.6 Discussion \& Conclusion . . . . . . . . . . . . . . . . . . . . 56 3 Trials-with-fewer-errors: Feature-based learning and exploration 61 3.1 Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . 62 3.2 Goals and Scope . . . . . . . . . . . . . . . . . . . . . . . . 64 3.3 Feature-based Multi-Armed Bandit Task . . . . . . . . . . . 65 3.4 Function Learning Approach . . . . . . . . . . . . . . . . . . 69 3.4.1 Gaussian Process Regression . . . . . . . . . . . . . . 70 3.4.2 Upper Confidence Bound strategy . . . . . . . . . . . 74 3.4.3 Mean Tracking Approach . . . . . . . . . . . . . . . 77 3.5 Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . 78 3.6 Experiment 1A and 1B: Influence of feature information on learning and exploration . . . . . . . . . . . . . . . . . . . . 79 3.6.1 Method . . . . . . . . . . . . . . . . . . . . . . . . . 80 3.6.2 Results and Discussion . . . . . . . . . . . . . . . . . 84 3.7 Experiment 2A and AB: Are People Function Learners and the Hidden Dangers of Function Learning . . . . . . . . . . 92 3.7.1 Method . . . . . . . . . . . . . . . . . . . . . . . . . 93 3.7.2 Results and Discussion . . . . . . . . . . . . . . . . . 94 3.8 Experiment 3: Different Flavors of Exploration and Factors Affecting Exploration . . . . . . . . . . . . . . . . . . . . . . 102 3.8.1 Method . . . . . . . . . . . . . . . . . . . . . . . . . 104 3.8.2 Results and Discussion . . . . . . . . . . . . . . . . . 106 3.9 General Discussion . . . . . . . . . . . . . . . . . . . . . . . 110 3.9.1 Implications . . . . . . . . . . . . . . . . . . . . . . . 112 3.9.2 Limitations . . . . . . . . . . . . . . . . . . . . . . . 115 3.9.3 Concluding Remarks . . . . . . . . . . . . . . . . . . 117 3.A Ensuring data quality . . . . . . . . . . . . . . . . . . . . . . 119 3.B Details on stimuli in the functional knowledge task . . . . . 120 3.B.1 Items in the linear environments . . . . . . . . . . . 120 3.B.2 Items in the nonlinear environments . . . . . . . . . 122 3.C Additional Results . . . . . . . . . . . . . . . . . . . . . . . 124 3.D Bayesian Models Performance and Parameter Overview . . . 131 Bibliography 133},
  langid = {english},
  file = {/Users/thomasgorman/Documents/Zotero_Markdown/stojic_stojic-theis-strategy_2017-zotero.md;/Users/thomasgorman/Zotero/storage/ZYJ5YMJS/Stojic - Strategy Selection and Function Learning in Decisi.pdf}
}

@misc{sundhMeanvarianceSignatureBayesian2021,
  title = {The Mean-Variance Signature of {{Bayesian}} Probability Judgment},
  author = {Sundh, Joakim and Zhu, Jianqiao and Chater, Nick and Sanborn, Adam},
  year = {2021},
  month = jul,
  institution = {{PsyArXiv}},
  doi = {10.31234/osf.io/yuhaz},
  urldate = {2021-12-14},
  abstract = {Human probability judgments are variable and subject to systematic biases. Sampling-based accounts of probability judgment have successfully explained such idiosyncrasies by assuming that people remember or simulate instances of events and base their judgments on sampled frequencies. Biases have been explained either by noise corrupting sample accumulation (the Probability Theory + Noise account), or as a Bayesian adjustment to the uncertainty implicit in small samples (the Bayesian sampler). While these two accounts closely mimic one another, here we show that they can be distinguished by a novel linear regression method that relates the variance of repeated judgments to their means. First, the efficacy of the method is confirmed by model recovery, and it more accurately recovers parameters than computationally complex methods. Second, the method is applied to both existing and new probability judgment data, which confirm that judgments are based on a small number of samples that are adjusted by a prior, as predicted by the Bayesian sampler.},
  langid = {american},
  keywords = {Bayes,bias,Cognitive Psychology,Judgment and Decision Making,noise,probability,sampling,Social and Behavioral Sciences},
  file = {/Users/thomasgorman/Documents/Zotero_Markdown/sundh_mean-variance_2021-zotero.md;/Users/thomasgorman/OneDrive - Indiana University/resources/Zotero/Sundh et al_2021_The mean-variance signature of Bayesian probability judgment.pdf}
}

@article{tartagliniModelingArtificialCategory,
  title = {Modeling Artificial Category Learning from Pixels: {{Revisiting Shepard}}, {{Hovland}}, and {{Jenkins}} (1961) with Deep Neural Networks},
  author = {Tartaglini, Alexa R and Vong, Wai Keen and Lake, Brenden M},
  pages = {7},
  abstract = {Recent work has paired classic category learning models with convolutional neural networks (CNNs), allowing researchers to study categorization behavior from raw image inputs. However, this research typically uses naturalistic images, which assess participant responses to existing categories; yet, much of traditional category learning research has focused on using novel, artificial stimuli to examine the learning process behind how people acquire categories. In this work, we pair a CNN with ALCOVE (Kruschke, 1992), a well-known exemplar model of categorization, and attempt to examine whether this model can reproduce the classic type ordering effect from Shepard, Hovland, and Jenkins (1961) on raw images rather than abstract features. We examine this question with a variety of CNN architectures and image datasets and compare ALCOVE-CNN to two other models that lacked certain key features of ALCOVE. We found that our ALCOVE-CNN model could reproduce the type ordering effect more often than the other models we tested, but in limited situations. Our results showed that success varied greatly across the various configurations we tested, suggesting that the feature representations from CNNs provide strong constraints in properly capturing this effect.},
  langid = {english},
  file = {/Users/thomasgorman/OneDrive - Indiana University/resources/Zotero/Tartaglini et al_Modeling artiﬁcial category learning from pixels.pdf}
}

@misc{thartMeasuresImplicitExplicit2022,
  title = {Measures of {{Implicit}} and {{Explicit Adaptation Do Not Linearly Ad}}},
  author = {{'t Hart}, Bernard Marius and Taqvi, Urooj and Gastrock, Raphael and Ruttle, Jennifer and Modchalingam, Shanaathanan and Henriques, Denise Y.P.},
  year = {2022},
  doi = {10.1101/2022.06.07.495044},
  urldate = {2022-06-24},
  abstract = {Both implicit (unconscious, automatic) and explicit (effortful, strategic) processes contribute to various kinds of learning 1 , including visuomotor adaptation 2\textendash 4 . Implicit adaptation may be capped at some level 5 , regardless of the level of explicit adaptation, or implicit and explicit adaptation could be linearly added in total adaptation 6,7 . Both appear well accepted, but ironically contradict each other. In the latter case, the equation used is simple:  Which is used to ``predict'' that implicit adaptation is perfectly anti-correlated with explicit adaptation:  This derived implicit adaptation is sometimes further analyzed 8\textendash 10 . But the underlying additivity assumption is not always replicated 11 and is considered the ``least robust'' assumption in motor adaptation 12 . Here we directly test the additivity assumption, particularly how well it predicts implicit adaptation. We find that the relationship between explicit and implicit adaptation is not additive but more complicated and very noisy, which means that future studies should measure both implicit and explicit adaptation directly. It also highlights a challenge to the field to disentangle how various motor adaptation processes combine when producing movements.},
  annotation = {https://osf.io/kr5eh/},
  file = {/Users/thomasgorman/OneDrive - Indiana University/resources/Zotero/’t Hart et al_2022_Measures of Implicit and Explicit Adaptation Do Not Linearly Ad.pdf}
}

@phdthesis{thevenow-harrisonIncidentalLearningFeature,
  title = {The {{Incidental Learning}} of {{Feature Distributions}} in {{Supervised Classification}}},
  author = {{Thevenow-Harrison}, Jordan T.},
  address = {{United States -- Wisconsin}},
  urldate = {2021-10-23},
  abstract = {Categorization allows us to organize and extend our knowledge to make predictions about new things in the world. My dissertation presents series of experiments about how the statistical properties of stimuli incidental to a supervised classification task influence later learning. After exposure to task-incidental but statistically varying features, do people ``transfer in'' such knowledge to new problems where that information is suddenly applicable, or do they learn nothing at all in the first place such that they have nothing to transfer out of the first learning situation? What information about irrelevant features bias people when they move to another task where those features become relevant? The literature is unclear about how task-incidental features are used once they become relevant, and most studies use binary categories. Few studies present continuous features along integrated dimensions with many distributions. The findings suggest that participants represent the distribution task-relevant feature values differently than task-incidental feature values; they seem to represent the task-relevant feature distribution as consisting of two clusters and the task-incidental feature distribution as consisting of one cluster. Learners are faster and more accurate when the second task's category boundary is consistent with a trough in incidental feature distribution from the first task than when it is inconsistent, though this effect seems weak. These findings inform how we can structure environments and tasks to prepare people to learn without explicitly teaching them before the task.},
  copyright = {Database copyright ProQuest LLC; ProQuest does not claim copyright in the individual underlying works.},
  isbn = {9780355924633},
  langid = {english},
  school = {The University of Wisconsin - Madison},
  keywords = {Cognitive science,Education,Incidental learning,Learning science,Psychology,Statistical learning,Supervised classification,Supervised learning},
  file = {/Users/thomasgorman/OneDrive - Indiana University/resources/Zotero/Thevenow-Harrison_The Incidental Learning of Feature Distributions in Supervised Classification.pdf}
}

@article{thorndikeInfluenceImprovementOne1901a,
  title = {The Influence of Improvement in One Mental Function upon the Efficiency of Other Functions: {{III}}. {{Functions}} Involving Attention, Observation and Discrimination.},
  shorttitle = {The Influence of Improvement in One Mental Function upon the Efficiency of Other Functions},
  author = {Thorndike, Edward L. and Woodworth, R. S.},
  year = {1901},
  journal = {Psychological Review},
  volume = {8},
  number = {6},
  pages = {553},
  urldate = {2016-05-11},
  file = {/Users/thomasgorman/Zotero/storage/R5BD82M9/ContentServer.pdf}
}

@article{trumpowerIndividualDifferencesExtrapolation2005,
  title = {Individual {{Differences}} in {{Extrapolation}} of {{Function Learning}}},
  author = {Trumpower, David L},
  year = {2005},
  journal = {Proceedings of the Annual Meeting of the Cognitive Science Society},
  pages = {2},
  abstract = {Introduction Investigation of concept learning has focused predominantly on categorization, in which stimuli are associated with nominal response categories. More recently, however, concept learning research has begun to focus on function learning, in which continuously-valued stimuli are associated with continuously-valued responses. One particularly useful aspect of function learning is extrapolation - generating responses to novel stimulus values. Previous studies have found that regardless of training success, some participants extrapolate in accordance with the learned function whereas others do not (e.g., DeLosh, Busemeyer, \& McDaniel, 1997; Griego, 2001). Although models of function learning have gained some success in reproducing human extrapolation performance (e.g., DeLosh, et al., 1997), they have not yet been able to predict who will extrapolate. The purpose of this study was to determine if individual differences in extrapolation performance are related to problem solving in non-mathematical domains in order to gain a better understanding of the factors underlying function learning. Method Eleven undergraduate psychology students served as participants. They each completed a function learning phase of the experiment followed by a problem solving phase as described below.  Participants were first asked to learn the relationship between an organism's absorption of a newly discovered element, Zebon, and its release of another new element, Beros. During this training phase, participants were shown three vertical bars on a computer screen. The height of the first bar represented the amount of Zebon absorbed (input). The height of the second and third bars represented the predicted and actual amount of Beros released (output), respectively. Participants made their predictions by controlling the height of the second bar using the up and down arrow keys on the keyboard. The third bar was not revealed until participants made their predictions. Training consisted of 10 blocks of 20 trials. Training input values ranged from 81 to 119. Output values were determined by the mirror linear function: y=230-2.2x if x{$<$}100; y=2.2x-210 if x{$>$}100. An extrapolation phase followed, consisting of 30 novel input values outside of the training range, with no feedback.  Next, participants were asked to read and summarize two text passages (each an analog to Dunker's radiation problem, see Catrambone \& Holyoak, 1989). They were then asked to solve four matrix reasoning problems followed by Dunker's radiation problem. Results Extrapolation performance was assessed by calculating the mean absolute error (MAE) across the 30 extrapolation trials for each participant. MAEs ranged from 12.87 to 53.80. Previous studies have used 30 as a cut-off for classifying participants as having abstracted the function or not. A multiple linear regression was performed using performance on the matrix reasoning problems and on Dunker's radiation problem to predict extrapolation performance. Together, performance on the matrix reasoning problems and Dunker radiation problem accounted for a significant proportion of the variability in extrapolation performance, R2 =.828, SEE=6.15, F(2,7)=16.84, p{$<$}.01. Inspection of the regression coefficients revealed that better performance on the matrix reasoning problems, but worse performance on Dunker's radiation problem, was associated with better extrapolation performance. Discussion Both extrapolation of the function and completion of the matrix reasoning problems required participants to induce a novel response that could only be generated by comparing multiple pieces of information. That is, successful extrapolation required use of more than just a single exemplar. Similarly, successful matrix reasoning requires consideration of all elements of the matrix. However, successful solution of the radiation problem could result from access to just a single analog. Thus, it is suggested that one factor that determines extrapolation is a tendency to process many sources of information in an analytic manner, rather than a tendency to look for a single similar exemplar (or at most a small number of exemplars).},
  langid = {english},
  file = {/Users/thomasgorman/Documents/Zotero_Markdown/trumpower_individual_2005-zotero.md;/Users/thomasgorman/OneDrive - Indiana University/resources/Zotero/Trumpower_2005_Individual Differences in Extrapolation of Function Learning.pdf}
}

@article{turnerCommonRepresentationalFramework2019a,
  title = {Toward a Common Representational Framework for Adaptation.},
  author = {Turner, Brandon M.},
  year = {2019},
  journal = {Psychological Review},
  volume = {126},
  number = {5},
  pages = {660--692},
  issn = {1939-1471, 0033-295X},
  doi = {10.1037/rev0000148},
  urldate = {2020-05-31},
  abstract = {We develop a computational model \textendash{} the adaptive representation model (ARM) \textendash{} for relating two classic theories of learning dynamics: instance and strength theory. Within the model, we show how the principles of instance and strength theories can be instantiated, so that the validity of their as- sumptions can be tested against experimental data. We show how under some conditions, models embodying instance representations can be consid- ered a special case of a strength-based representation. We discuss a number of mechanisms for producing adaptive behaviors in dynamic environments, and detail how they may be instantiated within ARM. To evaluate the rela- tive strengths of the proposed mechanisms, we construct a suite of 10 model variants, and fit them to single-trial choice response time data from three experiments. The first experiment involves dynamic shifts in the frequency of category exposure, the second experiment involves shifts in the means of the category distributions, and the third experiment involves shifts in both the mean and variance of the category distributions. We evaluate model performance by assessing model fit, penalized for complexity, at both the individual and aggregate levels. We show that the mechanisms of prediction error and lateral inhibition are strong contributors to the successes of the model variants considered here. Our results suggest that the joint distribu- tion of choice and response time can be thought of as an emergent property of an evolving representation mapping stimulus attributes to their appropri- ate response assignment. Keywords: adaptation, learning, categorization, dynamic stimuli, cognitive modeling},
  langid = {english},
  file = {/Users/thomasgorman/Documents/Zotero_Markdown/turnerCommonRepresentationalFramework2019-zotero.md;/Users/thomasgorman/Zotero/storage/ENNI2MDR/Turner - 2019 - Toward a common representational framework for ada.pdf}
}

@article{turnerForecastAggregationRecalibration2014,
  title = {Forecast Aggregation via Recalibration},
  author = {Turner, Brandon M. and Steyvers, Mark and Merkle, Edgar C. and Budescu, David V. and Wallsten, Thomas S.},
  year = {2014},
  month = jun,
  journal = {Machine Learning},
  volume = {95},
  number = {3},
  pages = {261--289},
  issn = {1573-0565},
  doi = {10.1007/s10994-013-5401-4},
  urldate = {2022-04-19},
  abstract = {It is known that the average of many forecasts about a future event tends to outperform the individual assessments. With the goal of further improving forecast performance, this paper develops and compares a number of models for calibrating and aggregating forecasts that exploit the well-known fact that individuals exhibit systematic biases during judgment and elicitation. All of the models recalibrate judgments or mean judgments via a two-parameter calibration function, and differ in terms of whether (1) the calibration function is applied before or after the averaging, (2) averaging is done in probability or log-odds space, and (3) individual differences are captured via hierarchical modeling. Of the non-hierarchical models, the one that first recalibrates the individual judgments and then averages them in log-odds is the best relative to simple averaging, with 26.7~\% improvement in Brier score and better performance on 86~\% of the individual problems. The hierarchical version of this model does slightly better in terms of mean Brier score (28.2~\%) and slightly worse in terms of individual problems (85~\%).},
  langid = {english},
  keywords = {Aggregation,Calibration,Forecasting,Hierarchical Bayesian models,Individual differences,Systematic distortions,Wisdom of the crowd},
  file = {/Users/thomasgorman/OneDrive - Indiana University/resources/Zotero/Turner et al_2014_Forecast aggregation via recalibration.pdf}
}

@article{turnerHowLoopsAttention,
  title = {How {{Loops Among Attention}}, {{Learning}}, and {{Memory Distort Reality}}},
  author = {Turner, Brandon M and Blanco, Nathaniel J and Unger, Layla and Kvam, D and Ralston, Robert W and Sloutsky, Vladimir M},
  pages = {55},
  langid = {english},
  file = {/Users/thomasgorman/OneDrive - Indiana University/resources/Zotero/Turner et al_How Loops Among Attention, Learning, and Memory Distort Reality.pdf}
}

@article{vaciLargeDataBayesian2019,
  title = {Large Data and {{Bayesian}} Modeling\textemdash Aging Curves of {{NBA}} Players},
  author = {Vaci, Nemanja and Coci{\'c}, Dijana and Gula, Bartosz and Bilali{\'c}, Merim},
  year = {2019},
  month = aug,
  journal = {Behavior Research Methods},
  volume = {51},
  number = {4},
  pages = {1544--1564},
  issn = {1554-3528},
  doi = {10.3758/s13428-018-1183-8},
  urldate = {2021-05-04},
  abstract = {Researchers interested in changes that occur as people age are faced with a number of methodological problems, starting with the immense time scale they are trying to capture, which renders laboratory experiments useless and longitudinal studies rather rare. Fortunately, some people take part in particular activities and pastimes throughout their lives, and often these activities are systematically recorded. In this study, we use the wealth of data collected by the National Basketball Association to describe the aging curves of elite basketball players. We have developed a new approach rooted in the Bayesian tradition in order to understand the factors behind the development and deterioration of a complex motor skill. The new model uses Bayesian structural modeling to extract two latent factors, those of development and aging. The interaction of these factors provides insight into the rates of development and deterioration of skill over the course of a player's life. We show, for example, that elite athletes have different levels of decline in the later stages of their career, which is dependent on their skill acquisition phase. The model goes beyond description of the aging function, in that it can accommodate the aging curves of subgroups (e.g., different positions played in the game), as well as other relevant factors (e.g., the number of minutes on court per game) that might play a role in skill changes. The flexibility and general nature of the new model make it a perfect candidate for use across different domains in lifespan psychology.},
  langid = {english},
  file = {/Users/thomasgorman/OneDrive - Indiana University/resources/Zotero/Vaci et al_2019_Large data and Bayesian modeling—aging curves of NBA players.pdf}
}

@article{vandamMappingShapeVisuomotor2015,
  title = {Mapping {{Shape}} to {{Visuomotor Mapping}}: {{Learning}} and {{Generalisation}} of {{Sensorimotor Behaviour Based}} on {{Contextual Information}}},
  shorttitle = {Mapping {{Shape}} to {{Visuomotor Mapping}}},
  author = {{van Dam}, Loes C. J. and Ernst, Marc O.},
  year = {2015},
  month = mar,
  journal = {PLOS Computational Biology},
  volume = {11},
  number = {3},
  pages = {e1004172},
  publisher = {{Public Library of Science}},
  issn = {1553-7358},
  doi = {10.1371/journal.pcbi.1004172},
  urldate = {2021-07-06},
  abstract = {Humans can learn and store multiple visuomotor mappings (dual-adaptation) when feedback for each is provided alternately. Moreover, learned context cues associated with each mapping can be used to switch between the stored mappings. However, little is known about the associative learning between cue and required visuomotor mapping, and how learning generalises to novel but similar conditions. To investigate these questions, participants performed a rapid target-pointing task while we manipulated the offset between visual feedback and movement end-points. The visual feedback was presented with horizontal offsets of different amounts, dependent on the targets shape. Participants thus needed to use different visuomotor mappings between target location and required motor response depending on the target shape in order to ``hit'' it. The target shapes were taken from a continuous set of shapes, morphed between spiky and circular shapes. After training we tested participants performance, without feedback, on different target shapes that had not been learned previously. We compared two hypotheses. First, we hypothesised that participants could (explicitly) extract the linear relationship between target shape and visuomotor mapping and generalise accordingly. Second, using previous findings of visuomotor learning, we developed a (implicit) Bayesian learning model that predicts generalisation that is more consistent with categorisation (i.e. use one mapping or the other). The experimental results show that, although learning the associations requires explicit awareness of the cues' role, participants apply the mapping corresponding to the trained shape that is most similar to the current one, consistent with the Bayesian learning model. Furthermore, the Bayesian learning model predicts that learning should slow down with increased numbers of training pairs, which was confirmed by the present results. In short, we found a good correspondence between the Bayesian learning model and the empirical results indicating that this model poses a possible mechanism for simultaneously learning multiple visuomotor mappings.},
  langid = {english},
  keywords = {Extrapolation,Human learning,Interpolation,Kalman filter,Learning,Radii,Sensory perception,Vision},
  file = {/Users/thomasgorman/OneDrive - Indiana University/resources/Zotero/Dam_Ernst_2015_Mapping Shape to Visuomotor Mapping.pdf;/Users/thomasgorman/Zotero/storage/K9A3IC8P/article.html}
}

@article{vandierendonckParallelRuleActivation1995,
  title = {A Parallel Rule Activation and Rule Synthesis Model for Generalization in Category Learning},
  author = {Vandierendonck, Andr{\'e}},
  year = {1995},
  month = dec,
  journal = {Psychonomic Bulletin \& Review},
  volume = {2},
  number = {4},
  pages = {442--459},
  issn = {1069-9384, 1531-5320},
  doi = {10.3758/BF03210982},
  urldate = {2020-09-07},
  langid = {english},
  file = {/Users/thomasgorman/Zotero/storage/GK3CKGRX/Vandierendonck - 1995 - A parallel rule activation and rule synthesis mode.pdf}
}

@article{vanrossumSchmidtSchemaTheory1990,
  title = {Schmidt's Schema Theory: The Empirical Base of the Variability of Practice Hypothesis},
  shorttitle = {Schmidt's Schema Theory},
  author = {Van Rossum, Jacques H.A.},
  year = {1990},
  month = sep,
  journal = {Human Movement Science},
  volume = {9},
  number = {3-5},
  pages = {387--435},
  issn = {01679457},
  doi = {10.1016/0167-9457(90)90010-B},
  urldate = {2019-05-26},
  langid = {english},
  file = {/Users/thomasgorman/Zotero/storage/8VDFLNET/Van Rossum - 1990 - Schmidt's schema theory the empirical base of the.pdf}
}

@inproceedings{vekslerCategorizationReinforcementLearning2007,
  title = {Categorization and Reinforcement Learning: {{State}} Identification in Reinforcement Learning and Network Reinforcement Learning},
  shorttitle = {Categorization and Reinforcement Learning},
  booktitle = {In {{Proceedings}} of the 29th},
  author = {Veksler, Vladislav D. and Gray, Wayne D. and Schoelles, Michael J.},
  year = {2007},
  abstract = {We present Network Reinforcement Learning (NRL) as more efficient and robust than traditional reinforcement learning in complex environments. Combined with Configural Memory (Pearce, 1994), NRL can generalize from its experiences to novel stimuli, and learn how to deal with anomalies as well. We show how configural memory with NRL accounts for human and monkey data on a classic categorization paradigm. Finally, we argue for why the suggested mechanism is better than other reinforcement learning and categorization models for cognitive agents and AI.},
  file = {/Users/thomasgorman/OneDrive - Indiana University/resources/Zotero/Veksler et al_2007_Categorization and reinforcement learning.pdf;/Users/thomasgorman/Zotero/storage/KWTWAYXT/download.html}
}

@article{verheyenLearningHierarchicalOrganization,
  title = {Learning a {{Hierarchical Organization}} of {{Categories}}},
  author = {Verheyen, Steven},
  pages = {7},
  abstract = {Although exemplar models of category learning have been successfully applied to a wide range of classification problems, such models have only rarely been tested on their ability to deal with vertical category learning, that is, cases where the same stimuli may be classified at multiple levels of abstraction. We report an experiment in which participants learned to classify artificial stimuli at both levels of a nested hierarchy and displayed more accurate classification of these items at the lower level of the hierarchy than at the more general level. Some authors have suggested that exemplar models would have great difficulty accounting for this phenomenon, but we show that the ALCOVE exemplar model effectively captures the behavioral pattern arising in the experiment. Despite suggestions to the contrary, superior performance at the lower level of a nested hierarchy does not necessarily invalidate the class of exemplar models.},
  langid = {english},
  file = {/Users/thomasgorman/OneDrive - Indiana University/resources/Zotero/Verheyen_Learning a Hierarchical Organization of Categories.pdf}
}

@article{vikenModelingIndividualDifferences2002,
  title = {Modeling Individual Differences in Perceptual and Attentional Processes Related to Bulimic Symptoms.},
  author = {Viken, Richard J. and Treat, Teresa A. and Nosofsky, Robert M. and McFall, Richard M. and Palmeri, Thomas J.},
  year = {2002},
  journal = {Journal of Abnormal Psychology},
  volume = {111},
  number = {4},
  pages = {598--609},
  issn = {1939-1846, 0021-843X},
  doi = {10.1037/0021-843X.111.4.598},
  urldate = {2020-03-10},
  langid = {english},
  file = {/Users/thomasgorman/Zotero/storage/VN85H23T/Viken et al. - 2002 - Modeling individual differences in perceptual and .pdf}
}

@article{villagraDataAvailabilityFunction2018,
  title = {Data {{Availability}} and {{Function Extrapolation}}},
  author = {Villagra, Pablo Leon and Preda, Irina and Lucas, Christopher G},
  year = {2018},
  pages = {6},
  langid = {english},
  file = {/Users/thomasgorman/Documents/Zotero_Markdown/villagra_data_2018-zotero.md;/Users/thomasgorman/OneDrive - Indiana University/resources/Zotero/Villagra et al_Data Availability and Function Extrapolation.pdf}
}

@article{visserParameterRecoveryBias2017,
  title = {Parameter Recovery, Bias and Standard Errors in the Linear Ballistic Accumulator Model},
  author = {Visser, Ingmar and Poess{\'e}, Rens},
  year = {2017},
  journal = {British Journal of Mathematical and Statistical Psychology},
  volume = {70},
  number = {2},
  pages = {280--296},
  issn = {2044-8317},
  doi = {10.1111/bmsp.12100},
  urldate = {2021-11-30},
  abstract = {The linear ballistic accumulator (LBA) model (Brown \& Heathcote, , Cogn. Psychol., 57, 153) is increasingly popular in modelling response times from experimental data. An R package, glba, has been developed to fit the LBA model using maximum likelihood estimation which is validated by means of a parameter recovery study. At sufficient sample sizes parameter recovery is good, whereas at smaller sample sizes there can be large bias in parameters. In a second simulation study, two methods for computing parameter standard errors are compared. The Hessian-based method is found to be adequate and is (much) faster than the alternative bootstrap method. The use of parameter standard errors in model selection and inference is illustrated in an example using data from an implicit learning experiment (Visser et al., , Mem. Cogn., 35, 1502). It is shown that typical implicit learning effects are captured by different parameters of the LBA model.},
  langid = {english},
  keywords = {bootstrap,glba,implicit learning,linear ballistic accumulator model,maximum likelihood,parameter bias,parameter recovery,R-package,response times,standard error},
  file = {/Users/thomasgorman/OneDrive - Indiana University/resources/Zotero/Visser_Poessé_2017_Parameter recovery, bias and standard errors in the linear ballistic.pdf;/Users/thomasgorman/OneDrive - Indiana University/resources/Zotero/Visser_Poessé_2017_Supplemental_Code.pdf;/Users/thomasgorman/Zotero/storage/TI47PTY7/bmsp.html}
}

@article{vogelCategoryStructureDetermines2018,
  title = {Category Structure Determines the Relative Attractiveness of Global versus Local Averages},
  author = {Vogel, Tobias and Carr, Evan W. and Davis, Tyler and Winkielman, Piotr},
  year = {2018},
  month = feb,
  journal = {Journal of Experimental Psychology: Learning, Memory, and Cognition},
  volume = {44},
  number = {2},
  pages = {250--267},
  publisher = {{American Psychological Association}},
  issn = {0278-7393},
  doi = {10.1037/xlm0000446},
  urldate = {2020-07-18},
  abstract = {Stimuli that capture the central tendency of presented exemplars are often preferred\textemdash a phenomenon also known as the classic beauty-in-averageness effect. However, recent studies have shown that this effect can reverse under certain conditions. We propose that a key variable for such ugliness-in-averageness effects is the category structure of the presented exemplars. When exemplars cluster into multiple subcategories, the global average should no longer reflect the underlying stimulus distributions, and will thereby become unattractive. In contrast, the subcategory averages (i.e., local averages) should better reflect the stimulus distributions, and become more attractive. In 3 studies, we presented participants with dot patterns belonging to 2 different subcategories. Importantly, across studies, we also manipulated the distinctiveness of the subcategories. We found that participants preferred the local averages over the global average when they first learned to classify the patterns into 2 different subcategories in a contrastive categorization paradigm (Experiment 1). Moreover, participants still preferred local averages when first classifying patterns into a single category (Experiment 2) or when not classifying patterns at all during incidental learning (Experiment 3), as long as the subcategories were sufficiently distinct. Finally, as a proof-of-concept, we mapped our empirical results onto predictions generated by a well-known computational model of category learning (the Generalized Context Model [GCM]). Overall, our findings emphasize the key role of categorization for understanding the nature of preferences, including any effects that emerge from stimulus averaging. (PsycINFO Database Record (c) 2018 APA, all rights reserved)},
  file = {/Users/thomasgorman/OneDrive - Indiana University/resources/Zotero/Vogel et al_2018_Category structure determines the relative attractiveness of global versus.pdf}
}

@article{vongAdditionalFeaturesHelp2019a,
  title = {Do {{Additional Features Help}} or {{Hurt Category Learning}}? {{The Curse}} of {{Dimensionality}} in {{Human Learners}}},
  shorttitle = {Do {{Additional Features Help}} or {{Hurt Category Learning}}?},
  author = {Vong, Wai Keen and Hendrickson, Andrew T. and Navarro, Danielle J. and Perfors, Andrew},
  year = {2019},
  month = mar,
  journal = {Cognitive Science},
  volume = {43},
  number = {3},
  issn = {0364-0213, 1551-6709},
  doi = {10.1111/cogs.12724},
  urldate = {2021-09-11},
  abstract = {The curse of dimensionality, which has been widely studied in statistics and machine learning, occurs when additional features cause the size of the feature space to grow so quickly that learning classification rules becomes increasingly difficult. How do people overcome the curse of dimensionality when acquiring real-world categories that have many different features? Here we investigate the possibility that the structure of categories can help. We show that when categories follow a family resemblance structure, people are unaffected by the presence of additional features in learning. However, when categories are based on a single feature, they fall prey to the curse, and having additional irrelevant features hurts performance. We compare and contrast these results to three different computational models to show that a model with limited computational capacity best captures human performance across almost all of the conditions in both experiments.},
  langid = {english},
  keywords = {irrelevant variability,Python code},
  file = {/Users/thomasgorman/OneDrive - Indiana University/resources/Zotero/Vong et al_2019_Do Additional Features Help or Hurt Category Learning.pdf}
}

@article{vonhelversenLearningMultiplecueJudgment2010,
  title = {Learning in Multiple-Cue Judgment Tasks},
  author = {Von Helversen, Bettina and Rieskamp, J{\"o}rg},
  year = {2010},
  publisher = {{Cognitive Science Society}},
  doi = {10.5167/UZH-135898},
  urldate = {2020-12-21},
  abstract = {In our daily lives we often make quantitative judgments based on multiple pieces of information such as evaluating a student's paper based on form and content. Psychological research suggests that humans rely on several strategies to make multiple-cue judgments. The strategy that is used depends on the structure of the task. In contrast, recent research on learning in judgment tasks suggests that learning is relatively independent of task structure. In a simulation study we investigated how the performance of several learning models is influenced by the structure of the task and the amount of learning experience. We found that a linear additive neuronal network model performed well regardless of task structure and amount of learning. However, with little learning a heuristic model performed similarly well, and with extensive learning, associative learning models caught up with the linear additive model.},
  langid = {english},
  annotation = {bump},
  file = {/Users/thomasgorman/Documents/Zotero_Markdown/vonhelversenLearningMultiplecueJudgment2010-zotero.md;/Users/thomasgorman/Downloads/vonhelversenLearningMultiplecueJudgment2010-zotero.md;/Users/thomasgorman/Downloads/vonhelversenLearningMultiplecueJudgment2010.md;/Users/thomasgorman/OneDrive - Indiana University/resources/Zotero/Von Helversen_Rieskamp_2010_Learning in multiple-cue judgment tasks.pdf}
}

@article{vonhelversenMappingModelCognitive2008,
  title = {The {{Mapping Model}}: {{A Cognitive Theory}} of {{Quantitative Estimation}}},
  shorttitle = {The {{Mapping Model}}},
  author = {{von Helversen}, Bettina and Rieskamp, J{\"o}rg},
  year = {2008},
  month = mar,
  journal = {Journal of experimental psychology. General},
  volume = {137},
  pages = {73--96},
  doi = {10.1037/0096-3445.137.1.73},
  abstract = {How do people make quantitative estimations, such as estimating a car's selling price? Traditionally, linear-regression-type models have been used to answer this question. These models assume that people weight and integrate all information available to estimate a criterion. The authors propose an alternative cognitive theory for quantitative estimation. The mapping model, inspired by the work of N. R. Brown and R. S. Siegler (1993) on metrics and mappings, offers a heuristic approach to decision making. The authors test this model against established alternative models of estimation, namely, linear regression, an exemplar model, and a simple estimation heuristic. With 4 experimental studies the authors compare the models under different environmental conditions. The mapping model proves to be a valid model to predict people's estimates.},
  file = {/Users/thomasgorman/Documents/Zotero_Markdown/von_helversen_mapping_2008-zotero.md;/Users/thomasgorman/OneDrive - Indiana University/resources/Zotero/von Helversen_Rieskamp_2008_The Mapping Model.pdf}
}

@article{wagenaarMisperceptionExponentialGrowth1975,
  title = {Misperception of Exponential Growth},
  author = {Wagenaar, William A. and Sagaria, Sabato D.},
  year = {1975},
  month = nov,
  journal = {Perception \& Psychophysics},
  volume = {18},
  number = {6},
  pages = {416--422},
  issn = {1532-5962},
  doi = {10.3758/BF03204114},
  urldate = {2022-05-20},
  abstract = {Exponential growth in numerical series and graphs is grossly underestimated in an intuitive extrapolation task. Subjects' extrapolations are well described by a model with two parameters only: one for underestimation of the nonlinear growth, the other for linear compensation. The size of the effect is considerable; it is not unusual that two-thirds of the subjects produce estimates below 10\% of the normative value. The effect increases with the exponent of the stimulus series, and with addition of a constant to the stimulus series. Neither special instructions about the nature of exponential growth nor daily experience with growth processes enhanced the extrapolations.},
  langid = {english},
  keywords = {Exponential Growth,Linear Component,Median Rank,Method Procedure,Pollution Index},
  file = {/Users/thomasgorman/Documents/Zotero_Markdown/wagenaar_misperception_1975-zotero.md;/Users/thomasgorman/Zotero/storage/QL6JMDNY/Wagenaar and Sagaria - 1975 - Misperception of exponential growth.pdf}
}

@article{wangGCMNeuralNetwork2017,
  title = {A {{GCM}} Neural Network Using Cubic Logistic Map for Information Processing},
  author = {Wang, Tao and Jia, Nuo},
  year = {2017},
  month = jul,
  journal = {Neural Computing and Applications},
  volume = {28},
  number = {7},
  pages = {1891--1903},
  issn = {0941-0643, 1433-3058},
  doi = {10.1007/s00521-016-2407-4},
  urldate = {2021-12-01},
  abstract = {A new chaotic neural network described by a modified globally coupled map (GCM) model with cubic logistic map is proposed, which is called CL-GCM model. Its rich dynamical behaviors over a wide range of parameters and the dynamics mechanism of neurons are demonstrated in detail. Furthermore, the network with delay coupling can be precisely controlled to any specifiedperiodic orbit by feedback control or modulated parameter control with variable threshold. The results of simulations and experiments suggest that the network is controlled successfully. The controlled CL-GCM model exhibits excellent associative memory performance which appears it can output unique fixed pattern or periodic patterns with specified period which contain the stored pattern closest to the initial pattern.},
  langid = {english},
  file = {/Users/thomasgorman/OneDrive - Indiana University/resources/Zotero/Wang_Jia_2017_A GCM neural network using cubic logistic map for information processing.pdf}
}

@article{webbModelingIndividualDifferences,
  title = {Modeling {{Individual Differences}} in {{Category Learning Using ALCOVE}}},
  author = {Webb, Michael R and Lee, Michael D},
  pages = {14},
  abstract = {Many evaluations of cognitive models rely on data that have been averaged or aggregated across all experimental subjects, and so fail to consider the possibility that there are important individual differences between subjects. Other evaluations are done at the single-subject level, and so fail to benefit from the reduction of noise that data averaging or aggregation potentially provides. To overcome these weaknesses, we develop a general approach to modeling individual differences using families of cognitive models, where different groups of subjects are identified as having different psychological behavior. Separate models with separate parameterizations are applied to each group of subjects, and Bayesian model selection is used to determine the appropriate number of groups. We demonstrate the general approach in a concrete and detailed way using the ALCOVE model of category learning, and data from four previously analysed category learning experiments. Meaningful individual differences are found for three of the four experiments, and ALCOVE is able to account for this variation through psychologically interpretable differences in parameterization. The results highlight the potential of extending cognitive models to consider individual differences.},
  langid = {english},
  file = {/Users/thomasgorman/OneDrive - Indiana University/resources/Zotero/Webb_Lee_Modeling Individual Diﬀerences in Category Learning Using ALCOVE.pdf}
}

@techreport{weichartCommonMechanismsCan2021,
  type = {Preprint},
  title = {As {{Within}}, so {{Without}}; {{As Above}}, so {{Below}}: {{Common Mechanisms Can Support Between-}} and {{Within-Trial Learning Dynamics}}},
  shorttitle = {As {{Within}}, so {{Without}}; {{As Above}}, so {{Below}}},
  author = {Weichart, Emily Ruth and Galdo, Matthew and Sloutsky, Vladimir and Turner, Brandon},
  year = {2021},
  month = jun,
  institution = {{PsyArXiv}},
  doi = {10.31234/osf.io/94csh},
  urldate = {2021-08-10},
  abstract = {Two fundamental difficulties when learning is deciding 1) what information is relevant, and 2) when to use it. To overcome these difficulties, humans continuously make choices about which dimensions of information to selectively attend to, and monitor their relevance to the current goal. Although previous theories have specified how observers learn to attend to relevant dimensions over time, those theories have largely remained silent about how attention should be allocated on a within-trial basis, which dimensions of information should be sampled, and how the temporal ordering of information sampling influences learning. Here, we use the Adaptive Attention Representation Model (AARM) to demonstrate that a common set of mechanisms can be used to specify: 1) how the distribution of attention is updated between trials over the course of learning; and 2) how attention dynamically shifts among dimensions within-trial. We validate or proposed set of mechanisms by comparing AARM's predictions to observed behavior across five case studies, which collectively encompass different theoretical aspects of selective attention. Importantly, we use both eye-tracking and choice response data to provide a stringent test of how attention and decision processes dynamically interact. Specifically, how does attention to selected stimulus dimensions gives rise to decision dynamics, and in turn, how do decision dynamics influence our continuous choices about which dimensions to attend to via gaze fixations?},
  langid = {english},
  file = {/Users/thomasgorman/OneDrive - Indiana University/resources/Zotero/Weichart et al_2021_As Within, so Without\; As Above, so Below.pdf}
}

@article{weichartCommonMechanismsCan2022,
  title = {As within, so without, as above, so below: {{Common}} Mechanisms Can Support between- and within-Trial Category Learning Dynamics},
  shorttitle = {As within, so without, as above, so Below},
  author = {Weichart, Emily R. and Galdo, Matthew and Sloutsky, Vladimir M. and Turner, Brandon M.},
  year = {2022},
  month = jul,
  journal = {Psychological Review},
  publisher = {{American Psychological Association}},
  issn = {0033-295X},
  doi = {10.1037/rev0000381},
  urldate = {2022-08-18},
  abstract = {Two fundamental difficulties when learning novel categories are deciding (a) what information is relevant and (b) when to use that information. Although previous theories have specified how observers learn to attend to relevant dimensions over time, those theories have largely remained silent about how attention should be allocated on a within-trial basis, which dimensions of information should be sampled, and how the temporal order of information sampling influences learning. Here, we use the adaptive attention representation model (AARM) to demonstrate that a common set of mechanisms can be used to specify: (a) How the distribution of attention is updated between trials over the course of learning and (b) how attention dynamically shifts among dimensions within a trial. We validate our proposed set of mechanisms by comparing AARM's predictions to observed behavior in four case studies, which collectively encompass different theoretical aspects of selective attention. We use both eye-tracking and choice response data to provide a stringent test of how attention and decision processes dynamically interact during category learning. Specifically, how does attention to selected stimulus dimensions gives rise to decision dynamics, and in turn, how do decision dynamics influence which dimensions are attended to via gaze fixations? (PsycInfo Database Record (c) 2022 APA, all rights reserved)},
  keywords = {categorization,decision dynamics,Decision Making,eye tracking,learning,Learning,Models,Visual Tracking},
  annotation = {https://github.com/compmem},
  file = {/Users/thomasgorman/OneDrive - Indiana University/resources/Zotero/Weichart et al_2022_As within, so without, as above, so below.pdf}
}

@techreport{weigardCognitiveProcessModeling2021,
  type = {Preprint},
  title = {Cognitive Process Modeling Addresses Context Independence Violations in the {{ABCD Study}} Stop-Signal Task},
  author = {Weigard, Alexander and Matzke, Dora and Tanis, Charlotte and Heathcote, Andrew},
  year = {2021},
  month = jul,
  institution = {{Neuroscience}},
  doi = {10.1101/2021.07.26.453872},
  urldate = {2021-09-11},
  abstract = {The Adolescent Brain Cognitive Development (ABCD) Study is a longitudinal neuroimaging study of unprecedented scale that is in the process of following over 11,000 youth from middle childhood though age 20. However, a design feature of the study's stop-signal task violates "context independence", an assumption critical to current non-parametric methods for estimating stop-signal reaction time (SSRT), a key measure of inhibitory ability in the study. This has led some experts to call for the task to be changed and for previously collected data to be used with caution. We present a formal cognitive process model, the BEESTS-ABCD model, that provides a mechanistic explanation for the impact of this design feature, describes key behavioral trends in the ABCD data, and allows biases in SSRT estimates resulting from context independence violations to be quantified. We use the model to demonstrate that, although nonparametric SSRT estimates generally preserve the rank ordering of participants' SSRT values, failing to account for context independence violations can lead to erroneous inferences in several realistic scenarios. Nonetheless, as the BEESTS-ABCD model can be used to accurately recover estimates of SSRT and other mechanistic parameters of interest from ABCD data, the impact of such violations can be effectively mitigated.},
  langid = {english},
  file = {/Users/thomasgorman/OneDrive - Indiana University/resources/Zotero/Weigard et al_2021_Cognitive process modeling addresses context independence violations in the.pdf}
}

@techreport{weightmanResidualErrorsVisuomotor2021,
  type = {Preprint},
  title = {Residual Errors in Visuomotor Adaptation Persist despite Extended Motor Preparation Periods},
  author = {Weightman, Matthew and Brittain, John-Stuart and Chris Miall, R. and Jenkinson, Ned},
  year = {2021},
  month = jun,
  institution = {{Neuroscience}},
  doi = {10.1101/2021.06.28.450124},
  urldate = {2021-09-24},
  abstract = {Abstract           A consistent finding in sensorimotor adaptation is a persistent undershoot of full compensation, such that performance asymptotes with residual errors greater than seen at baseline. This behaviour has been attributed to limiting factors within the implicit adaptation system, which reaches a sub-optimal equilibrium between trial-by-trial learning and forgetting. However, recent research has suggested that allowing longer motor planning periods prior to movement eliminates these residual errors. The additional planning time allows required cognitive processes to be completed before movement onset, thus increasing accuracy. Here we looked to extend these findings by investigating the relationship between increased motor preparation time and the size of imposed visuomotor rotation (30\textdegree, 45\textdegree{} or 60\textdegree ), with regards to the final asymptotic level of adaptation. We found that restricting preparation time to 0.35 seconds impaired adaptation for moderate and larger rotations, resulting in larger residual errors compared to groups with additional preparation time. However, we found that even extended preparation time failed to eliminate persistent errors, regardless of magnitude of cursor rotation. Thus, the asymptote of adaptation was significantly less than the degree of imposed rotation, for all experimental groups. Additionally, there was a positive relationship between asymptotic error and implicit retention. These data suggest that a prolonged motor preparation period is insufficient to reliably achieve complete adaptation and therefore our results provide support for the proposal that the balance between error-based learning and forgetting (i.e., incomplete retention) contributes to asymptotic adaptation levels.},
  langid = {english},
  file = {/Users/thomasgorman/OneDrive - Indiana University/resources/Zotero/Weightman et al_2021_Residual errors in visuomotor adaptation persist despite extended motor.pdf}
}

@article{weitnauerGroupingSimilarityHelps,
  title = {Grouping by {{Similarity Helps Concept Learning}}},
  author = {Weitnauer, Erik and Carvalho, Paulo F and Goldstone, Robert L and Ritter, Helge},
  pages = {6},
  abstract = {In inductive learning, the order in which concept instances are presented plays an important role in learning performance. Theories predict that interleaving instances of different concepts is especially beneficial if the concepts are highly similar to each other, whereas blocking instances belonging to the same concept provides an advantage for learning lowsimilarity concept structures. This leaves open the question of the relative influence of similarity on interleaved versus blocked presentation. To answer this question, we pit withinand between-category similarity effects against each other in a rich categorization task called Physical Bongard Problems. We manipulate the similarity of instances shown temporally close to each other with blocked and interleaved presentation. The results indicate a stronger effect of similarity on interleaving than on blocking. They further show a large benefit of comparing similar between-category instances on concept learning tasks where the feature dimensions are not known in advance but have to be constructed.},
  langid = {english},
  file = {/Users/thomasgorman/OneDrive - Indiana University/resources/Zotero/Weitnauer et al_Grouping by Similarity Helps Concept Learning.pdf}
}

@article{weitnauerSimilaritybasedOrderingInstances,
  title = {Similarity-Based {{Ordering}} of {{Instances}} for {{Efficient Concept Learning}}},
  author = {Weitnauer, Erik and Carvalho, Paulo F and Goldstone, Robert L and Ritter, Helge},
  pages = {7},
  abstract = {Theories in concept learning predict that interleaving instances of different concepts is especially beneficial if the concepts are highly similar to each other, whereas blocking instances belonging to the same concept provides an advantage for learning low-similarity concept structures. This suggests that the performance in concept learning tasks can be improved by grouping the instances of given concepts based on their similarity. To explore this hypothesis, we use Physical Bongard Problems, a rich categorization task with an open feature space, to analyze the combined effects of comparing dissimilar and similar instances within and across categories. We manipulate the within- and between-category similarity of instances presented close to each other in blocked, interleaved and simultaneous presentation schedules. The results show that grouping instances to promote dissimilar within- and similar betweencategory comparisons improves the learning results, to a degree depending on the strategy used by the learner.},
  langid = {english},
  file = {/Users/thomasgorman/Zotero/storage/DHYSKG8X/Weitnauer et al. - Similarity-based Ordering of Instances for Efﬁcien.pdf}
}

@article{westConstrainedScalingEffect2000,
  title = {Constrained Scaling: {{The}} Effect of Learned Psychophysical Scales on Idiosyncratic Response Bias},
  shorttitle = {Constrained Scaling},
  author = {West, Robert L. and Ward, Lawrence M. and Khosla, Rahul},
  year = {2000},
  month = jan,
  journal = {Perception \& Psychophysics},
  volume = {62},
  number = {1},
  pages = {137--151},
  issn = {0031-5117, 1532-5962},
  doi = {10.3758/BF03212067},
  urldate = {2021-05-22},
  langid = {english},
  file = {/Users/thomasgorman/Documents/Zotero_Markdown/west_constrained_2000-zotero.md;/Users/thomasgorman/OneDrive - Indiana University/resources/Zotero/West et al_2000_Constrained scaling.pdf}
}

@article{wifallPerceptualSimilarityAffects,
  title = {Perceptual {{Similarity Affects}} the {{Learning Curve}} (but {{Not Necessarily Leaming}})},
  author = {Wifall, Tim and McMurray, Bob and Hazeltine, Eliot},
  pages = {21},
  abstract = {What role does item similarity play in motor skill acquisition? To examine this question, we used a modified version of the chord learning task (Seibel, 1963) that entails producing simultaneous finger key presses, similar to playing a chord on a piano. In Experiment 1, difficulty, as indexed by response time (RT) to a particular chord on the first session, was held constant, and chords that were similar to other chords had longer RTs after practice than dissimilar chords. In Experiment 2, we used chords that produced different initial RTs to show that similarity affected asymptotic RT rather than the size of RT decrement achieved with practice. In Experiment 3, we eliminated differences in perceptual similarity by using Chinese characters for stimuli while retaining differences in motoric similarity, which resulted in nearly identical asymptotes for similar and dissimilar chords. Thus, the density effect observed in Experiments 1 and 2 appears to stem from competition triggered by similar stimuli. Because performance differences were immediately re-established when stimulus similarity was introduced in Experiment 3 during transfer sessions, competition appears to emerge among leamed, central representations that can be coactivated by multiple stimuli.},
  langid = {english},
  file = {/Users/thomasgorman/OneDrive - Indiana University/resources/Zotero/Wifall et al_Perceptual Similarity Affects the Learning Curve (but Not Necessarily Leaming)4.pdf}
}

@article{wilsonHumanKernel2015,
  title = {The {{Human Kernel}}},
  author = {Wilson, Andrew Gordon and Dann, Christoph and Lucas, Christopher G. and Xing, Eric P.},
  year = {2015},
  month = dec,
  journal = {arXiv:1510.07389 [cs, stat]},
  eprint = {1510.07389},
  primaryclass = {cs, stat},
  urldate = {2021-06-27},
  abstract = {Bayesian nonparametric models, such as Gaussian processes, provide a compelling framework for automatic statistical modelling: these models have a high degree of flexibility, and automatically calibrated complexity. However, automating human expertise remains elusive; for example, Gaussian processes with standard kernels struggle on function extrapolation problems that are trivial for human learners. In this paper, we create function extrapolation problems and acquire human responses, and then design a kernel learning framework to reverse engineer the inductive biases of human learners across a set of behavioral experiments. We use the learned kernels to gain psychological insights and to extrapolate in human-like ways that go beyond traditional stationary and polynomial kernels. Finally, we investigate Occam's razor in human and Gaussian process based function learning.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {/Users/thomasgorman/Documents/Zotero_Markdown/wilson_human_2015-zotero.md;/Users/thomasgorman/OneDrive - Indiana University/resources/Zotero/Wilson et al_2015_The Human Kernel.pdf;/Users/thomasgorman/Zotero/storage/7CPL4C8M/1510.html}
}

@article{wirebringSimilarityBasedProcessHuman2018,
  title = {A {{Similarity-Based Process}} for {{Human Judgment}} in the {{Parietal Cortex}}},
  author = {Wirebring, Linnea Karlsson and Stillesj{\"o}, Sara and Eriksson, Johan and Juslin, Peter and Nyberg, Lars},
  year = {2018},
  journal = {Frontiers in Human Neuroscience},
  volume = {12},
  issn = {1662-5161},
  urldate = {2022-05-27},
  abstract = {One important distinction in psychology is between inferences based on associative memory and inferences based on analysis and rules. Much previous empirical work conceive of associative and analytical processes as two exclusive ways of addressing a judgment task, where only one process is selected and engaged at a time, in an either-or fashion. However, related work indicate that the processes are better understood as being in interplay and simultaneously engaged. Based on computational modeling and brain imaging of spontaneously adopted judgment strategies together with analyses of brain activity elicited in tasks where participants were explicitly instructed to perform similarity-based associative judgments or rule-based judgments (n = 74), we identified brain regions related to the two types of processes. We observed considerable overlap in activity patterns. The precuneus was activated for both types of judgments, and its activity predicted how well a similarity-based model fit the judgments. Activity in the superior frontal gyrus predicted the fit of a rule-based judgment model. The results suggest the precuneus as a key node for similarity-based judgments, engaged both when overt responses are guided by similarity-based and rule-based processes. These results are interpreted such that similarity-based processes are engaged in parallel to rule-based-processes, a finding with direct implications for cognitive theories of judgment.},
  file = {/Users/thomasgorman/Documents/Zotero_Markdown/wirebring_similarity-based_2018-zotero.md;/Users/thomasgorman/OneDrive - Indiana University/resources/Zotero/Wirebring et al_2018_A Similarity-Based Process for Human Judgment in the Parietal Cortex.pdf}
}

@article{wisniewskiIndividualDifferencesAcquisition2014,
  title = {Individual Differences during Acquisition Predict Shifts in Generalization},
  author = {Wisniewski, Matthew G. and Church, Barbara A. and Mercado, Eduardo},
  year = {2014},
  month = may,
  journal = {Behavioural Processes},
  series = {{{SQAB}} 2013: {{Contextual Control}}},
  volume = {104},
  pages = {26--34},
  issn = {0376-6357},
  doi = {10.1016/j.beproc.2014.01.007},
  urldate = {2020-09-02},
  abstract = {Learning to distinguish subtle differences in objects or events can impact how one generalizes. In some cases, training can cause novel events to appear more familiar or attractive than those actually experienced during training: the peak shift effect. This study examined whether individual differences in learning led to systematic patterns of generalization. Participants were trained to identify simulated birdsongs, and then tested on their ability to identify a target song presented among several similar songs that differed in pitch. Initial analysis showed that those attaining moderate proficiency at discriminating songs during training were more likely to shift than those performing poorly or proficiently. However, a neural network trained to output individuals' gradient dynamics using only performance during training as input found an additional set of training variables that predicted shift. Specifically, one subset of shifters had highly conservative response biases accompanied by very little change to perceptual sensitivity in training. These findings suggest that discrimination learning may only lead to generalization shifts in some individuals, and that all individuals who shift may not do so for the same reason.},
  langid = {english},
  keywords = {Artificial neural network,Generalization gradient,Individual differences,Peak shift,Perceptual learning,Signal detection theory},
  file = {/Users/thomasgorman/OneDrive - Indiana University/resources/Zotero/Wisniewski et al_2014_Individual differences during acquisition predict shifts in generalization.pdf;/Users/thomasgorman/Zotero/storage/M89CS58Y/S0376635714000205.html}
}

@article{wrisbergVariabilityPracticeHypothesis1987,
  title = {The {{Variability}} of {{Practice Hypothesis}}: {{Further Tests}} and {{Methodological Discussion}}},
  shorttitle = {The {{Variability}} of {{Practice Hypothesis}}},
  author = {Wrisberg, Craig A. and Winter, Timothy P. and Kuhlman, Jolynn S.},
  year = {1987},
  month = dec,
  journal = {Research Quarterly for Exercise and Sport},
  volume = {58},
  number = {4},
  pages = {369--374},
  issn = {0270-1367, 2168-3824},
  doi = {10.1080/02701367.1987.10608114},
  urldate = {2019-09-06},
  abstract = {In the present study experimental subjects practiced variations in movement distance and/or movement time during training trials on a closed timing task. Control subjects trained with single distance-time combinations. During transfer trials all subjects attempted (without knowledge of results) a distance-time combination that was different (except in the case of one control condition) from any performed during training. The results revealed that the timing accuracy of the two experimental conditions that practiced a variety of times was significantly poorer than that of most of the other conditions during the training phase. However, transfer analyses revealed several significant differences between the performance of variable-trained and constant-trained conditions, in all cases favoring theformer. It was concluded that the transfer benefits of variable practice are (a) not due to the particular movement component selected for variation during training, and (b) to some extentalways determined by the similarity of training and transfer conditions experienced by constant-practice subjects.},
  langid = {english},
  keywords = {{$>$}2 conditions,Benefit of Variability,constant control,Empirical,Motor,Similarity,training hurt by variation,Variability,Varied Manipulation},
  file = {/Users/thomasgorman/Zotero/storage/AP32VZ6C/Wrisberg et al. - 1987 - The Variability of Practice Hypothesis Further Te.pdf}
}

@article{wuTimePressureChanges2022,
  title = {Time Pressure Changes How People Explore and Respond to Uncertainty},
  author = {Wu, Charley M. and Schulz, Eric and Pleskac, Timothy J. and Speekenbrink, Maarten},
  year = {2022},
  month = mar,
  journal = {Scientific Reports},
  volume = {12},
  number = {1},
  pages = {4122},
  publisher = {{Nature Publishing Group}},
  issn = {2045-2322},
  doi = {10.1038/s41598-022-07901-1},
  urldate = {2022-07-05},
  abstract = {How does time pressure influence exploration and decision-making? We investigated this question with several four-armed bandit tasks manipulating (within subjects) expected reward, uncertainty, and time pressure (limited vs. unlimited). With limited time, people have less opportunity to perform costly computations, thus shifting the cost-benefit balance of different exploration strategies. Through behavioral, reinforcement learning (RL), reaction time (RT), and evidence accumulation analyses, we show that time pressure changes how people explore and respond to uncertainty. Specifically, participants reduced their uncertainty-directed exploration under time pressure, were less value-directed, and repeated choices more often. Since our analyses relate uncertainty to slower responses and dampened evidence accumulation (i.e., drift rates), this demonstrates a resource-rational shift towards simpler, lower-cost strategies under time pressure. These results shed light on how people adapt their exploration and decision-making strategies to externally imposed cognitive constraints.},
  copyright = {2022 The Author(s)},
  langid = {english},
  keywords = {Cognitive control,Decision,Human behaviour,Learning algorithms},
  file = {/Users/thomasgorman/OneDrive - Indiana University/resources/Zotero/Wu et al_2022_Time pressure changes how people explore and respond to uncertainty.pdf;/Users/thomasgorman/Zotero/storage/VW9AEHP8/s41598-022-07901-1.html}
}

@article{xuMetricLearningEstimating2012,
  title = {Metric {{Learning}} for {{Estimating Psychological Similarities}}},
  author = {Xu, Jun-Ming and Zhu, Xiaojin and Rogers, Timothy T.},
  year = {2012},
  month = may,
  journal = {ACM Transactions on Intelligent Systems and Technology},
  volume = {3},
  number = {3},
  pages = {1--22},
  issn = {2157-6904, 2157-6912},
  doi = {10.1145/2168752.2168769},
  urldate = {2021-08-26},
  abstract = {An important problem in cognitive psychology is to quantify the perceived similarities between stimuli. Previous work attempted to address this problem with multidimensional scaling (MDS) and its variants. However, there are several shortcomings of the MDS approaches. We propose Yada, a novel general metric-learning procedure based on two-alternative forced-choice behavioral experiments. Our method learns forward and backward nonlinear mappings between an objective space in which the stimuli are defined by the standard feature vector representation and a subjective space in which the distance between a pair of stimuli corresponds to their perceived similarity. We conduct experiments on both synthetic and real human behavioral datasets to assess the effectiveness of Yada. The results show that Yada outperforms several standard embedding and metric-learning algorithms, both in terms of likelihood and recovery error.},
  langid = {english},
  file = {/Users/thomasgorman/OneDrive - Indiana University/resources/Zotero/Xu et al_2012_Metric Learning for Estimating Psychological Similarities.pdf}
}

@article{yangLearningTimeVarying2015,
  title = {Learning of {{Time Varying Functions}} Is {{Based}} on {{Association Between Successive Stimuli}}},
  author = {Yang, Lee-Xieng and Lee, Tzu-Hsi},
  year = {2015},
  journal = {EAPCogSci},
  pages = {6},
  abstract = {In function learning, the to-be-learned function always defines the relationships between stimulus and response. However, when a function defines the stimuli by time points, we can call this type of function as time-varying function. Learning timevarying function would be different from learning other ones. Specifically, the correlation between successive stimuli should play an important role in learning such functions. In this study, three experiments were conducted with the correlations as positive high, negative high, and positive low. The results show people perform well when the correlation between successive stimuli is high, no matter whether it is positive or negative. Also, people have difficulty learning the time-varying function with a low correlation between successive stimuli. A simple two-layered neural network model is evident to be able to provide good accounts for the data of all experiments. These results suggest that learning time varying function is based on association between successive stimuli.},
  langid = {english},
  file = {/Users/thomasgorman/Documents/Zotero_Markdown/yang_learning_2015-zotero.md;/Users/thomasgorman/OneDrive - Indiana University/resources/Zotero/Yang_Lee_Learning of Time Varying Functions is Based on Association Between Successive.pdf}
}

@article{youngHumanSensitivityMagnitude2012,
  title = {Human Sensitivity to the Magnitude and Probability of a Continuous Causal Relation in a Video Game.},
  author = {Young, Michael E. and Cole, James J.},
  year = {2012},
  journal = {Journal of Experimental Psychology: Animal Behavior Processes},
  volume = {38},
  number = {1},
  pages = {11--22},
  issn = {1939-2184, 0097-7403},
  doi = {10.1037/a0026357},
  urldate = {2021-05-22},
  abstract = {Continuous causation, in which incremental changes in one variable cause incremental changes in another, has received little attention in the causal judgment literature. A video game was adapted for the study of continuous causality in order to examine the novel cues to causality that are present in these paradigms. The spatial proximity of an object to an "enemy detector" produced auditory responses as a function of the object's proximity. Participants' behavior was a function of the range of the effect's auditory sensitivity and the moment-to-moment likelihood of detection. This new paradigm provides a rich platform for examining the cues to causation encountered in the learning of continuous causal relations.},
  langid = {english},
  keywords = {gradient search},
  file = {/Users/thomasgorman/Documents/Zotero_Markdown/young_human_2012-zotero.md;/Users/thomasgorman/OneDrive - Indiana University/resources/Zotero/Young_Cole_2012_Human sensitivity to the magnitude and probability of a continuous causal.pdf}
}

@article{zakiCategorizationRecognitionPerformance2003,
  title = {Categorization and Recognition Performance of a Memory-Impaired Group: {{Evidence}} for Single-System Models},
  shorttitle = {Categorization and Recognition Performance of a Memory-Impaired Group},
  author = {Zaki, Safa R. and Nosofsky, Robert M. and Jessup, Nenette M. and Unverzagt, Frederick W.},
  year = {2003},
  month = mar,
  journal = {Journal of the International Neuropsychological Society},
  volume = {9},
  number = {3},
  pages = {394--406},
  issn = {1355-6177, 1469-7661},
  doi = {10.1017/S1355617703930050},
  urldate = {2020-09-09},
  abstract = {Previous research has demonstrated dissociations between  categorization and recognition performance in amnesic patients,  supporting the idea that separate memory systems govern these  tasks. However, previous research has also demonstrated that  these dissociations are predicted by a single-system model that  allows for reasonable parameter differences across groups.  Generally, previous studies have employed categorization tasks  that are less demanding than the recognition tasks. In this  study, we distinguish between single-system and multiple-system  accounts by testing memory-impaired individuals in a more demanding  categorization task. These patients, just like previous amnesic  participants, show a dissociation between categorization and  recognition when tested in previously employed paradigms. However,  they display a categorization deficit when tested in the more  challenging categorization task. The results are interpreted  as support for a single-system framework in which categorization  and recognition depend on one representational system.  (               JINS               , 2003,               9               , 394\textendash 406.)},
  langid = {english},
  file = {/Users/thomasgorman/Zotero/storage/EZJJL7XJ/Zaki et al. - 2003 - Categorization and recognition performance of a me.pdf}
}

@article{zakiExemplarAccountsBlending,
  title = {Exemplar Accounts of Blending and Distinctiveness Effects in Perceptual Old\textendash New Recognition},
  author = {Zaki, Safa R. and Nosofsky, R. M.},
  urldate = {2020-09-06},
  file = {/Users/thomasgorman/Zotero/storage/88HCYQ6P/Zaki and Nosofsky - Exemplar accounts of blending and distinctiveness .pdf}
}

@article{zakiHighdistortionEnhancementEffect2007,
  title = {A High-Distortion Enhancement Effect in the Prototype-Learning Paradigm: {{Dramatic}} Effects of Category Learning during Test},
  shorttitle = {A High-Distortion Enhancement Effect in the Prototype-Learning Paradigm},
  author = {Zaki, Safa R. and Nosofsky, Robert M.},
  year = {2007},
  month = dec,
  journal = {Memory \& Cognition},
  volume = {35},
  number = {8},
  pages = {2088--2096},
  issn = {0090-502X, 1532-5946},
  doi = {10.3758/BF03192940},
  urldate = {2020-07-18},
  langid = {english},
  keywords = {Learning during testing,testing issues},
  file = {/Users/thomasgorman/Zotero/storage/FMV9K53I/Zaki and Nosofsky - 2007 - A high-distortion enhancement effect in the protot.pdf}
}

@article{zakiPrototypeExemplarAccounts2003,
  title = {Prototype and {{Exemplar Accounts}} of {{Category Learning}} and {{Attentional Allocation}}: {{A Reassessment}}.},
  shorttitle = {Prototype and {{Exemplar Accounts}} of {{Category Learning}} and {{Attentional Allocation}}},
  author = {Zaki, Safa R. and Nosofsky, Robert M. and Stanton, Roger D. and Cohen, Andrew L.},
  year = {2003},
  journal = {Journal of Experimental Psychology: Learning, Memory, and Cognition},
  volume = {29},
  number = {6},
  pages = {1160--1173},
  issn = {1939-1285, 0278-7393},
  doi = {10.1037/0278-7393.29.6.1160},
  urldate = {2020-07-19},
  langid = {english},
  file = {/Users/thomasgorman/Zotero/storage/L2MLY9NB/Zaki et al. - 2003 - Prototype and Exemplar Accounts of Category Learni.pdf}
}

@article{zauharConcurrentDynamicsCategory2016,
  title = {Concurrent {{Dynamics}} of {{Category Learning}} and {{Metacognitive Judgments}}},
  author = {{\v Z}auhar, Valnea and Baj{\v s}anski, Igor and Domijan, Dra{\v z}en},
  year = {2016},
  journal = {Frontiers in Psychology},
  volume = {7},
  pages = {1473},
  issn = {1664-1078},
  doi = {10.3389/fpsyg.2016.01473},
  urldate = {2021-12-05},
  abstract = {In two experiments, we examined the correspondence between the dynamics of metacognitive judgments and classification accuracy when participants were asked to learn category structures of different levels of complexity, i.e., to learn tasks of types I, II, and III according to Shepard et al. (1961). The stimuli were simple geometrical figures varying in the following three dimensions: color, shape, and size. In Experiment 1, we found moderate positive correlations between confidence and accuracy in task type II and weaker correlation in task type I and III. Moreover, the trend analysis in the backward learning curves revealed that there is a non-linear trend in accuracy for all three task types, but the same trend was observed in confidence for the task type I and II but not for task type III. In Experiment 2, we found that the feeling-of-warmth judgments (FOWs) showed moderate positive correlation with accuracy in all task types. Trend analysis revealed a similar non-linear component in accuracy and metacognitive judgments in task type II and III but not in task type I. Our results suggest that FOWs are a more sensitive measure of the progress of learning than confidence because FOWs capture global knowledge about the category structure, while confidence judgments are given at the level of an individual exemplar.},
  keywords = {backwards learning curve,meta-learning},
  file = {/Users/thomasgorman/OneDrive - Indiana University/resources/Zotero/Žauhar et al_2016_Concurrent Dynamics of Category Learning and Metacognitive Judgments.pdf}
}

@article{zhangAcquisitionRepresentationTransfer2015,
  title = {Acquisition, Representation, and Transfer of Models of Visuo-Motor Error},
  author = {Zhang, Hang and Kulsa, Mila Kirstie C. and Maloney, Laurence T.},
  year = {2015},
  month = jun,
  journal = {Journal of Vision},
  volume = {15},
  number = {8},
  pages = {6--6},
  publisher = {{The Association for Research in Vision and Ophthalmology}},
  issn = {1534-7362},
  doi = {10.1167/15.8.6},
  urldate = {2021-05-22},
  langid = {english},
  file = {/Users/thomasgorman/OneDrive - Indiana University/resources/Zotero/Zhang et al_2015_Acquisition, representation, and transfer of models of visuo-motor error.pdf;/Users/thomasgorman/Zotero/storage/APZV5EC2/article.html}
}

@article{zhangDecisionModelsGeneralizing2015,
  title = {Decision from {{Models}}: {{Generalizing Probability Information}} to {{Novel Tasks}}},
  shorttitle = {Decision from {{Models}}},
  author = {Zhang, Hang and Paily, Jacienta T. and Maloney, Laurence T.},
  year = {2015},
  month = jan,
  journal = {Decision (Washington, D.C.)},
  volume = {2},
  number = {1},
  pages = {39--53},
  issn = {2325-9965},
  doi = {10.1037/dec0000022},
  urldate = {2021-05-16},
  abstract = {We investigate a new type of decision under risk where\textemdash to succeed\textemdash participants must generalize their experience in one set of tasks to a novel set of tasks. We asked participants to trade distance for reward in a virtual minefield where each successive step incurred the same fixed probability of failure (referred to as hazard). With constant hazard, the probability of success (the survival function) decreases exponentially with path length. On each trial, participants chose between a shorter path with smaller reward and a longer (more dangerous) path with larger reward. They received feedback in 160 training trials: encountering a mine along their chosen path resulted in zero reward and successful completion of the path led to the reward associated with the path chosen. They then completed 600 no-feedback test trials with novel combinations of path length and rewards. To maximize expected gain, participants had to learn the correct exponential model in training and generalize it to the test conditions. We compared how participants discounted reward with increasing path length to the predictions of nine choice models including the correct exponential model. The choices of a majority of the participants were best accounted for by a model of the correct exponential form although with marked overestimation of the hazard rate. The decision-from-models paradigm differs from experience-based decision paradigms such as decision-from-sampling in the importance assigned to generalizing experience-based information to novel tasks. The task itself is representative of everyday tasks involving repeated decisions in stochastically invariant environments.},
  pmcid = {PMC4300983},
  pmid = {25621287},
  file = {/Users/thomasgorman/Documents/Zotero_Markdown/zhang_decision_2015-zotero.md;/Users/thomasgorman/OneDrive - Indiana University/resources/Zotero/Zhang et al_2015_Decision from Models.doc;/Users/thomasgorman/OneDrive - Indiana University/resources/Zotero/Zhang et al_2015_Decision from Models2.pdf}
}

@article{zhangInformationSamplingExplains,
  title = {Information Sampling Explains {{Bayesian}} Learners' Biases in Correlation Judgment},
  author = {Zhang, Xiumei and He, Lisheng and Bhatia, Sudeep},
  pages = {9},
  abstract = {Correlation judgments are at the core of belief formation. In previous studies of correlation judgment from 2D scatterplots, observers underestimate correlations, and display stronger underestimation biases when the scatterplot is shown in a landscape view than in a portrait view. Yet, it is unclear how these biases arise. Here, we propose that observers are Bayesian learners who perform ``mental regression'' using the observed data points in graph. Accordingly, judgment errors can arise from biased visual information sampling. We test our model's predictions with two eye-tracking experiments and find that the Bayesian learning model, applied to information obtained from visual fixation data, replicates classic behavioral findings. The model also predicts trial-level estimation biases at a high accuracy level. Our study shows how computational models trained on process-level data can shed light on the cognitive mechanisms underlying belief formation, and yield theory-driven practical implications for data visualization and statistical communication.},
  langid = {english},
  file = {/Users/thomasgorman/Documents/Zotero_Markdown/zhangInformationSamplingExplains-zotero.md;/Users/thomasgorman/Documents/Zotero_Markdown/zhangInformationSamplingExplainsa-zotero.md;/Users/thomasgorman/OneDrive - Indiana University/resources/Zotero/Zhang et al_Information sampling explains Bayesian learners’ biases in correlation judgment.pdf}
}

@article{zhangSpatialRepresentationOrdinal2016,
  title = {Spatial {{Representation}} of {{Ordinal Information}}},
  author = {Zhang, Meng and Gao, Xuefei and Li, Baichen and Yu, Shuyuan and Gong, Tianwei and Jiang, Ting and Hu, Qingfen and Chen, Yinghe},
  year = {2016},
  journal = {Frontiers in Psychology},
  volume = {7},
  publisher = {{Frontiers}},
  issn = {1664-1078},
  doi = {10.3389/fpsyg.2016.00505},
  urldate = {2021-04-09},
  abstract = {Right hand responds faster than left hand when shown larger numbers and vice-versa when shown smaller numbers (the SNARC effect). Accumulating evidence suggests that the SNARC effect may not be exclusive for numbers and can be extended to other ordinal sequences (e.g., months or letters in the alphabet) as well. In this study, we tested the SNARC effect with a non-numerically ordered sequence: The Chinese notations for the color spectrum (Red, Orange, Yellow, Green, Blue, Indigo, and Violet). Chinese color word sequence reserves relatively weak ordinal information, because each element color in the sequence normally appears in non-sequential contexts, making it ideal to test the spatial organization of sequential information that was stored in the long-term memory. This study found a reliable SNARC-like effect for Chinese color words (deciding whether the presented color word was before or after the reference color word ``green''), suggesting that, without access to any quantitative information or exposure to any previous training, ordinal representation can still activate a sense of space. The results support that weak ordinal information without quantitative magnitude encoded in the long-term memory can activate spatial representation in a comparison task.},
  langid = {english},
  keywords = {Chinese color words,Numerical cognition,Ordinal sequences,SNARC effect,spatial representation},
  file = {/Users/thomasgorman/OneDrive - Indiana University/resources/Zotero/Zhang et al_2016_Spatial Representation of Ordinal Information.pdf}
}

@article{zhaoBuildingObjectbasedCausal2021,
  title = {Building {{Object-based Causal Programs}} for {{Human-like Generalization}}},
  author = {Zhao, Bonan and Lucas, Christopher G. and Bramley, Neil R.},
  year = {2021},
  month = nov,
  journal = {arXiv:2111.12560 [cs]},
  eprint = {2111.12560},
  primaryclass = {cs},
  urldate = {2021-12-04},
  abstract = {We present a novel task that measures how people generalize objects' causal powers based on observing a single (Experiment 1) or a few (Experiment 2) causal interactions between object pairs. We propose a computational modeling framework that can synthesize human-like generalization patterns in our task setting, and sheds light on how people may navigate the compositional space of possible causal functions and categories efficiently. Our modeling framework combines a causal function generator that makes use of agent and recipient objects' features and relations, and a Bayesian non-parametric inference process to govern the degree of similarity-based generalization. Our model has a natural "resource-rational" variant that outperforms a naive Bayesian account in describing participants, in particular reproducing a generalization-order effect and causal asymmetry observed in our behavioral experiments. We argue that this modeling framework provides a computationally plausible mechanism for real world causal generalization.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Other Computer Science},
  file = {/Users/thomasgorman/OneDrive - Indiana University/resources/Zotero/Zhao et al_2021_Building Object-based Causal Programs for Human-like Generalization.pdf;/Users/thomasgorman/Zotero/storage/FQ4W3VEM/2111.html}
}

@techreport{zhuAutocorrelatedBayesianSampler2021,
  type = {Preprint},
  title = {The {{Autocorrelated Bayesian Sampler}} for {{Estimation}}, {{Choice}}, {{Confidence}}, and {{Response Times}}},
  author = {Zhu, Jian-Qiao and Sundh, Joakim and Chater, Nick and Sanborn, Adam N},
  year = {2021},
  month = feb,
  institution = {{PsyArXiv}},
  doi = {10.31234/osf.io/3qxf7},
  urldate = {2021-02-13},
  abstract = {Estimation, choice, confidence, and response times are the primary behavioural measures in perceptual and cognitive tasks. These measures have attracted extensive modeling efforts in the cognitive sciences, but there is the lack of a unified approach to explain all measures simultaneously within one framework. We propose an Autocorrelated Bayesian Sampler (ABS), assuming that people sequentially sample from a posterior probability distribution of hypotheses on each trial of a perceptual or cognitive task. Unlike most accounts of choice, we do not assume that the system has global knowledge of the posterior distribution. Instead it uses a sophisticated sampling algorithm to make do with local knowledge, and so produces autocorrelated samples. The model assumes that each sample takes time to generate, and that samples are used by well-validated mechanisms to produce estimates, choices, and confidence judgments. This relatively simple framework clears a number of well-known empirical hurdles for models of choice, confidence, and response time. The autocorrelation between samples also allows the model to predict the long-range between-trial dependence observed in both estimates and response times.},
  langid = {english},
  file = {/Users/thomasgorman/OneDrive - Indiana University/resources/Zotero/Zhu et al_2021_The Autocorrelated Bayesian Sampler for Estimation, Choice, Confidence, and.pdf}
}

@article{zhuLearningPerceiveAffordance2010,
  title = {Learning {{To Perceive}} the {{Affordance}} for {{Long-Distance Throwing}}: {{Smart Mechanism}} or {{Function Learning}}?},
  shorttitle = {Learning {{To Perceive}} the {{Affordance}} for {{Long-Distance Throwing}}},
  author = {Zhu, {\relax QIN} and Bingham, Geoffrey},
  year = {2010},
  journal = {Journal of experimental psychology. Human perception and performance},
  volume = {36},
  pages = {862--75},
  doi = {10.1037/a0018738},
  abstract = {Bingham, Schmidt, \& Rosenblum, (1989) showed that people are able to select, by hefting balls, the optimal weight for each size ball to be thrown farthest. We now investigate function learning and smart mechanisms as hypotheses about how this affordance is perceived. Twenty-four unskilled adult throwers learned to throw by practicing with a subset of balls that would only allow acquisition of the ability to perceive the affordance if hefting acts as a smart mechanism to provide access to a single information variable that specifies the affordance. Participants hefted 48 balls of different sizes and weights and judged throwability. Then, participants, assigned to one of four groups, practiced throwing (three groups with vision and one without) for a month using different subsets of balls. Finally, hefting and throwing were tested again with all the balls. The results showed: (1) inability to detect throwability before practice, (2) throwing improved with practice, and (3) participants learned to perceive the affordance, but only with visual feedback. These results indicated that the affordance is perceived using a smart mechanism acquired while learning to throw.},
  file = {/Users/thomasgorman/OneDrive - Indiana University/resources/Zotero/ZHU_Bingham_2010_Learning To Perceive the Affordance for Long-Distance Throwing.pdf}
}
