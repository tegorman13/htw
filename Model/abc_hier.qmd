---
title: Individual ABC Fits
author: Thomas Gorman
date: "`r Sys.Date()`"
code-fold: true
code-tools: true
execute: 
  warning: false
  eval: true
---





```{r}

pacman::p_load(dplyr,purrr,tidyr,ggplot2, data.table, here, patchwork, conflicted, stringr)
conflict_prefer_all("dplyr", quiet = TRUE)

walk(c("Display_Functions"), ~ source(here::here(paste0("Functions/", .x, ".R"))))
ds <- readRDS(here::here("data/e1_md_11-06-23.rds"))  |> as.data.table()
ids <- c(1,2,4,5,6,7,8, 10,11,12,13)
ids2 <- c(1,66,36)
ids3 <- c(20,71,101,4,76,192)
idsBad <- c(76,192, 101)

source(here::here("Functions/fun_indv_fit.R"))

```




```{r fig.width=11, fig.height=10}

#ind_fits <- readRDS(here::here("data/indv_sim/ind_abc_ss_1000_ng100_bufp55.rds"))

ind_fits <- readRDS(here::here("data/indv_sim/ind_abc_2000_ng100_buf5.rds"))


ind_fits_df <- imap_dfr(ind_fits |> list_assign(runInfo = zap()), ~imap_dfr(.x, ~{
  teter_data <- .x[["teter_results"]] %>% mutate(result_type = "teter_results")
  te_data <- .x[["te_results"]] %>% mutate(result_type = "te_results")
  tr_data <- .x[["tr_results"]] %>% mutate(result_type = "tr_results")
  combined_data <- bind_rows(teter_data, te_data, tr_data)
}, .id = "id"))


post_dat <- ind_fits_df |> 
  select(sim_dat,rank) |> unnest(sim_dat,names_repair = repair_names) |> filter(expMode2=="Test") |>
  group_by(id,condit,x) |>
  mutate(avg_y=mean(y)) |> 
  relocate(id,condit,Model,Fit_Method,expMode2,tr,rank,c,lr,x,y,avg_y) 

post_dat_l <- post_dat %>%
  pivot_longer(
    cols = c(pred, y),
    names_to = "Resp",
    values_to = "val"
  ) %>%
  mutate(
    Resp = case_when(
      Resp == "y" ~ "Observed",
      Model == "ALM" ~ "ALM",
      Model == "EXAM" ~ "EXAM"
    )
  ) |> arrange(tr,id,Resp) 


```


```{r}

```

##  Posterior Average Table: 
```{r fig.width=12, fig.height=17}
#| eval: true
post_tabs <- abc_tables(post_dat_l)
post_tabs$et_sum |> gt::gt()

post_tabs$et_sum |> select(condit,Fit_Method,Avg_ALM_error, Avg_EXAM_error) |> filter(Fit_Method=="Test Only")

```

## Distributions: 
```{r, fig.width=12, fig.height=17}
#| eval: true
plot_sampled_posterior(ind_fits)
plot_indv_posterior(ind_fits_df)


ind_fits_df |> filter(id %in% ids2, Fit_Method=="Test & Train") |> 
  ggplot(aes(x=c)) + geom_density(aes(fill=Group), alpha=.5) + 
  facet_wrap(id~Model,scales="free",ncol=2) + 
  theme_bw() + theme(legend.position = "bottom") + labs(title = "Posterior distribution of c") 

ind_fits_df |> filter(id %in% ids2, Fit_Method=="Test & Train") |> 
  ggplot(aes(x=lr)) + geom_density(aes(fill=Group), alpha=.5) + 
  facet_wrap(id~Model,scales="free",ncol=2) + 
  theme_bw() + theme(legend.position = "bottom") + labs(title = "Posterior distribution of c") 


ind_fits_df |> filter(id %in% idsBad, Fit_Method=="Test & Train") |> 
  ggplot(aes(x=c)) + geom_density(aes(fill=Group), alpha=.5) + 
  facet_wrap(id~Model,scales="free",ncol=2) + 
  theme_bw() + theme(legend.position = "bottom") + labs(title = "Posterior distribution of c") 

ind_fits_df |> filter(id %in% idsBad, Fit_Method=="Test & Train") |> 
  ggplot(aes(x=lr)) + geom_density(aes(fill=Group), alpha=.5) + 
  facet_wrap(id~Model,scales="free",ncol=2) + 
  theme_bw() + theme(legend.position = "bottom") + labs(title = "Posterior distribution of c") 


```


## Distributions: 
```{r, fig.width=12, fig.height=15}
#| eval: true
plot_sampled_posterior(ind_fits)
plot_indv_posterior(ind_fits_df)

```

## Posterior Predictive: 
```{r, fig.width=12, fig.height=14}
#| eval: true
group_predictive_plots(post_dat_l)
group_best_plots(post_dat_l)
```



## Individual Plots:
```{r, fig.width=12, fig.height=17}
#| eval: true
indv_best_plots(post_dat_l)
indv_predictive_plots(post_dat_l, ids2)
indv_predictive_plots(post_dat_l, idsBad)

```


## Bigger Tables:
```{r}
#| eval: true

post_tabs$et_sum_x |> kable()

post_tabs$et_sum_x_indv |> kable()
```




##  Posterior Average
```{r fig.width=12, fig.height=17}

et <- post_dat_l |>
  group_by(id, condit, Fit_Method, Resp, x) |>
  summarise(val = mean(val), .groups = 'drop') |>
  pivot_wider(
    names_from = Resp,
    values_from = val,
    values_fill = list(val = NA)
  ) |>
  mutate(
    ALM_error = abs(ALM - Observed),
    EXAM_error = abs(EXAM - Observed),
    Best_Model = case_when(
      ALM_error < EXAM_error ~ "ALM",
      EXAM_error < ALM_error ~ "EXAM",
      TRUE ~ NA_character_  # In case of a tie or missing data
    )
  )

et_counts <- et %>%
  group_by(condit,Fit_Method, Best_Model) %>% 
  summarise(count = n(), .groups = 'drop')


 ggplot(et, aes(x = factor(x), fill = Best_Model)) +
  geom_bar(position = "dodge") +
  facet_wrap(condit~Fit_Method, scales = "free") +
  labs(
    title = "Frequency of Best Model by x Value",
    x = "x Value",
    y = "Frequency",
    fill = "Best Model"
  ) +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))



ggplot(et, aes( x = factor(x), y = id, fill = Best_Model)) +
  geom_tile(color = "white") +
  facet_wrap(condit~Fit_Method,scales="free") +
  labs(title = "Best Model for Each ID and X Value",
       x = "X",
       y = "ID",
       fill = "Best Model") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 90, hjust = 1))




et_sum_x <- post_dat_l |>
  group_by(condit, Fit_Method, Resp, x) |>
  summarise(val = mean(val), .groups = 'drop') |>
  pivot_wider(
    names_from = Resp,
    values_from = val,
    values_fill = list(val = NA)
  ) |>
  group_by(condit, Fit_Method, x) |>
  transmute(
    ALM_error = abs(ALM - Observed),
    EXAM_error = abs(EXAM - Observed),
    Best_Model = case_when(
      ALM_error < EXAM_error ~ "ALM",
      EXAM_error < ALM_error ~ "EXAM",
      TRUE ~ NA_character_  # In case of a tie or missing data
    )
  ) 






et_sum_id <- post_dat_l |>
  group_by(id,condit, Fit_Method, Resp) |>
  summarise(val = mean(val), .groups = 'drop') |>
  pivot_wider(
    names_from = Resp,
    values_from = val,
    values_fill = list(val = NA)
  ) |>
  group_by(id,condit, Fit_Method) |>
  transmute(
    ALM_error = abs(ALM - Observed),
    EXAM_error = abs(EXAM - Observed),
    Best_Model = case_when(
      ALM_error < EXAM_error ~ "ALM",
      EXAM_error < ALM_error ~ "EXAM",
      TRUE ~ NA_character_  # In case of a tie or missing data
    )
  ) 


et_sum <- post_dat_l |>
  group_by(id,condit, Fit_Method, Resp) |>
  summarise(val = mean(val), .groups = 'drop') |>
  pivot_wider(
    names_from = Resp,
    values_from = val,
    values_fill = list(val = NA)
  ) |>
  mutate(
    ALM_error = abs(ALM - Observed),
    EXAM_error = abs(EXAM - Observed),
    Best_Model = case_when(
      ALM_error < EXAM_error ~ "ALM",
      EXAM_error < ALM_error ~ "EXAM",
      TRUE ~ NA_character_  # In case of a tie or missing data
    )
  ) |>
  group_by(condit, Fit_Method) %>%
  summarise(
    Avg_ALM_error = mean(ALM_error, na.rm = TRUE),
    Avg_EXAM_error = mean(EXAM_error, na.rm = TRUE),
    N_ALM = sum(Best_Model == "ALM", na.rm = TRUE),
    N_EXAM = sum(Best_Model == "EXAM", na.rm = TRUE)
  ) %>%
  mutate(
    Best_Model = case_when(
      Avg_ALM_error < Avg_EXAM_error ~ "ALM",
      Avg_EXAM_error < Avg_ALM_error ~ "EXAM",
      TRUE ~ "Tie"  # In case of a tie or missing data
    )
  )





# unique(et$Resp)
# unique(et$Fit_Method)
# unique(et$condit)
# unique(et$x)

```



```{r}






```



```{r, fig.width=12, fig.height=11}
source(here::here("Functions/fun_indv_fit.R"))

plot_sampled_posterior(ind_fits)
plot_indv_posterior(ind_fits_df)
group_predictive_plots(ind_fits_df)
group_best_plots(ind_fits_df)
indv_best_plots(ind_fits_df)
indv_predictive_plots(ind_fits_df, ids2)
indv_predictive_plots(ind_fits_df, idsBad)
```

```{r}


pdf(here::here("assets/tmp_plots/test.pdf"))
plot_sampled_posterior(ind_fits)
plot_indv_posterior(ind_fits_df)
group_predictive_plots(ind_fits_df)
group_best_plots(ind_fits_df)
indv_best_plots(ind_fits_df)
indv_predictive_plots(ind_fits_df, ids2)
indv_predictive_plots(ind_fits_df, idsBad)
dev.off()

```



```{r fig.width=10, fig.height=8}

post_dat_l |> group_by(id,condit,Fit_Method, Resp,x) |>
  summarise(val=mean(val)) |>
  ggplot(aes(x = x, y = val, fill=Resp)) + 
  stat_bar + 
  facet_wrap(condit~Fit_Method, scales="free") + 
  labs(title = "Full Posterior")

post_dat_l |> group_by(id,condit,Fit_Method, Resp,x) |>
  filter(rank==1) |>
  summarise(val=mean(val)) |>
  ggplot(aes(x = x, y = val, fill=Resp)) + 
  stat_bar + 
  facet_wrap(condit~Fit_Method, scales="free") + 
  labs(title = "Full Posterior")
```



```{r fig.width=11, fig.height=15}



post_dat_l |> filter(id %in% ids2, rank==1) |> ggplot(aes(x = x, y = val, fill=Resp)) + 
  stat_bar + 
  facet_wrap(Fit_Method~id, scales="free") + 
  labs(title = "Single Best Fit")

post_dat_l |> filter(id %in% ids2) |> ggplot(aes(x = x, y = val, fill=Resp)) + 
  stat_bar + 
  facet_wrap(Fit_Method~id, scales="free") + 
  labs(title = "Average of posterior predictive distributions")

post_dat_l |> filter(id %in% ids2, rank<=10) |> ggplot(aes(x = x, y = val, fill=Resp)) + 
  stat_bar + 
  facet_wrap(Fit_Method~id, scales="free") + 
  labs(title = "10 best fits")

post_dat |> filter(id %in% ids2) |> ggplot(aes(x = x, y = y, fill=condit)) + 
  stat_summary(fun=mean, geom="bar", position=position_dodge(), alpha=.75) +
  stat_summary(fun.data=mean_se, geom="errorbar", position=position_dodge()) +
  stat_halfeye(aes(x=x,y=pred,color=condit),position=position_dodge()) +
  ggh4x::facet_nested_wrap(Fit_Method~Model~id, ncol=6, scales="free") + labs(title = "Average of posterior predictive distributions")


r_all <- post_dat_l |> filter(id %in% ids) |> mutate(dist="All")
r1 <- post_dat_l |> filter(id %in% ids, rank==1) |> mutate(dist="best")
r_10 <- post_dat_l |> filter(id %in% ids, rank<=10) |> mutate(dist="top10")

d <- bind_rows(r_all,r1)

d |> ggplot(aes(x = x, y = val, fill=Resp)) + 
  stat_bar + 
  ggh4x::facet_nested_wrap(id~Fit_Method~dist, scales="free",ncol=6) + 
  labs(title = "Average of posterior predictive distributions")


```




```{r}



```




```{r}

library(dtplyr)

post_dt <- ind_fits_df |> select(sim_dat,rank) |> unnest(sim_dat) # > dtplyr::lazy_dt()
post_dat <- ind_fits_df |> select(sim_dat,rank) |> unnest(sim_dat) |> as.data.table()

post_dat1 <- filter(post_dat,expMode2=="Test") |>
  group_by(id,condit,x) |>
  mutate(avg_y=mean(y)) |> 
  #relocate(id,condit,Model,Fit_Method,expMode2,tr,rank,c,lr,x,y,avg_y) |>
  show_query()


t1 <- system.time({ 
post_dat1 <- filter(post_dat,expMode2=="Test") |>
  group_by(id,condit,x) |>
  mutate(avg_y=mean(y)) |> 
  relocate(id,condit,Model,Fit_Method,expMode2,tr,rank,c,lr,x,y,avg_y) |>
  pivot_longer(
    cols = c(pred, y),
    names_to = "Resp",
    values_to = "val"
  ) %>%
  mutate(
    Resp = case_when(
      Resp == "y" ~ "Observed",
      Model == "ALM" ~ "ALM",
      Model == "EXAM" ~ "EXAM"
    )
  ) |> arrange(tr,id,Resp) 
})

t2 <- system.time({ 
post_dat2 <- setorder(melt(setcolorder(post_dat[expMode2 == "Test"][, `:=`(avg_y = mean(y)), 
    by = .(id, condit, x)], c("id", "condit", "Model", "Fit_Method", 
"expMode2", "tr", "rank", "c", "lr", "x", "y", "avg_y", "pred", 
"resid")), measure.vars = c("pred", "y"), variable.name = "Resp", 
    value.name = "val", variable.factor = FALSE)[, `:=`(Resp = fcase(Resp == 
    "y", "Observed", Model == "ALM", "ALM", Model == "EXAM", 
    "EXAM")), by = .(id, condit, x)], tr, id, Resp, na.last = TRUE)
})

show_query()
post_dat_l <- post_dat %>%
  
```


```{r}




post_ev <- ind_fits$id_fits_exam_varied |> 
  map_dfr(~tibble(pluck(.x$teter_results)),.id = "id") |> 
  filter(id %in% c(13)) |> 
  filter(rank==1) |> 
  select(sim_dat) |> unnest(sim_dat) 


post_ev |> filter(expMode2=="Test") |> 
  ggploat(aes(x = x, y = pred, fill=condit)) + 
  stat_summary(fun=mean, geom="bar", position=position_dodge(), alpha=.75) +
  stat_summary(fun.data=mean_se, geom="errorbar", position=position_dodge()) +
  #stat_summary(fun=mean, geom="point", aes(x=x,y=y,color=condit), position=position_dodge()) +
  stat_halfeye(aes(x=x,y=y,color=condit),position=position_dodge()) +
  ggh4x::facet_nested_wrap(~id) + labs(title = "Average of posterior predictive distributions")  



post_alm <- ind_fits$id_fits_alm_varied |> 
  map_dfr(~tibble(pluck(.x$teter_results)),.id = "id") |> 
  filter(id %in% c(1,2,4,5,6,7,8, 10,11,12,13)) |> 
  filter(rank<10) |> 
  select(sim_dat) |> unnest(sim_dat) 

post_alm |> filter(expMode2=="Test") |> 
  ggplot(aes(x = x, y = pred, fill=condit)) + 
  stat_summary(fun=mean, geom="bar", position=position_dodge(), alpha=.75) +
  stat_summary(fun.data=mean_se, geom="errorbar", position=position_dodge()) +
  #stat_summary(fun=mean, geom="point", aes(x=x,y=y,color=condit), position=position_dodge()) +
  stat_halfeye(aes(x=x,y=y,color=condit),position=position_dodge()) +
  ggh4x::facet_nested_wrap(~id) + labs(title = "Average of posterior predictive distributions")  



```





```{r}
#| eval: false
# ind_abc_s500_ng300_buf5 <- readRDS("~/Library/CloudStorage/GoogleDrive-tegorman13@gmail.com/My Drive/HTW/gl/data/indv_sim/ind_abc_s500_ng300_buf5.rds")

ind_abc_ss_1000_13_56_52 <- readRDS("~/Library/CloudStorage/GoogleDrive-tegorman13@gmail.com/My Drive/HTW/gl/data/indv_sim/ind_abc_ss_1000_13_56_52.rds")


abc_ev <- ind_abc_ss_1000_13_56_52$id_fits_exam_varied |>
  map_dfr(~tibble(pluck(.x$teter_results)),.id = "id") |> filter(id %in% c(1,2)) |> select(sim_dat) |> unnest(sim_dat) |> filter(rank==1)



abc_ev <- ind_abc_s500_ng300_buf5$id_fits_exam_varied |>
  map_dfr(~tibble(pluck(.x$teter_results)),.id = "id") |> filter(id %in% c(1,2)) |>
  map(sim_dat)


abc_ev <- ind_abc_s500_ng300_buf5$id_fits_exam_varied |>
  map_dfr(~tibble(pluck(.x$teter_results)),.id = "id") |> filter(id %in% c(1,2)) |> select(sim_dat) |>
  pluck("sim_dat")


abc_ev <- ind_abc_s500_ng300_buf5$id_fits_exam_varied |>
  map_dfr(~tibble(pluck(.x$teter_results)),.id = "id") |> filter(id %in% c(1,2)) |> select(sim_dat) |> unnest(sim_dat) |> filter(rank==1) |>
  mutate(pred=pred[[1]])
  #mutate(pred=unnest(pred)$...195,resid=unnest(resid)$...195 )

abc_ev |> filter(expMode2=="Test") |> 
  ggplot(aes(x = x, y = pred, fill=condit)) + 
  stat_summary(fun=mean, geom="bar", position=position_dodge(), alpha=.75) +
  stat_summary(fun.data=mean_se, geom="errorbar", position=position_dodge()) +
  #stat_summary(fun=mean, geom="point", aes(x=x,y=y,color=condit), position=position_dodge()) +
  stat_halfeye(aes(x=x,y=y,color=condit),position=position_dodge()) +
  ggh4x::facet_nested_wrap(~id) + labs(title = "Average of posterior predictive distributions")  

colnames(abc_ev)
k=abc_ev["pred"]
names(k)


abc_ev <- id_fits_exam_varied |>
  map_dfr(~tibble(pluck(.x$teter_results)),.id = "id") |> filter(id %in% c(1,2)) |> select(sim_dat) |> unnest(sim_dat)


```





# learning curve code
nbins <- 10
maxT <- 200
t <- dg[trial<=maxT] %>% .[,Block:=cut(trial,breaks=seq(1,maxT+(nbins-2),nbins),include.lowest=TRUE,labels=FALSE),by=id] %>%
 .[,c("id","agebin","nth_play","trial","Block","Rt","rt.max.5s","gameState","ng1","gsum1","gameState3","ng3","gsum3")]
t[, trial_perc_bin := cut(trial/max(trial), breaks = seq(0, 1, .1), include.lowest = TRUE), by = id]
# 

```{r}


  sim_data_gen_s <- function(data, input_layer, output_layer, simulation_function, prior_samples, return_dat) {
    simulation_function <- match.fun(simulation_function)
    suppressMessages(simulation_results <- map_dfc(seq_len(nrow(prior_samples)), function(idx) {
      params <- prior_samples[idx, ]
      simulation_function(data=as.data.table(data), c=params$c, lr=params$lr, input_layer=input_layer, output_layer=output_layer, return_dat = return_dat)    
      }))
  }




input_layer =  c(100,350,600,800,1000,1200)
output_layer = input_layer
return_dat="train_data, test_data"
data <- ds |> filter(id==1) 
train_idx <- which(data$expMode2=="Train")
test_idx <- which(data$expMode2=="Test")

kde_results <- purrr::map(group_posterior_all, ~purrr::map_if(.x, is.list, ~compute_kde(.x$c, .x$lr, ngrid = 100, nsamples=100)))

sim_data <- sim_data_gen_s(data,input_layer,output_layer,full_sim_exam, kde_results$abc_ev$te_results$kde_samples, return_dat)

simulated = as_vector(sim_data[,1])
observed=data 


dist_mean_sd <- function(simulated, observed) {
  # Calculate the means and standard deviations for simulated and observed data
  
  d <- tibble(observed,pred=simulated) 
  nbins <- 4
  dtrain <- d |> filter(expMode2=="Train") |> 
  mutate(Block=cut(tr,breaks=seq(1,max(tr), length.out=nbins+1),include.lowest=TRUE,labels=FALSE))
 
  sum_stat_train <- dtrain |> group_by(Block,x) |> summarise(mean_sim=mean(pred),sd_sim=sd(pred),mean_obs=mean(y),sd_obs=sd(y), mean_dif = mean_obs-mean_sim, sd_dif = sd_obs-sd_sim) 

  sum_stat_test <- d |> filter(expMode2=="Test") |> group_by(x) |> summarise(mean_sim=mean(pred),sd_sim=sd(pred),mean_obs=mean(y),sd_obs=sd(y), mean_dif = mean_obs-mean_sim, sd_dif = sd_obs-sd_sim)

  train_mean_rmse <- sqrt(mean((sum_stat$mean_dif^2)))
  train_sd <- mean(sum_stat_train$sd_obs)

  test_mean_rmse <- sqrt(mean((sum_stat_test$mean_dif^2)))
  test_sd <- mean(sum_stat_test$sd_obs)
  
  return(tibble::lst(train_mean_rmse,test_mean_rmse, train_sd, test_sd))
  
}

```



# Steps to fit individual level models
1) subset empirical data to individual level

```{r}
id1 <- ds |> filter(id==1) 

input_layer =  c(100,350,600,800,1000,1200)
output_layer = input_layer
n_prior_samples=500
prior_samples <- kde_results$abc_ev$teter_results$kde_samples
return_dat="train_data, test_data"
Model="EXAM"; Group="Varied"
data=id1

train_idx <- which(id1$expMode2=="Train")
test_idx <- which(id1$expMode2=="Test")



sim_data_wrapper <- function(args) {
  sim_data_gen_s(args[[1]], args[[2]], args[[3]], simulation_function = args[[4]], args[[5]], return_dat = args[[6]])
}

sim_data_gen_s <- function(data, input_layer, output_layer, simulation_function, prior_samples, return_dat) {
  simulation_function <- match.fun(simulation_function)
  suppressMessages(simulation_results <- map_dfc(seq_len(nrow(prior_samples)), function(idx) {
    params <- prior_samples[idx, ]
    simulation_function(data=as.data.table(data), c=params$c, lr=params$lr, input_layer=input_layer, output_layer=output_layer, return_dat = return_dat)
  }))
}

full_sim_exam <- function(data, c, lr,pred_fun=exam.response, input_layer, output_layer,return_dat="test_data",mode="sim") {
  train_data <- data[expMode2=="Train", c("condit","tr","expMode2", "x","y")] 
  test_data <- data[expMode2=="Test", c("condit","tr","expMode2", "x","y")] 
  trainVec=sort(unique(train_data$x))
  if (train_data$condit[1] != "Varied") {
    trainVec <- c(0, trainVec)
  }
  train_results <- alm.sim(train_data, c, lr, input_layer, output_layer)
  test_prediction <- map_dbl(test_data$x, ~ pred_fun(.x, c, input_layer, 
                                                     output_layer, train_results$wm,  trainVec=trainVec))
  
  train_data$pred <- train_results$d$almResp
  test_data$pred <- test_prediction
  fd = eval(parse(text=paste0("rbind(",return_dat,")")))
  if(mode=="sim"){return(fd$pred)
  }else {return(fd)}
}

args_list <- list(
  Exam_Varied=list(id1, input_layer, output_layer, full_sim_exam, prior_samples, return_dat)
)

sim1 <- full_sim_exam(data=as.data.table(id1), c=.02, lr=2.9, input_layer=input_layer, output_layer=output_layer, return_dat = return_dat)
id1p<- id1 |> mutate(pred=sim1, resid=y-pred)



t1=system.time({
sim_dataAll <- map(args_list, sim_data_wrapper) |> as.data.table()
})
t1





target_data_train_test <- id1[expMode2 %in% c("Test", "Train"), ]$y
target_data_test <- id1[expMode2 == "Test", ]$y
target_data_train <- id1[expMode2 == "Train", ]$y

te_distances <- purrr::map_dbl(sim_dataAll[test_idx, ], dist_rmse, observed = target_data_test)


pct_keep=.1
te_results <- tibble(distance = te_distances, c = prior_samples$c, 
  lr = prior_samples$lr,  sim_index= seq_along(te_distances)) |> 
    arrange(distance) |> 
    filter(if (!is.null(pct_keep)) row_number() <= n() * pct_keep else distance <= tol) |>
    mutate(rank=row_number(),Model,Group,Fit_Method="Test Only") |>
    rowwise() |>
    mutate(sim_dat = list(tibble(Model,Fit_Method,c,lr,distance,rank,data,pred=(sim_dataAll[, .SD, .SDcols = sim_index])) |> 
    mutate(resid=y-pred)))

head(te_results)

id1_test <- sim_dataAll[test_idx, ]
id1_test[,1]


```


kde_results <- purrr::map(group_posterior_all, ~purrr::map_if(.x, is.list, ~compute_kde(.x$c, .x$lr, ngrid = 100, nsamples=1000)))
id1 <- ds |> filter(id==1) 
prior_samples <- kde_results$abc_ev$teter_results$kde_samples

head(te_results)
# Rowwise: 
  distance          c    lr sim_index  rank Model Group  Fit_Method sim_dat            
     <dbl>      <dbl> <dbl>     <int> <int> <chr> <chr>  <chr>      <list>             
1     287. 0.00000696 5.76        393     1 EXAM  Varied Test Only  <tibble [149 × 14]>
2     295. 0.00000696 5.69        215     2 EXAM  Varied Test Only  <tibble [149 × 14]>
3     308. 0.0114     0.488       834     3 EXAM  Varied Test Only  <tibble [149 × 14]>
4     308. 0.00953    0.428       850     4 EXAM  Varied Test Only  <tibble [149 × 14]>
5     310. 0.0105     0.488       735     5 EXAM  Varied Test Only  <tibble [149 × 14]>
6     312. 0.00191    1.82        631     6 EXAM  Varied Test Only  <tibble [149 × 14]>




```{r}

```

Write a function to  Obtain kde for each combo of Model, Fit_Method, and condit. Use MASS::kde2d

group_posterior_all has 6 lists in its first level ("abc_ev"   "abc_almv" "abc_altv" "abc_ec"   "abc_almc" "abc_altc"), 1 for each combo of condit (c=Constant, v=Varied) and Model (e=EXAM, alm=ALM, alt=Alt_Exam). Each of those 6 lists contains 3 further lists for each Fit_Method (teter_results, te_results, tr_results), the fit method lists contain the posterior parameters for c and lr. 

Use purrr functions to map through each of the first and 2nd level list items. 

pacman::p_load(dplyr,purrr,tidyr,ggplot2, data.table, here, patchwork, conflicted)
conflict_prefer_all("dplyr", quiet = TRUE)


# load group level abc posterior - posterior parameters and predicted data for each combo of condit, Fit_Method, and Model
group_posterior_all <- readRDS(here::here("data/abc_2M_rmse_p001.rds"))  

# In Model names, e is short hand for EXAM,alm for ALM, and alt for Alt_EXAM, c is for constant, v is for varied, teter is for test & train, te is for test only, tr is for train only
Model_Names <- list("EXAM", "Alt_EXAM", "ALM")
Fit_Methods <- list("Test & Train", "Test Only","Train Only")
condits <- list("Constant", "Varied")

## Example of getting to group level posterior data for one of the combos: 
names(group_posterior_all)
[1] "abc_ev"   "abc_almv" "abc_altv" "abc_ec"   "abc_almc" "abc_altc"
> names(group_posterior_all$abc_ev)
[1] "teter_results" "te_results"    "tr_results"    "Model"         "Group"         "pct_keep"      "fn_name"      
> group_posterior_all$abc_ev$te_results |> select(c,lr)
# A tibble: 2,000 × 2
# Rowwise: 
        c    lr
    <dbl> <dbl>
 1 0.268   2.43
 2 0.268   2.42